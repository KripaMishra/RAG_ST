{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline\n",
    "\n",
    "# Connect to Milvus\n",
    "connections.connect(\"default\", host=\"localhost\", port=\"19530\")\n",
    "\n",
    "# Define collection schema\n",
    "dim = 768  # Dimension of the embedding vector\n",
    "fields = [\n",
    "    FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=True),\n",
    "    FieldSchema(name=\"content\", dtype=DataType.VARCHAR, max_length=65535),\n",
    "    FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=dim)\n",
    "]\n",
    "schema = CollectionSchema(fields, \"RAG collection\")\n",
    "\n",
    "# Create collection\n",
    "collection_name = \"rag_collection\"\n",
    "collection = Collection(name=collection_name, schema=schema)\n",
    "\n",
    "# Create index (FLAT)\n",
    "index_params = {\n",
    "    \"metric_type\": \"L2\",\n",
    "    \"index_type\": \"FLAT\",\n",
    "    \"params\": {}\n",
    "}\n",
    "collection.create_index(field_name=\"embedding\", index_params=index_params)\n",
    "\n",
    "# Load models\n",
    "encoder = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "\n",
    "def add_documents(documents):\n",
    "    embeddings = encoder.encode(documents)\n",
    "    entities = [\n",
    "        [i for i in range(len(documents))],\n",
    "        documents,\n",
    "        embeddings.tolist()\n",
    "    ]\n",
    "    collection.insert(entities)\n",
    "    collection.flush()\n",
    "\n",
    "def search_similar_documents(query, top_k=5):\n",
    "    query_embedding = encoder.encode([query])[0]\n",
    "    search_params = {\"metric_type\": \"L2\", \"params\": {}}\n",
    "    results = collection.search(\n",
    "        data=[query_embedding.tolist()],\n",
    "        anns_field=\"embedding\",\n",
    "        param=search_params,\n",
    "        limit=top_k,\n",
    "        output_fields=[\"content\"]\n",
    "    )\n",
    "    return [hit.entity.get('content') for hit in results[0]]\n",
    "\n",
    "def generate_answer(query, context):\n",
    "    prompt = f\"Context: {context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\n",
    "    response = generator(prompt, max_length=100, num_return_sequences=1)\n",
    "    return response[0]['generated_text']\n",
    "\n",
    "# Example usage\n",
    "documents = [\n",
    "    \"The capital of France is Paris.\",\n",
    "    \"The Eiffel Tower is located in Paris.\",\n",
    "    \"London is the capital of the United Kingdom.\",\n",
    "    \"The United States has 50 states.\"\n",
    "]\n",
    "\n",
    "# Add documents to the collection\n",
    "add_documents(documents)\n",
    "\n",
    "# Search for similar documents\n",
    "query = \"What is the capital of France?\"\n",
    "similar_docs = search_similar_documents(query)\n",
    "\n",
    "# Generate an answer\n",
    "context = \" \".join(similar_docs)\n",
    "answer = generate_answer(query, context)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Similar documents: {similar_docs}\")\n",
    "print(f\"Generated answer: {answer}\")\n",
    "\n",
    "# Clean up\n",
    "collection.drop()\n",
    "connections.disconnect(\"default\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
