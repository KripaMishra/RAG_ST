[
  {
    "id": 3,
    "content": "documentation on CUDA APIs, programming model and development tools"
  },
  {
    "id": 25,
    "content": "Instead, use the NVIDIA Video Codec SDK ( https: developer nvidia com/nvidia-video-codec-sdk )"
  },
  {
    "id": 41,
    "content": "The guide covers installation and running CUDA applications and containers in this environment"
  },
  {
    "id": 45,
    "content": "GPUDirect RDMA A technology introduced in Kepler-class GPUs and CUDA 5"
  },
  {
    "id": 58,
    "content": "CUDA 12"
  },
  {
    "id": 60,
    "content": "html"
  },
  {
    "id": 62,
    "content": "x releases"
  },
  {
    "id": 63,
    "content": "1"
  },
  {
    "id": 64,
    "content": "1"
  },
  {
    "id": 66,
    "content": "nvidia"
  },
  {
    "id": 67,
    "content": "com/cuda-gpus"
  },
  {
    "id": 69,
    "content": "More information on compatibility can be found at https: docs"
  },
  {
    "id": 70,
    "content": "nvidia"
  },
  {
    "id": 71,
    "content": "com/cuda/cuda-c-best-practices-guide/index"
  },
  {
    "id": 72,
    "content": "html#cuda-compatibility-and-upgrades"
  },
  {
    "id": 73,
    "content": "Note : Starting with CUDA 11"
  },
  {
    "id": 75,
    "content": "CUDA minor version compatibility is described in detail in https: docs"
  },
  {
    "id": 76,
    "content": "nvidia"
  },
  {
    "id": 78,
    "content": "x >=525"
  },
  {
    "id": 79,
    "content": "60"
  },
  {
    "id": 80,
    "content": "13 >=528"
  },
  {
    "id": 81,
    "content": "33 CUDA 11"
  },
  {
    "id": 82,
    "content": "8"
  },
  {
    "id": 83,
    "content": "x CUDA 11"
  },
  {
    "id": 84,
    "content": "7"
  },
  {
    "id": 85,
    "content": "x CUDA 11"
  },
  {
    "id": 86,
    "content": "6"
  },
  {
    "id": 87,
    "content": "x CUDA 11"
  },
  {
    "id": 88,
    "content": "5"
  },
  {
    "id": 89,
    "content": "x CUDA 11"
  },
  {
    "id": 90,
    "content": "4"
  },
  {
    "id": 91,
    "content": "x CUDA 11"
  },
  {
    "id": 92,
    "content": "3"
  },
  {
    "id": 93,
    "content": "x CUDA 11"
  },
  {
    "id": 94,
    "content": "2"
  },
  {
    "id": 95,
    "content": "x CUDA 11"
  },
  {
    "id": 96,
    "content": "1"
  },
  {
    "id": 97,
    "content": "x >=450"
  },
  {
    "id": 98,
    "content": "80"
  },
  {
    "id": 99,
    "content": "02 >=452"
  },
  {
    "id": 100,
    "content": "39 CUDA 11 0 (11"
  },
  {
    "id": 101,
    "content": "0"
  },
  {
    "id": 102,
    "content": "3) >=450"
  },
  {
    "id": 103,
    "content": "36"
  },
  {
    "id": 104,
    "content": "06** >=451"
  },
  {
    "id": 106,
    "content": "** CUDA 11"
  },
  {
    "id": 107,
    "content": "0 was released with an earlier driver version, but by upgrading to Tesla Recommended Drivers 450"
  },
  {
    "id": 108,
    "content": "80"
  },
  {
    "id": 109,
    "content": "02 (Linux) / 452"
  },
  {
    "id": 110,
    "content": "39 (Windows), minor version compatibility is possible across the CUDA 11"
  },
  {
    "id": 111,
    "content": "x family of toolkits"
  },
  {
    "id": 113,
    "content": "com/drivers"
  },
  {
    "id": 115,
    "content": "For more information on customizing the install process on Windows, see https: docs"
  },
  {
    "id": 116,
    "content": "nvidia"
  },
  {
    "id": 117,
    "content": "com/cuda/cuda-installation-guide-microsoft-windows/index"
  },
  {
    "id": 118,
    "content": "html#install-cuda-software"
  },
  {
    "id": 119,
    "content": "For meta packages on Linux, see https: docs"
  },
  {
    "id": 120,
    "content": "nvidia"
  },
  {
    "id": 121,
    "content": "com/cuda/cuda-installation-guide-linux/index"
  },
  {
    "id": 122,
    "content": "html#package-manager-metas"
  },
  {
    "id": 123,
    "content": "1"
  },
  {
    "id": 124,
    "content": "2"
  },
  {
    "id": 125,
    "content": "New Features  This section lists new general CUDA and CUDA compilers features"
  },
  {
    "id": 126,
    "content": "1"
  },
  {
    "id": 127,
    "content": "2"
  },
  {
    "id": 128,
    "content": "1"
  },
  {
    "id": 131,
    "content": "More details can be found here"
  },
  {
    "id": 132,
    "content": "1"
  },
  {
    "id": 133,
    "content": "2"
  },
  {
    "id": 134,
    "content": "2"
  },
  {
    "id": 135,
    "content": "CUDA Compiler  For changes to PTX, refer to https: docs"
  },
  {
    "id": 136,
    "content": "nvidia"
  },
  {
    "id": 137,
    "content": "com/cuda/parallel-thread-execution/#ptx-isa-version-8-5"
  },
  {
    "id": 138,
    "content": "1"
  },
  {
    "id": 139,
    "content": "2"
  },
  {
    "id": 140,
    "content": "3"
  },
  {
    "id": 142,
    "content": "1"
  },
  {
    "id": 143,
    "content": "3"
  },
  {
    "id": 144,
    "content": "Resolved Issues  1"
  },
  {
    "id": 145,
    "content": "3"
  },
  {
    "id": 146,
    "content": "1"
  },
  {
    "id": 147,
    "content": "CUDA Compiler  Resolved an issue found when trying sm89 ptx of FP8 gemm kernel compiled by 12"
  },
  {
    "id": 148,
    "content": "4 when run on an sm90 device"
  },
  {
    "id": 149,
    "content": "Resolved an issue in which nvcc failed to compile any CUDA code when specifying C++20 with CUDA 12"
  },
  {
    "id": 150,
    "content": "5 and Visual Studio 2022 17"
  },
  {
    "id": 151,
    "content": "10"
  },
  {
    "id": 152,
    "content": "0"
  },
  {
    "id": 157,
    "content": "Fix to correct the calculation of write-after-read hazard latency"
  },
  {
    "id": 158,
    "content": "1"
  },
  {
    "id": 159,
    "content": "4"
  },
  {
    "id": 160,
    "content": "Known Issues and Limitations  Runfile will not be supported for Amazon Linux 2023"
  },
  {
    "id": 161,
    "content": "Launching Cooperative Group kernels with MPS is not supported on Tegra platforms"
  },
  {
    "id": 162,
    "content": "1"
  },
  {
    "id": 163,
    "content": "5"
  },
  {
    "id": 165,
    "content": "1"
  },
  {
    "id": 166,
    "content": "5"
  },
  {
    "id": 167,
    "content": "1"
  },
  {
    "id": 169,
    "content": "5"
  },
  {
    "id": 170,
    "content": "1"
  },
  {
    "id": 171,
    "content": "5"
  },
  {
    "id": 172,
    "content": "2"
  },
  {
    "id": 174,
    "content": "5"
  },
  {
    "id": 175,
    "content": "Support for Microsoft Windows 10 21H2 and Microsoft Windows 10 21H2 (SV1) is deprecated"
  },
  {
    "id": 176,
    "content": "1"
  },
  {
    "id": 177,
    "content": "5"
  },
  {
    "id": 178,
    "content": "3"
  },
  {
    "id": 179,
    "content": "Deprecated Toolchains  CUDA Toolkit 12"
  },
  {
    "id": 181,
    "content": "3 1"
  },
  {
    "id": 182,
    "content": "5"
  },
  {
    "id": 183,
    "content": "4"
  },
  {
    "id": 184,
    "content": "It will be dropped in an upcoming release"
  },
  {
    "id": 185,
    "content": "2"
  },
  {
    "id": 186,
    "content": "CUDA Libraries  This section covers CUDA Libraries release notes for 12"
  },
  {
    "id": 187,
    "content": "x releases"
  },
  {
    "id": 189,
    "content": "2"
  },
  {
    "id": 190,
    "content": "1"
  },
  {
    "id": 191,
    "content": "cuBLAS Library  2"
  },
  {
    "id": 192,
    "content": "1"
  },
  {
    "id": 193,
    "content": "1"
  },
  {
    "id": 194,
    "content": "cuBLAS: Release 12"
  },
  {
    "id": 197,
    "content": "out-of-place (C"
  },
  {
    "id": 198,
    "content": "= D)"
  },
  {
    "id": 199,
    "content": "2"
  },
  {
    "id": 200,
    "content": "1"
  },
  {
    "id": 201,
    "content": "2"
  },
  {
    "id": 206,
    "content": "2"
  },
  {
    "id": 207,
    "content": "1"
  },
  {
    "id": 208,
    "content": "3"
  },
  {
    "id": 209,
    "content": "cuBLAS: Release 12"
  },
  {
    "id": 215,
    "content": "The issue was introduced in cuBLAS 11"
  },
  {
    "id": 216,
    "content": "8"
  },
  {
    "id": 217,
    "content": "2"
  },
  {
    "id": 218,
    "content": "1"
  },
  {
    "id": 219,
    "content": "4"
  },
  {
    "id": 220,
    "content": "cuBLAS: Release 12"
  },
  {
    "id": 224,
    "content": "The user may provide the corrected SM count to cuBLAS using an API such as cublasSetSmCountTarget()"
  },
  {
    "id": 228,
    "content": "To avoid this issue, use the cublasSetWorkspace() function to provide user-owned workspace memory"
  },
  {
    "id": 229,
    "content": "2"
  },
  {
    "id": 230,
    "content": "1"
  },
  {
    "id": 231,
    "content": "5"
  },
  {
    "id": 232,
    "content": "cuBLAS: Release 12"
  },
  {
    "id": 240,
    "content": "Fixed creation of cuBLAS or cuBLASLt handles on Hopper GPUs under the Multi-Process Service (MPS)"
  },
  {
    "id": 242,
    "content": "2"
  },
  {
    "id": 243,
    "content": "1"
  },
  {
    "id": 244,
    "content": "6"
  },
  {
    "id": 245,
    "content": "cuBLAS: Release 12"
  },
  {
    "id": 246,
    "content": "3  New Features Improved performance on NVIDIA L40S Ada GPUs"
  },
  {
    "id": 250,
    "content": "2"
  },
  {
    "id": 251,
    "content": "1"
  },
  {
    "id": 252,
    "content": "7"
  },
  {
    "id": 253,
    "content": "cuBLAS: Release 12"
  },
  {
    "id": 256,
    "content": "2"
  },
  {
    "id": 257,
    "content": "1"
  },
  {
    "id": 258,
    "content": "8"
  },
  {
    "id": 259,
    "content": "cuBLAS: Release 12"
  },
  {
    "id": 262,
    "content": "The kernels apply the first batch’s bias vector to all batches"
  },
  {
    "id": 263,
    "content": "2"
  },
  {
    "id": 264,
    "content": "1"
  },
  {
    "id": 265,
    "content": "9"
  },
  {
    "id": 266,
    "content": "cuBLAS: Release 12"
  },
  {
    "id": 267,
    "content": "1 Update 1  New Features Support for FP8 on NVIDIA Ada GPUs"
  },
  {
    "id": 272,
    "content": "2"
  },
  {
    "id": 273,
    "content": "1"
  },
  {
    "id": 274,
    "content": "10"
  },
  {
    "id": 275,
    "content": "cuBLAS: Release 12"
  },
  {
    "id": 276,
    "content": "0 Update 1  New Features Improved performance on NVIDIA H100 SXM and NVIDIA H100 PCIe GPUs"
  },
  {
    "id": 279,
    "content": "Added forward compatible single precision complex GEMM that does not require workspace"
  },
  {
    "id": 280,
    "content": "2"
  },
  {
    "id": 281,
    "content": "1"
  },
  {
    "id": 282,
    "content": "11"
  },
  {
    "id": 283,
    "content": "cuBLAS: Release 12"
  },
  {
    "id": 284,
    "content": "0  New Features cublasLtMatmul now supports FP8 with a non-zero beta"
  },
  {
    "id": 288,
    "content": "CUBLASLT_EPILOGUE_BIAS epilogues"
  },
  {
    "id": 289,
    "content": "Removed: CUBLAS_MATMUL_STAGES_16x80 and CUBLAS_MATMUL_STAGES_64x80 from cublasLtMatmulStages_t"
  },
  {
    "id": 291,
    "content": "2"
  },
  {
    "id": 292,
    "content": "2"
  },
  {
    "id": 293,
    "content": "cuFFT Library  2"
  },
  {
    "id": 294,
    "content": "2"
  },
  {
    "id": 295,
    "content": "1"
  },
  {
    "id": 296,
    "content": "cuFFT: Release 12"
  },
  {
    "id": 298,
    "content": "2"
  },
  {
    "id": 299,
    "content": "2"
  },
  {
    "id": 300,
    "content": "2"
  },
  {
    "id": 302,
    "content": "4"
  },
  {
    "id": 303,
    "content": "This routine has now been removed from the header"
  },
  {
    "id": 304,
    "content": "2"
  },
  {
    "id": 305,
    "content": "2"
  },
  {
    "id": 306,
    "content": "3"
  },
  {
    "id": 307,
    "content": "cuFFT: Release 12"
  },
  {
    "id": 309,
    "content": "These new routines can be leveraged to give users more control over the behavior of cuFFT"
  },
  {
    "id": 312,
    "content": "h )"
  },
  {
    "id": 313,
    "content": "This routine is not supported by cuFFT, and will be removed from the header in a future release"
  },
  {
    "id": 315,
    "content": "e"
  },
  {
    "id": 317,
    "content": "2"
  },
  {
    "id": 318,
    "content": "2"
  },
  {
    "id": 319,
    "content": "4"
  },
  {
    "id": 320,
    "content": "cuFFT: Release 12"
  },
  {
    "id": 322,
    "content": "2"
  },
  {
    "id": 323,
    "content": "2"
  },
  {
    "id": 324,
    "content": "5"
  },
  {
    "id": 325,
    "content": "cuFFT: Release 12"
  },
  {
    "id": 328,
    "content": "2"
  },
  {
    "id": 329,
    "content": "2"
  },
  {
    "id": 330,
    "content": "6"
  },
  {
    "id": 331,
    "content": "cuFFT: Release 12"
  },
  {
    "id": 335,
    "content": "2"
  },
  {
    "id": 336,
    "content": "2"
  },
  {
    "id": 337,
    "content": "7"
  },
  {
    "id": 338,
    "content": "cuFFT: Release 12"
  },
  {
    "id": 340,
    "content": "2"
  },
  {
    "id": 341,
    "content": "2"
  },
  {
    "id": 342,
    "content": "8"
  },
  {
    "id": 343,
    "content": "cuFFT: Release 12"
  },
  {
    "id": 345,
    "content": "Known Issues Starting from CUDA 11"
  },
  {
    "id": 348,
    "content": "4"
  },
  {
    "id": 350,
    "content": "2"
  },
  {
    "id": 351,
    "content": "2"
  },
  {
    "id": 352,
    "content": "9"
  },
  {
    "id": 353,
    "content": "cuFFT: Release 12"
  },
  {
    "id": 355,
    "content": "2"
  },
  {
    "id": 356,
    "content": "2"
  },
  {
    "id": 357,
    "content": "10"
  },
  {
    "id": 358,
    "content": "cuFFT: Release 12"
  },
  {
    "id": 360,
    "content": "Resolved Issues cuFFT plans had an unintentional small memory overhead (of a few kB) per plan"
  },
  {
    "id": 361,
    "content": "cuSOLVER: Release 12"
  },
  {
    "id": 363,
    "content": "2"
  },
  {
    "id": 364,
    "content": "3"
  },
  {
    "id": 365,
    "content": "2"
  },
  {
    "id": 366,
    "content": "cuSOLVER: Release 12"
  },
  {
    "id": 367,
    "content": "5  New Features Performance improvements of cusolverDnXgesvd and cusolverDngesvd if jobu"
  },
  {
    "id": 368,
    "content": "= 'N' or jobvt"
  },
  {
    "id": 369,
    "content": "= 'N'"
  },
  {
    "id": 370,
    "content": "Known Issues With CUDA Toolkit 12"
  },
  {
    "id": 374,
    "content": "3"
  },
  {
    "id": 375,
    "content": "3"
  },
  {
    "id": 376,
    "content": "cuSOLVER: Release 12"
  },
  {
    "id": 378,
    "content": "The job configuration that computes both left and right singular vectors is up to 1"
  },
  {
    "id": 379,
    "content": "5x faster"
  },
  {
    "id": 380,
    "content": "Resolved Issues cusolverDnXtrtri_bufferSize now returns the correct workspace size in bytes"
  },
  {
    "id": 383,
    "content": "2"
  },
  {
    "id": 384,
    "content": "3"
  },
  {
    "id": 385,
    "content": "4"
  },
  {
    "id": 386,
    "content": "cuSOLVER: Release 12"
  },
  {
    "id": 389,
    "content": "2"
  },
  {
    "id": 390,
    "content": "3"
  },
  {
    "id": 391,
    "content": "5"
  },
  {
    "id": 392,
    "content": "cuSOLVER: Release 12"
  },
  {
    "id": 394,
    "content": "2"
  },
  {
    "id": 395,
    "content": "3"
  },
  {
    "id": 396,
    "content": "6"
  },
  {
    "id": 397,
    "content": "cuSOLVER: Release 12"
  },
  {
    "id": 401,
    "content": "2"
  },
  {
    "id": 402,
    "content": "4"
  },
  {
    "id": 403,
    "content": "cuSPARSE Library  2"
  },
  {
    "id": 404,
    "content": "4"
  },
  {
    "id": 405,
    "content": "1"
  },
  {
    "id": 406,
    "content": "cuSPARSE: Release 12"
  },
  {
    "id": 407,
    "content": "5 Update 1  New Features Added support for BSR format in cusparseSpMM"
  },
  {
    "id": 410,
    "content": "2"
  },
  {
    "id": 411,
    "content": "4"
  },
  {
    "id": 412,
    "content": "2"
  },
  {
    "id": 413,
    "content": "cuSPARSE: Release 12"
  },
  {
    "id": 416,
    "content": "2"
  },
  {
    "id": 417,
    "content": "4"
  },
  {
    "id": 418,
    "content": "3"
  },
  {
    "id": 419,
    "content": "cuSPARSE: Release 12"
  },
  {
    "id": 422,
    "content": "2"
  },
  {
    "id": 423,
    "content": "4"
  },
  {
    "id": 424,
    "content": "4"
  },
  {
    "id": 425,
    "content": "cuSPARSE: Release 12"
  },
  {
    "id": 427,
    "content": "2"
  },
  {
    "id": 428,
    "content": "4"
  },
  {
    "id": 429,
    "content": "5"
  },
  {
    "id": 430,
    "content": "cuSPARSE: Release 12"
  },
  {
    "id": 434,
    "content": "2"
  },
  {
    "id": 435,
    "content": "4"
  },
  {
    "id": 436,
    "content": "6"
  },
  {
    "id": 437,
    "content": "cuSPARSE: Release 12"
  },
  {
    "id": 440,
    "content": "cusparseSpMV() now checks the validity of the buffer pointer only when it is strictly needed"
  },
  {
    "id": 441,
    "content": "A compile-time warning has been added to all of them"
  },
  {
    "id": 442,
    "content": "2"
  },
  {
    "id": 443,
    "content": "4"
  },
  {
    "id": 444,
    "content": "7"
  },
  {
    "id": 445,
    "content": "cuSPARSE: Release 12"
  },
  {
    "id": 448,
    "content": "2"
  },
  {
    "id": 449,
    "content": "4"
  },
  {
    "id": 450,
    "content": "8"
  },
  {
    "id": 451,
    "content": "cuSPARSE: Release 12"
  },
  {
    "id": 454,
    "content": "2"
  },
  {
    "id": 455,
    "content": "4"
  },
  {
    "id": 456,
    "content": "9"
  },
  {
    "id": 457,
    "content": "cuSPARSE: Release 12"
  },
  {
    "id": 459,
    "content": "Starting from CUDA 12"
  },
  {
    "id": 460,
    "content": "0 the user needs to link to libnvJitLto"
  },
  {
    "id": 461,
    "content": "so , see cuSPARSE documentation"
  },
  {
    "id": 464,
    "content": "Deprecations Removed deprecated CUDA 11"
  },
  {
    "id": 465,
    "content": "x APIs, enumerators, and descriptors"
  },
  {
    "id": 466,
    "content": "2"
  },
  {
    "id": 467,
    "content": "5"
  },
  {
    "id": 468,
    "content": "Math Library  2"
  },
  {
    "id": 469,
    "content": "5"
  },
  {
    "id": 470,
    "content": "1"
  },
  {
    "id": 471,
    "content": "CUDA Math: Release 12"
  },
  {
    "id": 473,
    "content": "This finding is applicable to CUDA 12"
  },
  {
    "id": 474,
    "content": "5 and all previous versions"
  },
  {
    "id": 475,
    "content": "2"
  },
  {
    "id": 476,
    "content": "5"
  },
  {
    "id": 477,
    "content": "2"
  },
  {
    "id": 478,
    "content": "CUDA Math: Release 12"
  },
  {
    "id": 480,
    "content": "2"
  },
  {
    "id": 481,
    "content": "5"
  },
  {
    "id": 482,
    "content": "3"
  },
  {
    "id": 484,
    "content": "h and cuda_bf16"
  },
  {
    "id": 486,
    "content": "3"
  },
  {
    "id": 487,
    "content": "Known Issues Users of cuda_fp16"
  },
  {
    "id": 488,
    "content": "h and cuda_bf16"
  },
  {
    "id": 489,
    "content": "h headers are advised to disable host compilers strict aliasing rules based optimizations (e"
  },
  {
    "id": 490,
    "content": "g"
  },
  {
    "id": 492,
    "content": "This behavior may improve in future versions of the headers"
  },
  {
    "id": 493,
    "content": "2"
  },
  {
    "id": 494,
    "content": "5"
  },
  {
    "id": 495,
    "content": "4"
  },
  {
    "id": 498,
    "content": "round-to-nearest-even mode could produce spurious overflow to infinity"
  },
  {
    "id": 499,
    "content": "NVIDIA recommends that all developers requiring strict IEEE754 compliance update to CUDA Toolkit 12"
  },
  {
    "id": 500,
    "content": "2 or newer"
  },
  {
    "id": 503,
    "content": "2"
  },
  {
    "id": 504,
    "content": "5"
  },
  {
    "id": 505,
    "content": "5"
  },
  {
    "id": 506,
    "content": "CUDA Math: Release 12"
  },
  {
    "id": 508,
    "content": "2"
  },
  {
    "id": 509,
    "content": "5"
  },
  {
    "id": 510,
    "content": "6"
  },
  {
    "id": 513,
    "content": "Deprecations All previously deprecated undocumented APIs are removed from CUDA 12"
  },
  {
    "id": 514,
    "content": "0"
  },
  {
    "id": 515,
    "content": "2"
  },
  {
    "id": 516,
    "content": "6"
  },
  {
    "id": 517,
    "content": "NVIDIA Performance Primitives (NPP)  2"
  },
  {
    "id": 518,
    "content": "6"
  },
  {
    "id": 519,
    "content": "1"
  },
  {
    "id": 520,
    "content": "NPP: Release 12"
  },
  {
    "id": 521,
    "content": "4  New Features Enhanced large file support with size_t"
  },
  {
    "id": 522,
    "content": "2"
  },
  {
    "id": 523,
    "content": "6"
  },
  {
    "id": 524,
    "content": "2"
  },
  {
    "id": 525,
    "content": "NPP: Release 12"
  },
  {
    "id": 526,
    "content": "0  Deprecations Deprecating non-CTX API support from next release"
  },
  {
    "id": 528,
    "content": "2"
  },
  {
    "id": 529,
    "content": "7"
  },
  {
    "id": 530,
    "content": "nvJPEG Library  2"
  },
  {
    "id": 531,
    "content": "7"
  },
  {
    "id": 532,
    "content": "1"
  },
  {
    "id": 533,
    "content": "nvJPEG: Release 12"
  },
  {
    "id": 534,
    "content": "4  New Features IDCT performance optimizations for single image CUDA decode"
  },
  {
    "id": 536,
    "content": "2"
  },
  {
    "id": 537,
    "content": "7"
  },
  {
    "id": 538,
    "content": "2"
  },
  {
    "id": 539,
    "content": "nvJPEG: Release 12"
  },
  {
    "id": 541,
    "content": "2"
  },
  {
    "id": 542,
    "content": "7"
  },
  {
    "id": 543,
    "content": "3"
  },
  {
    "id": 544,
    "content": "nvJPEG: Release 12"
  },
  {
    "id": 545,
    "content": "2  New Features Added support for JPEG Lossless decode (process 14, FO prediction)"
  },
  {
    "id": 546,
    "content": "nvJPEG is now supported on L4T"
  },
  {
    "id": 547,
    "content": "2"
  },
  {
    "id": 548,
    "content": "7"
  },
  {
    "id": 549,
    "content": "4"
  },
  {
    "id": 550,
    "content": "nvJPEG: Release 12 0  New Features Immproved the GPU Memory optimisation for the nvJPEG codec"
  },
  {
    "id": 553,
    "content": "Deprecations The reuse of Huffman table in Encoder ( nvjpegEncoderParamsCopyHuffmanTables )"
  },
  {
    "id": 556,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 568,
    "content": "3"
  },
  {
    "id": 569,
    "content": "2"
  },
  {
    "id": 570,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 571,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 572,
    "content": "3"
  },
  {
    "id": 573,
    "content": "3"
  },
  {
    "id": 575,
    "content": "S"
  },
  {
    "id": 578,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 579,
    "content": "Navigation"
  },
  {
    "id": 580,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 581,
    "content": "pageBottom();}\n1"
  },
  {
    "id": 582,
    "content": "CUDA 11"
  },
  {
    "id": 583,
    "content": "6 Features v12 5 | PDF | Archive NVIDIA CUDA Features Archive The list of CUDA features by release"
  },
  {
    "id": 585,
    "content": "1"
  },
  {
    "id": 586,
    "content": "1"
  },
  {
    "id": 587,
    "content": "2"
  },
  {
    "id": 589,
    "content": "1"
  },
  {
    "id": 590,
    "content": "1"
  },
  {
    "id": 591,
    "content": "3"
  },
  {
    "id": 595,
    "content": "5 update 1"
  },
  {
    "id": 598,
    "content": "1"
  },
  {
    "id": 599,
    "content": "1"
  },
  {
    "id": 600,
    "content": "5"
  },
  {
    "id": 603,
    "content": "LTO (introduced in CUDA 11"
  },
  {
    "id": 606,
    "content": "1"
  },
  {
    "id": 607,
    "content": "1"
  },
  {
    "id": 608,
    "content": "6"
  },
  {
    "id": 610,
    "content": "1"
  },
  {
    "id": 611,
    "content": "1"
  },
  {
    "id": 612,
    "content": "7"
  },
  {
    "id": 613,
    "content": "INT128 developer tool support  In 11"
  },
  {
    "id": 614,
    "content": "5, CUDA C++ support for 128 bit was added"
  },
  {
    "id": 615,
    "content": "With the latest version of libcu++, int 128 data datype is supported by math functions"
  },
  {
    "id": 616,
    "content": "2"
  },
  {
    "id": 617,
    "content": "Notices  2"
  },
  {
    "id": 618,
    "content": "1"
  },
  {
    "id": 621,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 633,
    "content": "2"
  },
  {
    "id": 634,
    "content": "2"
  },
  {
    "id": 635,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 636,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 637,
    "content": "2"
  },
  {
    "id": 638,
    "content": "3"
  },
  {
    "id": 640,
    "content": "S"
  },
  {
    "id": 643,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 644,
    "content": "Navigation"
  },
  {
    "id": 645,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 646,
    "content": "pageBottom();}\n1"
  },
  {
    "id": 647,
    "content": "CUDA Toolkit Supplement to Software License Agreement for NVIDIA Software Development Kits 2"
  },
  {
    "id": 648,
    "content": "1"
  },
  {
    "id": 655,
    "content": "# 1"
  },
  {
    "id": 660,
    "content": "1"
  },
  {
    "id": 661,
    "content": "1"
  },
  {
    "id": 662,
    "content": "License  1"
  },
  {
    "id": 663,
    "content": "1"
  },
  {
    "id": 664,
    "content": "1"
  },
  {
    "id": 667,
    "content": "1"
  },
  {
    "id": 668,
    "content": "1"
  },
  {
    "id": 669,
    "content": "2"
  },
  {
    "id": 675,
    "content": "1"
  },
  {
    "id": 676,
    "content": "1"
  },
  {
    "id": 677,
    "content": "3"
  },
  {
    "id": 680,
    "content": "1"
  },
  {
    "id": 681,
    "content": "1"
  },
  {
    "id": 682,
    "content": "4"
  },
  {
    "id": 685,
    "content": "1"
  },
  {
    "id": 686,
    "content": "1"
  },
  {
    "id": 687,
    "content": "5"
  },
  {
    "id": 690,
    "content": "1"
  },
  {
    "id": 691,
    "content": "1"
  },
  {
    "id": 692,
    "content": "6"
  },
  {
    "id": 695,
    "content": "1"
  },
  {
    "id": 696,
    "content": "1"
  },
  {
    "id": 697,
    "content": "7"
  },
  {
    "id": 699,
    "content": "1"
  },
  {
    "id": 700,
    "content": "2"
  },
  {
    "id": 708,
    "content": "1"
  },
  {
    "id": 709,
    "content": "3"
  },
  {
    "id": 711,
    "content": "3"
  },
  {
    "id": 712,
    "content": "2"
  },
  {
    "id": 714,
    "content": "property rights, subject to NVIDIA’s rights under Section 1"
  },
  {
    "id": 715,
    "content": "3"
  },
  {
    "id": 716,
    "content": "1"
  },
  {
    "id": 719,
    "content": "com"
  },
  {
    "id": 720,
    "content": "1"
  },
  {
    "id": 721,
    "content": "4"
  },
  {
    "id": 723,
    "content": "THEREIN, WHETHER LATENT OR PATENT"
  },
  {
    "id": 724,
    "content": "NO WARRANTY IS MADE ON THE BASIS OF TRADE USAGE, COURSE OF DEALING OR COURSE OF TRADE"
  },
  {
    "id": 725,
    "content": "1"
  },
  {
    "id": 726,
    "content": "5"
  },
  {
    "id": 729,
    "content": "00"
  },
  {
    "id": 732,
    "content": "1"
  },
  {
    "id": 733,
    "content": "6"
  },
  {
    "id": 737,
    "content": "1"
  },
  {
    "id": 738,
    "content": "7"
  },
  {
    "id": 740,
    "content": "Any attempted assignment not approved by NVIDIA in writing shall be void and of no effect"
  },
  {
    "id": 748,
    "content": "Government subcontractor is subject to the restrictions in this Agreement pursuant to DFARS 227"
  },
  {
    "id": 750,
    "content": "227-19, as applicable"
  },
  {
    "id": 752,
    "content": "S"
  },
  {
    "id": 755,
    "content": "S"
  },
  {
    "id": 756,
    "content": "Any notice delivered by NVIDIA to you under this Agreement will be delivered via mail, email or fax"
  },
  {
    "id": 759,
    "content": "Any additional and/or conflicting terms on documents issued by you are null, void, and invalid"
  },
  {
    "id": 761,
    "content": "2"
  },
  {
    "id": 764,
    "content": "2"
  },
  {
    "id": 765,
    "content": "1"
  },
  {
    "id": 767,
    "content": "2"
  },
  {
    "id": 768,
    "content": "2"
  },
  {
    "id": 770,
    "content": "2"
  },
  {
    "id": 771,
    "content": "3"
  },
  {
    "id": 773,
    "content": "2"
  },
  {
    "id": 774,
    "content": "4"
  },
  {
    "id": 776,
    "content": "limited to, Microsoft, Thomson, Fraunhofer IIS, Sisvel S"
  },
  {
    "id": 777,
    "content": "p"
  },
  {
    "id": 778,
    "content": "A"
  },
  {
    "id": 779,
    "content": ", MPEG-LA, and Coding Technologies"
  },
  {
    "id": 781,
    "content": "2"
  },
  {
    "id": 782,
    "content": "5"
  },
  {
    "id": 784,
    "content": "com"
  },
  {
    "id": 785,
    "content": "2"
  },
  {
    "id": 786,
    "content": "6"
  },
  {
    "id": 788,
    "content": "0 of the 64-bit Windows software, the file cudart64_90"
  },
  {
    "id": 789,
    "content": "dll is redistributable"
  },
  {
    "id": 790,
    "content": "GPL v3 terms and conditions are hereby incorporated into the Agreement by this reference: http: www"
  },
  {
    "id": 791,
    "content": "gnu"
  },
  {
    "id": 795,
    "content": "0"
  },
  {
    "id": 796,
    "content": "Apache License Version 2"
  },
  {
    "id": 797,
    "content": "0 terms and conditions are hereby incorporated into the Agreement by this reference"
  },
  {
    "id": 798,
    "content": "http: www"
  },
  {
    "id": 799,
    "content": "apache"
  },
  {
    "id": 800,
    "content": "org/licenses/LICENSE-2"
  },
  {
    "id": 801,
    "content": "0"
  },
  {
    "id": 804,
    "content": "CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE"
  },
  {
    "id": 811,
    "content": "matching"
  },
  {
    "id": 812,
    "content": "THE BASIC LIBRARY FUNCTIONS - Written by: Philip Hazel Email local part: ph10 Email domain: cam"
  },
  {
    "id": 813,
    "content": "ac"
  },
  {
    "id": 814,
    "content": "uk University of Cambridge Computing Service, Cambridge, England"
  },
  {
    "id": 817,
    "content": "following disclaimer in the documentation and/or other materials provided with the distribution"
  },
  {
    "id": 831,
    "content": "cuBLAS library routines were written by or derived from code written by Ahmad M"
  },
  {
    "id": 832,
    "content": "Abdelfattah, David Keyes, and Hatem Ltaief, and are subject to the Apache License, Version 2"
  },
  {
    "id": 834,
    "content": "edu"
  },
  {
    "id": 835,
    "content": "sa) David Keyes (david keyes@kaust"
  },
  {
    "id": 836,
    "content": "edu"
  },
  {
    "id": 837,
    "content": "sa) Hatem Ltaief (hatem ltaief@kaust"
  },
  {
    "id": 838,
    "content": "edu"
  },
  {
    "id": 844,
    "content": "Developed by: IMPACT Group, University of Illinois, http: impact"
  },
  {
    "id": 845,
    "content": "crhc"
  },
  {
    "id": 846,
    "content": "illinois"
  },
  {
    "id": 852,
    "content": "in the documentation and/or other materials provided with the distribution"
  },
  {
    "id": 856,
    "content": "the documentation and/or other materials provided with the distribution"
  },
  {
    "id": 860,
    "content": "BSD 2-Clause License (http: www"
  },
  {
    "id": 861,
    "content": "opensource"
  },
  {
    "id": 862,
    "content": "org/licenses/bsd-license"
  },
  {
    "id": 865,
    "content": "0 - August 17th, 2003"
  },
  {
    "id": 867,
    "content": "0 (\"EPL\")"
  },
  {
    "id": 869,
    "content": "www eclipse"
  },
  {
    "id": 870,
    "content": "org"
  },
  {
    "id": 872,
    "content": "com), 2016 Google Inc"
  },
  {
    "id": 875,
    "content": "DEALINGS IN THE SOFTWARE"
  },
  {
    "id": 877,
    "content": "0"
  },
  {
    "id": 881,
    "content": "Introduction v12"
  },
  {
    "id": 884,
    "content": "2"
  },
  {
    "id": 886,
    "content": "2"
  },
  {
    "id": 887,
    "content": "1"
  },
  {
    "id": 891,
    "content": "sln"
  },
  {
    "id": 893,
    "content": "2"
  },
  {
    "id": 894,
    "content": "2"
  },
  {
    "id": 896,
    "content": "2"
  },
  {
    "id": 897,
    "content": "3"
  },
  {
    "id": 905,
    "content": "nvidia-nvjpeg-cu125 2"
  },
  {
    "id": 906,
    "content": "4"
  },
  {
    "id": 908,
    "content": "3"
  },
  {
    "id": 909,
    "content": "1"
  },
  {
    "id": 911,
    "content": "3"
  },
  {
    "id": 912,
    "content": "1"
  },
  {
    "id": 913,
    "content": "1"
  },
  {
    "id": 915,
    "content": "In the case of the RPM installers, the instructions for the Local and Network variants are the same"
  },
  {
    "id": 916,
    "content": "For more details, refer to the Linux Installation Guide"
  },
  {
    "id": 917,
    "content": "3"
  },
  {
    "id": 918,
    "content": "1"
  },
  {
    "id": 919,
    "content": "1"
  },
  {
    "id": 920,
    "content": "1"
  },
  {
    "id": 921,
    "content": "RPM Installer  Perform the following steps to install CUDA and verify the installation"
  },
  {
    "id": 922,
    "content": "Install EPEL to satisfy the DKMS dependency by following the instructions at EPEL’s website"
  },
  {
    "id": 926,
    "content": "run --silent Create an xorg"
  },
  {
    "id": 929,
    "content": "3"
  },
  {
    "id": 930,
    "content": "1"
  },
  {
    "id": 931,
    "content": "2"
  },
  {
    "id": 933,
    "content": "3"
  },
  {
    "id": 934,
    "content": "1"
  },
  {
    "id": 935,
    "content": "2"
  },
  {
    "id": 936,
    "content": "2"
  },
  {
    "id": 940,
    "content": "run --silent Create an xorg"
  },
  {
    "id": 943,
    "content": "com/NVIDIA/cuda-samples/tree/master/Samples/nbody"
  },
  {
    "id": 944,
    "content": "3"
  },
  {
    "id": 945,
    "content": "1"
  },
  {
    "id": 946,
    "content": "3"
  },
  {
    "id": 948,
    "content": "3"
  },
  {
    "id": 949,
    "content": "1"
  },
  {
    "id": 950,
    "content": "3"
  },
  {
    "id": 951,
    "content": "2"
  },
  {
    "id": 953,
    "content": "3"
  },
  {
    "id": 954,
    "content": "1"
  },
  {
    "id": 955,
    "content": "4"
  },
  {
    "id": 956,
    "content": "1"
  },
  {
    "id": 959,
    "content": "3"
  },
  {
    "id": 960,
    "content": "1"
  },
  {
    "id": 961,
    "content": "4"
  },
  {
    "id": 962,
    "content": "2"
  },
  {
    "id": 965,
    "content": "3"
  },
  {
    "id": 966,
    "content": "1"
  },
  {
    "id": 967,
    "content": "5"
  },
  {
    "id": 968,
    "content": "2"
  },
  {
    "id": 970,
    "content": "x86_64"
  },
  {
    "id": 971,
    "content": "rpm 3"
  },
  {
    "id": 972,
    "content": "1"
  },
  {
    "id": 973,
    "content": "5"
  },
  {
    "id": 974,
    "content": "3"
  },
  {
    "id": 976,
    "content": "download"
  },
  {
    "id": 977,
    "content": "nvidia"
  },
  {
    "id": 978,
    "content": "com/compute/cuda/repos/amzn2023/x86_64/cuda-amzn2023"
  },
  {
    "id": 979,
    "content": "repo sudo dnf clean expire-cache 3"
  },
  {
    "id": 980,
    "content": "1"
  },
  {
    "id": 981,
    "content": "5"
  },
  {
    "id": 982,
    "content": "4"
  },
  {
    "id": 985,
    "content": "so symbolic link, if necessary: The libcuda"
  },
  {
    "id": 986,
    "content": "so library is installed in the /usr/lib{,64}/nvidia directory"
  },
  {
    "id": 988,
    "content": "so in the /usr/lib{,64} directory"
  },
  {
    "id": 989,
    "content": "Reboot the system: sudo reboot Perform the post-installation actions"
  },
  {
    "id": 990,
    "content": "3"
  },
  {
    "id": 991,
    "content": "1"
  },
  {
    "id": 992,
    "content": "6"
  },
  {
    "id": 994,
    "content": "alternative to installing the nvidia-pyindex package: --extra-index-url https: pypi"
  },
  {
    "id": 995,
    "content": "ngc"
  },
  {
    "id": 996,
    "content": "nvidia"
  },
  {
    "id": 1000,
    "content": "1"
  },
  {
    "id": 1001,
    "content": "7"
  },
  {
    "id": 1003,
    "content": "1"
  },
  {
    "id": 1004,
    "content": "8"
  },
  {
    "id": 1006,
    "content": "download"
  },
  {
    "id": 1007,
    "content": "nvidia"
  },
  {
    "id": 1008,
    "content": "com/compute/cuda/repos /cuda-keyring_1"
  },
  {
    "id": 1009,
    "content": "1-1_all"
  },
  {
    "id": 1010,
    "content": "deb sudo dpkg -i cuda-keyring_1"
  },
  {
    "id": 1011,
    "content": "1-1_all"
  },
  {
    "id": 1012,
    "content": "deb Pin file to prioritize CUDA repository: wget https: developer"
  },
  {
    "id": 1013,
    "content": "download"
  },
  {
    "id": 1014,
    "content": "nvidia"
  },
  {
    "id": 1015,
    "content": "com/compute/cuda/repos /cuda-"
  },
  {
    "id": 1017,
    "content": "1"
  },
  {
    "id": 1018,
    "content": "9"
  },
  {
    "id": 1020,
    "content": "3"
  },
  {
    "id": 1021,
    "content": "1"
  },
  {
    "id": 1022,
    "content": "9"
  },
  {
    "id": 1023,
    "content": "1"
  },
  {
    "id": 1024,
    "content": "Debian Installer  Perform the following steps to install CUDA and verify the installation"
  },
  {
    "id": 1025,
    "content": "3"
  },
  {
    "id": 1026,
    "content": "1"
  },
  {
    "id": 1030,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 1042,
    "content": "4"
  },
  {
    "id": 1043,
    "content": "2"
  },
  {
    "id": 1044,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 1045,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 1046,
    "content": "4"
  },
  {
    "id": 1047,
    "content": "3"
  },
  {
    "id": 1049,
    "content": "S"
  },
  {
    "id": 1052,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 1053,
    "content": "Navigation"
  },
  {
    "id": 1054,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 1055,
    "content": "pageBottom();}\n1"
  },
  {
    "id": 1056,
    "content": "Introduction v12"
  },
  {
    "id": 1058,
    "content": "Introduction  CUDA ® is a parallel computing platform and programming model invented by NVIDIA"
  },
  {
    "id": 1061,
    "content": "Serial portions of applications are run on the CPU, and parallel portions are offloaded to the GPU"
  },
  {
    "id": 1063,
    "content": "CUDA-capable GPUs have hundreds of cores that can collectively run thousands of computing threads"
  },
  {
    "id": 1065,
    "content": "32-bit compilation native and cross-compilation is removed from CUDA 12"
  },
  {
    "id": 1066,
    "content": "0 and later Toolkit"
  },
  {
    "id": 1068,
    "content": "h) 1"
  },
  {
    "id": 1069,
    "content": "2"
  },
  {
    "id": 1071,
    "content": "You do not need previous experience with CUDA or experience with parallel computation"
  },
  {
    "id": 1072,
    "content": "2"
  },
  {
    "id": 1074,
    "content": "Test that the installed software runs correctly and communicates with the hardware"
  },
  {
    "id": 1075,
    "content": "2"
  },
  {
    "id": 1076,
    "content": "1"
  },
  {
    "id": 1079,
    "content": "DeviceManager 2"
  },
  {
    "id": 1080,
    "content": "2"
  },
  {
    "id": 1081,
    "content": "Download the NVIDIA CUDA Toolkit  The NVIDIA CUDA Toolkit is available at https: developer nvidia"
  },
  {
    "id": 1083,
    "content": "deployment"
  },
  {
    "id": 1086,
    "content": "nvidia"
  },
  {
    "id": 1087,
    "content": "com/compute/cuda/12"
  },
  {
    "id": 1088,
    "content": "5"
  },
  {
    "id": 1089,
    "content": "1/docs/sidebar/md5sum"
  },
  {
    "id": 1091,
    "content": "2"
  },
  {
    "id": 1092,
    "content": "3"
  },
  {
    "id": 1094,
    "content": "installer can be executed in silent mode by executing the package with the -s flag"
  },
  {
    "id": 1095,
    "content": "Additional parameters can be passed which will install specific subpackages instead of all packages"
  },
  {
    "id": 1097,
    "content": "5) cuda_profiler_api_12"
  },
  {
    "id": 1098,
    "content": "5 CUDA Profiler API"
  },
  {
    "id": 1099,
    "content": "cupti_12"
  },
  {
    "id": 1101,
    "content": "documentation_12"
  },
  {
    "id": 1103,
    "content": "nvprof_12"
  },
  {
    "id": 1104,
    "content": "5 Tool for collecting and viewing CUDA application profiling data from the command-line"
  },
  {
    "id": 1105,
    "content": "nvprune_12"
  },
  {
    "id": 1106,
    "content": "5 Prunes host object files and libraries to only contain device code for the specified targets"
  },
  {
    "id": 1107,
    "content": "visual_studio_integration_12"
  },
  {
    "id": 1108,
    "content": "5 Installs CUDA project wizard and builds customization files in VS"
  },
  {
    "id": 1109,
    "content": "For example, to install only the compiler and driver components:"
  },
  {
    "id": 1110,
    "content": "exe -s nvcc_12"
  },
  {
    "id": 1111,
    "content": "1 Display"
  },
  {
    "id": 1116,
    "content": "Within each directory is a"
  },
  {
    "id": 1117,
    "content": "dll and"
  },
  {
    "id": 1118,
    "content": "nvi file that can be ignored as they are not part of the installable files"
  },
  {
    "id": 1120,
    "content": "This is intended for enterprise-level deployment"
  },
  {
    "id": 1121,
    "content": "2"
  },
  {
    "id": 1122,
    "content": "3"
  },
  {
    "id": 1123,
    "content": "1"
  },
  {
    "id": 1125,
    "content": "2"
  },
  {
    "id": 1126,
    "content": "4"
  },
  {
    "id": 1128,
    "content": "org/nvidia"
  },
  {
    "id": 1129,
    "content": "2"
  },
  {
    "id": 1130,
    "content": "4"
  },
  {
    "id": 1131,
    "content": "1"
  },
  {
    "id": 1132,
    "content": "Conda Overview  The Conda installation installs the CUDA Toolkit"
  },
  {
    "id": 1133,
    "content": "The installation steps are listed below"
  },
  {
    "id": 1134,
    "content": "2"
  },
  {
    "id": 1135,
    "content": "4"
  },
  {
    "id": 1136,
    "content": "2"
  },
  {
    "id": 1138,
    "content": "4"
  },
  {
    "id": 1139,
    "content": "3"
  },
  {
    "id": 1141,
    "content": "4"
  },
  {
    "id": 1142,
    "content": "4"
  },
  {
    "id": 1144,
    "content": "3"
  },
  {
    "id": 1146,
    "content": "3"
  },
  {
    "id": 1147,
    "content": "0 - c nvidia / label / cuda -11"
  },
  {
    "id": 1148,
    "content": "3"
  },
  {
    "id": 1149,
    "content": "1 This example will install all packages released as part of CUDA 11"
  },
  {
    "id": 1150,
    "content": "3"
  },
  {
    "id": 1151,
    "content": "1"
  },
  {
    "id": 1152,
    "content": "2"
  },
  {
    "id": 1153,
    "content": "5"
  },
  {
    "id": 1156,
    "content": "2"
  },
  {
    "id": 1157,
    "content": "6"
  },
  {
    "id": 1159,
    "content": "To do this, you need to compile and run some of the included sample programs"
  },
  {
    "id": 1160,
    "content": "2"
  },
  {
    "id": 1161,
    "content": "6"
  },
  {
    "id": 1162,
    "content": "1"
  },
  {
    "id": 1179,
    "content": "To build the Windows projects (for release or debug mode), use the provided *"
  },
  {
    "id": 1180,
    "content": "sln solution files for Microsoft Visual Studio 2015 (deprecated in CUDA 11"
  },
  {
    "id": 1181,
    "content": "1), 2017, 2019, or 2022"
  },
  {
    "id": 1182,
    "content": "You can use either the solution files located in each of the examples directories in https: github"
  },
  {
    "id": 1183,
    "content": "com/nvidia/cuda-samples 4"
  },
  {
    "id": 1184,
    "content": "1"
  },
  {
    "id": 1185,
    "content": "Compiling Sample Projects  The bandwidthTest project is a good sample project to build and run"
  },
  {
    "id": 1186,
    "content": "It is located in https: github"
  },
  {
    "id": 1188,
    "content": "5\\bin\\win64\\Release"
  },
  {
    "id": 1189,
    "content": "If all works correctly, the output should be similar to Figure 2"
  },
  {
    "id": 1190,
    "content": "4"
  },
  {
    "id": 1191,
    "content": "2"
  },
  {
    "id": 1193,
    "content": "props files are"
  },
  {
    "id": 1194,
    "content": "The environment variable is set automatically using the Build Customization CUDA 12"
  },
  {
    "id": 1195,
    "content": "5"
  },
  {
    "id": 1196,
    "content": "props file, and is installed automatically as part of the CUDA Toolkit installation process"
  },
  {
    "id": 1197,
    "content": "Table 3 CUDA Visual Studio props locations  Visual Studio CUDA 12"
  },
  {
    "id": 1198,
    "content": "5"
  },
  {
    "id": 1200,
    "content": "Cpp\\v4"
  },
  {
    "id": 1202,
    "content": "5"
  },
  {
    "id": 1203,
    "content": "props file when building your own CUDA applications"
  },
  {
    "id": 1204,
    "content": "4"
  },
  {
    "id": 1205,
    "content": "3"
  },
  {
    "id": 1208,
    "content": "5 Toolkit"
  },
  {
    "id": 1209,
    "content": "The new project is technically a C++ project ("
  },
  {
    "id": 1210,
    "content": "vcxproj) that is preconfigured to use NVIDIA’s Build Customizations"
  },
  {
    "id": 1212,
    "content": "Note A supported version of MSVC must be installed to use this feature"
  },
  {
    "id": 1213,
    "content": "4"
  },
  {
    "id": 1214,
    "content": "4"
  },
  {
    "id": 1222,
    "content": "6"
  },
  {
    "id": 1223,
    "content": "Notices  6"
  },
  {
    "id": 1224,
    "content": "1"
  },
  {
    "id": 1227,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 1239,
    "content": "6"
  },
  {
    "id": 1240,
    "content": "2"
  },
  {
    "id": 1241,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 1242,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 1243,
    "content": "6"
  },
  {
    "id": 1244,
    "content": "3"
  },
  {
    "id": 1246,
    "content": "S"
  },
  {
    "id": 1249,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 1250,
    "content": "Navigation"
  },
  {
    "id": 1251,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 1252,
    "content": "pageBottom();}\n1"
  },
  {
    "id": 1253,
    "content": "Why do I see “nvcc: No such file or directory” when I try to build a CUDA application"
  },
  {
    "id": 1254,
    "content": "15"
  },
  {
    "id": 1255,
    "content": "3"
  },
  {
    "id": 1257,
    "content": "15"
  },
  {
    "id": 1258,
    "content": "4"
  },
  {
    "id": 1259,
    "content": "Why do I see multiple “404 Not Found” errors when updating my repository meta-data on Ubuntu"
  },
  {
    "id": 1260,
    "content": "15"
  },
  {
    "id": 1261,
    "content": "5"
  },
  {
    "id": 1262,
    "content": "What do I do if the display does not load, or CUDA does not work, after performing a system update"
  },
  {
    "id": 1263,
    "content": "15"
  },
  {
    "id": 1264,
    "content": "9"
  },
  {
    "id": 1265,
    "content": "Introduction v12"
  },
  {
    "id": 1267,
    "content": "Introduction  CUDA ® is a parallel computing platform and programming model invented by NVIDIA ®"
  },
  {
    "id": 1270,
    "content": "Serial portions of applications are run on the CPU, and parallel portions are offloaded to the GPU"
  },
  {
    "id": 1272,
    "content": "CUDA-capable GPUs have hundreds of cores that can collectively run thousands of computing threads"
  },
  {
    "id": 1275,
    "content": "1"
  },
  {
    "id": 1276,
    "content": "1"
  },
  {
    "id": 1278,
    "content": "nvidia"
  },
  {
    "id": 1281,
    "content": "y (y =10"
  },
  {
    "id": 1282,
    "content": "x >=11"
  },
  {
    "id": 1283,
    "content": "x >=22 x 22"
  },
  {
    "id": 1284,
    "content": "x 1"
  },
  {
    "id": 1285,
    "content": "4"
  },
  {
    "id": 1287,
    "content": "For systems that have enabled the sudo package, use the sudo prefix for all necessary commands"
  },
  {
    "id": 1288,
    "content": "2"
  },
  {
    "id": 1291,
    "content": "Remember that the prerequisites will still be required to use the NVIDIA CUDA Toolkit"
  },
  {
    "id": 1292,
    "content": "2"
  },
  {
    "id": 1293,
    "content": "1"
  },
  {
    "id": 1296,
    "content": "The Release Notes for the CUDA Toolkit also contain a list of supported products"
  },
  {
    "id": 1297,
    "content": "2"
  },
  {
    "id": 1298,
    "content": "2"
  },
  {
    "id": 1301,
    "content": "The remainder gives information about your distribution"
  },
  {
    "id": 1302,
    "content": "2"
  },
  {
    "id": 1303,
    "content": "3"
  },
  {
    "id": 1306,
    "content": "2"
  },
  {
    "id": 1307,
    "content": "4"
  },
  {
    "id": 1309,
    "content": "17"
  },
  {
    "id": 1310,
    "content": "4-301, the 3"
  },
  {
    "id": 1311,
    "content": "17"
  },
  {
    "id": 1316,
    "content": "2"
  },
  {
    "id": 1317,
    "content": "5"
  },
  {
    "id": 1319,
    "content": "distros: Ubuntu 20 04, Ubuntu 22 04 RHEL 8 3, RHEL 8 4, RHEL 9"
  },
  {
    "id": 1320,
    "content": "0 Starting with CUDA toolkit 12"
  },
  {
    "id": 1321,
    "content": "2"
  },
  {
    "id": 1322,
    "content": "2, GDS kernel driver package nvidia-gds version 12"
  },
  {
    "id": 1323,
    "content": "2"
  },
  {
    "id": 1324,
    "content": "2-1 (provided by nvidia-fs-dkms 2"
  },
  {
    "id": 1325,
    "content": "17"
  },
  {
    "id": 1327,
    "content": "2"
  },
  {
    "id": 1328,
    "content": "6"
  },
  {
    "id": 1331,
    "content": "2"
  },
  {
    "id": 1332,
    "content": "7"
  },
  {
    "id": 1333,
    "content": "Download the NVIDIA CUDA Toolkit  The NVIDIA CUDA Toolkit is available at https: developer nvidia"
  },
  {
    "id": 1334,
    "content": "com/cuda-downloads"
  },
  {
    "id": 1337,
    "content": "nvidia"
  },
  {
    "id": 1338,
    "content": "com/compute/cuda/12"
  },
  {
    "id": 1339,
    "content": "5"
  },
  {
    "id": 1340,
    "content": "1/docs/sidebar/md5sum"
  },
  {
    "id": 1343,
    "content": "d/00-nvidia"
  },
  {
    "id": 1345,
    "content": "2"
  },
  {
    "id": 1346,
    "content": "9"
  },
  {
    "id": 1349,
    "content": "Read on for more detailed instructions"
  },
  {
    "id": 1350,
    "content": "3"
  },
  {
    "id": 1351,
    "content": "1"
  },
  {
    "id": 1356,
    "content": "3"
  },
  {
    "id": 1357,
    "content": "2"
  },
  {
    "id": 1358,
    "content": "RHEL 8 / Rocky 8  3"
  },
  {
    "id": 1359,
    "content": "2"
  },
  {
    "id": 1360,
    "content": "1"
  },
  {
    "id": 1363,
    "content": "To enable EPEL: sudo dnf install https: dl"
  },
  {
    "id": 1364,
    "content": "fedoraproject"
  },
  {
    "id": 1365,
    "content": "org/pub/epel/epel-release-latest-8"
  },
  {
    "id": 1366,
    "content": "noarch"
  },
  {
    "id": 1368,
    "content": "gpg-pubkey-7fa2af80* Choose an installation method: local repo or network repo"
  },
  {
    "id": 1369,
    "content": "3"
  },
  {
    "id": 1370,
    "content": "2"
  },
  {
    "id": 1371,
    "content": "2"
  },
  {
    "id": 1373,
    "content": "2"
  },
  {
    "id": 1374,
    "content": "3"
  },
  {
    "id": 1376,
    "content": "download"
  },
  {
    "id": 1377,
    "content": "nvidia"
  },
  {
    "id": 1380,
    "content": "For upgrades, you must also also fetch an updated"
  },
  {
    "id": 1381,
    "content": "repo entry: sudo dnf config-manager --add-repo https: developer"
  },
  {
    "id": 1382,
    "content": "download"
  },
  {
    "id": 1383,
    "content": "nvidia"
  },
  {
    "id": 1384,
    "content": "com/compute/cuda/repos/$distro/$arch/cuda-$distro"
  },
  {
    "id": 1385,
    "content": "repo Clean Yum repository cache: sudo dnf clean expire-cache 3"
  },
  {
    "id": 1386,
    "content": "2"
  },
  {
    "id": 1387,
    "content": "4"
  },
  {
    "id": 1390,
    "content": "so symbolic link, if necessary The libcuda"
  },
  {
    "id": 1391,
    "content": "so library is installed in the /usr/lib{,64}/nvidia directory"
  },
  {
    "id": 1393,
    "content": "so in the /usr/lib{,64} directory"
  },
  {
    "id": 1394,
    "content": "Reboot the system: sudo reboot Perform the post-installation actions"
  },
  {
    "id": 1395,
    "content": "3"
  },
  {
    "id": 1396,
    "content": "3"
  },
  {
    "id": 1397,
    "content": "RHEL 9 / Rocky 9  3"
  },
  {
    "id": 1398,
    "content": "3"
  },
  {
    "id": 1399,
    "content": "1"
  },
  {
    "id": 1401,
    "content": "To enable EPEL: sudo dnf install https: dl"
  },
  {
    "id": 1402,
    "content": "fedoraproject"
  },
  {
    "id": 1403,
    "content": "org/pub/epel/epel-release-latest-9"
  },
  {
    "id": 1404,
    "content": "noarch"
  },
  {
    "id": 1406,
    "content": "gpg-pubkey-7fa2af80* Choose an installation method: local repo or network repo"
  },
  {
    "id": 1407,
    "content": "3"
  },
  {
    "id": 1408,
    "content": "3"
  },
  {
    "id": 1409,
    "content": "2"
  },
  {
    "id": 1411,
    "content": "3"
  },
  {
    "id": 1412,
    "content": "3"
  },
  {
    "id": 1414,
    "content": "download"
  },
  {
    "id": 1415,
    "content": "nvidia"
  },
  {
    "id": 1417,
    "content": "For upgrades, you must also also fetch an updated"
  },
  {
    "id": 1418,
    "content": "repo entry: sudo dnf config-manager --add-repo https: developer"
  },
  {
    "id": 1419,
    "content": "download"
  },
  {
    "id": 1420,
    "content": "nvidia"
  },
  {
    "id": 1421,
    "content": "com/compute/cuda/repos/$distro/$arch/cuda-$distro"
  },
  {
    "id": 1422,
    "content": "repo Clean Yum repository cache: sudo dnf clean expire-cache 3"
  },
  {
    "id": 1423,
    "content": "3"
  },
  {
    "id": 1424,
    "content": "4"
  },
  {
    "id": 1426,
    "content": "3"
  },
  {
    "id": 1427,
    "content": "4"
  },
  {
    "id": 1428,
    "content": "KylinOS 10  3"
  },
  {
    "id": 1429,
    "content": "4"
  },
  {
    "id": 1430,
    "content": "1"
  },
  {
    "id": 1432,
    "content": "3"
  },
  {
    "id": 1433,
    "content": "4"
  },
  {
    "id": 1434,
    "content": "2"
  },
  {
    "id": 1436,
    "content": "4"
  },
  {
    "id": 1437,
    "content": "3"
  },
  {
    "id": 1439,
    "content": "download"
  },
  {
    "id": 1440,
    "content": "nvidia"
  },
  {
    "id": 1441,
    "content": "com/compute/cuda/repos/kylin10/x86_64/cuda-$distro"
  },
  {
    "id": 1444,
    "content": "3"
  },
  {
    "id": 1445,
    "content": "5"
  },
  {
    "id": 1446,
    "content": "Fedora  3"
  },
  {
    "id": 1447,
    "content": "5"
  },
  {
    "id": 1448,
    "content": "1"
  },
  {
    "id": 1450,
    "content": "3"
  },
  {
    "id": 1451,
    "content": "5"
  },
  {
    "id": 1452,
    "content": "2"
  },
  {
    "id": 1454,
    "content": "x86_64"
  },
  {
    "id": 1455,
    "content": "rpm where distro is fedora37 or fedora39 , for example"
  },
  {
    "id": 1456,
    "content": "3"
  },
  {
    "id": 1457,
    "content": "5"
  },
  {
    "id": 1458,
    "content": "3"
  },
  {
    "id": 1460,
    "content": "download"
  },
  {
    "id": 1461,
    "content": "nvidia"
  },
  {
    "id": 1464,
    "content": "For upgrades, you must also fetch an updated"
  },
  {
    "id": 1465,
    "content": "repo entry: sudo dnf config-manager --add-repo https: developer"
  },
  {
    "id": 1466,
    "content": "download"
  },
  {
    "id": 1467,
    "content": "nvidia"
  },
  {
    "id": 1468,
    "content": "com/compute/cuda/repos/$distro/x86_64/cuda-$distro"
  },
  {
    "id": 1469,
    "content": "repo Clean DNF repository cache: sudo dnf clean expire-cache 3"
  },
  {
    "id": 1470,
    "content": "5"
  },
  {
    "id": 1471,
    "content": "4"
  },
  {
    "id": 1474,
    "content": "files, particularly if you use a non-default partition scheme"
  },
  {
    "id": 1476,
    "content": "so library is installed in the /usr/lib{,64}/nvidia directory"
  },
  {
    "id": 1478,
    "content": "16"
  },
  {
    "id": 1479,
    "content": "6-2-default In the above example, the variant is default and version is 3"
  },
  {
    "id": 1480,
    "content": "16"
  },
  {
    "id": 1481,
    "content": "6-2"
  },
  {
    "id": 1484,
    "content": "3"
  },
  {
    "id": 1485,
    "content": "6"
  },
  {
    "id": 1486,
    "content": "2"
  },
  {
    "id": 1488,
    "content": "x86_64"
  },
  {
    "id": 1489,
    "content": "rpm 3"
  },
  {
    "id": 1490,
    "content": "6"
  },
  {
    "id": 1491,
    "content": "3"
  },
  {
    "id": 1492,
    "content": "Network Repo Installation for SLES  Enable the network repo: sudo zypper addrepo https: developer"
  },
  {
    "id": 1493,
    "content": "download"
  },
  {
    "id": 1494,
    "content": "nvidia"
  },
  {
    "id": 1497,
    "content": "For upgrades, you must also also fetch an updated"
  },
  {
    "id": 1498,
    "content": "repo entry: sudo zypper removerepo cuda-$distro-$arch sudo zypper addrepo https: developer"
  },
  {
    "id": 1499,
    "content": "download"
  },
  {
    "id": 1500,
    "content": "nvidia"
  },
  {
    "id": 1501,
    "content": "com/compute/cuda/repos/$distro/$arch/cuda-$distro"
  },
  {
    "id": 1503,
    "content": "6"
  },
  {
    "id": 1504,
    "content": "4"
  },
  {
    "id": 1507,
    "content": "3"
  },
  {
    "id": 1508,
    "content": "7"
  },
  {
    "id": 1509,
    "content": "OpenSUSE  3"
  },
  {
    "id": 1510,
    "content": "7"
  },
  {
    "id": 1511,
    "content": "1"
  },
  {
    "id": 1513,
    "content": "3"
  },
  {
    "id": 1514,
    "content": "7"
  },
  {
    "id": 1515,
    "content": "2"
  },
  {
    "id": 1517,
    "content": "x86_64"
  },
  {
    "id": 1518,
    "content": "rpm 3"
  },
  {
    "id": 1519,
    "content": "7"
  },
  {
    "id": 1520,
    "content": "3"
  },
  {
    "id": 1522,
    "content": "download"
  },
  {
    "id": 1523,
    "content": "nvidia"
  },
  {
    "id": 1524,
    "content": "com/compute/cuda/repos/opensuse15/x86_64/cuda-opensuse15"
  },
  {
    "id": 1527,
    "content": "For upgrades, you must also also fetch an updated"
  },
  {
    "id": 1528,
    "content": "repo entry: sudo zypper removerepo cuda-opensuse15-x86_64 sudo zypper addrepo https: developer"
  },
  {
    "id": 1529,
    "content": "download"
  },
  {
    "id": 1530,
    "content": "nvidia"
  },
  {
    "id": 1531,
    "content": "com/compute/cuda/repos/opensuse15/x86_64/cuda-opensuse15"
  },
  {
    "id": 1532,
    "content": "repo Refresh Zypper repository cache: sudo zypper refresh 3"
  },
  {
    "id": 1533,
    "content": "7"
  },
  {
    "id": 1534,
    "content": "4"
  },
  {
    "id": 1537,
    "content": "3"
  },
  {
    "id": 1538,
    "content": "8"
  },
  {
    "id": 1540,
    "content": "3"
  },
  {
    "id": 1541,
    "content": "8"
  },
  {
    "id": 1542,
    "content": "1"
  },
  {
    "id": 1543,
    "content": "Prepare WSL  Perform the pre-installation actions"
  },
  {
    "id": 1545,
    "content": "3"
  },
  {
    "id": 1546,
    "content": "8"
  },
  {
    "id": 1547,
    "content": "2"
  },
  {
    "id": 1549,
    "content": "gpg /usr/share/keyrings/ 3"
  },
  {
    "id": 1550,
    "content": "8"
  },
  {
    "id": 1551,
    "content": "3"
  },
  {
    "id": 1556,
    "content": "3"
  },
  {
    "id": 1557,
    "content": "9"
  },
  {
    "id": 1558,
    "content": "Ubuntu  3"
  },
  {
    "id": 1559,
    "content": "9"
  },
  {
    "id": 1560,
    "content": "1"
  },
  {
    "id": 1562,
    "content": "3"
  },
  {
    "id": 1563,
    "content": "9"
  },
  {
    "id": 1564,
    "content": "2"
  },
  {
    "id": 1566,
    "content": "gpg /usr/share/keyrings/ Add pin file to prioritize CUDA repository: wget https: developer"
  },
  {
    "id": 1567,
    "content": "download"
  },
  {
    "id": 1568,
    "content": "nvidia"
  },
  {
    "id": 1569,
    "content": "com/compute/cuda/repos x86_64/cuda-"
  },
  {
    "id": 1570,
    "content": "pin sudo mv cuda- pin /etc/apt/preferences d/cuda-repository-pin-600 3"
  },
  {
    "id": 1571,
    "content": "9"
  },
  {
    "id": 1572,
    "content": "3"
  },
  {
    "id": 1575,
    "content": "10"
  },
  {
    "id": 1577,
    "content": "3"
  },
  {
    "id": 1578,
    "content": "10"
  },
  {
    "id": 1579,
    "content": "2"
  },
  {
    "id": 1581,
    "content": "gpg /usr/share/keyrings/ 3"
  },
  {
    "id": 1582,
    "content": "10"
  },
  {
    "id": 1583,
    "content": "3"
  },
  {
    "id": 1585,
    "content": "Install the new cuda-keyring package: wget https: developer"
  },
  {
    "id": 1586,
    "content": "download"
  },
  {
    "id": 1587,
    "content": "nvidia"
  },
  {
    "id": 1588,
    "content": "com/compute/cuda/repos /cuda-keyring_1"
  },
  {
    "id": 1589,
    "content": "1-1_all"
  },
  {
    "id": 1591,
    "content": "1-1_all"
  },
  {
    "id": 1593,
    "content": "download"
  },
  {
    "id": 1594,
    "content": "nvidia"
  },
  {
    "id": 1596,
    "content": "download"
  },
  {
    "id": 1597,
    "content": "nvidia"
  },
  {
    "id": 1598,
    "content": "com/compute/cuda/repos x86_64/ /\" | sudo tee /etc/apt/sources"
  },
  {
    "id": 1599,
    "content": "list"
  },
  {
    "id": 1600,
    "content": "d/cuda--x86_64"
  },
  {
    "id": 1601,
    "content": "list 3"
  },
  {
    "id": 1602,
    "content": "10"
  },
  {
    "id": 1603,
    "content": "4"
  },
  {
    "id": 1606,
    "content": "3"
  },
  {
    "id": 1607,
    "content": "11"
  },
  {
    "id": 1608,
    "content": "Amazon Linux 2023  3"
  },
  {
    "id": 1609,
    "content": "11"
  },
  {
    "id": 1610,
    "content": "1"
  },
  {
    "id": 1612,
    "content": "3"
  },
  {
    "id": 1613,
    "content": "11"
  },
  {
    "id": 1614,
    "content": "2"
  },
  {
    "id": 1616,
    "content": "x86_64"
  },
  {
    "id": 1617,
    "content": "rpm 3"
  },
  {
    "id": 1618,
    "content": "11"
  },
  {
    "id": 1619,
    "content": "3"
  },
  {
    "id": 1621,
    "content": "download"
  },
  {
    "id": 1622,
    "content": "nvidia"
  },
  {
    "id": 1623,
    "content": "com/compute/cuda/repos/amzn2023/x86_64/cuda-amzn2023"
  },
  {
    "id": 1624,
    "content": "repo Clean DNF repository cache: sudo dnf clean expire-cache 3"
  },
  {
    "id": 1625,
    "content": "11"
  },
  {
    "id": 1626,
    "content": "4"
  },
  {
    "id": 1629,
    "content": "so symbolic link, if necessary: The libcuda"
  },
  {
    "id": 1630,
    "content": "so library is installed in the /usr/lib{,64}/nvidia directory"
  },
  {
    "id": 1631,
    "content": "3"
  },
  {
    "id": 1632,
    "content": "12"
  },
  {
    "id": 1636,
    "content": "0 and later Toolkit"
  },
  {
    "id": 1639,
    "content": "\"Package:\" # Ubuntu 3"
  },
  {
    "id": 1640,
    "content": "12"
  },
  {
    "id": 1641,
    "content": "2"
  },
  {
    "id": 1644,
    "content": "Will not upgrade beyond the 555 branch drivers"
  },
  {
    "id": 1645,
    "content": "3"
  },
  {
    "id": 1646,
    "content": "12"
  },
  {
    "id": 1647,
    "content": "3"
  },
  {
    "id": 1648,
    "content": "Optional 32-bit Packages for Linux x86_64"
  },
  {
    "id": 1649,
    "content": "deb/"
  },
  {
    "id": 1655,
    "content": "12"
  },
  {
    "id": 1656,
    "content": "4"
  },
  {
    "id": 1660,
    "content": "Y+1 packages"
  },
  {
    "id": 1661,
    "content": "4"
  },
  {
    "id": 1667,
    "content": "provided on https: download nvidia com/XFree86/"
  },
  {
    "id": 1669,
    "content": "d/nvidia-gsp"
  },
  {
    "id": 1670,
    "content": "conf To install NVIDIA Open GPU Kernel Modules, follow the instructions below"
  },
  {
    "id": 1671,
    "content": "5"
  },
  {
    "id": 1672,
    "content": "1"
  },
  {
    "id": 1674,
    "content": "2"
  },
  {
    "id": 1676,
    "content": "-v cuda-drivers- For example: sudo apt-get install -v nvidia-kernel-open-dkms=550"
  },
  {
    "id": 1677,
    "content": "90"
  },
  {
    "id": 1678,
    "content": "07-1 sudo apt-get install -v cuda-drivers-550 5"
  },
  {
    "id": 1679,
    "content": "3"
  },
  {
    "id": 1681,
    "content": "4"
  },
  {
    "id": 1683,
    "content": "5"
  },
  {
    "id": 1685,
    "content": "6"
  },
  {
    "id": 1687,
    "content": "7"
  },
  {
    "id": 1690,
    "content": "8"
  },
  {
    "id": 1695,
    "content": "ko files"
  },
  {
    "id": 1699,
    "content": "6"
  },
  {
    "id": 1700,
    "content": "1"
  },
  {
    "id": 1702,
    "content": "nvidia-driver Note This is also required for upgrading between branch locked streams"
  },
  {
    "id": 1706,
    "content": "download"
  },
  {
    "id": 1707,
    "content": "nvidia"
  },
  {
    "id": 1708,
    "content": "com/compute/cuda/repos/rhel8/x86_64/precompiled/ for more information"
  },
  {
    "id": 1709,
    "content": "7"
  },
  {
    "id": 1710,
    "content": "Kickstart Installation  7"
  },
  {
    "id": 1711,
    "content": "1"
  },
  {
    "id": 1713,
    "content": "run” file and is completely self-contained"
  },
  {
    "id": 1714,
    "content": "8"
  },
  {
    "id": 1715,
    "content": "1"
  },
  {
    "id": 1718,
    "content": "The Runfile installation does not include support for cross-platform development"
  },
  {
    "id": 1719,
    "content": "8"
  },
  {
    "id": 1720,
    "content": "2"
  },
  {
    "id": 1721,
    "content": "Installation  Perform the pre-installation actions"
  },
  {
    "id": 1723,
    "content": "Since the NVIDIA drivers are not yet installed, the text terminals may not display correctly"
  },
  {
    "id": 1726,
    "content": "Run the installer and follow the on-screen prompts: sudo sh cuda__linux"
  },
  {
    "id": 1728,
    "content": "configuration file update"
  },
  {
    "id": 1732,
    "content": "conf , may need to be modified"
  },
  {
    "id": 1733,
    "content": "In some cases, nvidia-xconfig can be used to automatically generate an xorg"
  },
  {
    "id": 1734,
    "content": "conf file that works for the system"
  },
  {
    "id": 1736,
    "content": "conf file"
  },
  {
    "id": 1737,
    "content": "Note Installing Mesa may overwrite the /usr/lib/libGL"
  },
  {
    "id": 1740,
    "content": "Perform the post-installation actions"
  },
  {
    "id": 1741,
    "content": "8"
  },
  {
    "id": 1742,
    "content": "3"
  },
  {
    "id": 1744,
    "content": "3"
  },
  {
    "id": 1745,
    "content": "1"
  },
  {
    "id": 1746,
    "content": "Fedora  Create a file at /usr/lib/modprobe"
  },
  {
    "id": 1748,
    "content": "cfg Reboot the system"
  },
  {
    "id": 1749,
    "content": "8"
  },
  {
    "id": 1750,
    "content": "3"
  },
  {
    "id": 1751,
    "content": "2"
  },
  {
    "id": 1752,
    "content": "RHEL / Rocky and KylinOS  Create a file at /etc/modprobe"
  },
  {
    "id": 1754,
    "content": "3"
  },
  {
    "id": 1755,
    "content": "3"
  },
  {
    "id": 1756,
    "content": "OpenSUSE  Create a file at /etc/modprobe"
  },
  {
    "id": 1758,
    "content": "3"
  },
  {
    "id": 1759,
    "content": "4"
  },
  {
    "id": 1760,
    "content": "SLES  No actions to disable Nouveau are required as Nouveau is not installed on SLES"
  },
  {
    "id": 1761,
    "content": "8"
  },
  {
    "id": 1762,
    "content": "3"
  },
  {
    "id": 1763,
    "content": "5"
  },
  {
    "id": 1764,
    "content": "WSL  No actions to disable Nouveau are required as Nouveau is not installed on WSL"
  },
  {
    "id": 1765,
    "content": "8"
  },
  {
    "id": 1766,
    "content": "3"
  },
  {
    "id": 1767,
    "content": "6"
  },
  {
    "id": 1768,
    "content": "Ubuntu  Create a file at /etc/modprobe"
  },
  {
    "id": 1770,
    "content": "3"
  },
  {
    "id": 1771,
    "content": "7"
  },
  {
    "id": 1772,
    "content": "Debian  Create a file at /etc/modprobe"
  },
  {
    "id": 1774,
    "content": "4"
  },
  {
    "id": 1778,
    "content": "\" -eq 0 ]; then # Count the number of NVIDIA controllers found"
  },
  {
    "id": 1781,
    "content": "5"
  },
  {
    "id": 1788,
    "content": "install the nvidia-drm kernel module on systems that do not need the provided features"
  },
  {
    "id": 1790,
    "content": "Useful in cases where /tmp cannot be used (doesn’t exist, is full, is mounted with ‘noexec’, etc"
  },
  {
    "id": 1791,
    "content": ")"
  },
  {
    "id": 1792,
    "content": "Show Installer Options --help Prints the list of command-line options to stdout"
  },
  {
    "id": 1793,
    "content": "8"
  },
  {
    "id": 1794,
    "content": "6"
  },
  {
    "id": 1797,
    "content": "9"
  },
  {
    "id": 1799,
    "content": "org/nvidia"
  },
  {
    "id": 1800,
    "content": "9"
  },
  {
    "id": 1801,
    "content": "1"
  },
  {
    "id": 1802,
    "content": "Conda Overview  The Conda installation installs the CUDA Toolkit"
  },
  {
    "id": 1803,
    "content": "9"
  },
  {
    "id": 1804,
    "content": "2"
  },
  {
    "id": 1806,
    "content": "3"
  },
  {
    "id": 1808,
    "content": "4"
  },
  {
    "id": 1810,
    "content": "3"
  },
  {
    "id": 1811,
    "content": "0 9"
  },
  {
    "id": 1812,
    "content": "5"
  },
  {
    "id": 1815,
    "content": "10"
  },
  {
    "id": 1825,
    "content": "download"
  },
  {
    "id": 1826,
    "content": "nvidia"
  },
  {
    "id": 1827,
    "content": "com/compute/cuda/redist/"
  },
  {
    "id": 1828,
    "content": "These component"
  },
  {
    "id": 1829,
    "content": "tar"
  },
  {
    "id": 1830,
    "content": "xz and"
  },
  {
    "id": 1831,
    "content": "zip binary archives do not replace existing packages such as"
  },
  {
    "id": 1832,
    "content": "deb,"
  },
  {
    "id": 1833,
    "content": "rpm, runfile, conda, etc"
  },
  {
    "id": 1834,
    "content": "For each release, a JSON manifest is provided such as redistrib_11"
  },
  {
    "id": 1835,
    "content": "4"
  },
  {
    "id": 1836,
    "content": "2"
  },
  {
    "id": 1837,
    "content": "json , which corresponds to the CUDA 11"
  },
  {
    "id": 1838,
    "content": "4"
  },
  {
    "id": 1839,
    "content": "2 release label (CUDA 11"
  },
  {
    "id": 1841,
    "content": "Instructions for developers using CMake and Bazel build systems are provided in the next sections"
  },
  {
    "id": 1842,
    "content": "11"
  },
  {
    "id": 1843,
    "content": "1"
  },
  {
    "id": 1846,
    "content": "17 and newer)"
  },
  {
    "id": 1848,
    "content": "For example CMakeLists"
  },
  {
    "id": 1849,
    "content": "txt file and commands, see cmake/2_ExternalProject/"
  },
  {
    "id": 1850,
    "content": "11"
  },
  {
    "id": 1851,
    "content": "3"
  },
  {
    "id": 1853,
    "content": "12"
  },
  {
    "id": 1856,
    "content": "12"
  },
  {
    "id": 1857,
    "content": "1"
  },
  {
    "id": 1859,
    "content": "Install repository meta-data package with: sudo dpkg -i cuda-repo-cross-_all"
  },
  {
    "id": 1860,
    "content": "deb where indicates the operating system, architecture, and/or the version of the package"
  },
  {
    "id": 1862,
    "content": "12"
  },
  {
    "id": 1863,
    "content": "2"
  },
  {
    "id": 1865,
    "content": "These actions are split into mandatory, recommended, and optional sections"
  },
  {
    "id": 1866,
    "content": "13"
  },
  {
    "id": 1867,
    "content": "1"
  },
  {
    "id": 1869,
    "content": "13"
  },
  {
    "id": 1870,
    "content": "1"
  },
  {
    "id": 1871,
    "content": "1"
  },
  {
    "id": 1873,
    "content": "Nsight Compute has moved to /opt/nvidia/nsight-compute/ only in rpm/deb installation method"
  },
  {
    "id": 1876,
    "content": "13"
  },
  {
    "id": 1877,
    "content": "2"
  },
  {
    "id": 1878,
    "content": "Recommended Actions  Other actions are recommended to verify the integrity of the installation"
  },
  {
    "id": 1879,
    "content": "13"
  },
  {
    "id": 1880,
    "content": "2"
  },
  {
    "id": 1881,
    "content": "1"
  },
  {
    "id": 1883,
    "content": "Consult your Linux distribution’s init documentation for details on how to automate this"
  },
  {
    "id": 1884,
    "content": "13"
  },
  {
    "id": 1885,
    "content": "2"
  },
  {
    "id": 1886,
    "content": "2"
  },
  {
    "id": 1888,
    "content": "13"
  },
  {
    "id": 1889,
    "content": "2"
  },
  {
    "id": 1890,
    "content": "3"
  },
  {
    "id": 1892,
    "content": "To do this, you need to compile and run some of the sample programs, located in https: github"
  },
  {
    "id": 1893,
    "content": "com/nvidia/cuda-samples"
  },
  {
    "id": 1895,
    "content": "13"
  },
  {
    "id": 1896,
    "content": "2"
  },
  {
    "id": 1897,
    "content": "3"
  },
  {
    "id": 1898,
    "content": "1"
  },
  {
    "id": 1900,
    "content": "not work on an iGPU/dGPU system"
  },
  {
    "id": 1901,
    "content": "13"
  },
  {
    "id": 1902,
    "content": "2"
  },
  {
    "id": 1903,
    "content": "3"
  },
  {
    "id": 1904,
    "content": "2"
  },
  {
    "id": 1905,
    "content": "Running the Binaries  After compilation, find and run deviceQuery from https: github"
  },
  {
    "id": 1906,
    "content": "com/nvidia/cuda-samples"
  },
  {
    "id": 1914,
    "content": "com/nvidia/cuda-samples"
  },
  {
    "id": 1915,
    "content": "13"
  },
  {
    "id": 1916,
    "content": "2"
  },
  {
    "id": 1917,
    "content": "4"
  },
  {
    "id": 1919,
    "content": "4/bin/nsight_ee_plugins_manage"
  },
  {
    "id": 1920,
    "content": "sh install Refer to Nsight Eclipse Plugins Installation Guide for more details"
  },
  {
    "id": 1921,
    "content": "13"
  },
  {
    "id": 1922,
    "content": "2"
  },
  {
    "id": 1923,
    "content": "5"
  },
  {
    "id": 1926,
    "content": "3"
  },
  {
    "id": 1928,
    "content": "13"
  },
  {
    "id": 1929,
    "content": "3"
  },
  {
    "id": 1930,
    "content": "1"
  },
  {
    "id": 1933,
    "content": "must be installed The source code is installed as a tarball in the /usr/local/cuda-12"
  },
  {
    "id": 1934,
    "content": "4/extras directory"
  },
  {
    "id": 1935,
    "content": "13"
  },
  {
    "id": 1936,
    "content": "3"
  },
  {
    "id": 1937,
    "content": "3"
  },
  {
    "id": 1947,
    "content": "Corporation ” and “ bus_id ” with the Bus ID of the GPU"
  },
  {
    "id": 1949,
    "content": "4=/new/toolkit package"
  },
  {
    "id": 1954,
    "content": "Each repository you wish to restrict to specific architectures must have its sources"
  },
  {
    "id": 1955,
    "content": "list entry modified"
  },
  {
    "id": 1957,
    "content": "d/ directory"
  },
  {
    "id": 1958,
    "content": "Normally, it is sufficient to modify only the entries in /etc/apt/sources"
  },
  {
    "id": 1961,
    "content": "For instance, on Ubuntu 14"
  },
  {
    "id": 1967,
    "content": "sudo apt-get install --verbose-versions cuda 15"
  },
  {
    "id": 1971,
    "content": "4"
  },
  {
    "id": 1973,
    "content": "list file"
  },
  {
    "id": 1974,
    "content": "Repositories that do not host packages for the newly added architecture will present this error"
  },
  {
    "id": 1975,
    "content": "Please see the Advanced Setup section for details on how to modify your sources"
  },
  {
    "id": 1976,
    "content": "list file to prevent these errors"
  },
  {
    "id": 1979,
    "content": "conf, edit /etc/default/grub to add “ nogpumanager ” to GRUB_CMDLINE_LINUX_DEFAULT"
  },
  {
    "id": 1982,
    "content": "network repo, the required packages will need to be explicitly installed at the desired version"
  },
  {
    "id": 1987,
    "content": "12"
  },
  {
    "id": 1991,
    "content": "4/doc"
  },
  {
    "id": 1994,
    "content": "nvidia"
  },
  {
    "id": 1995,
    "content": "com/c/accelerated-computing/cuda/206"
  },
  {
    "id": 1996,
    "content": "17"
  },
  {
    "id": 1998,
    "content": "d/nvidia-gsp"
  },
  {
    "id": 1999,
    "content": "conf Note Replace XXX with the NVIDIA driver branch number such as 550"
  },
  {
    "id": 2003,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 2015,
    "content": "19"
  },
  {
    "id": 2016,
    "content": "2"
  },
  {
    "id": 2017,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 2018,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 2019,
    "content": "19"
  },
  {
    "id": 2020,
    "content": "3"
  },
  {
    "id": 2022,
    "content": "S"
  },
  {
    "id": 2024,
    "content": "20"
  },
  {
    "id": 2026,
    "content": "Introduction v12"
  },
  {
    "id": 2027,
    "content": "5 | PDF | Archive CUDA C++ Programming Guide The programming guide to the CUDA model and interface"
  },
  {
    "id": 2028,
    "content": "Changes from Version 12"
  },
  {
    "id": 2029,
    "content": "4 Added section Asynchronous Data Copies using Tensor Memory Access (TMA)"
  },
  {
    "id": 2035,
    "content": "The schematic Figure 1 shows an example distribution of chip resources for a CPU versus a GPU"
  },
  {
    "id": 2037,
    "content": "of transistors"
  },
  {
    "id": 2040,
    "content": "1"
  },
  {
    "id": 2041,
    "content": "2"
  },
  {
    "id": 2045,
    "content": " 1"
  },
  {
    "id": 2046,
    "content": "3"
  },
  {
    "id": 2048,
    "content": "numbers of cores"
  },
  {
    "id": 2056,
    "content": "1"
  },
  {
    "id": 2057,
    "content": "4"
  },
  {
    "id": 2059,
    "content": "Cooperative Groups describes synchronization primitives for various groups of CUDA threads"
  },
  {
    "id": 2063,
    "content": "2"
  },
  {
    "id": 2065,
    "content": "2"
  },
  {
    "id": 2066,
    "content": "1"
  },
  {
    "id": 2070,
    "content": "} Here, each of the N threads that execute VecAdd() performs one pair-wise addition"
  },
  {
    "id": 2071,
    "content": "2"
  },
  {
    "id": 2072,
    "content": "2"
  },
  {
    "id": 2084,
    "content": "2"
  },
  {
    "id": 2085,
    "content": "2"
  },
  {
    "id": 2086,
    "content": "1"
  },
  {
    "id": 2095,
    "content": "sync()"
  },
  {
    "id": 2098,
    "content": "2"
  },
  {
    "id": 2099,
    "content": "3"
  },
  {
    "id": 2103,
    "content": "constant, and texture memory spaces are persistent across kernel launches by the same application"
  },
  {
    "id": 2107,
    "content": "while parallel code executes on the device"
  },
  {
    "id": 2108,
    "content": "2"
  },
  {
    "id": 2109,
    "content": "5"
  },
  {
    "id": 2112,
    "content": "2"
  },
  {
    "id": 2113,
    "content": "5"
  },
  {
    "id": 2114,
    "content": "1"
  },
  {
    "id": 2117,
    "content": "g"
  },
  {
    "id": 2118,
    "content": ", cuda::memcpy_async ) or implicitly managed within a library (e"
  },
  {
    "id": 2119,
    "content": "g"
  },
  {
    "id": 2120,
    "content": ", cooperative_groups::memcpy_async )"
  },
  {
    "id": 2124,
    "content": "scopes are implemented as extensions to standard C++ in the CUDA Standard C++ library"
  },
  {
    "id": 2125,
    "content": "2"
  },
  {
    "id": 2126,
    "content": "6"
  },
  {
    "id": 2130,
    "content": "Y"
  },
  {
    "id": 2135,
    "content": "0, respectively"
  },
  {
    "id": 2136,
    "content": "3"
  },
  {
    "id": 2143,
    "content": "in the reference manual"
  },
  {
    "id": 2144,
    "content": "3"
  },
  {
    "id": 2145,
    "content": "1"
  },
  {
    "id": 2147,
    "content": "It is however usually more effective to use a high-level programming language such as C++"
  },
  {
    "id": 2148,
    "content": "In both cases, kernels must be compiled into binary code by nvcc to execute on the device"
  },
  {
    "id": 2150,
    "content": "A complete description can be found in the nvcc user manual"
  },
  {
    "id": 2151,
    "content": "3"
  },
  {
    "id": 2152,
    "content": "1"
  },
  {
    "id": 2153,
    "content": "1"
  },
  {
    "id": 2154,
    "content": "Compilation Workflow  3"
  },
  {
    "id": 2155,
    "content": "1"
  },
  {
    "id": 2156,
    "content": "1"
  },
  {
    "id": 2157,
    "content": "1"
  },
  {
    "id": 2158,
    "content": "Offline Compilation  Source files compiled with nvcc can include a mix of host code (i"
  },
  {
    "id": 2159,
    "content": "e"
  },
  {
    "id": 2160,
    "content": ", code that executes on the host) and device code (i"
  },
  {
    "id": 2161,
    "content": "e"
  },
  {
    "id": 2165,
    "content": "3"
  },
  {
    "id": 2166,
    "content": "1"
  },
  {
    "id": 2167,
    "content": "1"
  },
  {
    "id": 2168,
    "content": "2"
  },
  {
    "id": 2172,
    "content": "compilation library for CUDA C++; more information can be found in the NVRTC User guide"
  },
  {
    "id": 2173,
    "content": "3"
  },
  {
    "id": 2174,
    "content": "1"
  },
  {
    "id": 2175,
    "content": "2"
  },
  {
    "id": 2177,
    "content": "0"
  },
  {
    "id": 2180,
    "content": "z where z≥y"
  },
  {
    "id": 2181,
    "content": "Also, the binary compatibility between desktop and Tegra is not supported"
  },
  {
    "id": 2182,
    "content": "3"
  },
  {
    "id": 2183,
    "content": "1"
  },
  {
    "id": 2184,
    "content": "3"
  },
  {
    "id": 2186,
    "content": "0 and above"
  },
  {
    "id": 2190,
    "content": "0 and is not backward or forward compatible"
  },
  {
    "id": 2191,
    "content": "3"
  },
  {
    "id": 2192,
    "content": "1"
  },
  {
    "id": 2193,
    "content": "4"
  },
  {
    "id": 2196,
    "content": "For example, nvcc x"
  },
  {
    "id": 2200,
    "content": "0 binary code for devices with compute capability 5"
  },
  {
    "id": 2201,
    "content": "0 and 5"
  },
  {
    "id": 2202,
    "content": "2, 6"
  },
  {
    "id": 2203,
    "content": "0 binary code for devices with compute capability 6"
  },
  {
    "id": 2204,
    "content": "0 and 6"
  },
  {
    "id": 2205,
    "content": "1, 7"
  },
  {
    "id": 2206,
    "content": "0 binary code for devices with compute capability 7"
  },
  {
    "id": 2207,
    "content": "0 and 7"
  },
  {
    "id": 2208,
    "content": "5, PTX code which is compiled to binary code at runtime for devices with compute capability 8"
  },
  {
    "id": 2209,
    "content": "0 and 8"
  },
  {
    "id": 2210,
    "content": "6"
  },
  {
    "id": 2211,
    "content": "x"
  },
  {
    "id": 2213,
    "content": "0 and higher"
  },
  {
    "id": 2214,
    "content": "The __CUDA_ARCH__ macro can be used to differentiate various code paths based on compute capability"
  },
  {
    "id": 2215,
    "content": "If x"
  },
  {
    "id": 2217,
    "content": "0"
  },
  {
    "id": 2222,
    "content": "3"
  },
  {
    "id": 2223,
    "content": "1"
  },
  {
    "id": 2224,
    "content": "5"
  },
  {
    "id": 2227,
    "content": "3"
  },
  {
    "id": 2228,
    "content": "1"
  },
  {
    "id": 2229,
    "content": "6"
  },
  {
    "id": 2230,
    "content": "64-Bit Compatibility  The 64-bit version of nvcc compiles device code in 64-bit mode (i"
  },
  {
    "id": 2231,
    "content": "e"
  },
  {
    "id": 2233,
    "content": "3"
  },
  {
    "id": 2234,
    "content": "2"
  },
  {
    "id": 2236,
    "content": "lib or libcudart"
  },
  {
    "id": 2237,
    "content": "a , or dynamically via cudart"
  },
  {
    "id": 2238,
    "content": "dll or libcudart"
  },
  {
    "id": 2239,
    "content": "so"
  },
  {
    "id": 2240,
    "content": "Applications that require cudart dll and/or cudart"
  },
  {
    "id": 2241,
    "content": "so for dynamic linking typically include them as part of the application installation package"
  },
  {
    "id": 2250,
    "content": "3"
  },
  {
    "id": 2251,
    "content": "2"
  },
  {
    "id": 2252,
    "content": "1"
  },
  {
    "id": 2253,
    "content": "Initialization  As of CUDA 12"
  },
  {
    "id": 2255,
    "content": "runtime"
  },
  {
    "id": 2256,
    "content": "Before 12"
  },
  {
    "id": 2260,
    "content": "e"
  },
  {
    "id": 2263,
    "content": "As of CUDA 12"
  },
  {
    "id": 2266,
    "content": "3"
  },
  {
    "id": 2267,
    "content": "2"
  },
  {
    "id": 2268,
    "content": "2"
  },
  {
    "id": 2272,
    "content": "3 (Maxwell) 40bit 40bit 40bit compute capability 6"
  },
  {
    "id": 2273,
    "content": "0 (Pascal) or newer up to 47bit up to 49bit up to 48bit Note On devices of compute capability 5"
  },
  {
    "id": 2281,
    "content": "hitProp = cudaAccessPropertyPersisting ;   Type of access property on cache hit stream_attribute"
  },
  {
    "id": 2289,
    "content": "will be less likely to evict their own or each others’ persisting cache lines"
  },
  {
    "id": 2290,
    "content": "3"
  },
  {
    "id": 2291,
    "content": "2"
  },
  {
    "id": 2292,
    "content": "3"
  },
  {
    "id": 2293,
    "content": "3"
  },
  {
    "id": 2297,
    "content": "3"
  },
  {
    "id": 2298,
    "content": "2"
  },
  {
    "id": 2299,
    "content": "3"
  },
  {
    "id": 2300,
    "content": "4"
  },
  {
    "id": 2303,
    "content": "window_size = min ( prop"
  },
  {
    "id": 2308,
    "content": "2"
  },
  {
    "id": 2309,
    "content": "3"
  },
  {
    "id": 2310,
    "content": "5"
  },
  {
    "id": 2313,
    "content": "3"
  },
  {
    "id": 2314,
    "content": "2"
  },
  {
    "id": 2315,
    "content": "3"
  },
  {
    "id": 2316,
    "content": "6"
  },
  {
    "id": 2319,
    "content": "priority"
  },
  {
    "id": 2320,
    "content": "3"
  },
  {
    "id": 2321,
    "content": "2"
  },
  {
    "id": 2322,
    "content": "3"
  },
  {
    "id": 2323,
    "content": "7"
  },
  {
    "id": 2325,
    "content": "accessPolicyMaxWindowSize : The maximum size of the access policy window"
  },
  {
    "id": 2326,
    "content": "3"
  },
  {
    "id": 2327,
    "content": "2"
  },
  {
    "id": 2328,
    "content": "3"
  },
  {
    "id": 2329,
    "content": "8"
  },
  {
    "id": 2346,
    "content": "g"
  },
  {
    "id": 2349,
    "content": "3"
  },
  {
    "id": 2350,
    "content": "2"
  },
  {
    "id": 2351,
    "content": "7"
  },
  {
    "id": 2352,
    "content": "2"
  },
  {
    "id": 2354,
    "content": "In exchange for explicit assistance from code, the GPU can reduce the net cast by a fence operation"
  },
  {
    "id": 2359,
    "content": "3"
  },
  {
    "id": 2360,
    "content": "2"
  },
  {
    "id": 2361,
    "content": "7"
  },
  {
    "id": 2362,
    "content": "3"
  },
  {
    "id": 2367,
    "content": "tag launches with the remote domain in CUDA 12 0 and later; for example, NCCL 2"
  },
  {
    "id": 2368,
    "content": "16 will do so"
  },
  {
    "id": 2376,
    "content": "3"
  },
  {
    "id": 2377,
    "content": "2"
  },
  {
    "id": 2378,
    "content": "8"
  },
  {
    "id": 2381,
    "content": "3"
  },
  {
    "id": 2382,
    "content": "2"
  },
  {
    "id": 2383,
    "content": "8"
  },
  {
    "id": 2384,
    "content": "1"
  },
  {
    "id": 2392,
    "content": "Async memory copies might also be synchronous if they involve host memory that is not page-locked"
  },
  {
    "id": 2393,
    "content": "3"
  },
  {
    "id": 2394,
    "content": "2"
  },
  {
    "id": 2395,
    "content": "8"
  },
  {
    "id": 2396,
    "content": "2"
  },
  {
    "id": 2397,
    "content": "Concurrent Kernel Execution  Some devices of compute capability 2"
  },
  {
    "id": 2398,
    "content": "x and higher can execute multiple kernels concurrently"
  },
  {
    "id": 2401,
    "content": "If a user wants to run kernels from multiple process simultaneously on the SM, one must enable MPS"
  },
  {
    "id": 2403,
    "content": "3"
  },
  {
    "id": 2404,
    "content": "2"
  },
  {
    "id": 2405,
    "content": "8"
  },
  {
    "id": 2406,
    "content": "3"
  },
  {
    "id": 2410,
    "content": "3"
  },
  {
    "id": 2411,
    "content": "2"
  },
  {
    "id": 2412,
    "content": "8"
  },
  {
    "id": 2413,
    "content": "4"
  },
  {
    "id": 2414,
    "content": "Concurrent Data Transfers  Some devices of compute capability 2"
  },
  {
    "id": 2415,
    "content": "x and higher can overlap copies to and from the device"
  },
  {
    "id": 2417,
    "content": "In order to be overlapped, any host memory involved in the transfers must be page-locked"
  },
  {
    "id": 2418,
    "content": "3"
  },
  {
    "id": 2419,
    "content": "2"
  },
  {
    "id": 2420,
    "content": "8"
  },
  {
    "id": 2421,
    "content": "5"
  },
  {
    "id": 2422,
    "content": "Streams  Applications manage the concurrent operations described above through streams"
  },
  {
    "id": 2425,
    "content": "3"
  },
  {
    "id": 2426,
    "content": "2"
  },
  {
    "id": 2427,
    "content": "8"
  },
  {
    "id": 2428,
    "content": "5"
  },
  {
    "id": 2429,
    "content": "1"
  },
  {
    "id": 2435,
    "content": "h and cuda_runtime"
  },
  {
    "id": 2436,
    "content": "h )), the default stream is a regular stream and each host thread has its own default stream"
  },
  {
    "id": 2438,
    "content": "h at the top of the translation unit"
  },
  {
    "id": 2441,
    "content": "3"
  },
  {
    "id": 2442,
    "content": "2"
  },
  {
    "id": 2443,
    "content": "8"
  },
  {
    "id": 2444,
    "content": "5"
  },
  {
    "id": 2445,
    "content": "3"
  },
  {
    "id": 2446,
    "content": "Explicit Synchronization  There are various ways to explicitly synchronize streams with each other"
  },
  {
    "id": 2450,
    "content": "3"
  },
  {
    "id": 2451,
    "content": "2"
  },
  {
    "id": 2452,
    "content": "8"
  },
  {
    "id": 2453,
    "content": "5"
  },
  {
    "id": 2454,
    "content": "4"
  },
  {
    "id": 2456,
    "content": "configurations described in Compute Capability 7"
  },
  {
    "id": 2457,
    "content": "x"
  },
  {
    "id": 2460,
    "content": "3"
  },
  {
    "id": 2461,
    "content": "2"
  },
  {
    "id": 2462,
    "content": "8"
  },
  {
    "id": 2463,
    "content": "5"
  },
  {
    "id": 2464,
    "content": "5"
  },
  {
    "id": 2470,
    "content": "3"
  },
  {
    "id": 2471,
    "content": "2"
  },
  {
    "id": 2472,
    "content": "8"
  },
  {
    "id": 2473,
    "content": "5"
  },
  {
    "id": 2474,
    "content": "7"
  },
  {
    "id": 2478,
    "content": "2"
  },
  {
    "id": 2479,
    "content": "8"
  },
  {
    "id": 2480,
    "content": "6"
  },
  {
    "id": 2482,
    "content": "Available starting with devices of compute capability 9"
  },
  {
    "id": 2484,
    "content": "3"
  },
  {
    "id": 2485,
    "content": "2"
  },
  {
    "id": 2486,
    "content": "8"
  },
  {
    "id": 2487,
    "content": "6"
  },
  {
    "id": 2488,
    "content": "1"
  },
  {
    "id": 2489,
    "content": "Background  A CUDA application utilizes the GPU by launching and executing multiple kernels on it"
  },
  {
    "id": 2491,
    "content": "primary_kernel , there is some potential for concurrent execution"
  },
  {
    "id": 2495,
    "content": "These APIs require at least compute capability 9"
  },
  {
    "id": 2496,
    "content": "0 to provide overlapping execution"
  },
  {
    "id": 2497,
    "content": "3"
  },
  {
    "id": 2498,
    "content": "2"
  },
  {
    "id": 2499,
    "content": "8"
  },
  {
    "id": 2500,
    "content": "6"
  },
  {
    "id": 2501,
    "content": "2"
  },
  {
    "id": 2507,
    "content": "manner is unsafe and can lead to deadlock"
  },
  {
    "id": 2508,
    "content": "3"
  },
  {
    "id": 2509,
    "content": "2"
  },
  {
    "id": 2510,
    "content": "8"
  },
  {
    "id": 2511,
    "content": "6"
  },
  {
    "id": 2512,
    "content": "3"
  },
  {
    "id": 2514,
    "content": "kernel"
  },
  {
    "id": 2522,
    "content": "3"
  },
  {
    "id": 2523,
    "content": "2"
  },
  {
    "id": 2524,
    "content": "8"
  },
  {
    "id": 2525,
    "content": "7"
  },
  {
    "id": 2526,
    "content": "1"
  },
  {
    "id": 2527,
    "content": "Graph Structure  An operation forms a node in a graph"
  },
  {
    "id": 2528,
    "content": "An operation may be scheduled at any time once the nodes on which it depends are complete"
  },
  {
    "id": 2529,
    "content": "Scheduling is left up to the CUDA system"
  },
  {
    "id": 2530,
    "content": "3"
  },
  {
    "id": 2531,
    "content": "2"
  },
  {
    "id": 2532,
    "content": "8"
  },
  {
    "id": 2533,
    "content": "7"
  },
  {
    "id": 2534,
    "content": "1"
  },
  {
    "id": 2535,
    "content": "1"
  },
  {
    "id": 2540,
    "content": "node types define additional incoming ports, and only kernel nodes define additional outgoing ports"
  },
  {
    "id": 2542,
    "content": "3"
  },
  {
    "id": 2543,
    "content": "2"
  },
  {
    "id": 2544,
    "content": "8"
  },
  {
    "id": 2545,
    "content": "7"
  },
  {
    "id": 2546,
    "content": "2"
  },
  {
    "id": 2550,
    "content": "2"
  },
  {
    "id": 2551,
    "content": "8"
  },
  {
    "id": 2552,
    "content": "7"
  },
  {
    "id": 2553,
    "content": "3"
  },
  {
    "id": 2556,
    "content": "); kernel_B >> ("
  },
  {
    "id": 2559,
    "content": "3"
  },
  {
    "id": 2560,
    "content": "2"
  },
  {
    "id": 2561,
    "content": "8"
  },
  {
    "id": 2562,
    "content": "7"
  },
  {
    "id": 2563,
    "content": "3"
  },
  {
    "id": 2564,
    "content": "1"
  },
  {
    "id": 2568,
    "content": "( event1 , stream1 ); cudaStreamWaitEvent ( stream2 , event1 ); kernel_B >> ("
  },
  {
    "id": 2569,
    "content": "); kernel_C >> ("
  },
  {
    "id": 2572,
    "content": "3"
  },
  {
    "id": 2573,
    "content": "2"
  },
  {
    "id": 2574,
    "content": "8"
  },
  {
    "id": 2575,
    "content": "7"
  },
  {
    "id": 2576,
    "content": "3"
  },
  {
    "id": 2577,
    "content": "2"
  },
  {
    "id": 2583,
    "content": "3"
  },
  {
    "id": 2584,
    "content": "2"
  },
  {
    "id": 2585,
    "content": "8"
  },
  {
    "id": 2586,
    "content": "7"
  },
  {
    "id": 2587,
    "content": "3"
  },
  {
    "id": 2588,
    "content": "3"
  },
  {
    "id": 2590,
    "content": "of capture mode, but will also return an error value and a NULL graph"
  },
  {
    "id": 2591,
    "content": "3"
  },
  {
    "id": 2592,
    "content": "2"
  },
  {
    "id": 2593,
    "content": "8"
  },
  {
    "id": 2594,
    "content": "7"
  },
  {
    "id": 2595,
    "content": "4"
  },
  {
    "id": 2608,
    "content": "3"
  },
  {
    "id": 2609,
    "content": "2"
  },
  {
    "id": 2610,
    "content": "8"
  },
  {
    "id": 2611,
    "content": "7"
  },
  {
    "id": 2612,
    "content": "5"
  },
  {
    "id": 2618,
    "content": "topology is unknown to the caller (i"
  },
  {
    "id": 2619,
    "content": "e"
  },
  {
    "id": 2620,
    "content": ", The graph resulted from stream capture of a library call)"
  },
  {
    "id": 2623,
    "content": "The following sections explain each approach in more detail"
  },
  {
    "id": 2624,
    "content": "3"
  },
  {
    "id": 2625,
    "content": "2"
  },
  {
    "id": 2626,
    "content": "8"
  },
  {
    "id": 2627,
    "content": "7"
  },
  {
    "id": 2628,
    "content": "5"
  },
  {
    "id": 2629,
    "content": "1"
  },
  {
    "id": 2630,
    "content": "Graph Update Limitations  Kernel nodes: The owning context of the function cannot change"
  },
  {
    "id": 2634,
    "content": "e"
  },
  {
    "id": 2635,
    "content": ", cudaPitchedPtr , cudaArray_t , etc"
  },
  {
    "id": 2637,
    "content": "3"
  },
  {
    "id": 2638,
    "content": "2"
  },
  {
    "id": 2639,
    "content": "8"
  },
  {
    "id": 2640,
    "content": "7"
  },
  {
    "id": 2641,
    "content": "5"
  },
  {
    "id": 2642,
    "content": "2"
  },
  {
    "id": 2648,
    "content": "3"
  },
  {
    "id": 2649,
    "content": "2"
  },
  {
    "id": 2650,
    "content": "8"
  },
  {
    "id": 2651,
    "content": "7"
  },
  {
    "id": 2652,
    "content": "7"
  },
  {
    "id": 2653,
    "content": "2"
  },
  {
    "id": 2654,
    "content": "1"
  },
  {
    "id": 2655,
    "content": "2"
  },
  {
    "id": 2664,
    "content": "3"
  },
  {
    "id": 2665,
    "content": "2"
  },
  {
    "id": 2666,
    "content": "8"
  },
  {
    "id": 2667,
    "content": "7"
  },
  {
    "id": 2668,
    "content": "7"
  },
  {
    "id": 2669,
    "content": "2"
  },
  {
    "id": 2670,
    "content": "1"
  },
  {
    "id": 2671,
    "content": "3"
  },
  {
    "id": 2672,
    "content": "1"
  },
  {
    "id": 2677,
    "content": "3"
  },
  {
    "id": 2678,
    "content": "2"
  },
  {
    "id": 2679,
    "content": "8"
  },
  {
    "id": 2680,
    "content": "7"
  },
  {
    "id": 2681,
    "content": "8"
  },
  {
    "id": 2687,
    "content": "3"
  },
  {
    "id": 2688,
    "content": "2"
  },
  {
    "id": 2689,
    "content": "8"
  },
  {
    "id": 2690,
    "content": "7"
  },
  {
    "id": 2691,
    "content": "8"
  },
  {
    "id": 2692,
    "content": "1"
  },
  {
    "id": 2695,
    "content": "3"
  },
  {
    "id": 2696,
    "content": "2"
  },
  {
    "id": 2697,
    "content": "8"
  },
  {
    "id": 2698,
    "content": "7"
  },
  {
    "id": 2699,
    "content": "8"
  },
  {
    "id": 2700,
    "content": "2"
  },
  {
    "id": 2703,
    "content": "3"
  },
  {
    "id": 2704,
    "content": "2"
  },
  {
    "id": 2705,
    "content": "8"
  },
  {
    "id": 2706,
    "content": "7"
  },
  {
    "id": 2707,
    "content": "8"
  },
  {
    "id": 2708,
    "content": "3"
  },
  {
    "id": 2713,
    "content": "2"
  },
  {
    "id": 2714,
    "content": "8"
  },
  {
    "id": 2715,
    "content": "7"
  },
  {
    "id": 2716,
    "content": "8"
  },
  {
    "id": 2717,
    "content": "4"
  },
  {
    "id": 2719,
    "content": "WHILE conditional node"
  },
  {
    "id": 2720,
    "content": "The handle is created using cudaGraphCondAssignDefault to avoid the need for an upstream kernel"
  },
  {
    "id": 2724,
    "content": "2"
  },
  {
    "id": 2725,
    "content": "8"
  },
  {
    "id": 2726,
    "content": "8"
  },
  {
    "id": 2729,
    "content": "3"
  },
  {
    "id": 2730,
    "content": "2"
  },
  {
    "id": 2731,
    "content": "8"
  },
  {
    "id": 2732,
    "content": "8"
  },
  {
    "id": 2733,
    "content": "1"
  },
  {
    "id": 2735,
    "content": "2"
  },
  {
    "id": 2736,
    "content": "8"
  },
  {
    "id": 2737,
    "content": "8"
  },
  {
    "id": 2738,
    "content": "2"
  },
  {
    "id": 2741,
    "content": "2"
  },
  {
    "id": 2742,
    "content": "8"
  },
  {
    "id": 2743,
    "content": "9"
  },
  {
    "id": 2745,
    "content": "3"
  },
  {
    "id": 2746,
    "content": "2"
  },
  {
    "id": 2747,
    "content": "9"
  },
  {
    "id": 2748,
    "content": "Multi-Device System  3"
  },
  {
    "id": 2749,
    "content": "2"
  },
  {
    "id": 2750,
    "content": "9"
  },
  {
    "id": 2751,
    "content": "1"
  },
  {
    "id": 2754,
    "content": "2"
  },
  {
    "id": 2755,
    "content": "9"
  },
  {
    "id": 2756,
    "content": "3"
  },
  {
    "id": 2761,
    "content": "3"
  },
  {
    "id": 2762,
    "content": "2"
  },
  {
    "id": 2763,
    "content": "9"
  },
  {
    "id": 2764,
    "content": "4"
  },
  {
    "id": 2766,
    "content": "e"
  },
  {
    "id": 2767,
    "content": ", a kernel executing on one device can dereference a pointer to the memory of the other device)"
  },
  {
    "id": 2771,
    "content": "2"
  },
  {
    "id": 2772,
    "content": "9"
  },
  {
    "id": 2773,
    "content": "4"
  },
  {
    "id": 2774,
    "content": "1"
  },
  {
    "id": 2776,
    "content": "See also Allocating DMA Buffers on 64-bit Platforms"
  },
  {
    "id": 2777,
    "content": "3"
  },
  {
    "id": 2778,
    "content": "2"
  },
  {
    "id": 2779,
    "content": "9"
  },
  {
    "id": 2780,
    "content": "5"
  },
  {
    "id": 2785,
    "content": "device can start"
  },
  {
    "id": 2788,
    "content": "3"
  },
  {
    "id": 2789,
    "content": "2"
  },
  {
    "id": 2790,
    "content": "10"
  },
  {
    "id": 2792,
    "content": "0 and higher"
  },
  {
    "id": 2796,
    "content": "e"
  },
  {
    "id": 2799,
    "content": "3"
  },
  {
    "id": 2800,
    "content": "2"
  },
  {
    "id": 2801,
    "content": "11"
  },
  {
    "id": 2804,
    "content": "0 and higher"
  },
  {
    "id": 2807,
    "content": "aligned size"
  },
  {
    "id": 2810,
    "content": "Note Since CUDA 11"
  },
  {
    "id": 2812,
    "content": "x and higher"
  },
  {
    "id": 2813,
    "content": "The memory-sharing IPC APIs are still not supported on Tegra platforms"
  },
  {
    "id": 2814,
    "content": "3"
  },
  {
    "id": 2815,
    "content": "2"
  },
  {
    "id": 2816,
    "content": "12"
  },
  {
    "id": 2822,
    "content": "cudaGetLastError()"
  },
  {
    "id": 2823,
    "content": "3"
  },
  {
    "id": 2824,
    "content": "2"
  },
  {
    "id": 2825,
    "content": "13"
  },
  {
    "id": 2828,
    "content": "3"
  },
  {
    "id": 2829,
    "content": "2"
  },
  {
    "id": 2830,
    "content": "14"
  },
  {
    "id": 2832,
    "content": "3"
  },
  {
    "id": 2833,
    "content": "2"
  },
  {
    "id": 2834,
    "content": "14"
  },
  {
    "id": 2835,
    "content": "1"
  },
  {
    "id": 2838,
    "content": "texture width, height, and depth depending on the compute capability of the device"
  },
  {
    "id": 2841,
    "content": "0, 1"
  },
  {
    "id": 2842,
    "content": "0] for unsigned integer type and [-1"
  },
  {
    "id": 2843,
    "content": "0, 1"
  },
  {
    "id": 2846,
    "content": "coordinates cause the coordinates to be specified in the range [0"
  },
  {
    "id": 2847,
    "content": "0, 1"
  },
  {
    "id": 2849,
    "content": "It is valid to call the device functions of Section B"
  },
  {
    "id": 2851,
    "content": "0, 1"
  },
  {
    "id": 2861,
    "content": "3"
  },
  {
    "id": 2862,
    "content": "2"
  },
  {
    "id": 2863,
    "content": "14"
  },
  {
    "id": 2864,
    "content": "1"
  },
  {
    "id": 2865,
    "content": "3"
  },
  {
    "id": 2869,
    "content": "0 and higher"
  },
  {
    "id": 2870,
    "content": "3"
  },
  {
    "id": 2871,
    "content": "2"
  },
  {
    "id": 2872,
    "content": "14"
  },
  {
    "id": 2873,
    "content": "1"
  },
  {
    "id": 2874,
    "content": "4"
  },
  {
    "id": 2879,
    "content": "2"
  },
  {
    "id": 2880,
    "content": "14"
  },
  {
    "id": 2881,
    "content": "2"
  },
  {
    "id": 2882,
    "content": "2"
  },
  {
    "id": 2884,
    "content": "e"
  },
  {
    "id": 2886,
    "content": "Faces are ordered as indicated in Table 3"
  },
  {
    "id": 2887,
    "content": "3"
  },
  {
    "id": 2888,
    "content": "2"
  },
  {
    "id": 2889,
    "content": "14"
  },
  {
    "id": 2890,
    "content": "2"
  },
  {
    "id": 2891,
    "content": "3"
  },
  {
    "id": 2893,
    "content": "e"
  },
  {
    "id": 2895,
    "content": "3"
  },
  {
    "id": 2896,
    "content": "2"
  },
  {
    "id": 2897,
    "content": "14"
  },
  {
    "id": 2898,
    "content": "3"
  },
  {
    "id": 2899,
    "content": "CUDA Arrays  CUDA arrays are opaque memory layouts optimized for texture fetching"
  },
  {
    "id": 2902,
    "content": "3"
  },
  {
    "id": 2903,
    "content": "2"
  },
  {
    "id": 2904,
    "content": "14"
  },
  {
    "id": 2905,
    "content": "4"
  },
  {
    "id": 2908,
    "content": "3"
  },
  {
    "id": 2909,
    "content": "2"
  },
  {
    "id": 2910,
    "content": "15"
  },
  {
    "id": 2915,
    "content": "3"
  },
  {
    "id": 2916,
    "content": "2"
  },
  {
    "id": 2917,
    "content": "15"
  },
  {
    "id": 2918,
    "content": "1"
  },
  {
    "id": 2923,
    "content": "0, they can only be written by shaders, not the fixed function pipeline)"
  },
  {
    "id": 2931,
    "content": "height ; u = u * 2"
  },
  {
    "id": 2933,
    "content": "5f ;   Write positions positions [ y * width + x ] = make_float4 ( u , w , v , 1"
  },
  {
    "id": 2935,
    "content": "3"
  },
  {
    "id": 2936,
    "content": "2"
  },
  {
    "id": 2937,
    "content": "15"
  },
  {
    "id": 2938,
    "content": "2"
  },
  {
    "id": 2943,
    "content": "3"
  },
  {
    "id": 2944,
    "content": "2"
  },
  {
    "id": 2945,
    "content": "15"
  },
  {
    "id": 2946,
    "content": "2"
  },
  {
    "id": 2947,
    "content": "1"
  },
  {
    "id": 2951,
    "content": ") {"
  },
  {
    "id": 2952,
    "content": "Render ();"
  },
  {
    "id": 2953,
    "content": "}"
  },
  {
    "id": 2956,
    "content": "float v = y / ( float ) height ; u = u * 2"
  },
  {
    "id": 2959,
    "content": "2"
  },
  {
    "id": 2960,
    "content": "15"
  },
  {
    "id": 2961,
    "content": "2"
  },
  {
    "id": 2962,
    "content": "2"
  },
  {
    "id": 2967,
    "content": ") {"
  },
  {
    "id": 2971,
    "content": "2"
  },
  {
    "id": 2972,
    "content": "15"
  },
  {
    "id": 2973,
    "content": "2"
  },
  {
    "id": 2974,
    "content": "3"
  },
  {
    "id": 2979,
    "content": ") {"
  },
  {
    "id": 2983,
    "content": "2"
  },
  {
    "id": 2984,
    "content": "15"
  },
  {
    "id": 2985,
    "content": "3"
  },
  {
    "id": 2987,
    "content": "applications should create multiple CUDA contexts, one for each GPU in the SLI configuration"
  },
  {
    "id": 2988,
    "content": "While this is not a strict requirement, it avoids unnecessary data transfers between devices"
  },
  {
    "id": 2994,
    "content": "3"
  },
  {
    "id": 2995,
    "content": "2"
  },
  {
    "id": 2996,
    "content": "16"
  },
  {
    "id": 2998,
    "content": "Communication Interface"
  },
  {
    "id": 2999,
    "content": "There are two types of resources that can be imported: memory objects and synchronization objects"
  },
  {
    "id": 3003,
    "content": "All outstanding signals and waits must have completed before the semaphore object is destroyed"
  },
  {
    "id": 3004,
    "content": "3"
  },
  {
    "id": 3005,
    "content": "2"
  },
  {
    "id": 3006,
    "content": "16"
  },
  {
    "id": 3007,
    "content": "1"
  },
  {
    "id": 3008,
    "content": "Vulkan Interoperability  3"
  },
  {
    "id": 3009,
    "content": "2"
  },
  {
    "id": 3010,
    "content": "16"
  },
  {
    "id": 3011,
    "content": "1"
  },
  {
    "id": 3012,
    "content": "1"
  },
  {
    "id": 3022,
    "content": "Cluster size of 8 is forward compatible starting compute capability 9"
  },
  {
    "id": 3026,
    "content": "h for any use cases that cannot depend on the CUDA software stack"
  },
  {
    "id": 3028,
    "content": "5"
  },
  {
    "id": 3029,
    "content": "3"
  },
  {
    "id": 3032,
    "content": "e"
  },
  {
    "id": 3036,
    "content": "x, 8"
  },
  {
    "id": 3039,
    "content": "5"
  },
  {
    "id": 3040,
    "content": "3"
  },
  {
    "id": 3041,
    "content": "1"
  },
  {
    "id": 3046,
    "content": "checking that the integrated device property (see Device Enumeration ) is equal to 1"
  },
  {
    "id": 3047,
    "content": "5"
  },
  {
    "id": 3048,
    "content": "3"
  },
  {
    "id": 3049,
    "content": "2"
  },
  {
    "id": 3050,
    "content": "Device Memory Accesses  An instruction that accesses addressable memory (i"
  },
  {
    "id": 3051,
    "content": "e"
  },
  {
    "id": 3054,
    "content": "e"
  },
  {
    "id": 3062,
    "content": "e"
  },
  {
    "id": 3076,
    "content": "x )"
  },
  {
    "id": 3081,
    "content": "x, 6"
  },
  {
    "id": 3082,
    "content": "x, 7"
  },
  {
    "id": 3083,
    "content": "x, 8"
  },
  {
    "id": 3084,
    "content": "x, and 9"
  },
  {
    "id": 3085,
    "content": "0 respectively"
  },
  {
    "id": 3092,
    "content": "5"
  },
  {
    "id": 3093,
    "content": "4"
  },
  {
    "id": 3094,
    "content": "1"
  },
  {
    "id": 3096,
    "content": "(Number of Results per Clock Cycle per Multiprocessor)  Compute Capability 5"
  },
  {
    "id": 3097,
    "content": "0, 5"
  },
  {
    "id": 3098,
    "content": "2 5"
  },
  {
    "id": 3099,
    "content": "3 6"
  },
  {
    "id": 3100,
    "content": "0 6"
  },
  {
    "id": 3101,
    "content": "1 6"
  },
  {
    "id": 3102,
    "content": "2 7"
  },
  {
    "id": 3103,
    "content": "x 8"
  },
  {
    "id": 3104,
    "content": "0 8"
  },
  {
    "id": 3105,
    "content": "6 8"
  },
  {
    "id": 3106,
    "content": "9 9"
  },
  {
    "id": 3110,
    "content": "conversions 32 16 32 16 16-bit DPX Multiple instruct"
  },
  {
    "id": 3113,
    "content": "h , device_functions"
  },
  {
    "id": 3114,
    "content": "h , …)"
  },
  {
    "id": 3116,
    "content": "performance than code compiled with -prec-sqrt=true"
  },
  {
    "id": 3118,
    "content": "e"
  },
  {
    "id": 3119,
    "content": ", with -prec-div=false and -prec-sqrt=false )"
  },
  {
    "id": 3128,
    "content": "__brev and __popc map to a single instruction and __brevll and __popcll to a few instructions"
  },
  {
    "id": 3134,
    "content": "e"
  },
  {
    "id": 3136,
    "content": "141592653589793f , 1"
  },
  {
    "id": 3137,
    "content": "0f , 0"
  },
  {
    "id": 3138,
    "content": "5f"
  },
  {
    "id": 3139,
    "content": "5"
  },
  {
    "id": 3140,
    "content": "4"
  },
  {
    "id": 3141,
    "content": "2"
  },
  {
    "id": 3143,
    "content": "e"
  },
  {
    "id": 3149,
    "content": "5"
  },
  {
    "id": 3150,
    "content": "4"
  },
  {
    "id": 3151,
    "content": "3"
  },
  {
    "id": 3153,
    "content": "x as well as 8"
  },
  {
    "id": 3154,
    "content": "x and 64 operations per clock cycle for devices of compute capability 5"
  },
  {
    "id": 3155,
    "content": "x, 6"
  },
  {
    "id": 3156,
    "content": "1 and 6"
  },
  {
    "id": 3157,
    "content": "2"
  },
  {
    "id": 3159,
    "content": "5"
  },
  {
    "id": 3160,
    "content": "5"
  },
  {
    "id": 3169,
    "content": "retain most if not all the performance of cudaMalloc"
  },
  {
    "id": 3172,
    "content": "nvidia"
  },
  {
    "id": 3173,
    "content": "com/cuda-gpus lists all CUDA-enabled devices with their compute capability"
  },
  {
    "id": 3175,
    "content": "7"
  },
  {
    "id": 3176,
    "content": "C++ Language Extensions  7"
  },
  {
    "id": 3177,
    "content": "1"
  },
  {
    "id": 3179,
    "content": "7"
  },
  {
    "id": 3180,
    "content": "1"
  },
  {
    "id": 3181,
    "content": "1"
  },
  {
    "id": 3182,
    "content": "__global__  The __global__ execution space specifier declares a function as being a kernel"
  },
  {
    "id": 3184,
    "content": "0 or higher (see CUDA Dynamic Parallelism for more details)"
  },
  {
    "id": 3186,
    "content": "7"
  },
  {
    "id": 3187,
    "content": "1"
  },
  {
    "id": 3188,
    "content": "2"
  },
  {
    "id": 3190,
    "content": "7"
  },
  {
    "id": 3191,
    "content": "1"
  },
  {
    "id": 3192,
    "content": "3"
  },
  {
    "id": 3196,
    "content": "1"
  },
  {
    "id": 3197,
    "content": "4"
  },
  {
    "id": 3199,
    "content": "9 7"
  },
  {
    "id": 3200,
    "content": "1"
  },
  {
    "id": 3201,
    "content": "5"
  },
  {
    "id": 3203,
    "content": "neither function qualifier can be applied to an inline function"
  },
  {
    "id": 3204,
    "content": "7"
  },
  {
    "id": 3205,
    "content": "1"
  },
  {
    "id": 3206,
    "content": "6"
  },
  {
    "id": 3208,
    "content": "7"
  },
  {
    "id": 3209,
    "content": "2"
  },
  {
    "id": 3212,
    "content": "7"
  },
  {
    "id": 3213,
    "content": "2"
  },
  {
    "id": 3214,
    "content": "1"
  },
  {
    "id": 3217,
    "content": "7"
  },
  {
    "id": 3218,
    "content": "2"
  },
  {
    "id": 3219,
    "content": "2"
  },
  {
    "id": 3222,
    "content": "7"
  },
  {
    "id": 3223,
    "content": "2"
  },
  {
    "id": 3224,
    "content": "3"
  },
  {
    "id": 3229,
    "content": "7"
  },
  {
    "id": 3230,
    "content": "2"
  },
  {
    "id": 3231,
    "content": "4"
  },
  {
    "id": 3234,
    "content": "e"
  },
  {
    "id": 3236,
    "content": "e"
  },
  {
    "id": 3237,
    "content": ", all threads in the grid see the same address, Is read-only, i"
  },
  {
    "id": 3238,
    "content": "e"
  },
  {
    "id": 3243,
    "content": "2"
  },
  {
    "id": 3244,
    "content": "5"
  },
  {
    "id": 3246,
    "content": "7"
  },
  {
    "id": 3247,
    "content": "2"
  },
  {
    "id": 3248,
    "content": "6"
  },
  {
    "id": 3249,
    "content": "__restrict__  nvcc supports restricted pointers via the __restrict__ keyword"
  },
  {
    "id": 3257,
    "content": "} The effects here are a reduced number of memory accesses and reduced number of computations"
  },
  {
    "id": 3259,
    "content": "7"
  },
  {
    "id": 3260,
    "content": "3"
  },
  {
    "id": 3261,
    "content": "Built-in Vector Types  7"
  },
  {
    "id": 3262,
    "content": "3"
  },
  {
    "id": 3263,
    "content": "1"
  },
  {
    "id": 3269,
    "content": "3"
  },
  {
    "id": 3270,
    "content": "2"
  },
  {
    "id": 3272,
    "content": "7"
  },
  {
    "id": 3273,
    "content": "4"
  },
  {
    "id": 3275,
    "content": "They are only valid within functions that are executed on the device"
  },
  {
    "id": 3276,
    "content": "7"
  },
  {
    "id": 3277,
    "content": "4"
  },
  {
    "id": 3278,
    "content": "1"
  },
  {
    "id": 3279,
    "content": "gridDim  This variable is of type dim3 (see dim3 ) and contains the dimensions of the grid"
  },
  {
    "id": 3280,
    "content": "7"
  },
  {
    "id": 3281,
    "content": "4"
  },
  {
    "id": 3282,
    "content": "2"
  },
  {
    "id": 3284,
    "content": "7"
  },
  {
    "id": 3285,
    "content": "4"
  },
  {
    "id": 3286,
    "content": "3"
  },
  {
    "id": 3287,
    "content": "blockDim  This variable is of type dim3 (see dim3 ) and contains the dimensions of the block"
  },
  {
    "id": 3288,
    "content": "7"
  },
  {
    "id": 3289,
    "content": "4"
  },
  {
    "id": 3290,
    "content": "4"
  },
  {
    "id": 3292,
    "content": "7"
  },
  {
    "id": 3293,
    "content": "4"
  },
  {
    "id": 3294,
    "content": "5"
  },
  {
    "id": 3296,
    "content": "7"
  },
  {
    "id": 3297,
    "content": "5"
  },
  {
    "id": 3299,
    "content": "from or write to the same memory location without synchronization"
  },
  {
    "id": 3307,
    "content": "The fourth outcome is not possible, because the first write must be visible before the second write"
  },
  {
    "id": 3317,
    "content": "Devices of compute capability 2"
  },
  {
    "id": 3318,
    "content": "x and higher support three variations of __syncthreads() described below"
  },
  {
    "id": 3323,
    "content": "Note For"
  },
  {
    "id": 3325,
    "content": "Otherwise, the behavior is undefined"
  },
  {
    "id": 3326,
    "content": "7"
  },
  {
    "id": 3327,
    "content": "7"
  },
  {
    "id": 3329,
    "content": "7"
  },
  {
    "id": 3330,
    "content": "8"
  },
  {
    "id": 3332,
    "content": "border and clamp addressing modes are supported"
  },
  {
    "id": 3333,
    "content": "For integer types, it may optionally promote the integer to single-precision floating point"
  },
  {
    "id": 3334,
    "content": "7"
  },
  {
    "id": 3335,
    "content": "8"
  },
  {
    "id": 3336,
    "content": "1"
  },
  {
    "id": 3337,
    "content": "2"
  },
  {
    "id": 3339,
    "content": "7"
  },
  {
    "id": 3340,
    "content": "8"
  },
  {
    "id": 3341,
    "content": "1"
  },
  {
    "id": 3342,
    "content": "3"
  },
  {
    "id": 3344,
    "content": "7"
  },
  {
    "id": 3345,
    "content": "8"
  },
  {
    "id": 3346,
    "content": "1"
  },
  {
    "id": 3347,
    "content": "4"
  },
  {
    "id": 3349,
    "content": "7"
  },
  {
    "id": 3350,
    "content": "8"
  },
  {
    "id": 3351,
    "content": "1"
  },
  {
    "id": 3352,
    "content": "5"
  },
  {
    "id": 3354,
    "content": "7"
  },
  {
    "id": 3355,
    "content": "8"
  },
  {
    "id": 3356,
    "content": "1"
  },
  {
    "id": 3357,
    "content": "6"
  },
  {
    "id": 3359,
    "content": "If not, the values fetched will be zeros"
  },
  {
    "id": 3360,
    "content": "7"
  },
  {
    "id": 3361,
    "content": "8"
  },
  {
    "id": 3362,
    "content": "1"
  },
  {
    "id": 3363,
    "content": "7"
  },
  {
    "id": 3365,
    "content": "7"
  },
  {
    "id": 3366,
    "content": "8"
  },
  {
    "id": 3367,
    "content": "1"
  },
  {
    "id": 3368,
    "content": "8"
  },
  {
    "id": 3370,
    "content": "7"
  },
  {
    "id": 3371,
    "content": "8"
  },
  {
    "id": 3372,
    "content": "1"
  },
  {
    "id": 3373,
    "content": "9"
  },
  {
    "id": 3375,
    "content": "7"
  },
  {
    "id": 3376,
    "content": "8"
  },
  {
    "id": 3377,
    "content": "1"
  },
  {
    "id": 3378,
    "content": "10"
  },
  {
    "id": 3380,
    "content": "7"
  },
  {
    "id": 3381,
    "content": "8"
  },
  {
    "id": 3382,
    "content": "1"
  },
  {
    "id": 3383,
    "content": "11"
  },
  {
    "id": 3385,
    "content": "7"
  },
  {
    "id": 3386,
    "content": "8"
  },
  {
    "id": 3387,
    "content": "1"
  },
  {
    "id": 3388,
    "content": "12"
  },
  {
    "id": 3390,
    "content": "7"
  },
  {
    "id": 3391,
    "content": "8"
  },
  {
    "id": 3392,
    "content": "1"
  },
  {
    "id": 3393,
    "content": "13"
  },
  {
    "id": 3395,
    "content": "7"
  },
  {
    "id": 3396,
    "content": "8"
  },
  {
    "id": 3397,
    "content": "1"
  },
  {
    "id": 3398,
    "content": "14"
  },
  {
    "id": 3400,
    "content": "7"
  },
  {
    "id": 3401,
    "content": "8"
  },
  {
    "id": 3402,
    "content": "1"
  },
  {
    "id": 3403,
    "content": "15"
  },
  {
    "id": 3405,
    "content": "7"
  },
  {
    "id": 3406,
    "content": "8"
  },
  {
    "id": 3407,
    "content": "1"
  },
  {
    "id": 3408,
    "content": "16"
  },
  {
    "id": 3410,
    "content": "7"
  },
  {
    "id": 3411,
    "content": "8"
  },
  {
    "id": 3412,
    "content": "1"
  },
  {
    "id": 3413,
    "content": "17"
  },
  {
    "id": 3415,
    "content": "7"
  },
  {
    "id": 3416,
    "content": "8"
  },
  {
    "id": 3417,
    "content": "1"
  },
  {
    "id": 3418,
    "content": "18"
  },
  {
    "id": 3420,
    "content": "7"
  },
  {
    "id": 3421,
    "content": "8"
  },
  {
    "id": 3422,
    "content": "1"
  },
  {
    "id": 3423,
    "content": "19"
  },
  {
    "id": 3425,
    "content": "8"
  },
  {
    "id": 3426,
    "content": "1"
  },
  {
    "id": 3427,
    "content": "20"
  },
  {
    "id": 3429,
    "content": "7"
  },
  {
    "id": 3430,
    "content": "8"
  },
  {
    "id": 3431,
    "content": "1"
  },
  {
    "id": 3432,
    "content": "21"
  },
  {
    "id": 3434,
    "content": "7"
  },
  {
    "id": 3435,
    "content": "8"
  },
  {
    "id": 3436,
    "content": "1"
  },
  {
    "id": 3437,
    "content": "22"
  },
  {
    "id": 3439,
    "content": "7"
  },
  {
    "id": 3440,
    "content": "8"
  },
  {
    "id": 3441,
    "content": "1"
  },
  {
    "id": 3442,
    "content": "23"
  },
  {
    "id": 3444,
    "content": "7"
  },
  {
    "id": 3445,
    "content": "8"
  },
  {
    "id": 3446,
    "content": "1"
  },
  {
    "id": 3447,
    "content": "24"
  },
  {
    "id": 3449,
    "content": "7"
  },
  {
    "id": 3450,
    "content": "8"
  },
  {
    "id": 3451,
    "content": "1"
  },
  {
    "id": 3452,
    "content": "25"
  },
  {
    "id": 3454,
    "content": "7"
  },
  {
    "id": 3455,
    "content": "8"
  },
  {
    "id": 3456,
    "content": "1"
  },
  {
    "id": 3457,
    "content": "26"
  },
  {
    "id": 3459,
    "content": "7"
  },
  {
    "id": 3460,
    "content": "8"
  },
  {
    "id": 3461,
    "content": "1"
  },
  {
    "id": 3462,
    "content": "27"
  },
  {
    "id": 3464,
    "content": "7"
  },
  {
    "id": 3465,
    "content": "8"
  },
  {
    "id": 3466,
    "content": "1"
  },
  {
    "id": 3467,
    "content": "28"
  },
  {
    "id": 3469,
    "content": "7"
  },
  {
    "id": 3470,
    "content": "8"
  },
  {
    "id": 3471,
    "content": "1"
  },
  {
    "id": 3472,
    "content": "29"
  },
  {
    "id": 3474,
    "content": "7"
  },
  {
    "id": 3475,
    "content": "8"
  },
  {
    "id": 3476,
    "content": "1"
  },
  {
    "id": 3477,
    "content": "30"
  },
  {
    "id": 3479,
    "content": "The level-of-detail used is given by level"
  },
  {
    "id": 3480,
    "content": "7"
  },
  {
    "id": 3481,
    "content": "8"
  },
  {
    "id": 3482,
    "content": "1"
  },
  {
    "id": 3483,
    "content": "31"
  },
  {
    "id": 3485,
    "content": "7"
  },
  {
    "id": 3486,
    "content": "8"
  },
  {
    "id": 3487,
    "content": "1"
  },
  {
    "id": 3488,
    "content": "32"
  },
  {
    "id": 3490,
    "content": "7"
  },
  {
    "id": 3491,
    "content": "8"
  },
  {
    "id": 3492,
    "content": "1"
  },
  {
    "id": 3493,
    "content": "33"
  },
  {
    "id": 3495,
    "content": "7"
  },
  {
    "id": 3496,
    "content": "9"
  },
  {
    "id": 3497,
    "content": "Surface Functions  Surface functions are only supported by devices of compute capability 2"
  },
  {
    "id": 3498,
    "content": "0 and higher"
  },
  {
    "id": 3501,
    "content": "7"
  },
  {
    "id": 3502,
    "content": "9"
  },
  {
    "id": 3503,
    "content": "1"
  },
  {
    "id": 3504,
    "content": "Surface Object API  7"
  },
  {
    "id": 3505,
    "content": "9"
  },
  {
    "id": 3506,
    "content": "1"
  },
  {
    "id": 3507,
    "content": "1"
  },
  {
    "id": 3509,
    "content": "7"
  },
  {
    "id": 3510,
    "content": "9"
  },
  {
    "id": 3511,
    "content": "1"
  },
  {
    "id": 3512,
    "content": "2"
  },
  {
    "id": 3514,
    "content": "7"
  },
  {
    "id": 3515,
    "content": "9"
  },
  {
    "id": 3516,
    "content": "1"
  },
  {
    "id": 3517,
    "content": "3"
  },
  {
    "id": 3519,
    "content": "7"
  },
  {
    "id": 3520,
    "content": "9"
  },
  {
    "id": 3521,
    "content": "1"
  },
  {
    "id": 3522,
    "content": "4"
  },
  {
    "id": 3524,
    "content": "7"
  },
  {
    "id": 3525,
    "content": "9"
  },
  {
    "id": 3526,
    "content": "1"
  },
  {
    "id": 3527,
    "content": "5"
  },
  {
    "id": 3529,
    "content": "7"
  },
  {
    "id": 3530,
    "content": "9"
  },
  {
    "id": 3531,
    "content": "1"
  },
  {
    "id": 3532,
    "content": "6"
  },
  {
    "id": 3534,
    "content": "7"
  },
  {
    "id": 3535,
    "content": "9"
  },
  {
    "id": 3536,
    "content": "1"
  },
  {
    "id": 3537,
    "content": "7"
  },
  {
    "id": 3539,
    "content": "7"
  },
  {
    "id": 3540,
    "content": "9"
  },
  {
    "id": 3541,
    "content": "1"
  },
  {
    "id": 3542,
    "content": "8"
  },
  {
    "id": 3544,
    "content": "7"
  },
  {
    "id": 3545,
    "content": "9"
  },
  {
    "id": 3546,
    "content": "1"
  },
  {
    "id": 3547,
    "content": "9"
  },
  {
    "id": 3549,
    "content": "and y, and index layer"
  },
  {
    "id": 3550,
    "content": "7"
  },
  {
    "id": 3551,
    "content": "9"
  },
  {
    "id": 3552,
    "content": "1"
  },
  {
    "id": 3553,
    "content": "10"
  },
  {
    "id": 3555,
    "content": "7"
  },
  {
    "id": 3556,
    "content": "9"
  },
  {
    "id": 3557,
    "content": "1"
  },
  {
    "id": 3558,
    "content": "11"
  },
  {
    "id": 3560,
    "content": "face"
  },
  {
    "id": 3561,
    "content": "7"
  },
  {
    "id": 3562,
    "content": "9"
  },
  {
    "id": 3563,
    "content": "1"
  },
  {
    "id": 3564,
    "content": "12"
  },
  {
    "id": 3566,
    "content": "7"
  },
  {
    "id": 3567,
    "content": "9"
  },
  {
    "id": 3568,
    "content": "1"
  },
  {
    "id": 3569,
    "content": "13"
  },
  {
    "id": 3571,
    "content": "byte coordinate x and y, and index layerFace"
  },
  {
    "id": 3572,
    "content": "7"
  },
  {
    "id": 3573,
    "content": "9"
  },
  {
    "id": 3574,
    "content": "1"
  },
  {
    "id": 3575,
    "content": "14"
  },
  {
    "id": 3577,
    "content": "7"
  },
  {
    "id": 3578,
    "content": "10"
  },
  {
    "id": 3580,
    "content": "0 and higher"
  },
  {
    "id": 3582,
    "content": "double2"
  },
  {
    "id": 3583,
    "content": "Similarly, with the cuda_bf16"
  },
  {
    "id": 3584,
    "content": "h header included, T can also be __nv_bfloat16 or __nv_bfloat162"
  },
  {
    "id": 3585,
    "content": "The operation is cached in the read-only data cache (see Global Memory )"
  },
  {
    "id": 3586,
    "content": "7"
  },
  {
    "id": 3587,
    "content": "11"
  },
  {
    "id": 3589,
    "content": "0 and higher"
  },
  {
    "id": 3593,
    "content": "0 and higher"
  },
  {
    "id": 3597,
    "content": "The former number is greater than the latter since threads are time sliced"
  },
  {
    "id": 3598,
    "content": "7"
  },
  {
    "id": 3599,
    "content": "14"
  },
  {
    "id": 3603,
    "content": "suffix (example: atomicAdd_block ) are atomic at scope cuda::thread_scope_block"
  },
  {
    "id": 3608,
    "content": "The 128-bit atomicExch() is only supported by devices of compute capability 9"
  },
  {
    "id": 3609,
    "content": "x and higher"
  },
  {
    "id": 3610,
    "content": "7"
  },
  {
    "id": 3611,
    "content": "14"
  },
  {
    "id": 3612,
    "content": "1"
  },
  {
    "id": 3613,
    "content": "4"
  },
  {
    "id": 3616,
    "content": "0 and higher"
  },
  {
    "id": 3617,
    "content": "7"
  },
  {
    "id": 3618,
    "content": "14"
  },
  {
    "id": 3619,
    "content": "1"
  },
  {
    "id": 3620,
    "content": "5"
  },
  {
    "id": 3623,
    "content": "0 and higher"
  },
  {
    "id": 3624,
    "content": "7"
  },
  {
    "id": 3625,
    "content": "14"
  },
  {
    "id": 3626,
    "content": "1"
  },
  {
    "id": 3627,
    "content": "6"
  },
  {
    "id": 3629,
    "content": "7"
  },
  {
    "id": 3630,
    "content": "14"
  },
  {
    "id": 3631,
    "content": "1"
  },
  {
    "id": 3632,
    "content": "7"
  },
  {
    "id": 3634,
    "content": "7"
  },
  {
    "id": 3635,
    "content": "14"
  },
  {
    "id": 3636,
    "content": "1"
  },
  {
    "id": 3637,
    "content": "8"
  },
  {
    "id": 3640,
    "content": "atomicCAS() is only supported by devices of compute capability 9"
  },
  {
    "id": 3641,
    "content": "x and higher"
  },
  {
    "id": 3642,
    "content": "7"
  },
  {
    "id": 3643,
    "content": "14"
  },
  {
    "id": 3644,
    "content": "2"
  },
  {
    "id": 3645,
    "content": "Bitwise Functions  7"
  },
  {
    "id": 3646,
    "content": "14"
  },
  {
    "id": 3647,
    "content": "2"
  },
  {
    "id": 3648,
    "content": "1"
  },
  {
    "id": 3650,
    "content": "address The 64-bit version of atomicAnd() is only supported by devices of compute capability 5"
  },
  {
    "id": 3651,
    "content": "0 and higher"
  },
  {
    "id": 3652,
    "content": "7"
  },
  {
    "id": 3653,
    "content": "14"
  },
  {
    "id": 3654,
    "content": "2"
  },
  {
    "id": 3655,
    "content": "2"
  },
  {
    "id": 3657,
    "content": "The 64-bit version of atomicOr() is only supported by devices of compute capability 5"
  },
  {
    "id": 3658,
    "content": "0 and higher"
  },
  {
    "id": 3659,
    "content": "7"
  },
  {
    "id": 3660,
    "content": "14"
  },
  {
    "id": 3661,
    "content": "2"
  },
  {
    "id": 3662,
    "content": "3"
  },
  {
    "id": 3664,
    "content": "address The 64-bit version of atomicXor() is only supported by devices of compute capability 5"
  },
  {
    "id": 3665,
    "content": "0 and higher"
  },
  {
    "id": 3666,
    "content": "7"
  },
  {
    "id": 3667,
    "content": "15"
  },
  {
    "id": 3669,
    "content": "7"
  },
  {
    "id": 3670,
    "content": "15"
  },
  {
    "id": 3671,
    "content": "1"
  },
  {
    "id": 3673,
    "content": "7"
  },
  {
    "id": 3674,
    "content": "15"
  },
  {
    "id": 3675,
    "content": "2"
  },
  {
    "id": 3677,
    "content": "7"
  },
  {
    "id": 3678,
    "content": "15"
  },
  {
    "id": 3679,
    "content": "3"
  },
  {
    "id": 3681,
    "content": "7"
  },
  {
    "id": 3682,
    "content": "15"
  },
  {
    "id": 3683,
    "content": "4"
  },
  {
    "id": 3685,
    "content": "Only supported for compute architectures greater than or equal to 7"
  },
  {
    "id": 3686,
    "content": "x or later"
  },
  {
    "id": 3687,
    "content": "7"
  },
  {
    "id": 3688,
    "content": "15"
  },
  {
    "id": 3689,
    "content": "5"
  },
  {
    "id": 3691,
    "content": "to"
  },
  {
    "id": 3692,
    "content": "global instruction on the generic address denoted by ptr"
  },
  {
    "id": 3693,
    "content": "7"
  },
  {
    "id": 3694,
    "content": "16"
  },
  {
    "id": 3695,
    "content": "2"
  },
  {
    "id": 3697,
    "content": "to"
  },
  {
    "id": 3698,
    "content": "shared instruction on the generic address denoted by ptr"
  },
  {
    "id": 3699,
    "content": "7"
  },
  {
    "id": 3700,
    "content": "16"
  },
  {
    "id": 3701,
    "content": "3"
  },
  {
    "id": 3703,
    "content": "to"
  },
  {
    "id": 3704,
    "content": "const instruction on the generic address denoted by ptr"
  },
  {
    "id": 3705,
    "content": "7"
  },
  {
    "id": 3706,
    "content": "16"
  },
  {
    "id": 3707,
    "content": "4"
  },
  {
    "id": 3709,
    "content": "to"
  },
  {
    "id": 3710,
    "content": "local instruction on the generic address denoted by ptr"
  },
  {
    "id": 3711,
    "content": "7"
  },
  {
    "id": 3712,
    "content": "16"
  },
  {
    "id": 3713,
    "content": "5"
  },
  {
    "id": 3715,
    "content": "7"
  },
  {
    "id": 3716,
    "content": "16"
  },
  {
    "id": 3717,
    "content": "6"
  },
  {
    "id": 3719,
    "content": "7"
  },
  {
    "id": 3720,
    "content": "16"
  },
  {
    "id": 3721,
    "content": "7"
  },
  {
    "id": 3723,
    "content": "7"
  },
  {
    "id": 3724,
    "content": "16"
  },
  {
    "id": 3725,
    "content": "8"
  },
  {
    "id": 3728,
    "content": "It is supported with compute capability 5"
  },
  {
    "id": 3729,
    "content": "2 or higher"
  },
  {
    "id": 3730,
    "content": "7"
  },
  {
    "id": 3731,
    "content": "17"
  },
  {
    "id": 3732,
    "content": "3"
  },
  {
    "id": 3734,
    "content": "} 7"
  },
  {
    "id": 3735,
    "content": "18"
  },
  {
    "id": 3737,
    "content": "7"
  },
  {
    "id": 3738,
    "content": "18"
  },
  {
    "id": 3739,
    "content": "1"
  },
  {
    "id": 3742,
    "content": "7"
  },
  {
    "id": 3743,
    "content": "18"
  },
  {
    "id": 3744,
    "content": "2"
  },
  {
    "id": 3749,
    "content": "22"
  },
  {
    "id": 3750,
    "content": "3"
  },
  {
    "id": 3751,
    "content": "3"
  },
  {
    "id": 3753,
    "content": "threadIdx x , value ); } int main () { warpReduce >> (); cudaDeviceSynchronize (); return 0 ; } 7"
  },
  {
    "id": 3754,
    "content": "23"
  },
  {
    "id": 3756,
    "content": "It is supported with compute capability 7"
  },
  {
    "id": 3757,
    "content": "0 or higher"
  },
  {
    "id": 3758,
    "content": "7"
  },
  {
    "id": 3759,
    "content": "23"
  },
  {
    "id": 3760,
    "content": "3"
  },
  {
    "id": 3761,
    "content": "Example  The following code implements a mutex with exponential back-off"
  },
  {
    "id": 3773,
    "content": "The layout of the output matrix must be specified as either mem_row_major or mem_col_major"
  },
  {
    "id": 3778,
    "content": "wmma :: fragment frag ; float alpha = 0"
  },
  {
    "id": 3779,
    "content": "5f ;   Same value for all threads in warp /*"
  },
  {
    "id": 3780,
    "content": "*/ for ( int t = 0 ; t =10 bits)"
  },
  {
    "id": 3783,
    "content": "24"
  },
  {
    "id": 3784,
    "content": "3"
  },
  {
    "id": 3786,
    "content": "0 and higher"
  },
  {
    "id": 3787,
    "content": "The mma_sync operation will be performed with the"
  },
  {
    "id": 3788,
    "content": "rn (rounds to nearest even) rounding modifier"
  },
  {
    "id": 3789,
    "content": "7"
  },
  {
    "id": 3790,
    "content": "24"
  },
  {
    "id": 3791,
    "content": "4"
  },
  {
    "id": 3799,
    "content": "e"
  },
  {
    "id": 3800,
    "content": ", multiple of 16 bytes in both cases)"
  },
  {
    "id": 3802,
    "content": "consists of a logical operation bmmaBitOp followed by the accumulation defined by bmmaAccumulateOp"
  },
  {
    "id": 3804,
    "content": "0 and higher"
  },
  {
    "id": 3805,
    "content": "The accumulate op is always bmmaAccumulateOpPOPC which counts the number of set bits"
  },
  {
    "id": 3806,
    "content": "7"
  },
  {
    "id": 3807,
    "content": "24"
  },
  {
    "id": 3808,
    "content": "5"
  },
  {
    "id": 3813,
    "content": "compute_70 - code = sm_70 fragA"
  },
  {
    "id": 3818,
    "content": "g"
  },
  {
    "id": 3819,
    "content": "wmma::store_matrix_sync(dst, …); ) and then it can be safely passed to bar() as a pointer type [e"
  },
  {
    "id": 3820,
    "content": "g"
  },
  {
    "id": 3822,
    "content": "7"
  },
  {
    "id": 3823,
    "content": "24"
  },
  {
    "id": 3824,
    "content": "6"
  },
  {
    "id": 3825,
    "content": "Element Types and Matrix Sizes  Tensor Cores support a variety of element types and matrix sizes"
  },
  {
    "id": 3826,
    "content": "Example  The following code implements a 16x16x16 matrix multiplication in a single warp"
  },
  {
    "id": 3829,
    "content": "25"
  },
  {
    "id": 3831,
    "content": "Devices of compute capability 8"
  },
  {
    "id": 3833,
    "content": "On devices with compute capability below 8"
  },
  {
    "id": 3834,
    "content": "0 but starting 7"
  },
  {
    "id": 3835,
    "content": "0, these barriers are available without hardware acceleration"
  },
  {
    "id": 3836,
    "content": "nvcuda::experimental::awbarrier is deprecated in favor of cuda::barrier"
  },
  {
    "id": 3837,
    "content": "7"
  },
  {
    "id": 3838,
    "content": "26"
  },
  {
    "id": 3839,
    "content": "1"
  },
  {
    "id": 3841,
    "content": "sync() when using Cooperative Groups"
  },
  {
    "id": 3844,
    "content": "size() in this example"
  },
  {
    "id": 3847,
    "content": "The second parameter of init() is the expected arrival count , i"
  },
  {
    "id": 3848,
    "content": "e"
  },
  {
    "id": 3850,
    "content": "wait(std::move(token))"
  },
  {
    "id": 3852,
    "content": "e"
  },
  {
    "id": 3853,
    "content": ", cooperative_groups::this_thread_block()"
  },
  {
    "id": 3855,
    "content": "In contrast this_thread_block"
  },
  {
    "id": 3857,
    "content": "7"
  },
  {
    "id": 3858,
    "content": "26"
  },
  {
    "id": 3859,
    "content": "4"
  },
  {
    "id": 3861,
    "content": "arrive()"
  },
  {
    "id": 3862,
    "content": "When the last call to bar"
  },
  {
    "id": 3864,
    "content": "A token object of class cuda::barrier::arrival_token , as returned from token=bar"
  },
  {
    "id": 3865,
    "content": "arrive() , is associated with the current phase of the barrier"
  },
  {
    "id": 3866,
    "content": "A call to bar"
  },
  {
    "id": 3867,
    "content": "wait(std::move(token)) blocks the calling thread while the cuda::barrier is in the current phase, i"
  },
  {
    "id": 3868,
    "content": "e"
  },
  {
    "id": 3873,
    "content": "7"
  },
  {
    "id": 3874,
    "content": "26"
  },
  {
    "id": 3875,
    "content": "5"
  },
  {
    "id": 3881,
    "content": "barrier once they are unblocked from the wait"
  },
  {
    "id": 3885,
    "content": "26"
  },
  {
    "id": 3886,
    "content": "8"
  },
  {
    "id": 3888,
    "content": "7"
  },
  {
    "id": 3889,
    "content": "26"
  },
  {
    "id": 3890,
    "content": "8"
  },
  {
    "id": 3891,
    "content": "1"
  },
  {
    "id": 3893,
    "content": "26"
  },
  {
    "id": 3894,
    "content": "8"
  },
  {
    "id": 3895,
    "content": "2"
  },
  {
    "id": 3902,
    "content": "7"
  },
  {
    "id": 3903,
    "content": "27"
  },
  {
    "id": 3904,
    "content": "6"
  },
  {
    "id": 3905,
    "content": "2"
  },
  {
    "id": 3906,
    "content": "Trivially copyable  On devices with compute capability 8"
  },
  {
    "id": 3907,
    "content": "0, the cp"
  },
  {
    "id": 3908,
    "content": "async family of instructions allows copying data from global to shared memory asynchronously"
  },
  {
    "id": 3910,
    "content": "7"
  },
  {
    "id": 3911,
    "content": "27"
  },
  {
    "id": 3912,
    "content": "6"
  },
  {
    "id": 3913,
    "content": "3"
  },
  {
    "id": 3928,
    "content": "thread_rank () % 2 == 0"
  },
  {
    "id": 3930,
    "content": "size () / 2 ;   Map adjacent even and odd threads to the same id: const int thread_idx = block"
  },
  {
    "id": 3935,
    "content": "make_pipeline (); auto block_batch = [ & ]( size_t batch ) -> int { return block"
  },
  {
    "id": 3937,
    "content": "7"
  },
  {
    "id": 3938,
    "content": "28"
  },
  {
    "id": 3939,
    "content": "4"
  },
  {
    "id": 3941,
    "content": "When compiling without ISO C++ 2011 compatibility, include the header"
  },
  {
    "id": 3942,
    "content": "7"
  },
  {
    "id": 3943,
    "content": "28"
  },
  {
    "id": 3944,
    "content": "4"
  },
  {
    "id": 3945,
    "content": "1"
  },
  {
    "id": 3950,
    "content": "proxy"
  },
  {
    "id": 3951,
    "content": "async"
  },
  {
    "id": 3952,
    "content": "shared::cta instruction is used"
  },
  {
    "id": 3956,
    "content": "expect_tx"
  },
  {
    "id": 3961,
    "content": "To make the writes visible to subsequent bulk-asynchronous copies, the fence"
  },
  {
    "id": 3962,
    "content": "proxy"
  },
  {
    "id": 3963,
    "content": "async"
  },
  {
    "id": 3964,
    "content": "shared::cta instruction is used"
  },
  {
    "id": 3968,
    "content": "0"
  },
  {
    "id": 3969,
    "content": "Shared memory barrier address Must be 8 byte aligned (this is guaranteed by cuda::barrier )"
  },
  {
    "id": 3970,
    "content": "Size of transfer Must be a multiple of 16 bytes"
  },
  {
    "id": 3971,
    "content": "7"
  },
  {
    "id": 3972,
    "content": "29"
  },
  {
    "id": 3973,
    "content": "2"
  },
  {
    "id": 3975,
    "content": "-lcuda ) or by using the cudaGetDriverEntryPoint API"
  },
  {
    "id": 3984,
    "content": "6”"
  },
  {
    "id": 3993,
    "content": "0"
  },
  {
    "id": 3995,
    "content": "0"
  },
  {
    "id": 3996,
    "content": "Shared memory address Must be 128 byte aligned"
  },
  {
    "id": 3997,
    "content": "7"
  },
  {
    "id": 3998,
    "content": "29"
  },
  {
    "id": 3999,
    "content": "2"
  },
  {
    "id": 4000,
    "content": "1"
  },
  {
    "id": 4002,
    "content": "The cp"
  },
  {
    "id": 4003,
    "content": "async"
  },
  {
    "id": 4007,
    "content": "7"
  },
  {
    "id": 4008,
    "content": "31"
  },
  {
    "id": 4009,
    "content": "Assertion  Assertion is only supported by devices of compute capability 2"
  },
  {
    "id": 4010,
    "content": "x and higher"
  },
  {
    "id": 4011,
    "content": "void assert ( int expression ); stops the kernel execution if expression is equal to zero"
  },
  {
    "id": 4014,
    "content": "The format of this message is as follows: ::: block: [blockId x,blockId"
  },
  {
    "id": 4015,
    "content": "x,blockIdx"
  },
  {
    "id": 4016,
    "content": "z], thread: [threadIdx x,threadIdx y,threadIdx"
  },
  {
    "id": 4017,
    "content": "z] Assertion `` failed"
  },
  {
    "id": 4018,
    "content": "Any subsequent host-side synchronization calls made for the same device will return cudaErrorAssert"
  },
  {
    "id": 4020,
    "content": "For example, the following program from source file test"
  },
  {
    "id": 4022,
    "content": "failed"
  },
  {
    "id": 4023,
    "content": "They can affect performance and it is therefore recommended to disable them in production code"
  },
  {
    "id": 4025,
    "content": "h"
  },
  {
    "id": 4027,
    "content": "7"
  },
  {
    "id": 4028,
    "content": "32"
  },
  {
    "id": 4030,
    "content": "7"
  },
  {
    "id": 4031,
    "content": "33"
  },
  {
    "id": 4033,
    "content": "Formatted Output  Formatted output is only supported by devices of compute capability 2"
  },
  {
    "id": 4034,
    "content": "x and higher"
  },
  {
    "id": 4035,
    "content": "int printf ( const char * format [, arg ,"
  },
  {
    "id": 4036,
    "content": "]); prints formatted output from a kernel to a host-side output stream"
  },
  {
    "id": 4041,
    "content": "If an internal error occurs, -2 is returned"
  },
  {
    "id": 4042,
    "content": "7"
  },
  {
    "id": 4043,
    "content": "34"
  },
  {
    "id": 4044,
    "content": "1"
  },
  {
    "id": 4046,
    "content": "flag, width, precision, size and type, whether or not overall they form a valid format specifier"
  },
  {
    "id": 4048,
    "content": "7"
  },
  {
    "id": 4049,
    "content": "34"
  },
  {
    "id": 4050,
    "content": "2"
  },
  {
    "id": 4051,
    "content": "Limitations  Final formatting of the printf() output takes place on the host system"
  },
  {
    "id": 4055,
    "content": "It is recommended that the compilation platform matches the execution platform to ensure safety"
  },
  {
    "id": 4059,
    "content": "Prior to executing a stream callback added by cudaStreamAddCallback or cuStreamAddCallback"
  },
  {
    "id": 4060,
    "content": "The user must call cudaDeviceReset() or cuCtxDestroy() explicitly, as shown in the examples below"
  },
  {
    "id": 4063,
    "content": "7"
  },
  {
    "id": 4064,
    "content": "34"
  },
  {
    "id": 4065,
    "content": "3"
  },
  {
    "id": 4067,
    "content": "34"
  },
  {
    "id": 4068,
    "content": "4"
  },
  {
    "id": 4070,
    "content": "printf() command, so there are as many lines of output as there were threads launched in the grid"
  },
  {
    "id": 4071,
    "content": "As expected, global values (i"
  },
  {
    "id": 4072,
    "content": "e"
  },
  {
    "id": 4073,
    "content": ", float f ) are common between all threads, and local values (i"
  },
  {
    "id": 4074,
    "content": "e"
  },
  {
    "id": 4075,
    "content": ", threadIdx"
  },
  {
    "id": 4076,
    "content": "x ) are distinct per-thread"
  },
  {
    "id": 4078,
    "content": "2345f ); cudaDeviceSynchronize (); return 0 ; } will output: Hello thread 0, f=1"
  },
  {
    "id": 4080,
    "content": "7"
  },
  {
    "id": 4081,
    "content": "35"
  },
  {
    "id": 4083,
    "content": "x and higher"
  },
  {
    "id": 4088,
    "content": "7"
  },
  {
    "id": 4089,
    "content": "35"
  },
  {
    "id": 4090,
    "content": "1"
  },
  {
    "id": 4094,
    "content": "7"
  },
  {
    "id": 4095,
    "content": "35"
  },
  {
    "id": 4096,
    "content": "2"
  },
  {
    "id": 4098,
    "content": "e"
  },
  {
    "id": 4099,
    "content": ", by calling any of the free memory functions from Device Memory )"
  },
  {
    "id": 4100,
    "content": "Similarly, memory allocated via the runtime (i"
  },
  {
    "id": 4101,
    "content": "e"
  },
  {
    "id": 4103,
    "content": "e"
  },
  {
    "id": 4107,
    "content": "35"
  },
  {
    "id": 4108,
    "content": "3"
  },
  {
    "id": 4109,
    "content": "3"
  },
  {
    "id": 4112,
    "content": "; } 7"
  },
  {
    "id": 4113,
    "content": "36"
  },
  {
    "id": 4116,
    "content": "shared memory required for static allocation"
  },
  {
    "id": 4117,
    "content": "Compute capability 9"
  },
  {
    "id": 4119,
    "content": "cluster can be launched using cudaLaunchKernelEx API"
  },
  {
    "id": 4121,
    "content": "config , Func , parameter ); } 7"
  },
  {
    "id": 4122,
    "content": "37"
  },
  {
    "id": 4126,
    "content": ") {"
  },
  {
    "id": 4128,
    "content": "maxntid PTX directive"
  },
  {
    "id": 4130,
    "content": "minnctapersm PTX directive"
  },
  {
    "id": 4132,
    "content": "maxclusterrank PTX directive"
  },
  {
    "id": 4138,
    "content": "void __launch_bounds__ ( MY_KERNEL_MAX_THREADS , MY_KERNEL_MIN_BLOCKS ) MyKernel ("
  },
  {
    "id": 4139,
    "content": ") {"
  },
  {
    "id": 4143,
    "content": "major >= 2"
  },
  {
    "id": 4144,
    "content": "2 * THREADS_PER_BLOCK : THREADS_PER_BLOCK ); MyKernel >> ("
  },
  {
    "id": 4146,
    "content": "The __launch_bounds__() and __maxnreg__() qualifiers cannot be applied to the same kernel"
  },
  {
    "id": 4148,
    "content": "7"
  },
  {
    "id": 4149,
    "content": "38"
  },
  {
    "id": 4151,
    "content": "__global__ void __maxnreg__ ( maxNumberRegistersPerThread ) MyKernel ("
  },
  {
    "id": 4152,
    "content": ") {"
  },
  {
    "id": 4154,
    "content": "maxnreg PTX directive"
  },
  {
    "id": 4155,
    "content": "The value of maxrregcount is ignored for functions with the __maxnreg__ qualifier"
  },
  {
    "id": 4156,
    "content": "7"
  },
  {
    "id": 4157,
    "content": "39"
  },
  {
    "id": 4158,
    "content": "#pragma unroll  By default, the compiler unrolls small loops with a known trip count"
  },
  {
    "id": 4160,
    "content": "40"
  },
  {
    "id": 4163,
    "content": "u32 u32 u32"
  },
  {
    "id": 4166,
    "content": "7"
  },
  {
    "id": 4167,
    "content": "41"
  },
  {
    "id": 4171,
    "content": "e"
  },
  {
    "id": 4172,
    "content": ", the normal severity of the message as modified by any command-line options)"
  },
  {
    "id": 4175,
    "content": "Removal Notice: The support of diagnostic pragmas without nv_ prefix are removed from CUDA 12"
  },
  {
    "id": 4179,
    "content": "13 ( 1 , 2 ) See the C++ Standard for definition of integral constant expression"
  },
  {
    "id": 4180,
    "content": "8"
  },
  {
    "id": 4181,
    "content": "Cooperative Groups  8"
  },
  {
    "id": 4182,
    "content": "1"
  },
  {
    "id": 4188,
    "content": "8"
  },
  {
    "id": 4189,
    "content": "2"
  },
  {
    "id": 4190,
    "content": "What’s New in Cooperative Groups  8"
  },
  {
    "id": 4191,
    "content": "2"
  },
  {
    "id": 4192,
    "content": "1"
  },
  {
    "id": 4193,
    "content": "CUDA 12"
  },
  {
    "id": 4194,
    "content": "2  barrier_arrive and barrier_wait member functions were added for grid_group and thread_block"
  },
  {
    "id": 4195,
    "content": "Description of the API is available here"
  },
  {
    "id": 4196,
    "content": "8"
  },
  {
    "id": 4197,
    "content": "2"
  },
  {
    "id": 4198,
    "content": "2"
  },
  {
    "id": 4199,
    "content": "CUDA 12"
  },
  {
    "id": 4200,
    "content": "1  invoke_one and invoke_one_broadcast APIs were added"
  },
  {
    "id": 4201,
    "content": "8"
  },
  {
    "id": 4202,
    "content": "2"
  },
  {
    "id": 4203,
    "content": "3"
  },
  {
    "id": 4204,
    "content": "CUDA 12"
  },
  {
    "id": 4207,
    "content": "0 or higher"
  },
  {
    "id": 4208,
    "content": "8"
  },
  {
    "id": 4209,
    "content": "3"
  },
  {
    "id": 4215,
    "content": "g"
  },
  {
    "id": 4217,
    "content": "g"
  },
  {
    "id": 4224,
    "content": "} 8"
  },
  {
    "id": 4225,
    "content": "4"
  },
  {
    "id": 4226,
    "content": "Group Types  8"
  },
  {
    "id": 4227,
    "content": "4"
  },
  {
    "id": 4228,
    "content": "1"
  },
  {
    "id": 4233,
    "content": "8"
  },
  {
    "id": 4234,
    "content": "4"
  },
  {
    "id": 4235,
    "content": "1"
  },
  {
    "id": 4236,
    "content": "1"
  },
  {
    "id": 4243,
    "content": "8"
  },
  {
    "id": 4244,
    "content": "4"
  },
  {
    "id": 4245,
    "content": "1"
  },
  {
    "id": 4246,
    "content": "2"
  },
  {
    "id": 4247,
    "content": "Cluster Group  This group object represents all the threads launched in a single cluster"
  },
  {
    "id": 4257,
    "content": "5 or lower"
  },
  {
    "id": 4265,
    "content": "e"
  },
  {
    "id": 4269,
    "content": "It should consume no memory when instantiated in shared memory in cases where its not required"
  },
  {
    "id": 4271,
    "content": "all Compute Capabilities"
  },
  {
    "id": 4272,
    "content": "__global__ void kernel ("
  },
  {
    "id": 4275,
    "content": "} 8"
  },
  {
    "id": 4276,
    "content": "4"
  },
  {
    "id": 4277,
    "content": "2"
  },
  {
    "id": 4278,
    "content": "1"
  },
  {
    "id": 4279,
    "content": "1"
  },
  {
    "id": 4281,
    "content": "__global__ void cooperative_kernel ("
  },
  {
    "id": 4285,
    "content": "8"
  },
  {
    "id": 4286,
    "content": "4"
  },
  {
    "id": 4287,
    "content": "2"
  },
  {
    "id": 4288,
    "content": "2"
  },
  {
    "id": 4297,
    "content": "e"
  },
  {
    "id": 4300,
    "content": "64/128/256/512 sizes as well, but some additional steps are required on Compute Capability 7"
  },
  {
    "id": 4301,
    "content": "5 or lower, refer to Thread Block Tile for details"
  },
  {
    "id": 4302,
    "content": "Codegen Requirements: Compute Capability 5"
  },
  {
    "id": 4305,
    "content": "8"
  },
  {
    "id": 4306,
    "content": "5"
  },
  {
    "id": 4307,
    "content": "2"
  },
  {
    "id": 4311,
    "content": "Codegen Requirements: Compute Capability 7"
  },
  {
    "id": 4314,
    "content": "6"
  },
  {
    "id": 4316,
    "content": "the argument description"
  },
  {
    "id": 4325,
    "content": "using the appropriate cooperative launch APIs"
  },
  {
    "id": 4329,
    "content": "Having to wait on all outstanding requests can lose some flexibility (but gain simplicity)"
  },
  {
    "id": 4332,
    "content": "``min(dstLayout, srcLayout)`` elements"
  },
  {
    "id": 4333,
    "content": "Errata The memcpy_async API introduced in CUDA 11"
  },
  {
    "id": 4336,
    "content": "the number of bytes copied needs to be a multiple of N"
  },
  {
    "id": 4337,
    "content": "Codegen Requirements: Compute Capability 5 0 minimum, Compute Capability 8"
  },
  {
    "id": 4338,
    "content": "0 for asynchronicity, C++11 cooperative_groups/memcpy_async"
  },
  {
    "id": 4339,
    "content": "h header needs to be included"
  },
  {
    "id": 4344,
    "content": "Codegen Requirements: Compute Capability 5 0 minimum, Compute Capability 8"
  },
  {
    "id": 4345,
    "content": "0 for asynchronicity, C++11 cooperative_groups/memcpy_async"
  },
  {
    "id": 4346,
    "content": "h header needs to be included"
  },
  {
    "id": 4349,
    "content": "local_smem[stage] here ("
  },
  {
    "id": 4350,
    "content": ")     Calculate the amount fo data that was actually copied, for the next iteration"
  },
  {
    "id": 4352,
    "content": "6"
  },
  {
    "id": 4353,
    "content": "3"
  },
  {
    "id": 4356,
    "content": "val : Any type that satisfies the below requirements: Qualifies as trivially copyable i"
  },
  {
    "id": 4357,
    "content": "e"
  },
  {
    "id": 4363,
    "content": "Codegen Requirements: Compute Capability 5 0 minimum, Compute Capability 8"
  },
  {
    "id": 4364,
    "content": "0 for HW acceleration, C++11"
  },
  {
    "id": 4370,
    "content": "Thus in order to make use of intrinsics introduced in CC 8"
  },
  {
    "id": 4371,
    "content": "0, the cg:: namespace exposes several functional objects that mirror the hardware"
  },
  {
    "id": 4374,
    "content": ") on CC 8"
  },
  {
    "id": 4377,
    "content": "6"
  },
  {
    "id": 4378,
    "content": "3"
  },
  {
    "id": 4379,
    "content": "3"
  },
  {
    "id": 4387,
    "content": "0 minimum, C++11"
  },
  {
    "id": 4395,
    "content": "On devices with Compute Capability 9"
  },
  {
    "id": 4398,
    "content": "e"
  },
  {
    "id": 4411,
    "content": "8"
  },
  {
    "id": 4414,
    "content": "e"
  },
  {
    "id": 4416,
    "content": "No explicit checks are done by the driver in this regard because it is largely not feasible"
  },
  {
    "id": 4419,
    "content": "Deprecation Notice: cudaLaunchCooperativeKernelMultiDevice has been deprecated in CUDA 11"
  },
  {
    "id": 4420,
    "content": "3 for all devices"
  },
  {
    "id": 4421,
    "content": "Example of an alternative approach can be found in the multi device conjugate gradient sample"
  },
  {
    "id": 4426,
    "content": "2"
  },
  {
    "id": 4427,
    "content": "2"
  },
  {
    "id": 4428,
    "content": "1"
  },
  {
    "id": 4429,
    "content": "2"
  },
  {
    "id": 4431,
    "content": "9"
  },
  {
    "id": 4432,
    "content": "2"
  },
  {
    "id": 4433,
    "content": "2"
  },
  {
    "id": 4434,
    "content": "1"
  },
  {
    "id": 4435,
    "content": "3"
  },
  {
    "id": 4437,
    "content": "9"
  },
  {
    "id": 4438,
    "content": "2"
  },
  {
    "id": 4439,
    "content": "2"
  },
  {
    "id": 4440,
    "content": "1"
  },
  {
    "id": 4441,
    "content": "4"
  },
  {
    "id": 4446,
    "content": "As such, passing shared or local memory pointers to these APIs is illegal and will return an error"
  },
  {
    "id": 4447,
    "content": "9"
  },
  {
    "id": 4448,
    "content": "2"
  },
  {
    "id": 4449,
    "content": "2"
  },
  {
    "id": 4450,
    "content": "1"
  },
  {
    "id": 4451,
    "content": "5"
  },
  {
    "id": 4455,
    "content": "2"
  },
  {
    "id": 4456,
    "content": "2"
  },
  {
    "id": 4457,
    "content": "1"
  },
  {
    "id": 4458,
    "content": "6"
  },
  {
    "id": 4461,
    "content": "9"
  },
  {
    "id": 4462,
    "content": "3"
  },
  {
    "id": 4463,
    "content": "Programming Interface  9"
  },
  {
    "id": 4464,
    "content": "3"
  },
  {
    "id": 4465,
    "content": "1"
  },
  {
    "id": 4469,
    "content": "9"
  },
  {
    "id": 4470,
    "content": "3"
  },
  {
    "id": 4471,
    "content": "1"
  },
  {
    "id": 4472,
    "content": "1"
  },
  {
    "id": 4474,
    "content": "thread block for this call in addition to statically allocated memory"
  },
  {
    "id": 4475,
    "content": "S is an optional argument that defaults to the NULL stream"
  },
  {
    "id": 4476,
    "content": "9"
  },
  {
    "id": 4477,
    "content": "3"
  },
  {
    "id": 4478,
    "content": "1"
  },
  {
    "id": 4479,
    "content": "1"
  },
  {
    "id": 4480,
    "content": "1"
  },
  {
    "id": 4484,
    "content": "9"
  },
  {
    "id": 4485,
    "content": "3"
  },
  {
    "id": 4486,
    "content": "1"
  },
  {
    "id": 4487,
    "content": "1"
  },
  {
    "id": 4488,
    "content": "2"
  },
  {
    "id": 4491,
    "content": "It is not possible to reconfigure a kernel’s environment from the device"
  },
  {
    "id": 4492,
    "content": "9"
  },
  {
    "id": 4493,
    "content": "3"
  },
  {
    "id": 4494,
    "content": "1"
  },
  {
    "id": 4495,
    "content": "2"
  },
  {
    "id": 4497,
    "content": "not supported by the CUDA programming model and will have undefined behavior"
  },
  {
    "id": 4500,
    "content": "9"
  },
  {
    "id": 4501,
    "content": "3"
  },
  {
    "id": 4502,
    "content": "1"
  },
  {
    "id": 4503,
    "content": "2"
  },
  {
    "id": 4504,
    "content": "1"
  },
  {
    "id": 4507,
    "content": "9"
  },
  {
    "id": 4508,
    "content": "3"
  },
  {
    "id": 4509,
    "content": "1"
  },
  {
    "id": 4510,
    "content": "2"
  },
  {
    "id": 4511,
    "content": "2"
  },
  {
    "id": 4515,
    "content": "9"
  },
  {
    "id": 4516,
    "content": "3"
  },
  {
    "id": 4517,
    "content": "1"
  },
  {
    "id": 4518,
    "content": "2"
  },
  {
    "id": 4519,
    "content": "3"
  },
  {
    "id": 4524,
    "content": "9"
  },
  {
    "id": 4525,
    "content": "3"
  },
  {
    "id": 4526,
    "content": "1"
  },
  {
    "id": 4527,
    "content": "3"
  },
  {
    "id": 4528,
    "content": "Events  Only the inter-stream synchronization capabilities of CUDA events are supported"
  },
  {
    "id": 4531,
    "content": "9"
  },
  {
    "id": 4532,
    "content": "3"
  },
  {
    "id": 4533,
    "content": "1"
  },
  {
    "id": 4534,
    "content": "4"
  },
  {
    "id": 4536,
    "content": "parent grid"
  },
  {
    "id": 4537,
    "content": "9"
  },
  {
    "id": 4538,
    "content": "3"
  },
  {
    "id": 4539,
    "content": "1"
  },
  {
    "id": 4540,
    "content": "5"
  },
  {
    "id": 4543,
    "content": "9"
  },
  {
    "id": 4544,
    "content": "3"
  },
  {
    "id": 4545,
    "content": "1"
  },
  {
    "id": 4546,
    "content": "6"
  },
  {
    "id": 4547,
    "content": "Memory Declarations  9"
  },
  {
    "id": 4548,
    "content": "3"
  },
  {
    "id": 4549,
    "content": "1"
  },
  {
    "id": 4550,
    "content": "6"
  },
  {
    "id": 4551,
    "content": "1"
  },
  {
    "id": 4553,
    "content": "9"
  },
  {
    "id": 4554,
    "content": "3"
  },
  {
    "id": 4555,
    "content": "1"
  },
  {
    "id": 4556,
    "content": "6"
  },
  {
    "id": 4557,
    "content": "2"
  },
  {
    "id": 4560,
    "content": "e"
  },
  {
    "id": 4562,
    "content": "e"
  },
  {
    "id": 4563,
    "content": ", the one which is launched from the host)"
  },
  {
    "id": 4564,
    "content": "9"
  },
  {
    "id": 4565,
    "content": "3"
  },
  {
    "id": 4566,
    "content": "1"
  },
  {
    "id": 4567,
    "content": "6"
  },
  {
    "id": 4568,
    "content": "3"
  },
  {
    "id": 4571,
    "content": "3"
  },
  {
    "id": 4572,
    "content": "1"
  },
  {
    "id": 4573,
    "content": "6"
  },
  {
    "id": 4574,
    "content": "4"
  },
  {
    "id": 4575,
    "content": "Symbol Addresses  Device-side symbols (i"
  },
  {
    "id": 4576,
    "content": "e"
  },
  {
    "id": 4579,
    "content": "g"
  },
  {
    "id": 4582,
    "content": "9"
  },
  {
    "id": 4583,
    "content": "3"
  },
  {
    "id": 4584,
    "content": "1"
  },
  {
    "id": 4585,
    "content": "7"
  },
  {
    "id": 4589,
    "content": "For device-side exceptions, e"
  },
  {
    "id": 4590,
    "content": "g"
  },
  {
    "id": 4591,
    "content": ", access to an invalid address, an error in a child grid will be returned to the host"
  },
  {
    "id": 4592,
    "content": "9"
  },
  {
    "id": 4593,
    "content": "3"
  },
  {
    "id": 4594,
    "content": "1"
  },
  {
    "id": 4595,
    "content": "7"
  },
  {
    "id": 4596,
    "content": "1"
  },
  {
    "id": 4599,
    "content": "As with host-side launch, the device-side operator >> maps to underlying kernel launch APIs"
  },
  {
    "id": 4603,
    "content": "3"
  },
  {
    "id": 4604,
    "content": "1"
  },
  {
    "id": 4605,
    "content": "8"
  },
  {
    "id": 4608,
    "content": "It provides the low-level details related to supporting kernel launches at the PTX level"
  },
  {
    "id": 4609,
    "content": "9"
  },
  {
    "id": 4610,
    "content": "3"
  },
  {
    "id": 4611,
    "content": "2"
  },
  {
    "id": 4612,
    "content": "1"
  },
  {
    "id": 4614,
    "content": "e"
  },
  {
    "id": 4615,
    "content": ", no need to invoke cudaGetParameterBuffer() , if the launched kernel does not take any parameters"
  },
  {
    "id": 4616,
    "content": "9"
  },
  {
    "id": 4617,
    "content": "3"
  },
  {
    "id": 4618,
    "content": "2"
  },
  {
    "id": 4619,
    "content": "1"
  },
  {
    "id": 4620,
    "content": "1"
  },
  {
    "id": 4622,
    "content": "h"
  },
  {
    "id": 4625,
    "content": "kernel"
  },
  {
    "id": 4626,
    "content": "Other parameters specify the launch configuration, i"
  },
  {
    "id": 4627,
    "content": "e"
  },
  {
    "id": 4629,
    "content": "9"
  },
  {
    "id": 4630,
    "content": "3"
  },
  {
    "id": 4631,
    "content": "2"
  },
  {
    "id": 4632,
    "content": "1"
  },
  {
    "id": 4633,
    "content": "2"
  },
  {
    "id": 4635,
    "content": "address_size is 64"
  },
  {
    "id": 4638,
    "content": "portability in the future"
  },
  {
    "id": 4639,
    "content": "9"
  },
  {
    "id": 4640,
    "content": "3"
  },
  {
    "id": 4641,
    "content": "2"
  },
  {
    "id": 4642,
    "content": "2"
  },
  {
    "id": 4645,
    "content": "5 specification"
  },
  {
    "id": 4646,
    "content": "9"
  },
  {
    "id": 4647,
    "content": "3"
  },
  {
    "id": 4648,
    "content": "3"
  },
  {
    "id": 4649,
    "content": "Toolkit Support for Dynamic Parallelism  9"
  },
  {
    "id": 4650,
    "content": "3"
  },
  {
    "id": 4651,
    "content": "3"
  },
  {
    "id": 4652,
    "content": "1"
  },
  {
    "id": 4654,
    "content": "There is no need to include cuda_device_runtime_api"
  },
  {
    "id": 4655,
    "content": "h explicitly"
  },
  {
    "id": 4656,
    "content": "9"
  },
  {
    "id": 4657,
    "content": "3"
  },
  {
    "id": 4658,
    "content": "3"
  },
  {
    "id": 4659,
    "content": "2"
  },
  {
    "id": 4662,
    "content": "cu -o hello -lcudadevrt It is also possible to compile CUDA"
  },
  {
    "id": 4665,
    "content": "9"
  },
  {
    "id": 4666,
    "content": "4"
  },
  {
    "id": 4667,
    "content": "Programming Guidelines  9"
  },
  {
    "id": 4668,
    "content": "4"
  },
  {
    "id": 4669,
    "content": "1"
  },
  {
    "id": 4676,
    "content": "cu -o hello -lcudadevrt 9"
  },
  {
    "id": 4677,
    "content": "4"
  },
  {
    "id": 4678,
    "content": "2"
  },
  {
    "id": 4680,
    "content": "incurred for applications that link against the device runtime library"
  },
  {
    "id": 4681,
    "content": "9"
  },
  {
    "id": 4682,
    "content": "4"
  },
  {
    "id": 4683,
    "content": "3"
  },
  {
    "id": 4686,
    "content": "9"
  },
  {
    "id": 4687,
    "content": "4"
  },
  {
    "id": 4688,
    "content": "3"
  },
  {
    "id": 4689,
    "content": "1"
  },
  {
    "id": 4690,
    "content": "2"
  },
  {
    "id": 4693,
    "content": "9"
  },
  {
    "id": 4694,
    "content": "4"
  },
  {
    "id": 4695,
    "content": "3"
  },
  {
    "id": 4696,
    "content": "1"
  },
  {
    "id": 4697,
    "content": "3"
  },
  {
    "id": 4704,
    "content": "cudaDeviceGetLimit() can be called to get the current per-thread stack size"
  },
  {
    "id": 4705,
    "content": "9"
  },
  {
    "id": 4706,
    "content": "4"
  },
  {
    "id": 4707,
    "content": "3"
  },
  {
    "id": 4708,
    "content": "1"
  },
  {
    "id": 4709,
    "content": "4"
  },
  {
    "id": 4712,
    "content": "cudaLimitMallocHeapSize 9"
  },
  {
    "id": 4713,
    "content": "4"
  },
  {
    "id": 4714,
    "content": "3"
  },
  {
    "id": 4715,
    "content": "1"
  },
  {
    "id": 4716,
    "content": "5"
  },
  {
    "id": 4719,
    "content": "9"
  },
  {
    "id": 4720,
    "content": "4"
  },
  {
    "id": 4721,
    "content": "3"
  },
  {
    "id": 4722,
    "content": "1"
  },
  {
    "id": 4723,
    "content": "6"
  },
  {
    "id": 4725,
    "content": "9"
  },
  {
    "id": 4726,
    "content": "5"
  },
  {
    "id": 4728,
    "content": "0"
  },
  {
    "id": 4729,
    "content": "9"
  },
  {
    "id": 4730,
    "content": "5"
  },
  {
    "id": 4731,
    "content": "1"
  },
  {
    "id": 4734,
    "content": "CDP2 no longer has a virtualized pool for pending launches that don’t fit in the fixed-sized pool"
  },
  {
    "id": 4739,
    "content": "9"
  },
  {
    "id": 4740,
    "content": "5"
  },
  {
    "id": 4741,
    "content": "2"
  },
  {
    "id": 4743,
    "content": "0"
  },
  {
    "id": 4746,
    "content": "6"
  },
  {
    "id": 4747,
    "content": "1"
  },
  {
    "id": 4748,
    "content": "2"
  },
  {
    "id": 4749,
    "content": "1"
  },
  {
    "id": 4750,
    "content": "2"
  },
  {
    "id": 4752,
    "content": "9"
  },
  {
    "id": 4753,
    "content": "6"
  },
  {
    "id": 4754,
    "content": "1"
  },
  {
    "id": 4755,
    "content": "2"
  },
  {
    "id": 4756,
    "content": "1"
  },
  {
    "id": 4757,
    "content": "3"
  },
  {
    "id": 4758,
    "content": "Constant Memory (CDP1)  See Constant Memory , above, for CDP2 version of document"
  },
  {
    "id": 4760,
    "content": "That is to say, the value of all __constant__ variables must be set from the host prior to launch"
  },
  {
    "id": 4762,
    "content": "9"
  },
  {
    "id": 4763,
    "content": "6"
  },
  {
    "id": 4764,
    "content": "1"
  },
  {
    "id": 4765,
    "content": "2"
  },
  {
    "id": 4766,
    "content": "1"
  },
  {
    "id": 4767,
    "content": "4"
  },
  {
    "id": 4769,
    "content": "9"
  },
  {
    "id": 4770,
    "content": "6"
  },
  {
    "id": 4771,
    "content": "1"
  },
  {
    "id": 4772,
    "content": "2"
  },
  {
    "id": 4773,
    "content": "1"
  },
  {
    "id": 4774,
    "content": "5"
  },
  {
    "id": 4777,
    "content": "6"
  },
  {
    "id": 4778,
    "content": "1"
  },
  {
    "id": 4779,
    "content": "2"
  },
  {
    "id": 4780,
    "content": "1"
  },
  {
    "id": 4781,
    "content": "6"
  },
  {
    "id": 4783,
    "content": "using cudaDeviceSynchronize() in device code) is deprecated in CUDA 11"
  },
  {
    "id": 4784,
    "content": "6, removed for compute_90+ compilation, and is slated for full removal in a future CUDA release"
  },
  {
    "id": 4785,
    "content": "9"
  },
  {
    "id": 4786,
    "content": "6"
  },
  {
    "id": 4787,
    "content": "2"
  },
  {
    "id": 4788,
    "content": "Programming Interface (CDP1)  See Programming Interface , above, for CDP2 version of document"
  },
  {
    "id": 4789,
    "content": "9"
  },
  {
    "id": 4790,
    "content": "6"
  },
  {
    "id": 4791,
    "content": "2"
  },
  {
    "id": 4792,
    "content": "1"
  },
  {
    "id": 4793,
    "content": "CUDA C++ Reference (CDP1)  See CUDA C++ Reference , above, for CDP2 version of document"
  },
  {
    "id": 4795,
    "content": "9"
  },
  {
    "id": 4796,
    "content": "6"
  },
  {
    "id": 4797,
    "content": "2"
  },
  {
    "id": 4798,
    "content": "1"
  },
  {
    "id": 4799,
    "content": "1"
  },
  {
    "id": 4803,
    "content": "S is an optional argument that defaults to 0"
  },
  {
    "id": 4804,
    "content": "9"
  },
  {
    "id": 4805,
    "content": "6"
  },
  {
    "id": 4806,
    "content": "2"
  },
  {
    "id": 4807,
    "content": "1"
  },
  {
    "id": 4808,
    "content": "1"
  },
  {
    "id": 4809,
    "content": "1"
  },
  {
    "id": 4812,
    "content": "the launching thread reaches an explicit launch-synchronization point"
  },
  {
    "id": 4813,
    "content": "9"
  },
  {
    "id": 4814,
    "content": "6"
  },
  {
    "id": 4815,
    "content": "2"
  },
  {
    "id": 4816,
    "content": "1"
  },
  {
    "id": 4817,
    "content": "1"
  },
  {
    "id": 4818,
    "content": "2"
  },
  {
    "id": 4821,
    "content": "9"
  },
  {
    "id": 4822,
    "content": "6"
  },
  {
    "id": 4823,
    "content": "2"
  },
  {
    "id": 4824,
    "content": "1"
  },
  {
    "id": 4825,
    "content": "2"
  },
  {
    "id": 4826,
    "content": "Streams (CDP1)  See Streams , above, for CDP2 version of document"
  },
  {
    "id": 4829,
    "content": "9"
  },
  {
    "id": 4830,
    "content": "6"
  },
  {
    "id": 4831,
    "content": "2"
  },
  {
    "id": 4832,
    "content": "1"
  },
  {
    "id": 4833,
    "content": "2"
  },
  {
    "id": 4834,
    "content": "1"
  },
  {
    "id": 4837,
    "content": "9"
  },
  {
    "id": 4838,
    "content": "6"
  },
  {
    "id": 4839,
    "content": "2"
  },
  {
    "id": 4840,
    "content": "1"
  },
  {
    "id": 4841,
    "content": "3"
  },
  {
    "id": 4842,
    "content": "Events (CDP1)  See Events , above, for CDP2 version of document"
  },
  {
    "id": 4844,
    "content": "9"
  },
  {
    "id": 4845,
    "content": "6"
  },
  {
    "id": 4846,
    "content": "2"
  },
  {
    "id": 4847,
    "content": "1"
  },
  {
    "id": 4848,
    "content": "4"
  },
  {
    "id": 4849,
    "content": "Synchronization (CDP1)  See Synchronization , above, for CDP2 version of document"
  },
  {
    "id": 4852,
    "content": "9"
  },
  {
    "id": 4853,
    "content": "6"
  },
  {
    "id": 4854,
    "content": "2"
  },
  {
    "id": 4855,
    "content": "1"
  },
  {
    "id": 4856,
    "content": "4"
  },
  {
    "id": 4857,
    "content": "1"
  },
  {
    "id": 4861,
    "content": "9"
  },
  {
    "id": 4862,
    "content": "6"
  },
  {
    "id": 4863,
    "content": "2"
  },
  {
    "id": 4864,
    "content": "1"
  },
  {
    "id": 4865,
    "content": "5"
  },
  {
    "id": 4866,
    "content": "Device Management (CDP1)  See Device Management , above, for CDP2 version of document"
  },
  {
    "id": 4867,
    "content": "Only the device on which a kernel is running will be controllable from that kernel"
  },
  {
    "id": 4868,
    "content": "9"
  },
  {
    "id": 4869,
    "content": "6"
  },
  {
    "id": 4870,
    "content": "2"
  },
  {
    "id": 4871,
    "content": "1"
  },
  {
    "id": 4872,
    "content": "6"
  },
  {
    "id": 4873,
    "content": "Memory Declarations (CDP1)  See Memory Declarations , above, for CDP2 version of document"
  },
  {
    "id": 4874,
    "content": "9"
  },
  {
    "id": 4875,
    "content": "6"
  },
  {
    "id": 4876,
    "content": "2"
  },
  {
    "id": 4877,
    "content": "1"
  },
  {
    "id": 4878,
    "content": "6"
  },
  {
    "id": 4879,
    "content": "1"
  },
  {
    "id": 4881,
    "content": "9"
  },
  {
    "id": 4882,
    "content": "6"
  },
  {
    "id": 4883,
    "content": "2"
  },
  {
    "id": 4884,
    "content": "1"
  },
  {
    "id": 4885,
    "content": "6"
  },
  {
    "id": 4886,
    "content": "2"
  },
  {
    "id": 4887,
    "content": "Textures and Surfaces (CDP1)  See Textures and Surfaces , above, for CDP2 version of document"
  },
  {
    "id": 4889,
    "content": "9"
  },
  {
    "id": 4890,
    "content": "6"
  },
  {
    "id": 4891,
    "content": "2"
  },
  {
    "id": 4892,
    "content": "1"
  },
  {
    "id": 4893,
    "content": "6"
  },
  {
    "id": 4894,
    "content": "3"
  },
  {
    "id": 4897,
    "content": "6"
  },
  {
    "id": 4898,
    "content": "2"
  },
  {
    "id": 4899,
    "content": "1"
  },
  {
    "id": 4900,
    "content": "6"
  },
  {
    "id": 4901,
    "content": "4"
  },
  {
    "id": 4902,
    "content": "Device-side symbols (i"
  },
  {
    "id": 4903,
    "content": "e"
  },
  {
    "id": 4905,
    "content": "9"
  },
  {
    "id": 4906,
    "content": "6"
  },
  {
    "id": 4907,
    "content": "2"
  },
  {
    "id": 4908,
    "content": "1"
  },
  {
    "id": 4909,
    "content": "7"
  },
  {
    "id": 4911,
    "content": "For device-side exceptions, e"
  },
  {
    "id": 4912,
    "content": "g"
  },
  {
    "id": 4914,
    "content": "9"
  },
  {
    "id": 4915,
    "content": "6"
  },
  {
    "id": 4916,
    "content": "2"
  },
  {
    "id": 4917,
    "content": "1"
  },
  {
    "id": 4918,
    "content": "7"
  },
  {
    "id": 4919,
    "content": "1"
  },
  {
    "id": 4922,
    "content": "dim3 gridDim , dim3 blockDim , unsigned int sharedMemSize = 0 , cudaStream_t stream = 0 ); 9"
  },
  {
    "id": 4923,
    "content": "6"
  },
  {
    "id": 4924,
    "content": "2"
  },
  {
    "id": 4925,
    "content": "1"
  },
  {
    "id": 4926,
    "content": "8"
  },
  {
    "id": 4928,
    "content": "Warning: Note that calling this API from device code is deprecated in CUDA 11"
  },
  {
    "id": 4929,
    "content": "6, removed for compute_90+ compilation, and is slated for full removal in a future CUDA release"
  },
  {
    "id": 4932,
    "content": "9"
  },
  {
    "id": 4933,
    "content": "6"
  },
  {
    "id": 4934,
    "content": "2"
  },
  {
    "id": 4935,
    "content": "2"
  },
  {
    "id": 4936,
    "content": "1"
  },
  {
    "id": 4938,
    "content": "9"
  },
  {
    "id": 4939,
    "content": "6"
  },
  {
    "id": 4940,
    "content": "2"
  },
  {
    "id": 4941,
    "content": "2"
  },
  {
    "id": 4942,
    "content": "1"
  },
  {
    "id": 4943,
    "content": "1"
  },
  {
    "id": 4945,
    "content": "h"
  },
  {
    "id": 4946,
    "content": "The layout of the parameter buffer is explained in Parameter Buffer Layout (CDP1) , below"
  },
  {
    "id": 4947,
    "content": "9"
  },
  {
    "id": 4948,
    "content": "6"
  },
  {
    "id": 4949,
    "content": "2"
  },
  {
    "id": 4950,
    "content": "2"
  },
  {
    "id": 4951,
    "content": "1"
  },
  {
    "id": 4952,
    "content": "2"
  },
  {
    "id": 4954,
    "content": "address_size is 64   When address_size is 64"
  },
  {
    "id": 4955,
    "content": "b64 size ) ;   PTX-level Declaration of cudaGetParameterBuffer() when"
  },
  {
    "id": 4956,
    "content": "address_size is 32"
  },
  {
    "id": 4958,
    "content": "in bytes"
  },
  {
    "id": 4959,
    "content": "9"
  },
  {
    "id": 4960,
    "content": "6"
  },
  {
    "id": 4961,
    "content": "2"
  },
  {
    "id": 4962,
    "content": "2"
  },
  {
    "id": 4963,
    "content": "2"
  },
  {
    "id": 4965,
    "content": "9"
  },
  {
    "id": 4966,
    "content": "6"
  },
  {
    "id": 4967,
    "content": "2"
  },
  {
    "id": 4968,
    "content": "3"
  },
  {
    "id": 4970,
    "content": "9"
  },
  {
    "id": 4971,
    "content": "6"
  },
  {
    "id": 4972,
    "content": "2"
  },
  {
    "id": 4973,
    "content": "3"
  },
  {
    "id": 4974,
    "content": "1"
  },
  {
    "id": 4976,
    "content": "9"
  },
  {
    "id": 4977,
    "content": "6"
  },
  {
    "id": 4978,
    "content": "2"
  },
  {
    "id": 4979,
    "content": "3"
  },
  {
    "id": 4980,
    "content": "2"
  },
  {
    "id": 4982,
    "content": "9"
  },
  {
    "id": 4983,
    "content": "6"
  },
  {
    "id": 4984,
    "content": "3"
  },
  {
    "id": 4985,
    "content": "Programming Guidelines (CDP1)  See Programming Guidelines , above, for CDP2 version of document"
  },
  {
    "id": 4988,
    "content": "6"
  },
  {
    "id": 4989,
    "content": "3"
  },
  {
    "id": 4990,
    "content": "2"
  },
  {
    "id": 4991,
    "content": "Performance (CDP1)  See Performance , above, for CDP2 version of document"
  },
  {
    "id": 4992,
    "content": "9"
  },
  {
    "id": 4993,
    "content": "6"
  },
  {
    "id": 4994,
    "content": "3"
  },
  {
    "id": 4995,
    "content": "2"
  },
  {
    "id": 4996,
    "content": "1"
  },
  {
    "id": 4997,
    "content": "Synchronization (CDP1)  See CUDA Dynamic Parallelism , above, for CDP2 version of document"
  },
  {
    "id": 4999,
    "content": "6, removed for compute_90+ compilation, and is slated for full removal in a future CUDA release"
  },
  {
    "id": 5002,
    "content": "9"
  },
  {
    "id": 5003,
    "content": "6"
  },
  {
    "id": 5004,
    "content": "3"
  },
  {
    "id": 5005,
    "content": "2"
  },
  {
    "id": 5006,
    "content": "2"
  },
  {
    "id": 5009,
    "content": "9"
  },
  {
    "id": 5010,
    "content": "6"
  },
  {
    "id": 5011,
    "content": "3"
  },
  {
    "id": 5012,
    "content": "3"
  },
  {
    "id": 5014,
    "content": "9"
  },
  {
    "id": 5015,
    "content": "6"
  },
  {
    "id": 5016,
    "content": "3"
  },
  {
    "id": 5017,
    "content": "3"
  },
  {
    "id": 5018,
    "content": "1"
  },
  {
    "id": 5019,
    "content": "Runtime (CDP1)  See Runtime , above, for CDP2 version of document"
  },
  {
    "id": 5020,
    "content": "9"
  },
  {
    "id": 5021,
    "content": "6"
  },
  {
    "id": 5022,
    "content": "3"
  },
  {
    "id": 5023,
    "content": "3"
  },
  {
    "id": 5024,
    "content": "1"
  },
  {
    "id": 5025,
    "content": "1"
  },
  {
    "id": 5026,
    "content": "Memory Footprint (CDP1)  See Memory Footprint , above, for CDP2 version of document"
  },
  {
    "id": 5030,
    "content": "device configuration, which will be unavailable for program use even if it is not all consumed"
  },
  {
    "id": 5031,
    "content": "9"
  },
  {
    "id": 5032,
    "content": "6"
  },
  {
    "id": 5033,
    "content": "3"
  },
  {
    "id": 5034,
    "content": "3"
  },
  {
    "id": 5035,
    "content": "1"
  },
  {
    "id": 5036,
    "content": "2"
  },
  {
    "id": 5041,
    "content": "Note that this may also apply to cudaMemcpyAsync() , which might itself generate a kernel launch"
  },
  {
    "id": 5047,
    "content": "9"
  },
  {
    "id": 5048,
    "content": "6"
  },
  {
    "id": 5049,
    "content": "3"
  },
  {
    "id": 5050,
    "content": "3"
  },
  {
    "id": 5051,
    "content": "1"
  },
  {
    "id": 5052,
    "content": "3"
  },
  {
    "id": 5053,
    "content": "Pending Kernel Launches (CDP1)  See Pending Kernel Launches , above, for CDP2 version of document"
  },
  {
    "id": 5056,
    "content": "9"
  },
  {
    "id": 5057,
    "content": "6"
  },
  {
    "id": 5058,
    "content": "3"
  },
  {
    "id": 5059,
    "content": "3"
  },
  {
    "id": 5060,
    "content": "1"
  },
  {
    "id": 5061,
    "content": "4"
  },
  {
    "id": 5062,
    "content": "Configuration Options (CDP1)  See Configuration Options , above, for CDP2 version of document"
  },
  {
    "id": 5068,
    "content": "9"
  },
  {
    "id": 5069,
    "content": "6"
  },
  {
    "id": 5070,
    "content": "3"
  },
  {
    "id": 5071,
    "content": "3"
  },
  {
    "id": 5072,
    "content": "1"
  },
  {
    "id": 5073,
    "content": "5"
  },
  {
    "id": 5076,
    "content": "6"
  },
  {
    "id": 5077,
    "content": "3"
  },
  {
    "id": 5078,
    "content": "3"
  },
  {
    "id": 5079,
    "content": "1"
  },
  {
    "id": 5080,
    "content": "6"
  },
  {
    "id": 5081,
    "content": "Note that in PTX %smid and %warpid are defined as volatile values"
  },
  {
    "id": 5082,
    "content": "9"
  },
  {
    "id": 5083,
    "content": "6"
  },
  {
    "id": 5084,
    "content": "3"
  },
  {
    "id": 5085,
    "content": "3"
  },
  {
    "id": 5086,
    "content": "1"
  },
  {
    "id": 5087,
    "content": "7"
  },
  {
    "id": 5088,
    "content": "ECC Errors (CDP1)  See ECC Errors , above, for CDP2 version of document"
  },
  {
    "id": 5090,
    "content": "0"
  },
  {
    "id": 5092,
    "content": "Introduced in CUDA 10"
  },
  {
    "id": 5095,
    "content": "This often leads to lower performance and higher peak memory utilization for applications"
  },
  {
    "id": 5102,
    "content": "Note that the suite of APIs described in this section require a system that supports UVA"
  },
  {
    "id": 5103,
    "content": "10"
  },
  {
    "id": 5104,
    "content": "2"
  },
  {
    "id": 5106,
    "content": "device ); if ( deviceSupportsVmm = 0 ) { `device` supports Virtual Memory Management } 10"
  },
  {
    "id": 5107,
    "content": "3"
  },
  {
    "id": 5113,
    "content": "10"
  },
  {
    "id": 5114,
    "content": "3"
  },
  {
    "id": 5115,
    "content": "1"
  },
  {
    "id": 5123,
    "content": "below: #if defined(__linux__) prop"
  },
  {
    "id": 5125,
    "content": "10"
  },
  {
    "id": 5126,
    "content": "3"
  },
  {
    "id": 5127,
    "content": "2"
  },
  {
    "id": 5128,
    "content": "Memory Type  Before CUDA 10"
  },
  {
    "id": 5131,
    "content": "10"
  },
  {
    "id": 5132,
    "content": "3"
  },
  {
    "id": 5133,
    "content": "2"
  },
  {
    "id": 5134,
    "content": "1"
  },
  {
    "id": 5142,
    "content": "4"
  },
  {
    "id": 5145,
    "content": "Applications are expected to return the virtual address range back to CUDA using cuMemAddressFree"
  },
  {
    "id": 5149,
    "content": "5"
  },
  {
    "id": 5153,
    "content": "*B can take on either   the previous value or some value in-between"
  },
  {
    "id": 5157,
    "content": "6"
  },
  {
    "id": 5168,
    "content": "11 Stream Ordered Memory Allocator  11"
  },
  {
    "id": 5169,
    "content": "1"
  },
  {
    "id": 5175,
    "content": "3 toolkit support"
  },
  {
    "id": 5176,
    "content": "11"
  },
  {
    "id": 5177,
    "content": "2"
  },
  {
    "id": 5179,
    "content": "Starting with CUDA 11"
  },
  {
    "id": 5184,
    "content": "not yet defined"
  },
  {
    "id": 5185,
    "content": "One can use cudaGetLastError to clear the error instead of avoiding it"
  },
  {
    "id": 5186,
    "content": "11"
  },
  {
    "id": 5187,
    "content": "3"
  },
  {
    "id": 5192,
    "content": "The simplest use pattern is when the memory is allocated, used, and freed back into the same stream"
  },
  {
    "id": 5199,
    "content": "4"
  },
  {
    "id": 5203,
    "content": "The APIs cudaDeviceGetDefaultMempool and cudaMemPoolCreate give users handles to memory pools"
  },
  {
    "id": 5205,
    "content": "Note cudaMemPoolSetAttribute and cudaMemPoolGetAttribute control the attributes of the memory pools"
  },
  {
    "id": 5206,
    "content": "11"
  },
  {
    "id": 5207,
    "content": "5"
  },
  {
    "id": 5210,
    "content": "11"
  },
  {
    "id": 5211,
    "content": "6"
  },
  {
    "id": 5212,
    "content": "Explicit Pools  The API cudaMemPoolCreate creates an explicit pool"
  },
  {
    "id": 5217,
    "content": "7"
  },
  {
    "id": 5222,
    "content": "allocator for ( i = 0 ; i >> ( ptrs ,"
  },
  {
    "id": 5225,
    "content": "9"
  },
  {
    "id": 5227,
    "content": "previously freed in that stream becomes available for reuse for an allocation in any stream"
  },
  {
    "id": 5229,
    "content": "Upgrading to a newer CUDA driver may change, enhance, augment and/or reorder the reuse policies"
  },
  {
    "id": 5230,
    "content": "11"
  },
  {
    "id": 5231,
    "content": "9"
  },
  {
    "id": 5232,
    "content": "1"
  },
  {
    "id": 5235,
    "content": "otherStream , event ); cudaMallocAsync ( & ptr2 , size , otherStream ); 11"
  },
  {
    "id": 5236,
    "content": "9"
  },
  {
    "id": 5237,
    "content": "2"
  },
  {
    "id": 5240,
    "content": "Disabling this policy does not stop the cudaMemPoolReuseFollowEventDependencies from applying"
  },
  {
    "id": 5244,
    "content": "that would be allowed to access the original allocation"
  },
  {
    "id": 5247,
    "content": "11"
  },
  {
    "id": 5248,
    "content": "10"
  },
  {
    "id": 5258,
    "content": "11 11"
  },
  {
    "id": 5259,
    "content": "1"
  },
  {
    "id": 5264,
    "content": "2"
  },
  {
    "id": 5266,
    "content": "GPUs the allocations will be used on"
  },
  {
    "id": 5267,
    "content": "11 11"
  },
  {
    "id": 5268,
    "content": "3"
  },
  {
    "id": 5281,
    "content": "This behavior is controlled by the driver, not the runtime and may change in a future driver update"
  },
  {
    "id": 5282,
    "content": "11 11"
  },
  {
    "id": 5283,
    "content": "5"
  },
  {
    "id": 5286,
    "content": "11"
  },
  {
    "id": 5287,
    "content": "12"
  },
  {
    "id": 5291,
    "content": "11"
  },
  {
    "id": 5292,
    "content": "13"
  },
  {
    "id": 5293,
    "content": "Addendums  11"
  },
  {
    "id": 5294,
    "content": "13"
  },
  {
    "id": 5295,
    "content": "1"
  },
  {
    "id": 5297,
    "content": "11"
  },
  {
    "id": 5298,
    "content": "13"
  },
  {
    "id": 5299,
    "content": "2"
  },
  {
    "id": 5301,
    "content": "11"
  },
  {
    "id": 5302,
    "content": "13"
  },
  {
    "id": 5303,
    "content": "3"
  },
  {
    "id": 5305,
    "content": "However, memsets of the allocations can be stream captured"
  },
  {
    "id": 5306,
    "content": "11"
  },
  {
    "id": 5307,
    "content": "13"
  },
  {
    "id": 5308,
    "content": "4"
  },
  {
    "id": 5311,
    "content": "The attribute CU_POINTER_ATTRIBUTE_MEMPOOL_HANDLE was added in CUDA 11"
  },
  {
    "id": 5313,
    "content": "12 Graph Memory Nodes  12"
  },
  {
    "id": 5314,
    "content": "1"
  },
  {
    "id": 5318,
    "content": "12"
  },
  {
    "id": 5319,
    "content": "2"
  },
  {
    "id": 5320,
    "content": "Support and Compatibility  Graph memory nodes require an 11"
  },
  {
    "id": 5321,
    "content": "4 capable CUDA driver and support for the stream ordered allocator on the GPU"
  },
  {
    "id": 5323,
    "content": "deviceSupportsMemoryPools"
  },
  {
    "id": 5325,
    "content": "1 drivers"
  },
  {
    "id": 5327,
    "content": "Graph memory nodes are only supported on driver versions 11"
  },
  {
    "id": 5328,
    "content": "4 and newer"
  },
  {
    "id": 5329,
    "content": "12"
  },
  {
    "id": 5330,
    "content": "3"
  },
  {
    "id": 5344,
    "content": "12"
  },
  {
    "id": 5345,
    "content": "3"
  },
  {
    "id": 5346,
    "content": "3"
  },
  {
    "id": 5359,
    "content": "unfreed memory in order to avoid memory leaks, even for graphs instantiated with the flag"
  },
  {
    "id": 5365,
    "content": "4"
  },
  {
    "id": 5367,
    "content": "12"
  },
  {
    "id": 5368,
    "content": "4"
  },
  {
    "id": 5369,
    "content": "1"
  },
  {
    "id": 5380,
    "content": "12"
  },
  {
    "id": 5381,
    "content": "5"
  },
  {
    "id": 5382,
    "content": "1"
  },
  {
    "id": 5386,
    "content": "12"
  },
  {
    "id": 5387,
    "content": "6"
  },
  {
    "id": 5392,
    "content": "12"
  },
  {
    "id": 5393,
    "content": "7"
  },
  {
    "id": 5396,
    "content": "12"
  },
  {
    "id": 5397,
    "content": "7"
  },
  {
    "id": 5398,
    "content": "1"
  },
  {
    "id": 5400,
    "content": "The poolProps"
  },
  {
    "id": 5402,
    "content": "cudaMemAllocNodeParams params = {}; params"
  },
  {
    "id": 5403,
    "content": "poolProps"
  },
  {
    "id": 5404,
    "content": "allocType = cudaMemAllocationTypePinned; params"
  },
  {
    "id": 5405,
    "content": "poolProps"
  },
  {
    "id": 5406,
    "content": "location"
  },
  {
    "id": 5407,
    "content": "type = cudaMemLocationTypeDevice;   specify device 1 as the resident device params"
  },
  {
    "id": 5408,
    "content": "poolProps"
  },
  {
    "id": 5409,
    "content": "location"
  },
  {
    "id": 5410,
    "content": "id = 1; params"
  },
  {
    "id": 5412,
    "content": "location"
  },
  {
    "id": 5414,
    "content": "location"
  },
  {
    "id": 5415,
    "content": "type = cudaMemLocationTypeDevice;   access being requested for device 0 & 2"
  },
  {
    "id": 5416,
    "content": "accessDescs[0]"
  },
  {
    "id": 5417,
    "content": "location"
  },
  {
    "id": 5418,
    "content": "id = 0; accessDescs[1]"
  },
  {
    "id": 5419,
    "content": "location"
  },
  {
    "id": 5420,
    "content": "id = 2;   access request array has 2 entries"
  },
  {
    "id": 5421,
    "content": "params accessDescCount = 2; params"
  },
  {
    "id": 5424,
    "content": "supported by the add node api) accessDesc flags = cudaMemAccessFlagsProtReadWrite; accessDesc"
  },
  {
    "id": 5425,
    "content": "location"
  },
  {
    "id": 5426,
    "content": "type = cudaMemLocationTypeDevice; accessDesc"
  },
  {
    "id": 5427,
    "content": "location"
  },
  {
    "id": 5430,
    "content": "13"
  },
  {
    "id": 5434,
    "content": "behavior: functions are inlined in the user program and thus are subject to compiler optimizations"
  },
  {
    "id": 5435,
    "content": "13"
  },
  {
    "id": 5436,
    "content": "1"
  },
  {
    "id": 5439,
    "content": "5 ulp"
  },
  {
    "id": 5452,
    "content": "__dsqrt_[rn,rz,ru,rd](x) IEEE-compliant"
  },
  {
    "id": 5453,
    "content": "14"
  },
  {
    "id": 5457,
    "content": "Code Samples gives code samples"
  },
  {
    "id": 5458,
    "content": "14"
  },
  {
    "id": 5459,
    "content": "1"
  },
  {
    "id": 5463,
    "content": "0 Binary literals N3472 9"
  },
  {
    "id": 5464,
    "content": "0 Functions with deduced return type N3638 9"
  },
  {
    "id": 5465,
    "content": "0 Generalized lambda capture (init-capture) N3648 9"
  },
  {
    "id": 5466,
    "content": "0 Generic (polymorphic) lambda expressions N3649 9"
  },
  {
    "id": 5467,
    "content": "0 Variable templates N3651 9"
  },
  {
    "id": 5468,
    "content": "0 Relaxing requirements on constexpr functions N3652 9"
  },
  {
    "id": 5469,
    "content": "0 Member initializers and aggregates N3653 9"
  },
  {
    "id": 5470,
    "content": "0 Clarifying memory allocation N3664 Sized deallocation N3778 [[deprecated]] attribute N3760 9"
  },
  {
    "id": 5471,
    "content": "0 Single-quotation-mark as a digit separator N3781 9"
  },
  {
    "id": 5472,
    "content": "0 14"
  },
  {
    "id": 5473,
    "content": "3"
  },
  {
    "id": 5474,
    "content": "C++17 Language Features  All C++17 language features are supported in nvcc version 11"
  },
  {
    "id": 5475,
    "content": "0 and later, subject to restrictions described here"
  },
  {
    "id": 5476,
    "content": "14"
  },
  {
    "id": 5477,
    "content": "4"
  },
  {
    "id": 5478,
    "content": "C++20 Language Features  All C++20 language features are supported in nvcc version 12"
  },
  {
    "id": 5479,
    "content": "0 and later, subject to restrictions described here"
  },
  {
    "id": 5482,
    "content": "14"
  },
  {
    "id": 5483,
    "content": "5"
  },
  {
    "id": 5484,
    "content": "2"
  },
  {
    "id": 5485,
    "content": "Preprocessor Symbols  14"
  },
  {
    "id": 5486,
    "content": "5"
  },
  {
    "id": 5487,
    "content": "2"
  },
  {
    "id": 5488,
    "content": "1"
  },
  {
    "id": 5494,
    "content": "arr ; #endif } Then if a"
  },
  {
    "id": 5495,
    "content": "cu and b cu both include a"
  },
  {
    "id": 5496,
    "content": "h and instantiate getptr for the same type, and b"
  },
  {
    "id": 5498,
    "content": "o b"
  },
  {
    "id": 5500,
    "content": "To avoid this, either a"
  },
  {
    "id": 5502,
    "content": "14"
  },
  {
    "id": 5503,
    "content": "5"
  },
  {
    "id": 5504,
    "content": "3"
  },
  {
    "id": 5505,
    "content": "Qualifiers  14"
  },
  {
    "id": 5506,
    "content": "5"
  },
  {
    "id": 5507,
    "content": "3"
  },
  {
    "id": 5508,
    "content": "1"
  },
  {
    "id": 5516,
    "content": "14"
  },
  {
    "id": 5517,
    "content": "5"
  },
  {
    "id": 5518,
    "content": "3"
  },
  {
    "id": 5519,
    "content": "2"
  },
  {
    "id": 5521,
    "content": "destruction of an object with static or thread local storage duration"
  },
  {
    "id": 5527,
    "content": "14"
  },
  {
    "id": 5528,
    "content": "5"
  },
  {
    "id": 5529,
    "content": "4"
  },
  {
    "id": 5532,
    "content": "14"
  },
  {
    "id": 5533,
    "content": "5"
  },
  {
    "id": 5534,
    "content": "5"
  },
  {
    "id": 5535,
    "content": "Operators  14"
  },
  {
    "id": 5536,
    "content": "5"
  },
  {
    "id": 5537,
    "content": "5"
  },
  {
    "id": 5538,
    "content": "1"
  },
  {
    "id": 5540,
    "content": "It is not allowed to assign values to any of the built-in variables defined in Built-in Variables"
  },
  {
    "id": 5541,
    "content": "14"
  },
  {
    "id": 5542,
    "content": "5"
  },
  {
    "id": 5543,
    "content": "5"
  },
  {
    "id": 5544,
    "content": "2"
  },
  {
    "id": 5546,
    "content": "14"
  },
  {
    "id": 5547,
    "content": "5"
  },
  {
    "id": 5548,
    "content": "6"
  },
  {
    "id": 5550,
    "content": "14"
  },
  {
    "id": 5551,
    "content": "5"
  },
  {
    "id": 5552,
    "content": "8"
  },
  {
    "id": 5554,
    "content": "14"
  },
  {
    "id": 5555,
    "content": "5"
  },
  {
    "id": 5556,
    "content": "9"
  },
  {
    "id": 5560,
    "content": "5"
  },
  {
    "id": 5561,
    "content": "10"
  },
  {
    "id": 5563,
    "content": "e"
  },
  {
    "id": 5564,
    "content": ", a single file or several files linked together with relocatable device code and nvlink"
  },
  {
    "id": 5565,
    "content": "14"
  },
  {
    "id": 5566,
    "content": "5"
  },
  {
    "id": 5567,
    "content": "10"
  },
  {
    "id": 5568,
    "content": "2"
  },
  {
    "id": 5574,
    "content": "5"
  },
  {
    "id": 5575,
    "content": "10"
  },
  {
    "id": 5576,
    "content": "3"
  },
  {
    "id": 5579,
    "content": "Example:  first"
  },
  {
    "id": 5581,
    "content": "'/tmp/tmpxft_00005c8c_00000000-18_second"
  },
  {
    "id": 5582,
    "content": "o' nvlink fatal : merge_elf failed 14"
  },
  {
    "id": 5583,
    "content": "5"
  },
  {
    "id": 5584,
    "content": "10"
  },
  {
    "id": 5585,
    "content": "3"
  },
  {
    "id": 5586,
    "content": "1"
  },
  {
    "id": 5595,
    "content": "If such kernels are launched on older drivers, CUDA will issue the error CUDA_ERROR_NOT_SUPPORTED"
  },
  {
    "id": 5596,
    "content": "14"
  },
  {
    "id": 5597,
    "content": "5"
  },
  {
    "id": 5598,
    "content": "10"
  },
  {
    "id": 5599,
    "content": "3"
  },
  {
    "id": 5600,
    "content": "3"
  },
  {
    "id": 5602,
    "content": "1 toolkit or higher before linking them together"
  },
  {
    "id": 5603,
    "content": "Failure to do so will result in a linker error"
  },
  {
    "id": 5604,
    "content": "14"
  },
  {
    "id": 5605,
    "content": "5"
  },
  {
    "id": 5606,
    "content": "10"
  },
  {
    "id": 5607,
    "content": "4"
  },
  {
    "id": 5611,
    "content": "e"
  },
  {
    "id": 5613,
    "content": "e"
  },
  {
    "id": 5615,
    "content": "g"
  },
  {
    "id": 5617,
    "content": "14"
  },
  {
    "id": 5618,
    "content": "5"
  },
  {
    "id": 5619,
    "content": "10"
  },
  {
    "id": 5620,
    "content": "6"
  },
  {
    "id": 5621,
    "content": "Function Recursion  __global__ functions do not support recursion"
  },
  {
    "id": 5622,
    "content": "14"
  },
  {
    "id": 5623,
    "content": "5"
  },
  {
    "id": 5624,
    "content": "10"
  },
  {
    "id": 5625,
    "content": "7"
  },
  {
    "id": 5627,
    "content": "definition in friend declaration }; 14"
  },
  {
    "id": 5628,
    "content": "5"
  },
  {
    "id": 5629,
    "content": "10"
  },
  {
    "id": 5630,
    "content": "8"
  },
  {
    "id": 5631,
    "content": "Operator Function  An operator function cannot be a __global__ function"
  },
  {
    "id": 5632,
    "content": "14"
  },
  {
    "id": 5633,
    "content": "5"
  },
  {
    "id": 5634,
    "content": "10"
  },
  {
    "id": 5635,
    "content": "9"
  },
  {
    "id": 5638,
    "content": "14"
  },
  {
    "id": 5639,
    "content": "5"
  },
  {
    "id": 5640,
    "content": "11"
  },
  {
    "id": 5641,
    "content": "2"
  },
  {
    "id": 5642,
    "content": "Function Members  Static member functions cannot be __global__ functions"
  },
  {
    "id": 5643,
    "content": "14"
  },
  {
    "id": 5644,
    "content": "5"
  },
  {
    "id": 5645,
    "content": "11"
  },
  {
    "id": 5646,
    "content": "3"
  },
  {
    "id": 5648,
    "content": "e"
  },
  {
    "id": 5649,
    "content": ", __host__ , __device__ ) on the overridden and overriding functions must match"
  },
  {
    "id": 5652,
    "content": "-> foo (); error: virtual function call on an object created in device code"
  },
  {
    "id": 5653,
    "content": "} 14"
  },
  {
    "id": 5654,
    "content": "5"
  },
  {
    "id": 5655,
    "content": "11"
  },
  {
    "id": 5656,
    "content": "4"
  },
  {
    "id": 5658,
    "content": "14"
  },
  {
    "id": 5659,
    "content": "5"
  },
  {
    "id": 5660,
    "content": "11"
  },
  {
    "id": 5661,
    "content": "5"
  },
  {
    "id": 5663,
    "content": "14"
  },
  {
    "id": 5664,
    "content": "5"
  },
  {
    "id": 5665,
    "content": "11"
  },
  {
    "id": 5666,
    "content": "6"
  },
  {
    "id": 5673,
    "content": "14"
  },
  {
    "id": 5674,
    "content": "5"
  },
  {
    "id": 5675,
    "content": "12"
  },
  {
    "id": 5679,
    "content": "5"
  },
  {
    "id": 5680,
    "content": "13"
  },
  {
    "id": 5681,
    "content": "Digraphs are not supported on Windows"
  },
  {
    "id": 5682,
    "content": "14"
  },
  {
    "id": 5683,
    "content": "5"
  },
  {
    "id": 5684,
    "content": "14"
  },
  {
    "id": 5688,
    "content": "code"
  },
  {
    "id": 5689,
    "content": "14"
  },
  {
    "id": 5690,
    "content": "5"
  },
  {
    "id": 5691,
    "content": "16"
  },
  {
    "id": 5693,
    "content": "exe host compiler"
  },
  {
    "id": 5694,
    "content": "It also supports the [[deprecated]] standard attribute when the C++14 dialect has been enabled"
  },
  {
    "id": 5696,
    "content": "e"
  },
  {
    "id": 5697,
    "content": ", during device compilation phase)"
  },
  {
    "id": 5698,
    "content": "Other references to deprecated entities will be handled by the host compiler, e"
  },
  {
    "id": 5699,
    "content": "g"
  },
  {
    "id": 5700,
    "content": ", a reference from within a __host__ function"
  },
  {
    "id": 5702,
    "content": "nv_diag_suppress"
  },
  {
    "id": 5704,
    "content": "14"
  },
  {
    "id": 5705,
    "content": "5"
  },
  {
    "id": 5706,
    "content": "17"
  },
  {
    "id": 5708,
    "content": "exe host compiler"
  },
  {
    "id": 5709,
    "content": "It also supports the [[noreturn]] standard attribute when the C++11 dialect has been enabled"
  },
  {
    "id": 5710,
    "content": "The attribute/declspec can be used in both host and device code"
  },
  {
    "id": 5711,
    "content": "14"
  },
  {
    "id": 5712,
    "content": "5"
  },
  {
    "id": 5713,
    "content": "18"
  },
  {
    "id": 5716,
    "content": "5"
  },
  {
    "id": 5717,
    "content": "22"
  },
  {
    "id": 5718,
    "content": "2"
  },
  {
    "id": 5721,
    "content": "This form may have better performance than (a)"
  },
  {
    "id": 5722,
    "content": "} 14"
  },
  {
    "id": 5723,
    "content": "5"
  },
  {
    "id": 5724,
    "content": "22"
  },
  {
    "id": 5725,
    "content": "3"
  },
  {
    "id": 5727,
    "content": "directly invokable from device code"
  },
  {
    "id": 5728,
    "content": "14"
  },
  {
    "id": 5729,
    "content": "5"
  },
  {
    "id": 5730,
    "content": "22"
  },
  {
    "id": 5731,
    "content": "4"
  },
  {
    "id": 5734,
    "content": "p6] )"
  },
  {
    "id": 5735,
    "content": "14"
  },
  {
    "id": 5736,
    "content": "5"
  },
  {
    "id": 5737,
    "content": "22"
  },
  {
    "id": 5738,
    "content": "5"
  },
  {
    "id": 5740,
    "content": "g"
  },
  {
    "id": 5741,
    "content": ", __device__, __constant__, __shared__ )"
  },
  {
    "id": 5749,
    "content": "5"
  },
  {
    "id": 5750,
    "content": "22"
  },
  {
    "id": 5751,
    "content": "7"
  },
  {
    "id": 5752,
    "content": "thread_local  The thread_local storage specifier is not allowed in device code"
  },
  {
    "id": 5753,
    "content": "14"
  },
  {
    "id": 5754,
    "content": "5"
  },
  {
    "id": 5755,
    "content": "22"
  },
  {
    "id": 5756,
    "content": "8"
  },
  {
    "id": 5762,
    "content": "5"
  },
  {
    "id": 5763,
    "content": "22"
  },
  {
    "id": 5764,
    "content": "9"
  },
  {
    "id": 5766,
    "content": "14"
  },
  {
    "id": 5767,
    "content": "5"
  },
  {
    "id": 5768,
    "content": "22"
  },
  {
    "id": 5769,
    "content": "10"
  },
  {
    "id": 5773,
    "content": "5"
  },
  {
    "id": 5774,
    "content": "23"
  },
  {
    "id": 5776,
    "content": "5"
  },
  {
    "id": 5777,
    "content": "23"
  },
  {
    "id": 5778,
    "content": "1"
  },
  {
    "id": 5782,
    "content": "bodies struct S1_derived_t : S1_t { }; 14"
  },
  {
    "id": 5783,
    "content": "5"
  },
  {
    "id": 5784,
    "content": "23"
  },
  {
    "id": 5785,
    "content": "2"
  },
  {
    "id": 5788,
    "content": "5"
  },
  {
    "id": 5789,
    "content": "24"
  },
  {
    "id": 5791,
    "content": "14"
  },
  {
    "id": 5792,
    "content": "5"
  },
  {
    "id": 5793,
    "content": "24"
  },
  {
    "id": 5794,
    "content": "1"
  },
  {
    "id": 5797,
    "content": "14"
  },
  {
    "id": 5798,
    "content": "5"
  },
  {
    "id": 5799,
    "content": "24"
  },
  {
    "id": 5800,
    "content": "2"
  },
  {
    "id": 5801,
    "content": "Structured Binding  A structured binding cannot be declared with a variable memory space specifier"
  },
  {
    "id": 5802,
    "content": "Example: struct S { int x ; int y ; }; __device__ auto [ a1 , b1 ] = S { 4 , 5 };   error 14"
  },
  {
    "id": 5803,
    "content": "5"
  },
  {
    "id": 5804,
    "content": "25"
  },
  {
    "id": 5806,
    "content": "14"
  },
  {
    "id": 5807,
    "content": "5"
  },
  {
    "id": 5808,
    "content": "25"
  },
  {
    "id": 5809,
    "content": "1"
  },
  {
    "id": 5810,
    "content": "Module support  Modules are not supported in CUDA C++, in either host or device code"
  },
  {
    "id": 5811,
    "content": "Uses of the module , export and import keywords are diagnosed as errors"
  },
  {
    "id": 5812,
    "content": "14"
  },
  {
    "id": 5813,
    "content": "5"
  },
  {
    "id": 5814,
    "content": "25"
  },
  {
    "id": 5815,
    "content": "2"
  },
  {
    "id": 5816,
    "content": "Coroutine support  Coroutines are not supported in device code"
  },
  {
    "id": 5818,
    "content": "14"
  },
  {
    "id": 5819,
    "content": "5"
  },
  {
    "id": 5820,
    "content": "25"
  },
  {
    "id": 5821,
    "content": "3"
  },
  {
    "id": 5823,
    "content": "the requirements of device code"
  },
  {
    "id": 5833,
    "content": "7"
  },
  {
    "id": 5834,
    "content": "2"
  },
  {
    "id": 5865,
    "content": "static_assert ("
  },
  {
    "id": 5867,
    "content": "object represented by an extended lambda is passed from host to device code (e"
  },
  {
    "id": 5868,
    "content": "g"
  },
  {
    "id": 5875,
    "content": "frontend compiler versus the host compiler"
  },
  {
    "id": 5880,
    "content": "14"
  },
  {
    "id": 5881,
    "content": "7"
  },
  {
    "id": 5882,
    "content": "3"
  },
  {
    "id": 5886,
    "content": "14"
  },
  {
    "id": 5887,
    "content": "7"
  },
  {
    "id": 5888,
    "content": "4"
  },
  {
    "id": 5892,
    "content": "GPU foo >> ( lam1 ); cudaDeviceSynchronize (); } }; int main ( void ) { S1_t s1 ; s1"
  },
  {
    "id": 5894,
    "content": "open-std"
  },
  {
    "id": 5895,
    "content": "org/jtc1/sc22/wg21/docs/papers/2016/p0018r3"
  },
  {
    "id": 5896,
    "content": "html"
  },
  {
    "id": 5903,
    "content": "14"
  },
  {
    "id": 5904,
    "content": "8"
  },
  {
    "id": 5905,
    "content": "Code Samples  14"
  },
  {
    "id": 5906,
    "content": "8"
  },
  {
    "id": 5907,
    "content": "1"
  },
  {
    "id": 5909,
    "content": "PixelRGBA operator + ( const PixelRGBA & p1 , const PixelRGBA & p2 ) { return PixelRGBA ( p1"
  },
  {
    "id": 5912,
    "content": "return shape ; } 14"
  },
  {
    "id": 5913,
    "content": "8"
  },
  {
    "id": 5914,
    "content": "3"
  },
  {
    "id": 5916,
    "content": "} 14"
  },
  {
    "id": 5917,
    "content": "8"
  },
  {
    "id": 5918,
    "content": "4"
  },
  {
    "id": 5919,
    "content": "Function Template  template __device__ bool func ( T x ) {"
  },
  {
    "id": 5921,
    "content": "8"
  },
  {
    "id": 5922,
    "content": "5"
  },
  {
    "id": 5926,
    "content": "19 Note that this may negatively impact compile time due to presence of extra declarations"
  },
  {
    "id": 5928,
    "content": "7, clang, icc >= 15, and xlc >= 13"
  },
  {
    "id": 5929,
    "content": "1 21 including operator() 22 The restrictions are the same as with a non-constexpr callee function"
  },
  {
    "id": 5930,
    "content": "24 C++ Standard Section [basic types] 25 C++ Standard Section [expr"
  },
  {
    "id": 5933,
    "content": "Visual Studio Version >= 2022 and nvc++ version >= 20"
  },
  {
    "id": 5934,
    "content": "7"
  },
  {
    "id": 5936,
    "content": "15"
  },
  {
    "id": 5939,
    "content": "15"
  },
  {
    "id": 5940,
    "content": "1"
  },
  {
    "id": 5944,
    "content": "Capability 9 0 give more details on the architecture of devices of compute capabilities 5"
  },
  {
    "id": 5945,
    "content": "x, 6"
  },
  {
    "id": 5946,
    "content": "x, 7"
  },
  {
    "id": 5947,
    "content": "x, 8"
  },
  {
    "id": 5948,
    "content": "x and 9"
  },
  {
    "id": 5949,
    "content": "0 respectively"
  },
  {
    "id": 5950,
    "content": "16"
  },
  {
    "id": 5951,
    "content": "1"
  },
  {
    "id": 5962,
    "content": "e"
  },
  {
    "id": 5963,
    "content": ", behave equivalent to FADD"
  },
  {
    "id": 5964,
    "content": "F32"
  },
  {
    "id": 5965,
    "content": "FTZ"
  },
  {
    "id": 5967,
    "content": "e"
  },
  {
    "id": 5968,
    "content": ", behave equivalent to FADD"
  },
  {
    "id": 5969,
    "content": "F32"
  },
  {
    "id": 5970,
    "content": "RN"
  },
  {
    "id": 5972,
    "content": "and integer overflow is left undefined by IEEE-754"
  },
  {
    "id": 5974,
    "content": "https: developer"
  },
  {
    "id": 5976,
    "content": "16"
  },
  {
    "id": 5977,
    "content": "4"
  },
  {
    "id": 5978,
    "content": "Compute Capability 5"
  },
  {
    "id": 5979,
    "content": "x  16"
  },
  {
    "id": 5980,
    "content": "4"
  },
  {
    "id": 5981,
    "content": "1"
  },
  {
    "id": 5985,
    "content": "2"
  },
  {
    "id": 5987,
    "content": "Device Enumeration ) The cache behavior (e"
  },
  {
    "id": 5988,
    "content": "g"
  },
  {
    "id": 5990,
    "content": "16"
  },
  {
    "id": 5991,
    "content": "4"
  },
  {
    "id": 5992,
    "content": "2"
  },
  {
    "id": 5993,
    "content": "Global Memory  Global memory accesses are always cached in L2"
  },
  {
    "id": 5996,
    "content": "0"
  },
  {
    "id": 5997,
    "content": "For devices of compute capability 5"
  },
  {
    "id": 6000,
    "content": "the kernel launches for which thread blocks consume too much of the SM’s register file"
  },
  {
    "id": 6001,
    "content": "These exceptions are reported by the profiler"
  },
  {
    "id": 6002,
    "content": "16"
  },
  {
    "id": 6003,
    "content": "4"
  },
  {
    "id": 6004,
    "content": "3"
  },
  {
    "id": 6007,
    "content": "16"
  },
  {
    "id": 6008,
    "content": "5"
  },
  {
    "id": 6009,
    "content": "Compute Capability 6"
  },
  {
    "id": 6010,
    "content": "x  16"
  },
  {
    "id": 6011,
    "content": "5"
  },
  {
    "id": 6012,
    "content": "1"
  },
  {
    "id": 6013,
    "content": "Architecture  An SM consists of: 64 (compute capability 6"
  },
  {
    "id": 6014,
    "content": "0) or 128 (6"
  },
  {
    "id": 6015,
    "content": "1 and 6"
  },
  {
    "id": 6016,
    "content": "2) CUDA cores for arithmetic operations, 16 (6"
  },
  {
    "id": 6017,
    "content": "0) or 32 (6"
  },
  {
    "id": 6018,
    "content": "1 and 6"
  },
  {
    "id": 6019,
    "content": "2) special function units for single-precision floating-point transcendental functions, 2 (6"
  },
  {
    "id": 6020,
    "content": "0) or 4 (6"
  },
  {
    "id": 6021,
    "content": "1 and 6"
  },
  {
    "id": 6022,
    "content": "2) warp schedulers"
  },
  {
    "id": 6024,
    "content": "0 and 6"
  },
  {
    "id": 6025,
    "content": "2) or 48 KB (6 1), a shared memory of size 64 KB (6"
  },
  {
    "id": 6026,
    "content": "0 and 6"
  },
  {
    "id": 6027,
    "content": "2) or 96 KB (6"
  },
  {
    "id": 6028,
    "content": "1)"
  },
  {
    "id": 6029,
    "content": "16"
  },
  {
    "id": 6030,
    "content": "5"
  },
  {
    "id": 6031,
    "content": "2"
  },
  {
    "id": 6033,
    "content": "16"
  },
  {
    "id": 6034,
    "content": "5"
  },
  {
    "id": 6035,
    "content": "3"
  },
  {
    "id": 6040,
    "content": "16"
  },
  {
    "id": 6041,
    "content": "6"
  },
  {
    "id": 6042,
    "content": "2"
  },
  {
    "id": 6057,
    "content": "Compute capability 7"
  },
  {
    "id": 6060,
    "content": "16"
  },
  {
    "id": 6061,
    "content": "7"
  },
  {
    "id": 6062,
    "content": "Compute Capability 8"
  },
  {
    "id": 6063,
    "content": "x  16"
  },
  {
    "id": 6064,
    "content": "7"
  },
  {
    "id": 6065,
    "content": "1"
  },
  {
    "id": 6067,
    "content": "0 and 8"
  },
  {
    "id": 6068,
    "content": "7 (1"
  },
  {
    "id": 6069,
    "content": "5x Volta ’s 128 KB capacity) and 128 KB for devices of compute capabilities 8"
  },
  {
    "id": 6070,
    "content": "6 and 8"
  },
  {
    "id": 6071,
    "content": "9"
  },
  {
    "id": 6073,
    "content": "16"
  },
  {
    "id": 6074,
    "content": "7"
  },
  {
    "id": 6075,
    "content": "2"
  },
  {
    "id": 6077,
    "content": "16"
  },
  {
    "id": 6078,
    "content": "7"
  },
  {
    "id": 6079,
    "content": "3"
  },
  {
    "id": 6081,
    "content": "0 and 8 7 and 128 KB for devices of compute capabilities 8 6 and 8"
  },
  {
    "id": 6082,
    "content": "9"
  },
  {
    "id": 6084,
    "content": "0 and 8"
  },
  {
    "id": 6085,
    "content": "7, and to 0, 8, 16, 32, 64 or 100 KB for devices of compute capabilities 8"
  },
  {
    "id": 6086,
    "content": "6 and 8"
  },
  {
    "id": 6087,
    "content": "9"
  },
  {
    "id": 6088,
    "content": "An application can set the carveout , i"
  },
  {
    "id": 6089,
    "content": "e"
  },
  {
    "id": 6091,
    "content": "0 and 8 7 and 100 KB for devices of compute capabilities 8 6 and 8"
  },
  {
    "id": 6093,
    "content": "When using a percentage, the carveout is rounded up to the nearest supported shared memory capacity"
  },
  {
    "id": 6094,
    "content": "For example, for devices of compute capability 8"
  },
  {
    "id": 6095,
    "content": "0, 50% will map to a 100 KB carveout instead of an 82 KB one"
  },
  {
    "id": 6097,
    "content": "Devices of compute capability 8"
  },
  {
    "id": 6098,
    "content": "0 and 8"
  },
  {
    "id": 6100,
    "content": "6 and 8"
  },
  {
    "id": 6103,
    "content": "16"
  },
  {
    "id": 6104,
    "content": "8"
  },
  {
    "id": 6105,
    "content": "Compute Capability 9"
  },
  {
    "id": 6106,
    "content": "0  16"
  },
  {
    "id": 6107,
    "content": "8"
  },
  {
    "id": 6108,
    "content": "1"
  },
  {
    "id": 6112,
    "content": "0 (1"
  },
  {
    "id": 6113,
    "content": "33x NVIDIA Ampere GPU Architecture ’s 192 KB capacity)"
  },
  {
    "id": 6114,
    "content": "16"
  },
  {
    "id": 6115,
    "content": "8"
  },
  {
    "id": 6116,
    "content": "2"
  },
  {
    "id": 6117,
    "content": "16"
  },
  {
    "id": 6118,
    "content": "8"
  },
  {
    "id": 6119,
    "content": "3"
  },
  {
    "id": 6121,
    "content": "0"
  },
  {
    "id": 6123,
    "content": "e"
  },
  {
    "id": 6124,
    "content": ", the carveout"
  },
  {
    "id": 6125,
    "content": "Devices of compute capability 9"
  },
  {
    "id": 6127,
    "content": "5 16"
  },
  {
    "id": 6128,
    "content": "8"
  },
  {
    "id": 6129,
    "content": "4"
  },
  {
    "id": 6133,
    "content": "CUDA"
  },
  {
    "id": 6134,
    "content": "17"
  },
  {
    "id": 6143,
    "content": "} Full code can be found in the vectorAddDrv CUDA sample"
  },
  {
    "id": 6144,
    "content": "17"
  },
  {
    "id": 6145,
    "content": "1"
  },
  {
    "id": 6148,
    "content": "As a result, CUdeviceptr values from different contexts reference different memory locations"
  },
  {
    "id": 6155,
    "content": "17"
  },
  {
    "id": 6156,
    "content": "3"
  },
  {
    "id": 6168,
    "content": "17"
  },
  {
    "id": 6169,
    "content": "5"
  },
  {
    "id": 6170,
    "content": "Driver Entry Point Access  17"
  },
  {
    "id": 6171,
    "content": "5"
  },
  {
    "id": 6172,
    "content": "1"
  },
  {
    "id": 6174,
    "content": "Starting from CUDA 11"
  },
  {
    "id": 6176,
    "content": "CUDA features on older toolkits but with a newer driver"
  },
  {
    "id": 6177,
    "content": "17"
  },
  {
    "id": 6178,
    "content": "5"
  },
  {
    "id": 6179,
    "content": "2"
  },
  {
    "id": 6181,
    "content": "Table 23 Typedefs header files for CUDA driver APIs  API header file API Typedef header file cuda"
  },
  {
    "id": 6182,
    "content": "h cudaTypedefs"
  },
  {
    "id": 6183,
    "content": "h cudaGL"
  },
  {
    "id": 6184,
    "content": "h cudaGLTypedefs"
  },
  {
    "id": 6185,
    "content": "h cudaProfiler"
  },
  {
    "id": 6186,
    "content": "h cudaProfilerTypedefs"
  },
  {
    "id": 6187,
    "content": "h cudaVDPAU"
  },
  {
    "id": 6188,
    "content": "h cudaVDPAUTypedefs"
  },
  {
    "id": 6189,
    "content": "h cudaEGL"
  },
  {
    "id": 6190,
    "content": "h cudaEGLTypedefs"
  },
  {
    "id": 6191,
    "content": "h cudaD3D9"
  },
  {
    "id": 6192,
    "content": "h cudaD3D9Typedefs"
  },
  {
    "id": 6193,
    "content": "h cudaD3D10"
  },
  {
    "id": 6194,
    "content": "h cudaD3D10Typedefs"
  },
  {
    "id": 6195,
    "content": "h cudaD3D11"
  },
  {
    "id": 6196,
    "content": "h cudaD3D11Typedefs"
  },
  {
    "id": 6198,
    "content": "For example, cudaTypedefs"
  },
  {
    "id": 6201,
    "content": "0 (2000) is PFN_cuMemAlloc_v2000"
  },
  {
    "id": 6202,
    "content": "The typedef for the next version which was introduced in CUDA 3"
  },
  {
    "id": 6205,
    "content": "For CUDA 11"
  },
  {
    "id": 6207,
    "content": "5"
  },
  {
    "id": 6208,
    "content": "3"
  },
  {
    "id": 6210,
    "content": "17"
  },
  {
    "id": 6211,
    "content": "5"
  },
  {
    "id": 6212,
    "content": "3"
  },
  {
    "id": 6213,
    "content": "1"
  },
  {
    "id": 6216,
    "content": "h :   cuda"
  },
  {
    "id": 6219,
    "content": "0 and CUDA 10"
  },
  {
    "id": 6220,
    "content": "1 respectively"
  },
  {
    "id": 6223,
    "content": "0 (10000)"
  },
  {
    "id": 6224,
    "content": "Similarly, the CUDA version for retrieving the address to the _v2 version of the API should be 10"
  },
  {
    "id": 6225,
    "content": "1 (10010)"
  },
  {
    "id": 6228,
    "content": "3 driver"
  },
  {
    "id": 6231,
    "content": "Assuming we are using CUDA 11"
  },
  {
    "id": 6234,
    "content": "3"
  },
  {
    "id": 6236,
    "content": "In the above code examples, passing in a version less than 10000 (CUDA 10"
  },
  {
    "id": 6237,
    "content": "0) would be invalid"
  },
  {
    "id": 6238,
    "content": "17"
  },
  {
    "id": 6239,
    "content": "5"
  },
  {
    "id": 6240,
    "content": "3"
  },
  {
    "id": 6241,
    "content": "2"
  },
  {
    "id": 6243,
    "content": "2 as cuMemAllocAsync was introduced then"
  },
  {
    "id": 6245,
    "content": "Assuming CUDA runtime version >= 11"
  },
  {
    "id": 6248,
    "content": "17"
  },
  {
    "id": 6249,
    "content": "5"
  },
  {
    "id": 6250,
    "content": "3"
  },
  {
    "id": 6251,
    "content": "3"
  },
  {
    "id": 6255,
    "content": "17"
  },
  {
    "id": 6256,
    "content": "5"
  },
  {
    "id": 6257,
    "content": "3"
  },
  {
    "id": 6258,
    "content": "4"
  },
  {
    "id": 6260,
    "content": "For discussion, let us assume the user is on CUDA 11"
  },
  {
    "id": 6262,
    "content": "Manually define the prototype as cudaTypedefs"
  },
  {
    "id": 6263,
    "content": "h in CUDA 11"
  },
  {
    "id": 6267,
    "content": "17"
  },
  {
    "id": 6268,
    "content": "5"
  },
  {
    "id": 6269,
    "content": "4"
  },
  {
    "id": 6270,
    "content": "1"
  },
  {
    "id": 6271,
    "content": "Implications with cuGetProcAddress vs Implicit Linking  cuDeviceGetUuid was introduced in CUDA 9"
  },
  {
    "id": 6272,
    "content": "2"
  },
  {
    "id": 6274,
    "content": "h until CUDA 12"
  },
  {
    "id": 6275,
    "content": "0"
  },
  {
    "id": 6278,
    "content": "4"
  },
  {
    "id": 6280,
    "content": "CUDA_SUCCESS == status && pfn_cuDeviceGetUuid ) { pfn_cuDeviceGetUuid points to"
  },
  {
    "id": 6281,
    "content": "} In this example, assume the user is compiling with CUDA 11"
  },
  {
    "id": 6282,
    "content": "4"
  },
  {
    "id": 6284,
    "content": "17"
  },
  {
    "id": 6285,
    "content": "5"
  },
  {
    "id": 6286,
    "content": "4"
  },
  {
    "id": 6287,
    "content": "2"
  },
  {
    "id": 6293,
    "content": "In this example, assume the user is compiling with CUDA 11"
  },
  {
    "id": 6294,
    "content": "3"
  },
  {
    "id": 6297,
    "content": "4 (without updating the toolkit and runtime) without requiring recompilation"
  },
  {
    "id": 6300,
    "content": "In Implications to API/ABI , we discuss a more problematic case of API/ABI compatibility"
  },
  {
    "id": 6301,
    "content": "17"
  },
  {
    "id": 6302,
    "content": "5"
  },
  {
    "id": 6303,
    "content": "4"
  },
  {
    "id": 6304,
    "content": "3"
  },
  {
    "id": 6305,
    "content": "API Version Bumps with Explicit Version Checks  Above, was a specific concrete example"
  },
  {
    "id": 6308,
    "content": "has been modified twice since original creation in CUDA 11 4 and the latest in CUDA 11"
  },
  {
    "id": 6309,
    "content": "6 also modified the API/ABI interface to the function"
  },
  {
    "id": 6310,
    "content": "The usage in user code compiled against CUDA 11"
  },
  {
    "id": 6315,
    "content": "17"
  },
  {
    "id": 6316,
    "content": "5"
  },
  {
    "id": 6317,
    "content": "4"
  },
  {
    "id": 6318,
    "content": "4"
  },
  {
    "id": 6321,
    "content": "pfn_cuDeviceGetUuidRuntime ) { pfn_cuDeviceGetUuid points to"
  },
  {
    "id": 6323,
    "content": "3 => 11"
  },
  {
    "id": 6324,
    "content": "3 CUDA Runtime and Toolkit (includes header files cuda"
  },
  {
    "id": 6325,
    "content": "h and cudaTypedefs"
  },
  {
    "id": 6326,
    "content": "h) V11"
  },
  {
    "id": 6327,
    "content": "4 => 11"
  },
  {
    "id": 6328,
    "content": "4 CUDA Runtime and Toolkit (includes header files cuda"
  },
  {
    "id": 6329,
    "content": "h and cudaTypedefs"
  },
  {
    "id": 6331,
    "content": "In these cases, the typedef at compile time using a CUDA 11"
  },
  {
    "id": 6334,
    "content": "3) combination, labeled as v1x in the above"
  },
  {
    "id": 6336,
    "content": "17"
  },
  {
    "id": 6337,
    "content": "5"
  },
  {
    "id": 6338,
    "content": "4"
  },
  {
    "id": 6339,
    "content": "5"
  },
  {
    "id": 6342,
    "content": "17"
  },
  {
    "id": 6343,
    "content": "5"
  },
  {
    "id": 6344,
    "content": "4"
  },
  {
    "id": 6345,
    "content": "6"
  },
  {
    "id": 6347,
    "content": "17"
  },
  {
    "id": 6348,
    "content": "5"
  },
  {
    "id": 6349,
    "content": "4"
  },
  {
    "id": 6350,
    "content": "7"
  },
  {
    "id": 6352,
    "content": "So, on a system without MIG, the user might not even realize they are getting a different API"
  },
  {
    "id": 6354,
    "content": "The _v2 version, introduced in CUDA 3"
  },
  {
    "id": 6355,
    "content": "2 is currently used as the default cuCtxCreate when using cuda"
  },
  {
    "id": 6356,
    "content": "h but now has a newer version introduced in CUDA 11"
  },
  {
    "id": 6357,
    "content": "4 ( cuCtxCreate_v3 )"
  },
  {
    "id": 6359,
    "content": "For example, assume the following code compiled against a CUDA 11 3 toolkit with a CUDA 11"
  },
  {
    "id": 6362,
    "content": "17"
  },
  {
    "id": 6363,
    "content": "5"
  },
  {
    "id": 6364,
    "content": "5"
  },
  {
    "id": 6365,
    "content": "Determining cuGetProcAddress Failure Reasons  There are two types of errors with cuGetProcAddress"
  },
  {
    "id": 6368,
    "content": "4 would give this result of CU_GET_PROC_ADDRESS_VERSION_NOT_SUFFICIENT"
  },
  {
    "id": 6373,
    "content": "application running against a CUDA 11"
  },
  {
    "id": 6375,
    "content": "18"
  },
  {
    "id": 6390,
    "content": "or enables (when set to 0) asynchronous kernel launches"
  },
  {
    "id": 6392,
    "content": "5 and above"
  },
  {
    "id": 6394,
    "content": "CUDA_SCALE_LAUNCH_QUEUES “0"
  },
  {
    "id": 6395,
    "content": "25x”, “0"
  },
  {
    "id": 6396,
    "content": "5x”, “2x” or “4x” Scales the size of the queues available for launching work by a fixed multiplier"
  },
  {
    "id": 6398,
    "content": "x allow, a portion of L2 cache to be set-aside for persisting data accesses to global memory"
  },
  {
    "id": 6400,
    "content": "I"
  },
  {
    "id": 6401,
    "content": "e"
  },
  {
    "id": 6402,
    "content": ", the environment variable should be set before running the command nvidia-cuda-mps-control -d"
  },
  {
    "id": 6409,
    "content": "19"
  },
  {
    "id": 6410,
    "content": "Unified Memory Programming  Note This chapter applies to devices with compute capability 5"
  },
  {
    "id": 6411,
    "content": "0 or higher unless stated otherwise"
  },
  {
    "id": 6412,
    "content": "For devices with compute capability lower than 5"
  },
  {
    "id": 6413,
    "content": "0, refer to the CUDA toolkit documentation for CUDA 11"
  },
  {
    "id": 6414,
    "content": "8"
  },
  {
    "id": 6416,
    "content": "1"
  },
  {
    "id": 6418,
    "content": ")"
  },
  {
    "id": 6421,
    "content": "Applications can trigger manual migration of data and may use hints to control migration heuristics"
  },
  {
    "id": 6422,
    "content": "Total system memory usage may be reduced by avoiding duplicating memory on both CPUs and GPUs"
  },
  {
    "id": 6423,
    "content": "Functionality : it enables GPU programs to work on data that exceeds the GPU memory’s capacity"
  },
  {
    "id": 6427,
    "content": "and may perform better than System-Allocated Memory"
  },
  {
    "id": 6428,
    "content": "19"
  },
  {
    "id": 6429,
    "content": "1"
  },
  {
    "id": 6430,
    "content": "1"
  },
  {
    "id": 6437,
    "content": "1"
  },
  {
    "id": 6438,
    "content": "24+, 6"
  },
  {
    "id": 6439,
    "content": "2"
  },
  {
    "id": 6440,
    "content": "11+ or 6"
  },
  {
    "id": 6441,
    "content": "3+, devices with compute capability 7"
  },
  {
    "id": 6442,
    "content": "5 or higher and a CUDA driver version 535+ installed with Open Kernel Modules"
  },
  {
    "id": 6444,
    "content": "19"
  },
  {
    "id": 6445,
    "content": "1"
  },
  {
    "id": 6446,
    "content": "2"
  },
  {
    "id": 6452,
    "content": "19"
  },
  {
    "id": 6453,
    "content": "1"
  },
  {
    "id": 6454,
    "content": "2"
  },
  {
    "id": 6455,
    "content": "1"
  },
  {
    "id": 6460,
    "content": "1"
  },
  {
    "id": 6461,
    "content": "2"
  },
  {
    "id": 6462,
    "content": "2"
  },
  {
    "id": 6466,
    "content": "Managed Memory allocations, but do not provide full support, see Coherency and Concurrency"
  },
  {
    "id": 6467,
    "content": "Implementation details (may change any time): Devices of compute capability 5"
  },
  {
    "id": 6468,
    "content": "x allocate CUDA Managed Memory on the GPU"
  },
  {
    "id": 6469,
    "content": "Devices of compute capability 6"
  },
  {
    "id": 6470,
    "content": "x and greater populate the memory on first touch, just like System-Allocated Memory APIs"
  },
  {
    "id": 6471,
    "content": "19"
  },
  {
    "id": 6472,
    "content": "1"
  },
  {
    "id": 6473,
    "content": "2"
  },
  {
    "id": 6474,
    "content": "3"
  },
  {
    "id": 6483,
    "content": "19"
  },
  {
    "id": 6484,
    "content": "1"
  },
  {
    "id": 6485,
    "content": "2"
  },
  {
    "id": 6486,
    "content": "4"
  },
  {
    "id": 6488,
    "content": "more systems than Unified Memory"
  },
  {
    "id": 6489,
    "content": "19"
  },
  {
    "id": 6490,
    "content": "1"
  },
  {
    "id": 6491,
    "content": "2"
  },
  {
    "id": 6492,
    "content": "5"
  },
  {
    "id": 6497,
    "content": "to be read from and only occasionally written to"
  },
  {
    "id": 6501,
    "content": "from its preferred location"
  },
  {
    "id": 6505,
    "content": "19"
  },
  {
    "id": 6506,
    "content": "1"
  },
  {
    "id": 6507,
    "content": "2"
  },
  {
    "id": 6508,
    "content": "8"
  },
  {
    "id": 6509,
    "content": "3"
  },
  {
    "id": 6516,
    "content": "19"
  },
  {
    "id": 6517,
    "content": "2"
  },
  {
    "id": 6518,
    "content": "Unified memory on devices with full CUDA Unified Memory support  19"
  },
  {
    "id": 6519,
    "content": "2"
  },
  {
    "id": 6520,
    "content": "1"
  },
  {
    "id": 6529,
    "content": "19"
  },
  {
    "id": 6530,
    "content": "2"
  },
  {
    "id": 6531,
    "content": "1"
  },
  {
    "id": 6532,
    "content": "1"
  },
  {
    "id": 6538,
    "content": "19"
  },
  {
    "id": 6539,
    "content": "2"
  },
  {
    "id": 6540,
    "content": "1"
  },
  {
    "id": 6541,
    "content": "2"
  },
  {
    "id": 6545,
    "content": "19"
  },
  {
    "id": 6546,
    "content": "2"
  },
  {
    "id": 6547,
    "content": "2"
  },
  {
    "id": 6550,
    "content": "19"
  },
  {
    "id": 6551,
    "content": "2"
  },
  {
    "id": 6552,
    "content": "2"
  },
  {
    "id": 6553,
    "content": "1"
  },
  {
    "id": 6560,
    "content": "19"
  },
  {
    "id": 6561,
    "content": "2"
  },
  {
    "id": 6562,
    "content": "2"
  },
  {
    "id": 6563,
    "content": "1"
  },
  {
    "id": 6564,
    "content": "1"
  },
  {
    "id": 6568,
    "content": "the hardware The advice above only applies to virtual page sizes"
  },
  {
    "id": 6569,
    "content": "19"
  },
  {
    "id": 6570,
    "content": "2"
  },
  {
    "id": 6571,
    "content": "2"
  },
  {
    "id": 6572,
    "content": "1"
  },
  {
    "id": 6573,
    "content": "2"
  },
  {
    "id": 6581,
    "content": "Signaling a GPU thread from a CPU thread or vice-versa"
  },
  {
    "id": 6582,
    "content": "19"
  },
  {
    "id": 6583,
    "content": "2"
  },
  {
    "id": 6584,
    "content": "2"
  },
  {
    "id": 6585,
    "content": "2"
  },
  {
    "id": 6593,
    "content": "fault and migrate pages back to GPU memory"
  },
  {
    "id": 6594,
    "content": "19"
  },
  {
    "id": 6595,
    "content": "2"
  },
  {
    "id": 6596,
    "content": "2"
  },
  {
    "id": 6597,
    "content": "3"
  },
  {
    "id": 6599,
    "content": "For these devices, the attribute cudaDevAttrHostNativeAtomicSupported is set to 1"
  },
  {
    "id": 6600,
    "content": "19"
  },
  {
    "id": 6601,
    "content": "3"
  },
  {
    "id": 6602,
    "content": "Unified memory on devices without full CUDA Unified Memory support  19"
  },
  {
    "id": 6603,
    "content": "3"
  },
  {
    "id": 6604,
    "content": "1"
  },
  {
    "id": 6606,
    "content": "exception that system allocators cannot be used to allocate memory"
  },
  {
    "id": 6608,
    "content": "3"
  },
  {
    "id": 6609,
    "content": "2"
  },
  {
    "id": 6611,
    "content": "0 with limited support for data migration and coherency as well as memory oversubscription"
  },
  {
    "id": 6613,
    "content": "19"
  },
  {
    "id": 6614,
    "content": "3"
  },
  {
    "id": 6615,
    "content": "2"
  },
  {
    "id": 6616,
    "content": "1"
  },
  {
    "id": 6617,
    "content": "Data Migration and Coherency  GPU architectures of compute capability lower than 6"
  },
  {
    "id": 6619,
    "content": "With compute capability 6"
  },
  {
    "id": 6622,
    "content": "from CPU memory or from the memory of other GPUs in the system"
  },
  {
    "id": 6623,
    "content": "19"
  },
  {
    "id": 6624,
    "content": "3"
  },
  {
    "id": 6625,
    "content": "2"
  },
  {
    "id": 6626,
    "content": "2"
  },
  {
    "id": 6628,
    "content": "19"
  },
  {
    "id": 6629,
    "content": "3"
  },
  {
    "id": 6630,
    "content": "2"
  },
  {
    "id": 6631,
    "content": "3"
  },
  {
    "id": 6632,
    "content": "Multi-GPU  On systems with devices of compute capabilities lower than 6"
  },
  {
    "id": 6636,
    "content": "allocated in GPU memory"
  },
  {
    "id": 6639,
    "content": "Note that starting from CUDA 8"
  },
  {
    "id": 6640,
    "content": "0 CUDA_MANAGED_FORCE_DEVICE_ALLOC has no effect on Linux operating systems"
  },
  {
    "id": 6641,
    "content": "19"
  },
  {
    "id": 6642,
    "content": "3"
  },
  {
    "id": 6643,
    "content": "2"
  },
  {
    "id": 6644,
    "content": "4"
  },
  {
    "id": 6647,
    "content": "19"
  },
  {
    "id": 6648,
    "content": "3"
  },
  {
    "id": 6649,
    "content": "2"
  },
  {
    "id": 6650,
    "content": "4"
  },
  {
    "id": 6651,
    "content": "1"
  },
  {
    "id": 6652,
    "content": "GPU Exclusive Access To Managed Memory  To ensure coherency on pre-6"
  },
  {
    "id": 6656,
    "content": "CPU touches y"
  },
  {
    "id": 6657,
    "content": "(Note how it occurs before cudaDeviceSynchronize()"
  },
  {
    "id": 6658,
    "content": ") The code runs successfully on devices of compute capability 6"
  },
  {
    "id": 6659,
    "content": "x due to the GPU page faulting capability which lifts all restrictions on simultaneous access"
  },
  {
    "id": 6660,
    "content": "However, such memory access is invalid on pre-6"
  },
  {
    "id": 6661,
    "content": "x architectures even though the CPU is accessing different data than the GPU"
  },
  {
    "id": 6667,
    "content": "This does not apply to memory allocated using the flag cudaMemAttachHost or CU_MEM_ATTACH_HOST"
  },
  {
    "id": 6668,
    "content": "19"
  },
  {
    "id": 6669,
    "content": "3"
  },
  {
    "id": 6670,
    "content": "2"
  },
  {
    "id": 6671,
    "content": "4"
  },
  {
    "id": 6672,
    "content": "2"
  },
  {
    "id": 6676,
    "content": "documented as being fully synchronous with respect to the host"
  },
  {
    "id": 6690,
    "content": "(Currently, length must always be 0 to indicate that the entire region should be attached"
  },
  {
    "id": 6692,
    "content": "a specific stream, it is visible to all running kernels regardless of their stream"
  },
  {
    "id": 6694,
    "content": "is the programmer’s responsibility to ensure that guarantee is honored"
  },
  {
    "id": 6696,
    "content": "19"
  },
  {
    "id": 6697,
    "content": "3"
  },
  {
    "id": 6698,
    "content": "2"
  },
  {
    "id": 6699,
    "content": "4"
  },
  {
    "id": 6700,
    "content": "4"
  },
  {
    "id": 6702,
    "content": "0"
  },
  {
    "id": 6705,
    "content": "(As before, note the absence of cudaDeviceSynchronize() before the access"
  },
  {
    "id": 6706,
    "content": ") Accesses to y by the GPU running kernel will now produce undefined results"
  },
  {
    "id": 6708,
    "content": "cudaStreamAttachMemAsync ( stream1 , & x ); Associate “x” with stream1"
  },
  {
    "id": 6711,
    "content": "19"
  },
  {
    "id": 6712,
    "content": "3"
  },
  {
    "id": 6713,
    "content": "2"
  },
  {
    "id": 6714,
    "content": "4"
  },
  {
    "id": 6715,
    "content": "5"
  },
  {
    "id": 6721,
    "content": "19"
  },
  {
    "id": 6722,
    "content": "3"
  },
  {
    "id": 6723,
    "content": "2"
  },
  {
    "id": 6724,
    "content": "4"
  },
  {
    "id": 6725,
    "content": "6"
  },
  {
    "id": 6727,
    "content": "(The default allocation would be visible to all GPU kernels on all streams"
  },
  {
    "id": 6732,
    "content": "visibility"
  },
  {
    "id": 6734,
    "content": "19"
  },
  {
    "id": 6735,
    "content": "3"
  },
  {
    "id": 6736,
    "content": "2"
  },
  {
    "id": 6737,
    "content": "4"
  },
  {
    "id": 6738,
    "content": "7"
  },
  {
    "id": 6745,
    "content": "20 Lazy Loading  20"
  },
  {
    "id": 6746,
    "content": "1"
  },
  {
    "id": 6753,
    "content": "kernel is used/referenced for the first time"
  },
  {
    "id": 6755,
    "content": "20"
  },
  {
    "id": 6756,
    "content": "2"
  },
  {
    "id": 6757,
    "content": "1"
  },
  {
    "id": 6759,
    "content": "7+"
  },
  {
    "id": 6760,
    "content": "20"
  },
  {
    "id": 6761,
    "content": "2"
  },
  {
    "id": 6762,
    "content": "2"
  },
  {
    "id": 6763,
    "content": "Toolkit  Lazy Loading was introduced in CUDA 11 7, and received a significant upgrade in CUDA 11"
  },
  {
    "id": 6764,
    "content": "8"
  },
  {
    "id": 6767,
    "content": "20"
  },
  {
    "id": 6768,
    "content": "2"
  },
  {
    "id": 6769,
    "content": "3"
  },
  {
    "id": 6770,
    "content": "Compiler  Lazy Loading does not require any compiler support"
  },
  {
    "id": 6771,
    "content": "Both SASS and PTX compiled with pre-11"
  },
  {
    "id": 6772,
    "content": "7 compilers can be loaded with Lazy Loading enabled, and will see full benefits of the feature"
  },
  {
    "id": 6773,
    "content": "However, 11"
  },
  {
    "id": 6774,
    "content": "7+ CUDA Runtime is still required, as described above"
  },
  {
    "id": 6775,
    "content": "20"
  },
  {
    "id": 6776,
    "content": "3"
  },
  {
    "id": 6780,
    "content": "20"
  },
  {
    "id": 6781,
    "content": "3"
  },
  {
    "id": 6782,
    "content": "1"
  },
  {
    "id": 6784,
    "content": "However, you can also use this API to control with finer granularity when kernels are loaded"
  },
  {
    "id": 6785,
    "content": "20"
  },
  {
    "id": 6786,
    "content": "3"
  },
  {
    "id": 6787,
    "content": "2"
  },
  {
    "id": 6789,
    "content": "This will ensure that the kernel is loaded without changing the state"
  },
  {
    "id": 6790,
    "content": "20"
  },
  {
    "id": 6791,
    "content": "4"
  },
  {
    "id": 6794,
    "content": "\"lazy\" : \"eager\" ) << std :: endl ; return 0 ; } 20"
  },
  {
    "id": 6795,
    "content": "5"
  },
  {
    "id": 6798,
    "content": "20"
  },
  {
    "id": 6799,
    "content": "5"
  },
  {
    "id": 6800,
    "content": "1"
  },
  {
    "id": 6804,
    "content": "5"
  },
  {
    "id": 6805,
    "content": "2"
  },
  {
    "id": 6809,
    "content": "kernels that will be used in the program before trying to initialize your allocator 20"
  },
  {
    "id": 6810,
    "content": "5"
  },
  {
    "id": 6811,
    "content": "3"
  },
  {
    "id": 6816,
    "content": "21"
  },
  {
    "id": 6817,
    "content": "1"
  },
  {
    "id": 6819,
    "content": "21"
  },
  {
    "id": 6820,
    "content": "1"
  },
  {
    "id": 6821,
    "content": "1"
  },
  {
    "id": 6823,
    "content": "Use CUDA_VISIBLE_DEVICES instead"
  },
  {
    "id": 6824,
    "content": "21"
  },
  {
    "id": 6825,
    "content": "1"
  },
  {
    "id": 6826,
    "content": "2"
  },
  {
    "id": 6829,
    "content": "1"
  },
  {
    "id": 6830,
    "content": "3"
  },
  {
    "id": 6831,
    "content": "Allocators and EGM support  Mapping system memory as EGM does not cause any performance issues"
  },
  {
    "id": 6833,
    "content": "21"
  },
  {
    "id": 6834,
    "content": "1"
  },
  {
    "id": 6835,
    "content": "4"
  },
  {
    "id": 6839,
    "content": "types"
  },
  {
    "id": 6840,
    "content": "21"
  },
  {
    "id": 6841,
    "content": "2"
  },
  {
    "id": 6842,
    "content": "Using the EGM Interface  21"
  },
  {
    "id": 6843,
    "content": "2"
  },
  {
    "id": 6844,
    "content": "1"
  },
  {
    "id": 6846,
    "content": "21"
  },
  {
    "id": 6847,
    "content": "2"
  },
  {
    "id": 6848,
    "content": "2"
  },
  {
    "id": 6852,
    "content": "21"
  },
  {
    "id": 6853,
    "content": "2"
  },
  {
    "id": 6854,
    "content": "2"
  },
  {
    "id": 6855,
    "content": "1"
  },
  {
    "id": 6862,
    "content": "2"
  },
  {
    "id": 6863,
    "content": "2"
  },
  {
    "id": 6864,
    "content": "2"
  },
  {
    "id": 6869,
    "content": "cudaMallocAsync ( & ptr , size , memPool , stream ); Note EGM is mapped with 2MB pages"
  },
  {
    "id": 6870,
    "content": "Therefore, users may encounter more TLB misses when accessing very large allocations"
  },
  {
    "id": 6871,
    "content": "21"
  },
  {
    "id": 6872,
    "content": "2"
  },
  {
    "id": 6873,
    "content": "3"
  },
  {
    "id": 6882,
    "content": ", 8 ); 22"
  },
  {
    "id": 6885,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 6897,
    "content": "22"
  },
  {
    "id": 6898,
    "content": "2"
  },
  {
    "id": 6899,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 6900,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 6901,
    "content": "22"
  },
  {
    "id": 6902,
    "content": "3"
  },
  {
    "id": 6904,
    "content": "S"
  },
  {
    "id": 6907,
    "content": "Recommendations for taking advantage of minor version compatibility in your application 16"
  },
  {
    "id": 6908,
    "content": "Preface v12"
  },
  {
    "id": 6912,
    "content": "As a result, it is recommended that first-time readers proceed through the guide sequentially"
  },
  {
    "id": 6914,
    "content": "available at no cost from the CUDA website https: docs"
  },
  {
    "id": 6915,
    "content": "nvidia"
  },
  {
    "id": 6920,
    "content": "1"
  },
  {
    "id": 6921,
    "content": "3"
  },
  {
    "id": 6922,
    "content": "1"
  },
  {
    "id": 6925,
    "content": "1"
  },
  {
    "id": 6926,
    "content": "3"
  },
  {
    "id": 6927,
    "content": "2"
  },
  {
    "id": 6932,
    "content": "1"
  },
  {
    "id": 6933,
    "content": "3"
  },
  {
    "id": 6934,
    "content": "3"
  },
  {
    "id": 6940,
    "content": "1"
  },
  {
    "id": 6941,
    "content": "3"
  },
  {
    "id": 6942,
    "content": "4"
  },
  {
    "id": 6946,
    "content": "1"
  },
  {
    "id": 6947,
    "content": "4"
  },
  {
    "id": 6954,
    "content": "1"
  },
  {
    "id": 6955,
    "content": "5"
  },
  {
    "id": 6961,
    "content": "2"
  },
  {
    "id": 6964,
    "content": "This capability makes them well suited to computations that can leverage parallel execution"
  },
  {
    "id": 6966,
    "content": "2"
  },
  {
    "id": 6967,
    "content": "1"
  },
  {
    "id": 6974,
    "content": "concurrent, lightweight threads in order to maximize throughput"
  },
  {
    "id": 6977,
    "content": "2"
  },
  {
    "id": 6978,
    "content": "2"
  },
  {
    "id": 6982,
    "content": "(See Data Transfer Between Host and Device"
  },
  {
    "id": 6997,
    "content": "3"
  },
  {
    "id": 6998,
    "content": "1"
  },
  {
    "id": 6999,
    "content": "1"
  },
  {
    "id": 7003,
    "content": "e"
  },
  {
    "id": 7007,
    "content": "$ gcc -O2 -g -pg myprog"
  },
  {
    "id": 7008,
    "content": "c $ gprof"
  },
  {
    "id": 7009,
    "content": "/a"
  },
  {
    "id": 7010,
    "content": "out > profile"
  },
  {
    "id": 7011,
    "content": "txt Each sample counts as 0"
  },
  {
    "id": 7012,
    "content": "01 seconds % cumulative self self total time seconds seconds calls ms/call ms/call name 33"
  },
  {
    "id": 7013,
    "content": "34 0"
  },
  {
    "id": 7014,
    "content": "02 0 02 7208 0"
  },
  {
    "id": 7015,
    "content": "00 0 00 genTimeStep 16"
  },
  {
    "id": 7016,
    "content": "67 0"
  },
  {
    "id": 7017,
    "content": "03 0"
  },
  {
    "id": 7018,
    "content": "01 240 0"
  },
  {
    "id": 7019,
    "content": "04 0"
  },
  {
    "id": 7020,
    "content": "12 calcStats 16"
  },
  {
    "id": 7021,
    "content": "67 0"
  },
  {
    "id": 7022,
    "content": "04 0"
  },
  {
    "id": 7023,
    "content": "01 8 1"
  },
  {
    "id": 7024,
    "content": "25 1 25 calcSummaryData 16"
  },
  {
    "id": 7025,
    "content": "67 0"
  },
  {
    "id": 7026,
    "content": "05 0"
  },
  {
    "id": 7027,
    "content": "01 7 1"
  },
  {
    "id": 7028,
    "content": "43 1 43 write 16"
  },
  {
    "id": 7029,
    "content": "67 0"
  },
  {
    "id": 7030,
    "content": "06 0"
  },
  {
    "id": 7031,
    "content": "01 mcount 0"
  },
  {
    "id": 7032,
    "content": "00 0"
  },
  {
    "id": 7033,
    "content": "06 0"
  },
  {
    "id": 7034,
    "content": "00 236 0 00 0 00 tzset 0 00 0"
  },
  {
    "id": 7035,
    "content": "06 0"
  },
  {
    "id": 7036,
    "content": "00 192 0 00 0 00 tolower 0 00 0"
  },
  {
    "id": 7037,
    "content": "06 0"
  },
  {
    "id": 7038,
    "content": "00 47 0 00 0 00 strlen 0 00 0"
  },
  {
    "id": 7039,
    "content": "06 0"
  },
  {
    "id": 7040,
    "content": "00 45 0 00 0 00 strchr 0 00 0"
  },
  {
    "id": 7041,
    "content": "06 0"
  },
  {
    "id": 7042,
    "content": "00 1 0 00 50 00 main 0 00 0"
  },
  {
    "id": 7043,
    "content": "06 0"
  },
  {
    "id": 7044,
    "content": "00 1 0 00 0 00 memcpy 0 00 0"
  },
  {
    "id": 7045,
    "content": "06 0"
  },
  {
    "id": 7046,
    "content": "00 1 0 00 10"
  },
  {
    "id": 7047,
    "content": "11 print 0"
  },
  {
    "id": 7048,
    "content": "00 0"
  },
  {
    "id": 7049,
    "content": "06 0"
  },
  {
    "id": 7050,
    "content": "00 1 0 00 0 00 profil 0 00 0"
  },
  {
    "id": 7051,
    "content": "06 0"
  },
  {
    "id": 7052,
    "content": "00 1 0 00 50 00 report 3"
  },
  {
    "id": 7053,
    "content": "1"
  },
  {
    "id": 7054,
    "content": "2"
  },
  {
    "id": 7056,
    "content": "Understanding Scaling discusses the potential benefit we might expect from such parallelization"
  },
  {
    "id": 7059,
    "content": "3"
  },
  {
    "id": 7060,
    "content": "1"
  },
  {
    "id": 7061,
    "content": "3"
  },
  {
    "id": 7066,
    "content": "3"
  },
  {
    "id": 7067,
    "content": "1"
  },
  {
    "id": 7068,
    "content": "3"
  },
  {
    "id": 7069,
    "content": "1"
  },
  {
    "id": 7074,
    "content": "to spend effort on increasing P , maximizing the amount of code that can be parallelized"
  },
  {
    "id": 7075,
    "content": "3"
  },
  {
    "id": 7076,
    "content": "1"
  },
  {
    "id": 7077,
    "content": "3"
  },
  {
    "id": 7078,
    "content": "2"
  },
  {
    "id": 7080,
    "content": "e"
  },
  {
    "id": 7083,
    "content": "handling the larger problem"
  },
  {
    "id": 7084,
    "content": "3"
  },
  {
    "id": 7085,
    "content": "1"
  },
  {
    "id": 7086,
    "content": "3"
  },
  {
    "id": 7087,
    "content": "3"
  },
  {
    "id": 7092,
    "content": "4"
  },
  {
    "id": 7095,
    "content": ") 5"
  },
  {
    "id": 7097,
    "content": "5"
  },
  {
    "id": 7098,
    "content": "1"
  },
  {
    "id": 7107,
    "content": "5"
  },
  {
    "id": 7108,
    "content": "2"
  },
  {
    "id": 7112,
    "content": "See http: www"
  },
  {
    "id": 7113,
    "content": "openacc"
  },
  {
    "id": 7114,
    "content": "org/ for details"
  },
  {
    "id": 7115,
    "content": "5"
  },
  {
    "id": 7116,
    "content": "3"
  },
  {
    "id": 7119,
    "content": "code"
  },
  {
    "id": 7120,
    "content": "More difficult to parallelize are applications with a very flat profile - i"
  },
  {
    "id": 7121,
    "content": "e"
  },
  {
    "id": 7124,
    "content": "6"
  },
  {
    "id": 7129,
    "content": "6"
  },
  {
    "id": 7130,
    "content": "1"
  },
  {
    "id": 7131,
    "content": "Verification  6"
  },
  {
    "id": 7132,
    "content": "1"
  },
  {
    "id": 7133,
    "content": "1"
  },
  {
    "id": 7141,
    "content": "6"
  },
  {
    "id": 7142,
    "content": "1"
  },
  {
    "id": 7143,
    "content": "2"
  },
  {
    "id": 7150,
    "content": "6"
  },
  {
    "id": 7151,
    "content": "2"
  },
  {
    "id": 7153,
    "content": "nvidia"
  },
  {
    "id": 7154,
    "content": "com/cuda-gdb"
  },
  {
    "id": 7156,
    "content": "nvidia"
  },
  {
    "id": 7157,
    "content": "com/nsight-visual-studio-edition"
  },
  {
    "id": 7158,
    "content": "Several third-party debuggers support CUDA debugging as well; see: https: developer"
  },
  {
    "id": 7159,
    "content": "nvidia"
  },
  {
    "id": 7160,
    "content": "com/debugging-solutions for more details"
  },
  {
    "id": 7161,
    "content": "6"
  },
  {
    "id": 7162,
    "content": "3"
  },
  {
    "id": 7164,
    "content": "precision and performance available from https: developer"
  },
  {
    "id": 7165,
    "content": "nvidia com/content/precision-performance-floating-point-and-ieee-754-compliance-nvidia-gpus"
  },
  {
    "id": 7166,
    "content": "6"
  },
  {
    "id": 7167,
    "content": "3"
  },
  {
    "id": 7168,
    "content": "1"
  },
  {
    "id": 7171,
    "content": "6"
  },
  {
    "id": 7172,
    "content": "3"
  },
  {
    "id": 7173,
    "content": "2"
  },
  {
    "id": 7177,
    "content": "6"
  },
  {
    "id": 7178,
    "content": "3"
  },
  {
    "id": 7179,
    "content": "3"
  },
  {
    "id": 7182,
    "content": "Its result will often differ slightly from results obtained by doing the two operations separately"
  },
  {
    "id": 7183,
    "content": "6"
  },
  {
    "id": 7184,
    "content": "3"
  },
  {
    "id": 7185,
    "content": "4"
  },
  {
    "id": 7187,
    "content": "done with the FLDCW x86 assembly instruction or the equivalent operating system API"
  },
  {
    "id": 7188,
    "content": "7"
  },
  {
    "id": 7190,
    "content": "8"
  },
  {
    "id": 7192,
    "content": "8"
  },
  {
    "id": 7193,
    "content": "1"
  },
  {
    "id": 7194,
    "content": "Timing  CUDA calls and kernel executions can be timed using either CPU or GPU timers"
  },
  {
    "id": 7195,
    "content": "This section examines the functionality, advantages, and pitfalls of both approaches"
  },
  {
    "id": 7196,
    "content": "8"
  },
  {
    "id": 7197,
    "content": "1"
  },
  {
    "id": 7198,
    "content": "1"
  },
  {
    "id": 7206,
    "content": "8"
  },
  {
    "id": 7207,
    "content": "1"
  },
  {
    "id": 7208,
    "content": "2"
  },
  {
    "id": 7211,
    "content": "cudaEventRecord() is used to place the start and stop events into the default stream, stream 0"
  },
  {
    "id": 7212,
    "content": "The device will record a timestamp for the event when it reaches that event in the stream"
  },
  {
    "id": 7214,
    "content": "This value is expressed in milliseconds and has a resolution of approximately half a microsecond"
  },
  {
    "id": 7217,
    "content": "8"
  },
  {
    "id": 7218,
    "content": "2"
  },
  {
    "id": 7221,
    "content": "8"
  },
  {
    "id": 7222,
    "content": "2"
  },
  {
    "id": 7223,
    "content": "1"
  },
  {
    "id": 7228,
    "content": "hand, provide dedicated ECC resources, allowing overhead-free ECC protection"
  },
  {
    "id": 7229,
    "content": "2 8"
  },
  {
    "id": 7230,
    "content": "2"
  },
  {
    "id": 7231,
    "content": "2"
  },
  {
    "id": 7235,
    "content": "8"
  },
  {
    "id": 7236,
    "content": "2"
  },
  {
    "id": 7237,
    "content": "3"
  },
  {
    "id": 7243,
    "content": "9"
  },
  {
    "id": 7244,
    "content": "Memory Optimizations  Memory optimizations are the most important area for performance"
  },
  {
    "id": 7245,
    "content": "Bandwidth is best served by using as much fast memory and as little slow-access memory as possible"
  },
  {
    "id": 7247,
    "content": "9"
  },
  {
    "id": 7248,
    "content": "1"
  },
  {
    "id": 7253,
    "content": "9"
  },
  {
    "id": 7254,
    "content": "1"
  },
  {
    "id": 7255,
    "content": "1"
  },
  {
    "id": 7261,
    "content": "9"
  },
  {
    "id": 7262,
    "content": "1"
  },
  {
    "id": 7263,
    "content": "2"
  },
  {
    "id": 7276,
    "content": "evenly divisible by nThreads*nStreams"
  },
  {
    "id": 7283,
    "content": "9"
  },
  {
    "id": 7284,
    "content": "1"
  },
  {
    "id": 7285,
    "content": "3"
  },
  {
    "id": 7286,
    "content": "Zero Copy  Zero copy is a feature that was added in version 2"
  },
  {
    "id": 7287,
    "content": "2 of the CUDA Toolkit"
  },
  {
    "id": 7288,
    "content": "On integrated GPUs (i"
  },
  {
    "id": 7289,
    "content": "e"
  },
  {
    "id": 7291,
    "content": "be coalesced"
  },
  {
    "id": 7293,
    "content": "Note Low Priority: Use zero-copy operations on integrated GPUs for CUDA Toolkit version 2"
  },
  {
    "id": 7294,
    "content": "2 and later"
  },
  {
    "id": 7299,
    "content": "9"
  },
  {
    "id": 7300,
    "content": "1"
  },
  {
    "id": 7301,
    "content": "4"
  },
  {
    "id": 7306,
    "content": "9"
  },
  {
    "id": 7307,
    "content": "2"
  },
  {
    "id": 7313,
    "content": "9"
  },
  {
    "id": 7314,
    "content": "2"
  },
  {
    "id": 7315,
    "content": "1"
  },
  {
    "id": 7320,
    "content": "9"
  },
  {
    "id": 7321,
    "content": "2"
  },
  {
    "id": 7322,
    "content": "1"
  },
  {
    "id": 7323,
    "content": "1"
  },
  {
    "id": 7325,
    "content": "0 or higher: the k -th thread accesses the k -th word in a 32-byte aligned array"
  },
  {
    "id": 7326,
    "content": "For example, if the threads of a warp access adjacent 4-byte words (e"
  },
  {
    "id": 7327,
    "content": "g"
  },
  {
    "id": 7330,
    "content": "0 or higher"
  },
  {
    "id": 7331,
    "content": "9"
  },
  {
    "id": 7332,
    "content": "2"
  },
  {
    "id": 7333,
    "content": "1"
  },
  {
    "id": 7334,
    "content": "2"
  },
  {
    "id": 7336,
    "content": "256 bytes"
  },
  {
    "id": 7337,
    "content": "Therefore, choosing sensible thread block sizes, such as multiples of the warp size (i"
  },
  {
    "id": 7338,
    "content": "e"
  },
  {
    "id": 7339,
    "content": ", 32 on current GPUs), facilitates memory accesses by warps that are properly aligned"
  },
  {
    "id": 7341,
    "content": ") 9"
  },
  {
    "id": 7342,
    "content": "2"
  },
  {
    "id": 7343,
    "content": "1"
  },
  {
    "id": 7344,
    "content": "3"
  },
  {
    "id": 7348,
    "content": "0) is shown in Figure 5"
  },
  {
    "id": 7351,
    "content": "9"
  },
  {
    "id": 7352,
    "content": "2"
  },
  {
    "id": 7353,
    "content": "1"
  },
  {
    "id": 7354,
    "content": "4"
  },
  {
    "id": 7359,
    "content": "0)"
  },
  {
    "id": 7362,
    "content": "One method for doing so utilizes shared memory, which is discussed in the next section"
  },
  {
    "id": 7363,
    "content": "9"
  },
  {
    "id": 7364,
    "content": "2"
  },
  {
    "id": 7365,
    "content": "2"
  },
  {
    "id": 7366,
    "content": "L2 Cache  Starting with CUDA 11"
  },
  {
    "id": 7368,
    "content": "9"
  },
  {
    "id": 7369,
    "content": "2"
  },
  {
    "id": 7370,
    "content": "2"
  },
  {
    "id": 7371,
    "content": "1"
  },
  {
    "id": 7374,
    "content": "portion can be controlled using an access policy window on a CUDA stream or CUDA graph kernel node"
  },
  {
    "id": 7375,
    "content": "cudaStreamAttrValue stream_attribute ;   Stream level attributes data structure stream_attribute"
  },
  {
    "id": 7376,
    "content": "hitRatio = 1"
  },
  {
    "id": 7379,
    "content": "9"
  },
  {
    "id": 7380,
    "content": "2"
  },
  {
    "id": 7381,
    "content": "2"
  },
  {
    "id": 7382,
    "content": "2"
  },
  {
    "id": 7385,
    "content": "To understand the effect of hitRatio and num_bytes , we use a sliding window micro benchmark"
  },
  {
    "id": 7388,
    "content": "e"
  },
  {
    "id": 7394,
    "content": "performance drop is observed due to thrashing of L2 cache lines"
  },
  {
    "id": 7399,
    "content": "9"
  },
  {
    "id": 7400,
    "content": "2"
  },
  {
    "id": 7401,
    "content": "3"
  },
  {
    "id": 7402,
    "content": "1"
  },
  {
    "id": 7406,
    "content": "On devices of compute capability 5"
  },
  {
    "id": 7408,
    "content": "See Compute Capability 5"
  },
  {
    "id": 7409,
    "content": "x in the CUDA C++ Programming Guide for further details"
  },
  {
    "id": 7410,
    "content": "9"
  },
  {
    "id": 7411,
    "content": "2"
  },
  {
    "id": 7412,
    "content": "3"
  },
  {
    "id": 7413,
    "content": "2"
  },
  {
    "id": 7416,
    "content": "the warp size (w) is 32 for current devices"
  },
  {
    "id": 7426,
    "content": "8B and 16B per thread i"
  },
  {
    "id": 7427,
    "content": "e"
  },
  {
    "id": 7428,
    "content": ", using int , int2 and int4 for the template parameter"
  },
  {
    "id": 7432,
    "content": "9"
  },
  {
    "id": 7433,
    "content": "2"
  },
  {
    "id": 7434,
    "content": "4"
  },
  {
    "id": 7438,
    "content": "If it has, it will be declared using the"
  },
  {
    "id": 7439,
    "content": "local mnemonic and accessed using the ld local and st local mnemonics"
  },
  {
    "id": 7442,
    "content": "9"
  },
  {
    "id": 7443,
    "content": "2"
  },
  {
    "id": 7444,
    "content": "5"
  },
  {
    "id": 7447,
    "content": "9"
  },
  {
    "id": 7448,
    "content": "2"
  },
  {
    "id": 7449,
    "content": "5"
  },
  {
    "id": 7450,
    "content": "1"
  },
  {
    "id": 7454,
    "content": "6"
  },
  {
    "id": 7459,
    "content": "context for a thread"
  },
  {
    "id": 7462,
    "content": "11"
  },
  {
    "id": 7464,
    "content": "11"
  },
  {
    "id": 7465,
    "content": "1"
  },
  {
    "id": 7467,
    "content": "The throughput of individual arithmetic operations is detailed in the CUDA C++ Programming Guide"
  },
  {
    "id": 7468,
    "content": "11"
  },
  {
    "id": 7469,
    "content": "1"
  },
  {
    "id": 7470,
    "content": "1"
  },
  {
    "id": 7472,
    "content": "ight)\\) )"
  },
  {
    "id": 7473,
    "content": "(For further information, refer to Performance Guidelines in the CUDA C++ Programming Guide)"
  },
  {
    "id": 7474,
    "content": "11"
  },
  {
    "id": 7475,
    "content": "1"
  },
  {
    "id": 7476,
    "content": "2"
  },
  {
    "id": 7481,
    "content": "For example, consider the following code: for ( i = 0 ; i = 0, x"
  },
  {
    "id": 7482,
    "content": "= -0 , that is, signbit(x) == 0"
  },
  {
    "id": 7485,
    "content": "1"
  },
  {
    "id": 7486,
    "content": "6"
  },
  {
    "id": 7487,
    "content": "Math Libraries  Note Medium Priority: Use the fast math library whenever speed trumps precision"
  },
  {
    "id": 7489,
    "content": "g"
  },
  {
    "id": 7491,
    "content": "g"
  },
  {
    "id": 7499,
    "content": "For small integer powers (e"
  },
  {
    "id": 7500,
    "content": "g"
  },
  {
    "id": 7503,
    "content": "This advantage is increased when several powers of the same base are needed (e"
  },
  {
    "id": 7504,
    "content": "g"
  },
  {
    "id": 7508,
    "content": "significantly faster than the latter"
  },
  {
    "id": 7510,
    "content": "0)"
  },
  {
    "id": 7513,
    "content": ") 11"
  },
  {
    "id": 7514,
    "content": "1"
  },
  {
    "id": 7515,
    "content": "7"
  },
  {
    "id": 7517,
    "content": "functionName() call to the equivalent __functionName() call"
  },
  {
    "id": 7518,
    "content": "See Math Libraries"
  },
  {
    "id": 7519,
    "content": "11"
  },
  {
    "id": 7520,
    "content": "2"
  },
  {
    "id": 7523,
    "content": "accessing global memory whenever possible"
  },
  {
    "id": 7524,
    "content": "12 Control Flow  12"
  },
  {
    "id": 7525,
    "content": "1"
  },
  {
    "id": 7533,
    "content": "12"
  },
  {
    "id": 7534,
    "content": "2"
  },
  {
    "id": 7539,
    "content": "13"
  },
  {
    "id": 7541,
    "content": "14"
  },
  {
    "id": 7544,
    "content": "14"
  },
  {
    "id": 7545,
    "content": "1"
  },
  {
    "id": 7551,
    "content": "number of registers and the amount of memory available, and any special capabilities of the device"
  },
  {
    "id": 7552,
    "content": "14"
  },
  {
    "id": 7553,
    "content": "2"
  },
  {
    "id": 7557,
    "content": "14"
  },
  {
    "id": 7558,
    "content": "3"
  },
  {
    "id": 7561,
    "content": "14"
  },
  {
    "id": 7562,
    "content": "4"
  },
  {
    "id": 7565,
    "content": "management"
  },
  {
    "id": 7568,
    "content": "Runtime of the CUDA C++ Programming Guide"
  },
  {
    "id": 7569,
    "content": "15"
  },
  {
    "id": 7574,
    "content": "15"
  },
  {
    "id": 7575,
    "content": "1"
  },
  {
    "id": 7577,
    "content": "X"
  },
  {
    "id": 7578,
    "content": "Y"
  },
  {
    "id": 7579,
    "content": "Z, where:"
  },
  {
    "id": 7589,
    "content": "1) and work across all future minor releases within the major family (i"
  },
  {
    "id": 7590,
    "content": "e"
  },
  {
    "id": 7593,
    "content": "2 will run on newer drivers"
  },
  {
    "id": 7594,
    "content": "15"
  },
  {
    "id": 7595,
    "content": "2"
  },
  {
    "id": 7601,
    "content": "15"
  },
  {
    "id": 7602,
    "content": "3"
  },
  {
    "id": 7605,
    "content": "0)"
  },
  {
    "id": 7609,
    "content": "driver version for that toolkit version"
  },
  {
    "id": 7610,
    "content": "Prior to CUDA 11"
  },
  {
    "id": 7612,
    "content": "So, when an application is built with CUDA 11"
  },
  {
    "id": 7614,
    "content": "requirement"
  },
  {
    "id": 7615,
    "content": "| |=+=+=| | 0 Tesla T4 On | 00000000:00:1E"
  },
  {
    "id": 7618,
    "content": "15"
  },
  {
    "id": 7619,
    "content": "3"
  },
  {
    "id": 7620,
    "content": "1"
  },
  {
    "id": 7624,
    "content": "It is however usually more effective to use a high-level programming language such as C++"
  },
  {
    "id": 7627,
    "content": "z where z≥y"
  },
  {
    "id": 7630,
    "content": "15"
  },
  {
    "id": 7631,
    "content": "4"
  },
  {
    "id": 7633,
    "content": "major release is shipped"
  },
  {
    "id": 7636,
    "content": "15"
  },
  {
    "id": 7637,
    "content": "4"
  },
  {
    "id": 7638,
    "content": "1"
  },
  {
    "id": 7639,
    "content": "Existing CUDA Applications within Minor Versions of CUDA  $ nvidia - smi +-+ | NVIDIA - SMI 450"
  },
  {
    "id": 7640,
    "content": "80"
  },
  {
    "id": 7641,
    "content": "02 Driver Version : 450"
  },
  {
    "id": 7642,
    "content": "80"
  },
  {
    "id": 7643,
    "content": "02 CUDA Version : 11"
  },
  {
    "id": 7644,
    "content": "0 | |-+-+-+ | GPU Name Persistence - M | Bus - Id Disp"
  },
  {
    "id": 7645,
    "content": "| |=+=+=| | 0 Tesla T4 On | 00000000 : 00 : 1 E"
  },
  {
    "id": 7647,
    "content": "1 application (i"
  },
  {
    "id": 7648,
    "content": "e"
  },
  {
    "id": 7649,
    "content": "cudart 11"
  },
  {
    "id": 7653,
    "content": "5"
  },
  {
    "id": 7654,
    "content": "deviceQuery , CUDA Driver = CUDART , CUDA Driver Version = 11 0 , CUDA Runtime Version = 11"
  },
  {
    "id": 7656,
    "content": "The following sections discuss some caveats and considerations"
  },
  {
    "id": 7657,
    "content": "15"
  },
  {
    "id": 7658,
    "content": "4"
  },
  {
    "id": 7659,
    "content": "1"
  },
  {
    "id": 7660,
    "content": "1"
  },
  {
    "id": 7664,
    "content": "Users should refer to the CUDA headers and documentation for new CUDA APIs introduced in a release"
  },
  {
    "id": 7668,
    "content": "16"
  },
  {
    "id": 7669,
    "content": "3"
  },
  {
    "id": 7677,
    "content": "0 and earlier"
  },
  {
    "id": 7681,
    "content": "16"
  },
  {
    "id": 7682,
    "content": "4"
  },
  {
    "id": 7683,
    "content": "1"
  },
  {
    "id": 7685,
    "content": "different version of the CUDA Toolkit (or perhaps none at all) installed on their machines"
  },
  {
    "id": 7687,
    "content": "16"
  },
  {
    "id": 7688,
    "content": "4"
  },
  {
    "id": 7689,
    "content": "1"
  },
  {
    "id": 7690,
    "content": "1"
  },
  {
    "id": 7693,
    "content": "standard CUDA Toolkit installation, the files libcublas so and libcublas so"
  },
  {
    "id": 7694,
    "content": "5"
  },
  {
    "id": 7695,
    "content": "5 are both symlinks pointing to a specific build of cuBLAS, which is named like libcublas"
  },
  {
    "id": 7696,
    "content": "so"
  },
  {
    "id": 7697,
    "content": "5"
  },
  {
    "id": 7698,
    "content": "5"
  },
  {
    "id": 7699,
    "content": "x , where x is the build number (e"
  },
  {
    "id": 7700,
    "content": "g"
  },
  {
    "id": 7701,
    "content": ", libcublas"
  },
  {
    "id": 7702,
    "content": "so"
  },
  {
    "id": 7703,
    "content": "5"
  },
  {
    "id": 7704,
    "content": "5"
  },
  {
    "id": 7705,
    "content": "17 )"
  },
  {
    "id": 7706,
    "content": "However, the SONAME of this library is given as “ libcublas"
  },
  {
    "id": 7707,
    "content": "so"
  },
  {
    "id": 7708,
    "content": "5"
  },
  {
    "id": 7709,
    "content": "5 ”: $ objdump -p /usr/local/cuda/lib64/libcublas so | grep SONAME SONAME libcublas so"
  },
  {
    "id": 7710,
    "content": "5"
  },
  {
    "id": 7712,
    "content": "so"
  },
  {
    "id": 7713,
    "content": "5"
  },
  {
    "id": 7716,
    "content": "out | grep libcublas libcublas"
  },
  {
    "id": 7717,
    "content": "so"
  },
  {
    "id": 7718,
    "content": "5"
  },
  {
    "id": 7719,
    "content": "5 => /usr/local/cuda/lib64/libcublas"
  },
  {
    "id": 7720,
    "content": "so"
  },
  {
    "id": 7721,
    "content": "5"
  },
  {
    "id": 7723,
    "content": "install name of the cuBLAS library is given as @rpath/libcublas"
  },
  {
    "id": 7724,
    "content": "5"
  },
  {
    "id": 7725,
    "content": "5"
  },
  {
    "id": 7726,
    "content": "dylib , then the library is version 5"
  },
  {
    "id": 7727,
    "content": "5 and the copy of this library redistributed with the application must be named libcublas"
  },
  {
    "id": 7728,
    "content": "5"
  },
  {
    "id": 7729,
    "content": "5"
  },
  {
    "id": 7730,
    "content": "dylib , even though only -lcublas (with no version number specified) is used at link time"
  },
  {
    "id": 7732,
    "content": "To view a library’s install name, use the otool -L command: $ otool -L a"
  },
  {
    "id": 7733,
    "content": "out a out: @rpath/libcublas"
  },
  {
    "id": 7734,
    "content": "5"
  },
  {
    "id": 7735,
    "content": "5"
  },
  {
    "id": 7736,
    "content": "dylib ("
  },
  {
    "id": 7738,
    "content": "For example, a 64-bit application linked to cuBLAS 5"
  },
  {
    "id": 7739,
    "content": "5 will look for cublas64_55"
  },
  {
    "id": 7741,
    "content": "exe Microsoft (R) COFF/PE Dumper Version 10"
  },
  {
    "id": 7742,
    "content": "00"
  },
  {
    "id": 7743,
    "content": "40219"
  },
  {
    "id": 7744,
    "content": "01 Copyright (C) Microsoft Corporation"
  },
  {
    "id": 7745,
    "content": "Dump of file a"
  },
  {
    "id": 7746,
    "content": "exe File Type: EXECUTABLE IMAGE Section contains the following imports:"
  },
  {
    "id": 7747,
    "content": "cublas64_55"
  },
  {
    "id": 7748,
    "content": "dll"
  },
  {
    "id": 7749,
    "content": "16"
  },
  {
    "id": 7750,
    "content": "4"
  },
  {
    "id": 7751,
    "content": "1"
  },
  {
    "id": 7752,
    "content": "2"
  },
  {
    "id": 7756,
    "content": "cu Windows nvcc"
  },
  {
    "id": 7760,
    "content": "cu Windows nvcc"
  },
  {
    "id": 7763,
    "content": "Please see the MSDN documentation for these routines for more information"
  },
  {
    "id": 7764,
    "content": "17 Deployment Infrastructure Tools  17"
  },
  {
    "id": 7765,
    "content": "1"
  },
  {
    "id": 7771,
    "content": "17"
  },
  {
    "id": 7772,
    "content": "1"
  },
  {
    "id": 7773,
    "content": "1"
  },
  {
    "id": 7779,
    "content": "17"
  },
  {
    "id": 7780,
    "content": "1"
  },
  {
    "id": 7781,
    "content": "2"
  },
  {
    "id": 7782,
    "content": "Modifiable state  ECC mode Enable and disable ECC reporting"
  },
  {
    "id": 7784,
    "content": "GPU reset Reinitialize the GPU hardware and software state via a secondary bus reset"
  },
  {
    "id": 7785,
    "content": "17"
  },
  {
    "id": 7786,
    "content": "2"
  },
  {
    "id": 7789,
    "content": "nvidia"
  },
  {
    "id": 7790,
    "content": "com/gpu-deployment-kit"
  },
  {
    "id": 7792,
    "content": "See https: developer"
  },
  {
    "id": 7793,
    "content": "nvidia com/nvidia-management-library-nvml for additional information"
  },
  {
    "id": 7794,
    "content": "17"
  },
  {
    "id": 7795,
    "content": "3"
  },
  {
    "id": 7797,
    "content": "For a listing of some of these tools, see https: developer"
  },
  {
    "id": 7798,
    "content": "nvidia"
  },
  {
    "id": 7799,
    "content": "com/cluster-management"
  },
  {
    "id": 7800,
    "content": "17"
  },
  {
    "id": 7801,
    "content": "4"
  },
  {
    "id": 7806,
    "content": "17"
  },
  {
    "id": 7807,
    "content": "5"
  },
  {
    "id": 7810,
    "content": "18"
  },
  {
    "id": 7812,
    "content": "18"
  },
  {
    "id": 7813,
    "content": "1"
  },
  {
    "id": 7820,
    "content": "instruction usage, the use of arithmetic instructions that have low throughput should be avoided"
  },
  {
    "id": 7823,
    "content": "19 nvcc Compiler Switches  19"
  },
  {
    "id": 7824,
    "content": "1"
  },
  {
    "id": 7825,
    "content": "nvcc  The NVIDIA nvcc compiler driver converts"
  },
  {
    "id": 7826,
    "content": "cu files into C++ for the host system and CUDA assembly or binary instructions for the device"
  },
  {
    "id": 7828,
    "content": "per-kernel basis"
  },
  {
    "id": 7829,
    "content": ") --ptxas-options=-v or -Xptxas=-v lists per-kernel register, shared, and constant memory usage"
  },
  {
    "id": 7831,
    "content": "20 Notices  20"
  },
  {
    "id": 7832,
    "content": "1"
  },
  {
    "id": 7835,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 7847,
    "content": "20"
  },
  {
    "id": 7848,
    "content": "2"
  },
  {
    "id": 7849,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 7850,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 7851,
    "content": "20"
  },
  {
    "id": 7852,
    "content": "3"
  },
  {
    "id": 7854,
    "content": "S"
  },
  {
    "id": 7857,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 7858,
    "content": "Navigation"
  },
  {
    "id": 7859,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 7860,
    "content": "pageBottom();}\n1"
  },
  {
    "id": 7863,
    "content": "1"
  },
  {
    "id": 7864,
    "content": "2"
  },
  {
    "id": 7868,
    "content": "1"
  },
  {
    "id": 7869,
    "content": "3"
  },
  {
    "id": 7872,
    "content": "1"
  },
  {
    "id": 7873,
    "content": "3"
  },
  {
    "id": 7874,
    "content": "1"
  },
  {
    "id": 7876,
    "content": "1 through 5"
  },
  {
    "id": 7877,
    "content": "5 are compatible with Maxwell as long as they are built to include PTX versions of their kernels"
  },
  {
    "id": 7879,
    "content": "nvidia"
  },
  {
    "id": 7880,
    "content": "com/drivers"
  },
  {
    "id": 7883,
    "content": "1"
  },
  {
    "id": 7884,
    "content": "3"
  },
  {
    "id": 7885,
    "content": "2"
  },
  {
    "id": 7887,
    "content": "5 or Earlier ) or both"
  },
  {
    "id": 7888,
    "content": "1"
  },
  {
    "id": 7889,
    "content": "4"
  },
  {
    "id": 7894,
    "content": "may be faster or of greater accuracy"
  },
  {
    "id": 7895,
    "content": "1"
  },
  {
    "id": 7896,
    "content": "4"
  },
  {
    "id": 7897,
    "content": "1"
  },
  {
    "id": 7899,
    "content": "PTX version of each kernel"
  },
  {
    "id": 7900,
    "content": "Below are compiler settings that could be used to build mykernel"
  },
  {
    "id": 7901,
    "content": "cu to run on Fermi or Kepler devices natively and on Maxwell devices via PTX JIT"
  },
  {
    "id": 7903,
    "content": "compatibility"
  },
  {
    "id": 7904,
    "content": "Windows nvcc"
  },
  {
    "id": 7906,
    "content": "cu"
  },
  {
    "id": 7907,
    "content": "obj\" \"mykernel"
  },
  {
    "id": 7909,
    "content": "o -c mykernel"
  },
  {
    "id": 7912,
    "content": "1"
  },
  {
    "id": 7913,
    "content": "4"
  },
  {
    "id": 7914,
    "content": "2"
  },
  {
    "id": 7915,
    "content": "Applications Using CUDA Toolkit 6"
  },
  {
    "id": 7916,
    "content": "0 or Later  With version 6"
  },
  {
    "id": 7918,
    "content": "2)"
  },
  {
    "id": 7919,
    "content": "When using CUDA Toolkit 6"
  },
  {
    "id": 7922,
    "content": "cu"
  },
  {
    "id": 7923,
    "content": "obj\" \"mykernel"
  },
  {
    "id": 7925,
    "content": "o -c mykernel"
  },
  {
    "id": 7926,
    "content": "cu Note compute_XX refers to a PTX version and sm_XX refers to a cubin version"
  },
  {
    "id": 7928,
    "content": "2"
  },
  {
    "id": 7929,
    "content": "Revision History  Version 1"
  },
  {
    "id": 7930,
    "content": "0 Initial public release"
  },
  {
    "id": 7933,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 7945,
    "content": "3"
  },
  {
    "id": 7946,
    "content": "2"
  },
  {
    "id": 7947,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 7948,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 7949,
    "content": "3"
  },
  {
    "id": 7950,
    "content": "3"
  },
  {
    "id": 7952,
    "content": "S"
  },
  {
    "id": 7955,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 7956,
    "content": "Navigation"
  },
  {
    "id": 7957,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 7958,
    "content": "pageBottom();}\n1"
  },
  {
    "id": 7961,
    "content": "1"
  },
  {
    "id": 7962,
    "content": "2"
  },
  {
    "id": 7965,
    "content": "x (Maxwell) or 6"
  },
  {
    "id": 7966,
    "content": "x (Pascal) devices"
  },
  {
    "id": 7969,
    "content": "1"
  },
  {
    "id": 7970,
    "content": "3"
  },
  {
    "id": 7973,
    "content": "1"
  },
  {
    "id": 7974,
    "content": "3"
  },
  {
    "id": 7975,
    "content": "1"
  },
  {
    "id": 7977,
    "content": "1 through 7"
  },
  {
    "id": 7978,
    "content": "5 are compatible with Pascal as long as they are built to include PTX versions of their kernels"
  },
  {
    "id": 7980,
    "content": "nvidia"
  },
  {
    "id": 7981,
    "content": "com/drivers"
  },
  {
    "id": 7984,
    "content": "1"
  },
  {
    "id": 7985,
    "content": "3"
  },
  {
    "id": 7986,
    "content": "2"
  },
  {
    "id": 7988,
    "content": "5 or Earlier ) or both"
  },
  {
    "id": 7989,
    "content": "1"
  },
  {
    "id": 7990,
    "content": "4"
  },
  {
    "id": 7995,
    "content": "may be faster or of greater accuracy"
  },
  {
    "id": 7996,
    "content": "1"
  },
  {
    "id": 7997,
    "content": "4"
  },
  {
    "id": 7998,
    "content": "1"
  },
  {
    "id": 8000,
    "content": "PTX version of each kernel"
  },
  {
    "id": 8001,
    "content": "Below are compiler settings that could be used to build mykernel"
  },
  {
    "id": 8002,
    "content": "cu to run on Kepler or Maxwell devices natively and on Pascal devices via PTX JIT"
  },
  {
    "id": 8004,
    "content": "Windows nvcc"
  },
  {
    "id": 8006,
    "content": "cu"
  },
  {
    "id": 8007,
    "content": "obj\" \"mykernel"
  },
  {
    "id": 8009,
    "content": "o -c mykernel"
  },
  {
    "id": 8012,
    "content": "1"
  },
  {
    "id": 8013,
    "content": "4"
  },
  {
    "id": 8014,
    "content": "2"
  },
  {
    "id": 8015,
    "content": "Applications Using CUDA Toolkit 8"
  },
  {
    "id": 8016,
    "content": "0  With version 8"
  },
  {
    "id": 8018,
    "content": "0 and 6"
  },
  {
    "id": 8019,
    "content": "1)"
  },
  {
    "id": 8020,
    "content": "When using CUDA Toolkit 8"
  },
  {
    "id": 8023,
    "content": "cu"
  },
  {
    "id": 8024,
    "content": "obj\" \"mykernel"
  },
  {
    "id": 8026,
    "content": "o -c mykernel"
  },
  {
    "id": 8027,
    "content": "cu Note compute_XX refers to a PTX version and sm_XX refers to a cubin version"
  },
  {
    "id": 8029,
    "content": "2"
  },
  {
    "id": 8030,
    "content": "Revision History  Version 1"
  },
  {
    "id": 8031,
    "content": "0 Initial public release"
  },
  {
    "id": 8034,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 8046,
    "content": "3"
  },
  {
    "id": 8047,
    "content": "2"
  },
  {
    "id": 8048,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 8049,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 8050,
    "content": "3"
  },
  {
    "id": 8051,
    "content": "3"
  },
  {
    "id": 8053,
    "content": "S"
  },
  {
    "id": 8056,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 8057,
    "content": "Navigation"
  },
  {
    "id": 8058,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 8059,
    "content": "pageBottom();}\n1"
  },
  {
    "id": 8062,
    "content": "1"
  },
  {
    "id": 8063,
    "content": "2"
  },
  {
    "id": 8066,
    "content": "x (Maxwell) or 6"
  },
  {
    "id": 8067,
    "content": "x (Pascal) devices"
  },
  {
    "id": 8070,
    "content": "1"
  },
  {
    "id": 8071,
    "content": "3"
  },
  {
    "id": 8074,
    "content": "1"
  },
  {
    "id": 8075,
    "content": "3"
  },
  {
    "id": 8076,
    "content": "1"
  },
  {
    "id": 8078,
    "content": "1 through 8"
  },
  {
    "id": 8079,
    "content": "0 are compatible with Volta as long as they are built to include PTX versions of their kernels"
  },
  {
    "id": 8081,
    "content": "nvidia"
  },
  {
    "id": 8082,
    "content": "com/drivers"
  },
  {
    "id": 8085,
    "content": "1"
  },
  {
    "id": 8086,
    "content": "3"
  },
  {
    "id": 8087,
    "content": "2"
  },
  {
    "id": 8089,
    "content": "0 or Earlier ) or both"
  },
  {
    "id": 8090,
    "content": "1"
  },
  {
    "id": 8091,
    "content": "4"
  },
  {
    "id": 8096,
    "content": "may be faster or of greater accuracy"
  },
  {
    "id": 8097,
    "content": "1"
  },
  {
    "id": 8098,
    "content": "4"
  },
  {
    "id": 8099,
    "content": "1"
  },
  {
    "id": 8101,
    "content": "PTX version of each kernel"
  },
  {
    "id": 8102,
    "content": "Below are compiler settings that could be used to build mykernel"
  },
  {
    "id": 8103,
    "content": "cu to run on Maxwell or Pascal devices natively and on Volta devices via PTX JIT"
  },
  {
    "id": 8105,
    "content": "Windows nvcc"
  },
  {
    "id": 8107,
    "content": "cu"
  },
  {
    "id": 8108,
    "content": "obj\" \"mykernel"
  },
  {
    "id": 8110,
    "content": "o -c mykernel"
  },
  {
    "id": 8113,
    "content": "1"
  },
  {
    "id": 8114,
    "content": "4"
  },
  {
    "id": 8115,
    "content": "2"
  },
  {
    "id": 8116,
    "content": "Applications Using CUDA Toolkit 9"
  },
  {
    "id": 8117,
    "content": "0  With version 9"
  },
  {
    "id": 8119,
    "content": "0)"
  },
  {
    "id": 8120,
    "content": "When using CUDA Toolkit 9"
  },
  {
    "id": 8123,
    "content": "cu"
  },
  {
    "id": 8124,
    "content": "obj\" \"mykernel"
  },
  {
    "id": 8126,
    "content": "o -c mykernel"
  },
  {
    "id": 8127,
    "content": "cu Note compute_XX refers to a PTX version and sm_XX refers to a cubin version"
  },
  {
    "id": 8129,
    "content": "Any compute_2x and sm_2x flags need to be removed from your compiler commands"
  },
  {
    "id": 8130,
    "content": "1"
  },
  {
    "id": 8131,
    "content": "4"
  },
  {
    "id": 8132,
    "content": "3"
  },
  {
    "id": 8135,
    "content": "Please see Compute Capability 7"
  },
  {
    "id": 8136,
    "content": "0 in the CUDA C++ Programming Guide for details and corrective actions"
  },
  {
    "id": 8138,
    "content": "nvcc -arch=compute_60 -code=sm_70"
  },
  {
    "id": 8139,
    "content": "2"
  },
  {
    "id": 8140,
    "content": "Revision History  Version 1"
  },
  {
    "id": 8141,
    "content": "0 Initial public release"
  },
  {
    "id": 8142,
    "content": "Version 1"
  },
  {
    "id": 8144,
    "content": "3"
  },
  {
    "id": 8145,
    "content": "Notices  3"
  },
  {
    "id": 8146,
    "content": "1"
  },
  {
    "id": 8149,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 8161,
    "content": "3"
  },
  {
    "id": 8162,
    "content": "2"
  },
  {
    "id": 8163,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 8164,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 8165,
    "content": "3"
  },
  {
    "id": 8166,
    "content": "3"
  },
  {
    "id": 8168,
    "content": "S"
  },
  {
    "id": 8172,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 8173,
    "content": "Navigation"
  },
  {
    "id": 8174,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 8175,
    "content": "pageBottom();}\n1"
  },
  {
    "id": 8178,
    "content": "1"
  },
  {
    "id": 8179,
    "content": "2"
  },
  {
    "id": 8182,
    "content": "x (Maxwell) or 6"
  },
  {
    "id": 8183,
    "content": "x (Pascal) devices"
  },
  {
    "id": 8186,
    "content": "1"
  },
  {
    "id": 8187,
    "content": "3"
  },
  {
    "id": 8189,
    "content": "0, extending it with new instructions"
  },
  {
    "id": 8192,
    "content": "1"
  },
  {
    "id": 8193,
    "content": "4"
  },
  {
    "id": 8196,
    "content": "1"
  },
  {
    "id": 8197,
    "content": "4"
  },
  {
    "id": 8198,
    "content": "1"
  },
  {
    "id": 8200,
    "content": "1 through 8"
  },
  {
    "id": 8201,
    "content": "0 are compatible with Turing as long as they are built to include PTX versions of their kernels"
  },
  {
    "id": 8203,
    "content": "nvidia"
  },
  {
    "id": 8204,
    "content": "com/drivers"
  },
  {
    "id": 8207,
    "content": "1"
  },
  {
    "id": 8208,
    "content": "4"
  },
  {
    "id": 8209,
    "content": "2"
  },
  {
    "id": 8211,
    "content": "0 or Earlier ) or both"
  },
  {
    "id": 8212,
    "content": "1"
  },
  {
    "id": 8213,
    "content": "4"
  },
  {
    "id": 8214,
    "content": "3"
  },
  {
    "id": 8216,
    "content": "0 or Earlier ), or both"
  },
  {
    "id": 8217,
    "content": "1"
  },
  {
    "id": 8218,
    "content": "5"
  },
  {
    "id": 8223,
    "content": "may be faster or of greater accuracy"
  },
  {
    "id": 8224,
    "content": "1"
  },
  {
    "id": 8225,
    "content": "5"
  },
  {
    "id": 8226,
    "content": "1"
  },
  {
    "id": 8228,
    "content": "generate a PTX version of each kernel"
  },
  {
    "id": 8229,
    "content": "Below are compiler settings that could be used to build mykernel"
  },
  {
    "id": 8230,
    "content": "cu to run on Maxwell or Pascal devices natively and on Turing devices via PTX JIT"
  },
  {
    "id": 8232,
    "content": "Windows nvcc"
  },
  {
    "id": 8234,
    "content": "cu"
  },
  {
    "id": 8235,
    "content": "obj\" \"mykernel"
  },
  {
    "id": 8237,
    "content": "o -c mykernel"
  },
  {
    "id": 8240,
    "content": "1"
  },
  {
    "id": 8241,
    "content": "5"
  },
  {
    "id": 8242,
    "content": "2"
  },
  {
    "id": 8243,
    "content": "Applications Using CUDA Toolkit 9"
  },
  {
    "id": 8244,
    "content": "x  With versions 9"
  },
  {
    "id": 8246,
    "content": "0)"
  },
  {
    "id": 8247,
    "content": "When using CUDA Toolkit 9"
  },
  {
    "id": 8250,
    "content": "cu"
  },
  {
    "id": 8251,
    "content": "obj\" \"mykernel"
  },
  {
    "id": 8253,
    "content": "o -c mykernel"
  },
  {
    "id": 8254,
    "content": "cu Note compute_XX refers to a PTX version and sm_XX refers to a cubin version"
  },
  {
    "id": 8256,
    "content": "Any compute_2x and sm_2x flags need to be removed from your compiler commands"
  },
  {
    "id": 8257,
    "content": "1"
  },
  {
    "id": 8258,
    "content": "5"
  },
  {
    "id": 8259,
    "content": "3"
  },
  {
    "id": 8261,
    "content": "5)"
  },
  {
    "id": 8262,
    "content": "When using CUDA Toolkit 10"
  },
  {
    "id": 8265,
    "content": "Please see Compute Capability 7"
  },
  {
    "id": 8266,
    "content": "0 in the CUDA C++ Programming Guide for details and corrective actions"
  },
  {
    "id": 8268,
    "content": "nvcc -arch=compute_60 -code=sm_70"
  },
  {
    "id": 8269,
    "content": "2"
  },
  {
    "id": 8270,
    "content": "Revision History  Version 1"
  },
  {
    "id": 8271,
    "content": "0 Initial public release"
  },
  {
    "id": 8272,
    "content": "Version 1"
  },
  {
    "id": 8274,
    "content": "3"
  },
  {
    "id": 8275,
    "content": "Notices  3"
  },
  {
    "id": 8276,
    "content": "1"
  },
  {
    "id": 8279,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 8291,
    "content": "3"
  },
  {
    "id": 8292,
    "content": "2"
  },
  {
    "id": 8293,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 8294,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 8295,
    "content": "3"
  },
  {
    "id": 8296,
    "content": "3"
  },
  {
    "id": 8298,
    "content": "S"
  },
  {
    "id": 8302,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 8303,
    "content": "Navigation"
  },
  {
    "id": 8304,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 8305,
    "content": "pageBottom();}\n1"
  },
  {
    "id": 8308,
    "content": "1"
  },
  {
    "id": 8309,
    "content": "2"
  },
  {
    "id": 8313,
    "content": "x"
  },
  {
    "id": 8315,
    "content": "capability 8"
  },
  {
    "id": 8316,
    "content": "x"
  },
  {
    "id": 8321,
    "content": "with the NVIDIA Ampere GPU Architecture Support"
  },
  {
    "id": 8322,
    "content": "1"
  },
  {
    "id": 8323,
    "content": "3"
  },
  {
    "id": 8325,
    "content": "1"
  },
  {
    "id": 8326,
    "content": "3"
  },
  {
    "id": 8327,
    "content": "1"
  },
  {
    "id": 8330,
    "content": "nvidia"
  },
  {
    "id": 8331,
    "content": "com/drivers"
  },
  {
    "id": 8333,
    "content": "1"
  },
  {
    "id": 8334,
    "content": "3"
  },
  {
    "id": 8335,
    "content": "2"
  },
  {
    "id": 8336,
    "content": "Applications Built Using CUDA Toolkit 11 0  CUDA applications built using CUDA Toolkit 11"
  },
  {
    "id": 8338,
    "content": "0) or PTX form or both"
  },
  {
    "id": 8339,
    "content": "1"
  },
  {
    "id": 8340,
    "content": "4"
  },
  {
    "id": 8344,
    "content": "faster or of greater accuracy"
  },
  {
    "id": 8345,
    "content": "1"
  },
  {
    "id": 8346,
    "content": "4"
  },
  {
    "id": 8347,
    "content": "1"
  },
  {
    "id": 8348,
    "content": "Building Applications Using CUDA Toolkit 10"
  },
  {
    "id": 8349,
    "content": "x or Earlier  The nvcc compiler included with versions 10 x (10 0, 10 1 and 10"
  },
  {
    "id": 8351,
    "content": "x)"
  },
  {
    "id": 8352,
    "content": "When using CUDA Toolkit 10"
  },
  {
    "id": 8355,
    "content": "cu"
  },
  {
    "id": 8356,
    "content": "obj\" \"mykernel"
  },
  {
    "id": 8358,
    "content": "o -c mykernel"
  },
  {
    "id": 8361,
    "content": "For CUDA toolkits prior to 10"
  },
  {
    "id": 8363,
    "content": "x supports architectures up to _60 and _61)"
  },
  {
    "id": 8366,
    "content": "1"
  },
  {
    "id": 8367,
    "content": "4"
  },
  {
    "id": 8368,
    "content": "2"
  },
  {
    "id": 8370,
    "content": "0)"
  },
  {
    "id": 8371,
    "content": "When using CUDA Toolkit 11"
  },
  {
    "id": 8374,
    "content": "Please see Compute Capability 7"
  },
  {
    "id": 8375,
    "content": "0 in the Programming Guide for details and corrective actions"
  },
  {
    "id": 8377,
    "content": "nvcc -gencode=arch=compute_60,code=sm_80"
  },
  {
    "id": 8378,
    "content": "2"
  },
  {
    "id": 8379,
    "content": "Revision History  Version 1"
  },
  {
    "id": 8380,
    "content": "0 Initial public release"
  },
  {
    "id": 8383,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 8395,
    "content": "3"
  },
  {
    "id": 8396,
    "content": "2"
  },
  {
    "id": 8397,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 8398,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 8399,
    "content": "3"
  },
  {
    "id": 8400,
    "content": "3"
  },
  {
    "id": 8402,
    "content": "S"
  },
  {
    "id": 8406,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 8407,
    "content": "Navigation"
  },
  {
    "id": 8408,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 8409,
    "content": "pageBottom();}\n1"
  },
  {
    "id": 8412,
    "content": "1"
  },
  {
    "id": 8413,
    "content": "2"
  },
  {
    "id": 8417,
    "content": "0"
  },
  {
    "id": 8419,
    "content": "capability 9"
  },
  {
    "id": 8420,
    "content": "0"
  },
  {
    "id": 8425,
    "content": "1"
  },
  {
    "id": 8426,
    "content": "3"
  },
  {
    "id": 8428,
    "content": "1"
  },
  {
    "id": 8429,
    "content": "3"
  },
  {
    "id": 8430,
    "content": "1"
  },
  {
    "id": 8433,
    "content": "nvidia"
  },
  {
    "id": 8434,
    "content": "com/drivers"
  },
  {
    "id": 8436,
    "content": "1"
  },
  {
    "id": 8437,
    "content": "3"
  },
  {
    "id": 8438,
    "content": "2"
  },
  {
    "id": 8439,
    "content": "Applications Built Using CUDA Toolkit 11 8  CUDA applications built using CUDA Toolkit 11"
  },
  {
    "id": 8441,
    "content": "0) or PTX form or both"
  },
  {
    "id": 8442,
    "content": "1"
  },
  {
    "id": 8443,
    "content": "4"
  },
  {
    "id": 8448,
    "content": "0 and is not backward or forward compatible"
  },
  {
    "id": 8449,
    "content": "1"
  },
  {
    "id": 8450,
    "content": "4"
  },
  {
    "id": 8451,
    "content": "1"
  },
  {
    "id": 8452,
    "content": "Building Applications Using CUDA Toolkit 11"
  },
  {
    "id": 8453,
    "content": "7 or Earlier  The nvcc compiler included with version 11 7 or earlier (11 0-11"
  },
  {
    "id": 8455,
    "content": "x)"
  },
  {
    "id": 8456,
    "content": "When using CUDA Toolkit 11"
  },
  {
    "id": 8459,
    "content": "cu"
  },
  {
    "id": 8460,
    "content": "obj\" \"mykernel"
  },
  {
    "id": 8462,
    "content": "o -c mykernel"
  },
  {
    "id": 8465,
    "content": "For CUDA toolkits prior to 11"
  },
  {
    "id": 8467,
    "content": "x supports architectures up to sm_72 and sm_75)"
  },
  {
    "id": 8468,
    "content": "For further information and examples see the documentation for the specific CUDA toolkit version"
  },
  {
    "id": 8470,
    "content": "with future architectures"
  },
  {
    "id": 8471,
    "content": "1"
  },
  {
    "id": 8472,
    "content": "4"
  },
  {
    "id": 8473,
    "content": "2"
  },
  {
    "id": 8475,
    "content": "0)"
  },
  {
    "id": 8476,
    "content": "When using CUDA Toolkit 11"
  },
  {
    "id": 8479,
    "content": "Please see Compute Capability 7"
  },
  {
    "id": 8480,
    "content": "x in the CUDA C++ Programming Guide for details and corrective actions"
  },
  {
    "id": 8482,
    "content": "nvcc -gencode=arch=compute_60,code=sm_90"
  },
  {
    "id": 8483,
    "content": "2"
  },
  {
    "id": 8484,
    "content": "Revision History  Version 1"
  },
  {
    "id": 8485,
    "content": "0 Initial public release"
  },
  {
    "id": 8488,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 8500,
    "content": "3"
  },
  {
    "id": 8501,
    "content": "2"
  },
  {
    "id": 8502,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 8503,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 8504,
    "content": "3"
  },
  {
    "id": 8505,
    "content": "3"
  },
  {
    "id": 8507,
    "content": "S"
  },
  {
    "id": 8509,
    "content": "2 Starting with CUDA toolkit 11"
  },
  {
    "id": 8510,
    "content": "8, this default behavior can be changed with environment variable CUDA_MODULE_LOADING"
  },
  {
    "id": 8513,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 8514,
    "content": "Navigation"
  },
  {
    "id": 8515,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 8516,
    "content": "pageBottom();}\n1"
  },
  {
    "id": 8519,
    "content": "1"
  },
  {
    "id": 8520,
    "content": "2"
  },
  {
    "id": 8524,
    "content": "0"
  },
  {
    "id": 8526,
    "content": "capability 9"
  },
  {
    "id": 8527,
    "content": "x"
  },
  {
    "id": 8532,
    "content": "1"
  },
  {
    "id": 8533,
    "content": "3"
  },
  {
    "id": 8535,
    "content": "0, extending it with new instructions"
  },
  {
    "id": 8537,
    "content": "1"
  },
  {
    "id": 8538,
    "content": "4"
  },
  {
    "id": 8540,
    "content": "1"
  },
  {
    "id": 8541,
    "content": "4"
  },
  {
    "id": 8542,
    "content": "1"
  },
  {
    "id": 8545,
    "content": "nvidia"
  },
  {
    "id": 8546,
    "content": "com/drivers"
  },
  {
    "id": 8548,
    "content": "1"
  },
  {
    "id": 8549,
    "content": "4"
  },
  {
    "id": 8550,
    "content": "2"
  },
  {
    "id": 8552,
    "content": "2 or Earlier ), or both"
  },
  {
    "id": 8553,
    "content": "1"
  },
  {
    "id": 8554,
    "content": "4"
  },
  {
    "id": 8555,
    "content": "3"
  },
  {
    "id": 8557,
    "content": "2 or Earlier ), or both"
  },
  {
    "id": 8558,
    "content": "1"
  },
  {
    "id": 8559,
    "content": "5"
  },
  {
    "id": 8563,
    "content": "faster or of greater accuracy"
  },
  {
    "id": 8564,
    "content": "1"
  },
  {
    "id": 8565,
    "content": "5"
  },
  {
    "id": 8566,
    "content": "1"
  },
  {
    "id": 8567,
    "content": "Building Applications Using CUDA Toolkit 10"
  },
  {
    "id": 8568,
    "content": "x or Earlier  The nvcc compiler included with versions 10 x (10 0, 10 1 and 10"
  },
  {
    "id": 8570,
    "content": "x)"
  },
  {
    "id": 8571,
    "content": "When using CUDA Toolkit 10"
  },
  {
    "id": 8574,
    "content": "cu"
  },
  {
    "id": 8575,
    "content": "obj\" \"mykernel"
  },
  {
    "id": 8577,
    "content": "o -c mykernel"
  },
  {
    "id": 8580,
    "content": "For CUDA toolkits prior to 10"
  },
  {
    "id": 8582,
    "content": "x supports architectures up to _60 and _61)"
  },
  {
    "id": 8583,
    "content": "For further information and examples, see the documentation for the specific CUDA toolkit version"
  },
  {
    "id": 8585,
    "content": "with future architectures"
  },
  {
    "id": 8586,
    "content": "1"
  },
  {
    "id": 8587,
    "content": "5"
  },
  {
    "id": 8588,
    "content": "2"
  },
  {
    "id": 8590,
    "content": "0 and 8"
  },
  {
    "id": 8591,
    "content": "6)"
  },
  {
    "id": 8592,
    "content": "When using CUDA Toolkit 11 0 through 11"
  },
  {
    "id": 8595,
    "content": "cu"
  },
  {
    "id": 8596,
    "content": "obj\" \"mykernel"
  },
  {
    "id": 8598,
    "content": "o -c mykernel"
  },
  {
    "id": 8599,
    "content": "cu Alternatively, the simplified nvcc command-line option -arch=sm_XX can be used"
  },
  {
    "id": 8600,
    "content": "For CUDA toolkits prior to 11"
  },
  {
    "id": 8602,
    "content": "x supports architectures up to _72 and _75)"
  },
  {
    "id": 8603,
    "content": "The final -gencode to generate PTX also needs to be updated"
  },
  {
    "id": 8604,
    "content": "1"
  },
  {
    "id": 8605,
    "content": "5"
  },
  {
    "id": 8606,
    "content": "3"
  },
  {
    "id": 8608,
    "content": "9)"
  },
  {
    "id": 8609,
    "content": "When using CUDA Toolkit 11"
  },
  {
    "id": 8612,
    "content": "Please see Compute Capability 7"
  },
  {
    "id": 8613,
    "content": "x in the CUDA C++ Programming Guide for details and corrective actions"
  },
  {
    "id": 8615,
    "content": "nvcc -gencode=arch=compute_60,code=sm_89"
  },
  {
    "id": 8616,
    "content": "2"
  },
  {
    "id": 8617,
    "content": "Revision History  Version 1"
  },
  {
    "id": 8618,
    "content": "0 Initial public release"
  },
  {
    "id": 8620,
    "content": "3"
  },
  {
    "id": 8621,
    "content": "Notices  3"
  },
  {
    "id": 8622,
    "content": "1"
  },
  {
    "id": 8625,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 8637,
    "content": "3"
  },
  {
    "id": 8638,
    "content": "2"
  },
  {
    "id": 8639,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 8640,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 8641,
    "content": "3"
  },
  {
    "id": 8642,
    "content": "3"
  },
  {
    "id": 8644,
    "content": "S"
  },
  {
    "id": 8647,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 8648,
    "content": "Navigation"
  },
  {
    "id": 8649,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 8650,
    "content": "pageBottom();}\n1"
  },
  {
    "id": 8658,
    "content": "1"
  },
  {
    "id": 8659,
    "content": "2"
  },
  {
    "id": 8662,
    "content": "within the same warp"
  },
  {
    "id": 8663,
    "content": "1"
  },
  {
    "id": 8664,
    "content": "3"
  },
  {
    "id": 8667,
    "content": "1"
  },
  {
    "id": 8668,
    "content": "4"
  },
  {
    "id": 8669,
    "content": "1"
  },
  {
    "id": 8670,
    "content": "1"
  },
  {
    "id": 8671,
    "content": "Occupancy  The maximum number of concurrent warps per SMM remains the same as in SMX (i"
  },
  {
    "id": 8672,
    "content": "e"
  },
  {
    "id": 8677,
    "content": "e"
  },
  {
    "id": 8679,
    "content": "1"
  },
  {
    "id": 8680,
    "content": "4"
  },
  {
    "id": 8681,
    "content": "1"
  },
  {
    "id": 8682,
    "content": "2"
  },
  {
    "id": 8684,
    "content": "latencies compared to the Kepler design"
  },
  {
    "id": 8688,
    "content": "1"
  },
  {
    "id": 8689,
    "content": "4"
  },
  {
    "id": 8690,
    "content": "1"
  },
  {
    "id": 8691,
    "content": "3"
  },
  {
    "id": 8693,
    "content": "e"
  },
  {
    "id": 8695,
    "content": "1"
  },
  {
    "id": 8696,
    "content": "4"
  },
  {
    "id": 8697,
    "content": "1"
  },
  {
    "id": 8698,
    "content": "4"
  },
  {
    "id": 8700,
    "content": "and latency improvements also discussed above make this peak easier to approach"
  },
  {
    "id": 8702,
    "content": "In addition, there are now specialized integer instructions that can accelerate pointer arithmetic"
  },
  {
    "id": 8705,
    "content": "1"
  },
  {
    "id": 8706,
    "content": "4"
  },
  {
    "id": 8707,
    "content": "2"
  },
  {
    "id": 8708,
    "content": "Memory Throughput  1"
  },
  {
    "id": 8709,
    "content": "4"
  },
  {
    "id": 8710,
    "content": "2"
  },
  {
    "id": 8711,
    "content": "1"
  },
  {
    "id": 8717,
    "content": "Two new device attributes were added in CUDA Toolkit 6"
  },
  {
    "id": 8718,
    "content": "0: globalL1CacheSupported and localL1CacheSupported"
  },
  {
    "id": 8723,
    "content": "g"
  },
  {
    "id": 8727,
    "content": "1"
  },
  {
    "id": 8728,
    "content": "4"
  },
  {
    "id": 8729,
    "content": "3"
  },
  {
    "id": 8730,
    "content": "2"
  },
  {
    "id": 8732,
    "content": "e"
  },
  {
    "id": 8737,
    "content": "1"
  },
  {
    "id": 8738,
    "content": "4"
  },
  {
    "id": 8739,
    "content": "3"
  },
  {
    "id": 8740,
    "content": "3"
  },
  {
    "id": 8744,
    "content": "1"
  },
  {
    "id": 8745,
    "content": "4"
  },
  {
    "id": 8746,
    "content": "4"
  },
  {
    "id": 8748,
    "content": "A programming model enhancement leveraging this feature was introduced in CUDA 5"
  },
  {
    "id": 8749,
    "content": "0 to enable kernels running on GK110 to launch additional kernels onto the same GPU"
  },
  {
    "id": 8752,
    "content": "2"
  },
  {
    "id": 8753,
    "content": "Revision History  Version 1"
  },
  {
    "id": 8754,
    "content": "0 Initial Public Release Version 1"
  },
  {
    "id": 8755,
    "content": "1 Updated for second-generation Maxwell (compute capability 5"
  },
  {
    "id": 8756,
    "content": "2)"
  },
  {
    "id": 8757,
    "content": "Version 1"
  },
  {
    "id": 8758,
    "content": "2 Updated references to the CUDA C++ Programming Guide and CUDA C++ Best Practices Guide"
  },
  {
    "id": 8759,
    "content": "3"
  },
  {
    "id": 8760,
    "content": "Notices  3"
  },
  {
    "id": 8761,
    "content": "1"
  },
  {
    "id": 8764,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 8776,
    "content": "3"
  },
  {
    "id": 8777,
    "content": "2"
  },
  {
    "id": 8778,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 8779,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 8780,
    "content": "3"
  },
  {
    "id": 8781,
    "content": "3"
  },
  {
    "id": 8783,
    "content": "S"
  },
  {
    "id": 8786,
    "content": "x"
  },
  {
    "id": 8788,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 8789,
    "content": "Navigation"
  },
  {
    "id": 8790,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 8791,
    "content": "pageBottom();}\n1"
  },
  {
    "id": 8796,
    "content": "1"
  },
  {
    "id": 8797,
    "content": "2"
  },
  {
    "id": 8800,
    "content": "within the same warp"
  },
  {
    "id": 8801,
    "content": "1"
  },
  {
    "id": 8802,
    "content": "3"
  },
  {
    "id": 8805,
    "content": "1"
  },
  {
    "id": 8806,
    "content": "4"
  },
  {
    "id": 8807,
    "content": "1"
  },
  {
    "id": 8808,
    "content": "1"
  },
  {
    "id": 8811,
    "content": "A GP104 processor provides up to 20 SMs, and the similar GP102 design provides up to 30 SMs"
  },
  {
    "id": 8813,
    "content": "1"
  },
  {
    "id": 8814,
    "content": "4"
  },
  {
    "id": 8815,
    "content": "1"
  },
  {
    "id": 8816,
    "content": "2"
  },
  {
    "id": 8817,
    "content": "Occupancy  The maximum number of concurrent warps per SM remains the same as in Maxwell (i"
  },
  {
    "id": 8818,
    "content": "e"
  },
  {
    "id": 8824,
    "content": "e"
  },
  {
    "id": 8825,
    "content": ", available parallelism) needed for maximum device utilization are generally reduced"
  },
  {
    "id": 8826,
    "content": "1"
  },
  {
    "id": 8827,
    "content": "4"
  },
  {
    "id": 8828,
    "content": "2"
  },
  {
    "id": 8829,
    "content": "New Arithmetic Primitives  1"
  },
  {
    "id": 8830,
    "content": "4"
  },
  {
    "id": 8831,
    "content": "2"
  },
  {
    "id": 8832,
    "content": "1"
  },
  {
    "id": 8836,
    "content": "1"
  },
  {
    "id": 8837,
    "content": "4"
  },
  {
    "id": 8838,
    "content": "2"
  },
  {
    "id": 8839,
    "content": "2"
  },
  {
    "id": 8841,
    "content": "Both instructions offer a throughput equal to that of FP32 arithmetic"
  },
  {
    "id": 8842,
    "content": "1"
  },
  {
    "id": 8843,
    "content": "4"
  },
  {
    "id": 8844,
    "content": "3"
  },
  {
    "id": 8845,
    "content": "Memory Throughput  1"
  },
  {
    "id": 8846,
    "content": "4"
  },
  {
    "id": 8847,
    "content": "3"
  },
  {
    "id": 8848,
    "content": "1"
  },
  {
    "id": 8849,
    "content": "This allows much wider interfaces at similar power compared to traditional GDDR technology"
  },
  {
    "id": 8850,
    "content": "GP100 is linked to up to four stacks of HBM2 and uses two 512-bit memory controllers for each stack"
  },
  {
    "id": 8853,
    "content": "previous architectures"
  },
  {
    "id": 8857,
    "content": "4 1"
  },
  {
    "id": 8858,
    "content": "4"
  },
  {
    "id": 8859,
    "content": "3"
  },
  {
    "id": 8860,
    "content": "2"
  },
  {
    "id": 8865,
    "content": "Two new device attributes were added in CUDA Toolkit 6"
  },
  {
    "id": 8866,
    "content": "0: globalL1CacheSupported and localL1CacheSupported"
  },
  {
    "id": 8869,
    "content": "This situation is reported by the profiler"
  },
  {
    "id": 8870,
    "content": "1"
  },
  {
    "id": 8871,
    "content": "4"
  },
  {
    "id": 8872,
    "content": "4"
  },
  {
    "id": 8880,
    "content": "1"
  },
  {
    "id": 8881,
    "content": "4"
  },
  {
    "id": 8882,
    "content": "5"
  },
  {
    "id": 8883,
    "content": "Shared Memory  1"
  },
  {
    "id": 8884,
    "content": "4"
  },
  {
    "id": 8885,
    "content": "5"
  },
  {
    "id": 8886,
    "content": "1"
  },
  {
    "id": 8889,
    "content": "g"
  },
  {
    "id": 8891,
    "content": "Applications no longer need to select a preference of the L1/shared split for optimal performance"
  },
  {
    "id": 8894,
    "content": "1"
  },
  {
    "id": 8895,
    "content": "4"
  },
  {
    "id": 8896,
    "content": "5"
  },
  {
    "id": 8897,
    "content": "2"
  },
  {
    "id": 8899,
    "content": "e"
  },
  {
    "id": 8901,
    "content": "1"
  },
  {
    "id": 8902,
    "content": "4"
  },
  {
    "id": 8903,
    "content": "6"
  },
  {
    "id": 8904,
    "content": "Inter-GPU Communication  1"
  },
  {
    "id": 8905,
    "content": "4"
  },
  {
    "id": 8906,
    "content": "6"
  },
  {
    "id": 8907,
    "content": "1"
  },
  {
    "id": 8912,
    "content": "1"
  },
  {
    "id": 8913,
    "content": "4"
  },
  {
    "id": 8914,
    "content": "6"
  },
  {
    "id": 8915,
    "content": "2"
  },
  {
    "id": 8919,
    "content": "1"
  },
  {
    "id": 8920,
    "content": "4"
  },
  {
    "id": 8921,
    "content": "7"
  },
  {
    "id": 8923,
    "content": "The execution context (registers, shared memory, etc"
  },
  {
    "id": 8924,
    "content": ") are swapped to GPU DRAM so that another application can be swapped in and run"
  },
  {
    "id": 8926,
    "content": "Interactive kernel debugging on a single-GPU system is now possible"
  },
  {
    "id": 8927,
    "content": "1"
  },
  {
    "id": 8928,
    "content": "4"
  },
  {
    "id": 8929,
    "content": "8"
  },
  {
    "id": 8933,
    "content": "into the GPU address space for access over PCIe/NVLink interfaces"
  },
  {
    "id": 8936,
    "content": "On such systems, there is no need to explicitly allocate managed memory using cudaMallocManaged()"
  },
  {
    "id": 8937,
    "content": "2"
  },
  {
    "id": 8938,
    "content": "Revision History  Version 1"
  },
  {
    "id": 8939,
    "content": "0 Initial Public Release Version 1"
  },
  {
    "id": 8940,
    "content": "1 Updated references to the CUDA C++ Programming Guide and CUDA C++ Best Practices Guide"
  },
  {
    "id": 8943,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 8955,
    "content": "3"
  },
  {
    "id": 8956,
    "content": "2"
  },
  {
    "id": 8957,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 8958,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 8959,
    "content": "3"
  },
  {
    "id": 8960,
    "content": "3"
  },
  {
    "id": 8962,
    "content": "S"
  },
  {
    "id": 8965,
    "content": "x"
  },
  {
    "id": 8969,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 8970,
    "content": "Navigation"
  },
  {
    "id": 8971,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 8972,
    "content": "pageBottom();}\n1"
  },
  {
    "id": 8977,
    "content": "1"
  },
  {
    "id": 8978,
    "content": "2"
  },
  {
    "id": 8981,
    "content": "within the same warp"
  },
  {
    "id": 8982,
    "content": "1"
  },
  {
    "id": 8983,
    "content": "3"
  },
  {
    "id": 8986,
    "content": "1"
  },
  {
    "id": 8987,
    "content": "4"
  },
  {
    "id": 8988,
    "content": "1"
  },
  {
    "id": 8989,
    "content": "1"
  },
  {
    "id": 8994,
    "content": "GV100 provides up to 84 SMs"
  },
  {
    "id": 8995,
    "content": "1"
  },
  {
    "id": 8996,
    "content": "4"
  },
  {
    "id": 8997,
    "content": "1"
  },
  {
    "id": 8998,
    "content": "2"
  },
  {
    "id": 9002,
    "content": "When porting existing codes to Volta, the following three code patterns need careful attention"
  },
  {
    "id": 9005,
    "content": "Applications using __syncthreads() or the PTX bar"
  },
  {
    "id": 9007,
    "content": "The racecheck and synccheck tools provided by compute-sanitizer can help with locating violations"
  },
  {
    "id": 9008,
    "content": "1"
  },
  {
    "id": 9009,
    "content": "4"
  },
  {
    "id": 9010,
    "content": "1"
  },
  {
    "id": 9011,
    "content": "3"
  },
  {
    "id": 9012,
    "content": "Occupancy  The maximum number of concurrent warps per SM remains the same as in Pascal (i"
  },
  {
    "id": 9013,
    "content": "e"
  },
  {
    "id": 9015,
    "content": "1"
  },
  {
    "id": 9016,
    "content": "4"
  },
  {
    "id": 9017,
    "content": "1"
  },
  {
    "id": 9018,
    "content": "4"
  },
  {
    "id": 9019,
    "content": "Integer Arithmetic  Unlike Pascal GPUs, the GV100 SM includes dedicated FP32 and INT32 cores"
  },
  {
    "id": 9021,
    "content": "1"
  },
  {
    "id": 9022,
    "content": "4"
  },
  {
    "id": 9023,
    "content": "2"
  },
  {
    "id": 9026,
    "content": "16x16 size matrices spanning all 32 threads of the warp"
  },
  {
    "id": 9027,
    "content": "See the CUDA C++ Programming Guide for more information"
  },
  {
    "id": 9028,
    "content": "1"
  },
  {
    "id": 9029,
    "content": "4"
  },
  {
    "id": 9030,
    "content": "3"
  },
  {
    "id": 9031,
    "content": "Memory Throughput  1"
  },
  {
    "id": 9032,
    "content": "4"
  },
  {
    "id": 9033,
    "content": "3"
  },
  {
    "id": 9034,
    "content": "1"
  },
  {
    "id": 9037,
    "content": "compared to previous architectures"
  },
  {
    "id": 9039,
    "content": "1"
  },
  {
    "id": 9040,
    "content": "4"
  },
  {
    "id": 9041,
    "content": "3"
  },
  {
    "id": 9042,
    "content": "2"
  },
  {
    "id": 9044,
    "content": "single thread block to address the full 96 KB of shared memory"
  },
  {
    "id": 9048,
    "content": "performance"
  },
  {
    "id": 9049,
    "content": "1"
  },
  {
    "id": 9050,
    "content": "4"
  },
  {
    "id": 9051,
    "content": "4"
  },
  {
    "id": 9054,
    "content": "1"
  },
  {
    "id": 9055,
    "content": "4"
  },
  {
    "id": 9056,
    "content": "5"
  },
  {
    "id": 9061,
    "content": "other clients from making progress, and thus improve average latency and jitter accross the system"
  },
  {
    "id": 9062,
    "content": "1"
  },
  {
    "id": 9063,
    "content": "4"
  },
  {
    "id": 9064,
    "content": "6"
  },
  {
    "id": 9069,
    "content": "2"
  },
  {
    "id": 9070,
    "content": "Revision History  Version 1"
  },
  {
    "id": 9071,
    "content": "0 Initial Public Release Version 1"
  },
  {
    "id": 9072,
    "content": "1 Added Cooperative Groups section"
  },
  {
    "id": 9073,
    "content": "Updated references to the CUDA C++ Programming Guide and CUDA C++ Best Practices Guide"
  },
  {
    "id": 9074,
    "content": "3"
  },
  {
    "id": 9075,
    "content": "Notices  3"
  },
  {
    "id": 9076,
    "content": "1"
  },
  {
    "id": 9079,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 9091,
    "content": "3"
  },
  {
    "id": 9092,
    "content": "2"
  },
  {
    "id": 9093,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 9094,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 9095,
    "content": "3"
  },
  {
    "id": 9096,
    "content": "3"
  },
  {
    "id": 9098,
    "content": "S"
  },
  {
    "id": 9101,
    "content": "x"
  },
  {
    "id": 9103,
    "content": "3 As with previous architectures, MPS does not provide fatal fault isolation between clients"
  },
  {
    "id": 9105,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 9106,
    "content": "Navigation"
  },
  {
    "id": 9107,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 9108,
    "content": "pageBottom();}\n1"
  },
  {
    "id": 9111,
    "content": "CUDA C++ Programming Guide"
  },
  {
    "id": 9112,
    "content": "1"
  },
  {
    "id": 9113,
    "content": "2"
  },
  {
    "id": 9116,
    "content": "within the same warp"
  },
  {
    "id": 9117,
    "content": "1"
  },
  {
    "id": 9118,
    "content": "3"
  },
  {
    "id": 9121,
    "content": "x) as Volta, and provides similar improvements over Pascal"
  },
  {
    "id": 9122,
    "content": "1"
  },
  {
    "id": 9123,
    "content": "4"
  },
  {
    "id": 9124,
    "content": "1"
  },
  {
    "id": 9125,
    "content": "1"
  },
  {
    "id": 9130,
    "content": "1"
  },
  {
    "id": 9131,
    "content": "4"
  },
  {
    "id": 9132,
    "content": "1"
  },
  {
    "id": 9133,
    "content": "2"
  },
  {
    "id": 9140,
    "content": "Applications using __syncthreads() or the PTX bar"
  },
  {
    "id": 9142,
    "content": "The racecheck and synccheck tools provided by compute-sanitizer can help with locating violations"
  },
  {
    "id": 9143,
    "content": "1"
  },
  {
    "id": 9144,
    "content": "4"
  },
  {
    "id": 9145,
    "content": "1"
  },
  {
    "id": 9146,
    "content": "3"
  },
  {
    "id": 9148,
    "content": "1"
  },
  {
    "id": 9149,
    "content": "4"
  },
  {
    "id": 9150,
    "content": "1"
  },
  {
    "id": 9151,
    "content": "4"
  },
  {
    "id": 9152,
    "content": "Integer Arithmetic  Similar to Volta, the Turing SM includes dedicated FP32 and INT32 cores"
  },
  {
    "id": 9154,
    "content": "1"
  },
  {
    "id": 9155,
    "content": "4"
  },
  {
    "id": 9156,
    "content": "2"
  },
  {
    "id": 9161,
    "content": "See the CUDA C++ Programming Guide for more information"
  },
  {
    "id": 9162,
    "content": "1"
  },
  {
    "id": 9163,
    "content": "4"
  },
  {
    "id": 9164,
    "content": "3"
  },
  {
    "id": 9165,
    "content": "Memory Throughput  1"
  },
  {
    "id": 9166,
    "content": "4"
  },
  {
    "id": 9167,
    "content": "3"
  },
  {
    "id": 9168,
    "content": "1"
  },
  {
    "id": 9174,
    "content": "2"
  },
  {
    "id": 9175,
    "content": "Revision History  Version 1"
  },
  {
    "id": 9176,
    "content": "0 Initial Public Release Version 1"
  },
  {
    "id": 9177,
    "content": "1 Updated references to the CUDA C++ Programming Guide and CUDA C++ Best Practices Guide"
  },
  {
    "id": 9180,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 9192,
    "content": "3"
  },
  {
    "id": 9193,
    "content": "2"
  },
  {
    "id": 9194,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 9195,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 9196,
    "content": "3"
  },
  {
    "id": 9197,
    "content": "3"
  },
  {
    "id": 9199,
    "content": "S"
  },
  {
    "id": 9202,
    "content": "5"
  },
  {
    "id": 9205,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 9206,
    "content": "Navigation"
  },
  {
    "id": 9207,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 9208,
    "content": "pageBottom();}\n1"
  },
  {
    "id": 9212,
    "content": "1"
  },
  {
    "id": 9213,
    "content": "2"
  },
  {
    "id": 9215,
    "content": "code"
  },
  {
    "id": 9216,
    "content": "Avoid long sequences of diverged execution by threads within the same warp"
  },
  {
    "id": 9217,
    "content": "1"
  },
  {
    "id": 9218,
    "content": "3"
  },
  {
    "id": 9220,
    "content": "provides the following improvements over Volta and Turing"
  },
  {
    "id": 9221,
    "content": "1"
  },
  {
    "id": 9222,
    "content": "4"
  },
  {
    "id": 9223,
    "content": "1"
  },
  {
    "id": 9224,
    "content": "1"
  },
  {
    "id": 9225,
    "content": "Occupancy  The maximum number of concurrent warps per SM remains the same as in Volta (i"
  },
  {
    "id": 9226,
    "content": "e"
  },
  {
    "id": 9227,
    "content": ", 64) for compute capability 8 0, while for compute capability 8"
  },
  {
    "id": 9228,
    "content": "6 it is 48"
  },
  {
    "id": 9230,
    "content": "0 (i"
  },
  {
    "id": 9231,
    "content": "e"
  },
  {
    "id": 9232,
    "content": ", A100 GPUs) and 16 for GPUs with compute capability 8"
  },
  {
    "id": 9233,
    "content": "6"
  },
  {
    "id": 9234,
    "content": "For devices of compute capability 8"
  },
  {
    "id": 9235,
    "content": "0 (i"
  },
  {
    "id": 9236,
    "content": "e"
  },
  {
    "id": 9238,
    "content": "For devices of compute capability 8"
  },
  {
    "id": 9239,
    "content": "0 (i"
  },
  {
    "id": 9240,
    "content": "e"
  },
  {
    "id": 9241,
    "content": ", A100 GPUs) the maximum shared memory per thread block is 163 KB"
  },
  {
    "id": 9242,
    "content": "Overall, developers can expect similar occupancy as on Volta without changes to their application"
  },
  {
    "id": 9243,
    "content": "1"
  },
  {
    "id": 9244,
    "content": "4"
  },
  {
    "id": 9245,
    "content": "1"
  },
  {
    "id": 9246,
    "content": "2"
  },
  {
    "id": 9249,
    "content": "For more information please refer to the section on Async Copy in the CUDA C++ Programming Guide"
  },
  {
    "id": 9250,
    "content": "1"
  },
  {
    "id": 9251,
    "content": "4"
  },
  {
    "id": 9252,
    "content": "1"
  },
  {
    "id": 9253,
    "content": "3"
  },
  {
    "id": 9257,
    "content": "1"
  },
  {
    "id": 9258,
    "content": "4"
  },
  {
    "id": 9259,
    "content": "1"
  },
  {
    "id": 9260,
    "content": "4"
  },
  {
    "id": 9262,
    "content": "new warp wide reduction operations refer to Warp Reduce Functions in the CUDA C++ Programming Guide"
  },
  {
    "id": 9263,
    "content": "1"
  },
  {
    "id": 9264,
    "content": "4"
  },
  {
    "id": 9265,
    "content": "1"
  },
  {
    "id": 9266,
    "content": "5"
  },
  {
    "id": 9268,
    "content": "integrated into programs for more accurate DL training than 16-bit HMMA formats"
  },
  {
    "id": 9271,
    "content": "While a binary compiled for 8"
  },
  {
    "id": 9272,
    "content": "0 will run as is on 8"
  },
  {
    "id": 9273,
    "content": "6, it is recommended to compile explicitly for 8"
  },
  {
    "id": 9274,
    "content": "6 to benefit from the increased FP32 throughput"
  },
  {
    "id": 9275,
    "content": "1"
  },
  {
    "id": 9276,
    "content": "4"
  },
  {
    "id": 9277,
    "content": "2"
  },
  {
    "id": 9278,
    "content": "Memory System  1"
  },
  {
    "id": 9279,
    "content": "4"
  },
  {
    "id": 9280,
    "content": "2"
  },
  {
    "id": 9281,
    "content": "1"
  },
  {
    "id": 9283,
    "content": "1"
  },
  {
    "id": 9284,
    "content": "4"
  },
  {
    "id": 9285,
    "content": "2"
  },
  {
    "id": 9286,
    "content": "2"
  },
  {
    "id": 9289,
    "content": "1"
  },
  {
    "id": 9290,
    "content": "4"
  },
  {
    "id": 9291,
    "content": "2"
  },
  {
    "id": 9292,
    "content": "3"
  },
  {
    "id": 9297,
    "content": "1"
  },
  {
    "id": 9298,
    "content": "4"
  },
  {
    "id": 9299,
    "content": "3"
  },
  {
    "id": 9302,
    "content": "enable direct transfers (over either PCIe or NVLink) between GPUs"
  },
  {
    "id": 9305,
    "content": "2"
  },
  {
    "id": 9306,
    "content": "Revision History  Version 1"
  },
  {
    "id": 9307,
    "content": "1 Initial Public Release Added support for compute capability 8"
  },
  {
    "id": 9308,
    "content": "6 3"
  },
  {
    "id": 9311,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 9323,
    "content": "3"
  },
  {
    "id": 9324,
    "content": "2"
  },
  {
    "id": 9325,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 9326,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 9327,
    "content": "3"
  },
  {
    "id": 9328,
    "content": "3"
  },
  {
    "id": 9330,
    "content": "S"
  },
  {
    "id": 9334,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 9335,
    "content": "Navigation"
  },
  {
    "id": 9336,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 9337,
    "content": "pageBottom();}\n1"
  },
  {
    "id": 9341,
    "content": "1"
  },
  {
    "id": 9342,
    "content": "2"
  },
  {
    "id": 9344,
    "content": "code"
  },
  {
    "id": 9345,
    "content": "Avoid long sequences of diverged execution by threads within the same warp"
  },
  {
    "id": 9346,
    "content": "1"
  },
  {
    "id": 9347,
    "content": "3"
  },
  {
    "id": 9350,
    "content": "1"
  },
  {
    "id": 9351,
    "content": "4"
  },
  {
    "id": 9352,
    "content": "1"
  },
  {
    "id": 9353,
    "content": "1"
  },
  {
    "id": 9355,
    "content": "0 (that is, H100 GPUs)"
  },
  {
    "id": 9356,
    "content": "For devices of compute capability 9"
  },
  {
    "id": 9358,
    "content": "For devices of compute capability 9"
  },
  {
    "id": 9359,
    "content": "0 (H100 GPUs), the maximum shared memory per thread block is 227 KB"
  },
  {
    "id": 9362,
    "content": "1"
  },
  {
    "id": 9363,
    "content": "4"
  },
  {
    "id": 9364,
    "content": "1"
  },
  {
    "id": 9365,
    "content": "2"
  },
  {
    "id": 9371,
    "content": "1"
  },
  {
    "id": 9372,
    "content": "4"
  },
  {
    "id": 9373,
    "content": "1"
  },
  {
    "id": 9374,
    "content": "3"
  },
  {
    "id": 9379,
    "content": "1"
  },
  {
    "id": 9380,
    "content": "4"
  },
  {
    "id": 9381,
    "content": "1"
  },
  {
    "id": 9382,
    "content": "4"
  },
  {
    "id": 9384,
    "content": "0"
  },
  {
    "id": 9385,
    "content": "1"
  },
  {
    "id": 9386,
    "content": "4"
  },
  {
    "id": 9387,
    "content": "1"
  },
  {
    "id": 9388,
    "content": "5"
  },
  {
    "id": 9392,
    "content": "1"
  },
  {
    "id": 9393,
    "content": "4"
  },
  {
    "id": 9394,
    "content": "2"
  },
  {
    "id": 9395,
    "content": "Memory System  1"
  },
  {
    "id": 9396,
    "content": "4"
  },
  {
    "id": 9397,
    "content": "2"
  },
  {
    "id": 9398,
    "content": "1"
  },
  {
    "id": 9400,
    "content": "1"
  },
  {
    "id": 9401,
    "content": "4"
  },
  {
    "id": 9402,
    "content": "2"
  },
  {
    "id": 9403,
    "content": "2"
  },
  {
    "id": 9406,
    "content": "1"
  },
  {
    "id": 9407,
    "content": "4"
  },
  {
    "id": 9408,
    "content": "2"
  },
  {
    "id": 9409,
    "content": "3"
  },
  {
    "id": 9416,
    "content": "so )"
  },
  {
    "id": 9417,
    "content": "1"
  },
  {
    "id": 9418,
    "content": "4"
  },
  {
    "id": 9419,
    "content": "2"
  },
  {
    "id": 9420,
    "content": "4"
  },
  {
    "id": 9425,
    "content": "1"
  },
  {
    "id": 9426,
    "content": "4"
  },
  {
    "id": 9427,
    "content": "3"
  },
  {
    "id": 9432,
    "content": "2"
  },
  {
    "id": 9433,
    "content": "Revision History  Version 1"
  },
  {
    "id": 9435,
    "content": "0"
  },
  {
    "id": 9438,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 9450,
    "content": "3"
  },
  {
    "id": 9451,
    "content": "2"
  },
  {
    "id": 9452,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 9453,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 9454,
    "content": "3"
  },
  {
    "id": 9455,
    "content": "3"
  },
  {
    "id": 9457,
    "content": "S"
  },
  {
    "id": 9460,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 9461,
    "content": "Navigation"
  },
  {
    "id": 9462,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 9463,
    "content": "pageBottom();}\n1"
  },
  {
    "id": 9467,
    "content": "1"
  },
  {
    "id": 9468,
    "content": "2"
  },
  {
    "id": 9470,
    "content": "code"
  },
  {
    "id": 9471,
    "content": "Avoid long sequences of diverged execution by threads within the same warp"
  },
  {
    "id": 9472,
    "content": "1"
  },
  {
    "id": 9473,
    "content": "3"
  },
  {
    "id": 9475,
    "content": "following improvements over Turing and NVIDIA Ampere GPU architectures"
  },
  {
    "id": 9476,
    "content": "1"
  },
  {
    "id": 9477,
    "content": "4"
  },
  {
    "id": 9478,
    "content": "1"
  },
  {
    "id": 9479,
    "content": "1"
  },
  {
    "id": 9481,
    "content": "6 GPUs without changes to their application"
  },
  {
    "id": 9482,
    "content": "1"
  },
  {
    "id": 9483,
    "content": "4"
  },
  {
    "id": 9484,
    "content": "1"
  },
  {
    "id": 9485,
    "content": "2"
  },
  {
    "id": 9487,
    "content": "1"
  },
  {
    "id": 9488,
    "content": "4"
  },
  {
    "id": 9489,
    "content": "1"
  },
  {
    "id": 9490,
    "content": "3"
  },
  {
    "id": 9492,
    "content": "0"
  },
  {
    "id": 9493,
    "content": "While a binary compiled for 8"
  },
  {
    "id": 9494,
    "content": "0 will run as-is on 8"
  },
  {
    "id": 9495,
    "content": "9, it is recommended to compile explicitly for 8"
  },
  {
    "id": 9496,
    "content": "9 to benefit from the increased FP32 throughput"
  },
  {
    "id": 9497,
    "content": "1"
  },
  {
    "id": 9498,
    "content": "4"
  },
  {
    "id": 9499,
    "content": "2"
  },
  {
    "id": 9500,
    "content": "Memory System  1"
  },
  {
    "id": 9501,
    "content": "4"
  },
  {
    "id": 9502,
    "content": "2"
  },
  {
    "id": 9503,
    "content": "1"
  },
  {
    "id": 9505,
    "content": "1"
  },
  {
    "id": 9506,
    "content": "4"
  },
  {
    "id": 9507,
    "content": "2"
  },
  {
    "id": 9508,
    "content": "2"
  },
  {
    "id": 9511,
    "content": "Hence, GPUs with compute capability 8"
  },
  {
    "id": 9515,
    "content": "2"
  },
  {
    "id": 9516,
    "content": "Revision History  Version 1"
  },
  {
    "id": 9518,
    "content": "0 and 8"
  },
  {
    "id": 9519,
    "content": "6, NVIDIA Ada refers to devices of compute capability 8"
  },
  {
    "id": 9520,
    "content": "9"
  },
  {
    "id": 9523,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 9535,
    "content": "3"
  },
  {
    "id": 9536,
    "content": "2"
  },
  {
    "id": 9537,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 9538,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 9539,
    "content": "3"
  },
  {
    "id": 9540,
    "content": "3"
  },
  {
    "id": 9542,
    "content": "S"
  },
  {
    "id": 9545,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 9546,
    "content": "Navigation"
  },
  {
    "id": 9547,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 9548,
    "content": "pageBottom();}\n1"
  },
  {
    "id": 9549,
    "content": "Data Movement and Conversion Instructions: multimem ld_reduce, multimem st, multimem"
  },
  {
    "id": 9550,
    "content": "red 9"
  },
  {
    "id": 9551,
    "content": "7"
  },
  {
    "id": 9552,
    "content": "8"
  },
  {
    "id": 9553,
    "content": "14"
  },
  {
    "id": 9554,
    "content": "Data Movement and Conversion Instructions: cp"
  },
  {
    "id": 9555,
    "content": "async"
  },
  {
    "id": 9556,
    "content": "wait_group / cp"
  },
  {
    "id": 9557,
    "content": "async"
  },
  {
    "id": 9558,
    "content": "wait_all 9"
  },
  {
    "id": 9559,
    "content": "7"
  },
  {
    "id": 9560,
    "content": "8"
  },
  {
    "id": 9561,
    "content": "24"
  },
  {
    "id": 9562,
    "content": "6"
  },
  {
    "id": 9563,
    "content": "Parallel Synchronization and Communication Instructions: mbarrier"
  },
  {
    "id": 9564,
    "content": "complete_tx 9"
  },
  {
    "id": 9565,
    "content": "7"
  },
  {
    "id": 9566,
    "content": "12"
  },
  {
    "id": 9567,
    "content": "15"
  },
  {
    "id": 9568,
    "content": "13"
  },
  {
    "id": 9569,
    "content": "Parallel Synchronization and Communication Instructions: mbarrier"
  },
  {
    "id": 9570,
    "content": "arrive_drop 9"
  },
  {
    "id": 9571,
    "content": "7"
  },
  {
    "id": 9572,
    "content": "12"
  },
  {
    "id": 9573,
    "content": "15 15"
  },
  {
    "id": 9574,
    "content": "Parallel Synchronization and Communication Instructions: cp"
  },
  {
    "id": 9575,
    "content": "async"
  },
  {
    "id": 9576,
    "content": "mbarrier"
  },
  {
    "id": 9577,
    "content": "arrive 9"
  },
  {
    "id": 9578,
    "content": "7"
  },
  {
    "id": 9579,
    "content": "12"
  },
  {
    "id": 9580,
    "content": "15"
  },
  {
    "id": 9581,
    "content": "16"
  },
  {
    "id": 9582,
    "content": "Parallel Synchronization and Communication Instructions: mbarrier test_wait/mbarrier"
  },
  {
    "id": 9583,
    "content": "try_wait 9"
  },
  {
    "id": 9584,
    "content": "7"
  },
  {
    "id": 9585,
    "content": "12"
  },
  {
    "id": 9586,
    "content": "15"
  },
  {
    "id": 9587,
    "content": "17"
  },
  {
    "id": 9588,
    "content": "Parallel Synchronization and Communication Instructions: mbarrier"
  },
  {
    "id": 9589,
    "content": "pending_count 9"
  },
  {
    "id": 9590,
    "content": "7"
  },
  {
    "id": 9591,
    "content": "12"
  },
  {
    "id": 9592,
    "content": "15"
  },
  {
    "id": 9593,
    "content": "18"
  },
  {
    "id": 9594,
    "content": "Matrix multiply-accumulate operation using mma"
  },
  {
    "id": 9595,
    "content": "sp instruction with sparse matrix A 9"
  },
  {
    "id": 9596,
    "content": "7"
  },
  {
    "id": 9597,
    "content": "13"
  },
  {
    "id": 9598,
    "content": "5"
  },
  {
    "id": 9599,
    "content": "1"
  },
  {
    "id": 9600,
    "content": "Asynchronous Warpgroup Level Matrix Multiply-Accumulate Operation using wgmma"
  },
  {
    "id": 9601,
    "content": "mma_async instruction 9"
  },
  {
    "id": 9602,
    "content": "7"
  },
  {
    "id": 9603,
    "content": "14"
  },
  {
    "id": 9604,
    "content": "5"
  },
  {
    "id": 9605,
    "content": "1"
  },
  {
    "id": 9606,
    "content": "Asynchronous Warpgroup Level Multiply-and-Accumulate Operation using wgmma"
  },
  {
    "id": 9607,
    "content": "mma_async"
  },
  {
    "id": 9608,
    "content": "sp instruction 9"
  },
  {
    "id": 9609,
    "content": "7"
  },
  {
    "id": 9610,
    "content": "14"
  },
  {
    "id": 9611,
    "content": "6"
  },
  {
    "id": 9612,
    "content": "1"
  },
  {
    "id": 9613,
    "content": "Matrix fragments for warpgroup-level multiply-accumulate operation with sparse matrix A 9"
  },
  {
    "id": 9614,
    "content": "7"
  },
  {
    "id": 9615,
    "content": "14"
  },
  {
    "id": 9616,
    "content": "6"
  },
  {
    "id": 9617,
    "content": "2"
  },
  {
    "id": 9618,
    "content": "1"
  },
  {
    "id": 9620,
    "content": "30"
  },
  {
    "id": 9621,
    "content": "Introduction v8"
  },
  {
    "id": 9623,
    "content": "1"
  },
  {
    "id": 9624,
    "content": "1"
  },
  {
    "id": 9629,
    "content": "physics simulation to computational finance or computational biology"
  },
  {
    "id": 9631,
    "content": "1"
  },
  {
    "id": 9632,
    "content": "2"
  },
  {
    "id": 9637,
    "content": "1"
  },
  {
    "id": 9638,
    "content": "3"
  },
  {
    "id": 9639,
    "content": "PTX ISA Version 8 5  PTX ISA version 8"
  },
  {
    "id": 9640,
    "content": "5 introduces the following new features: Adds support for mma"
  },
  {
    "id": 9641,
    "content": "sp::ordered_metadata instruction"
  },
  {
    "id": 9642,
    "content": "1"
  },
  {
    "id": 9643,
    "content": "4"
  },
  {
    "id": 9645,
    "content": "State Spaces, Types, and Variables describes state spaces, types, and variable declarations"
  },
  {
    "id": 9647,
    "content": "http: ieeexplore"
  },
  {
    "id": 9648,
    "content": "ieee"
  },
  {
    "id": 9649,
    "content": "org/servlet/opac"
  },
  {
    "id": 9650,
    "content": "punumber=4610933 The OpenCL Specification, Version: 1"
  },
  {
    "id": 9651,
    "content": "1, Document Revision: 44, June 1, 2011"
  },
  {
    "id": 9652,
    "content": "https: docs"
  },
  {
    "id": 9653,
    "content": "nvidia"
  },
  {
    "id": 9654,
    "content": "com/cuda/cuda-c-programming-guide/index html CUDA Dynamic Parallelism Programming Guide"
  },
  {
    "id": 9655,
    "content": "https: docs"
  },
  {
    "id": 9656,
    "content": "nvidia"
  },
  {
    "id": 9657,
    "content": "com/cuda/cuda-c-programming-guide/index html#cuda-dynamic-parallelism CUDA Atomicity Requirements"
  },
  {
    "id": 9658,
    "content": "https: nvidia"
  },
  {
    "id": 9659,
    "content": "github"
  },
  {
    "id": 9660,
    "content": "io/cccl/libcudacxx/extended_api/memory_model"
  },
  {
    "id": 9661,
    "content": "html#atomicity PTX Writers Guide to Interoperability"
  },
  {
    "id": 9665,
    "content": "2"
  },
  {
    "id": 9666,
    "content": "2"
  },
  {
    "id": 9668,
    "content": "2"
  },
  {
    "id": 9669,
    "content": "2"
  },
  {
    "id": 9670,
    "content": "1"
  },
  {
    "id": 9673,
    "content": "The thread identifier is a three-element vector tid , (with elements tid x , tid y , and tid"
  },
  {
    "id": 9675,
    "content": "z )"
  },
  {
    "id": 9678,
    "content": "2"
  },
  {
    "id": 9679,
    "content": "2"
  },
  {
    "id": 9680,
    "content": "2"
  },
  {
    "id": 9684,
    "content": "2"
  },
  {
    "id": 9685,
    "content": "2"
  },
  {
    "id": 9686,
    "content": "3"
  },
  {
    "id": 9692,
    "content": "2"
  },
  {
    "id": 9693,
    "content": "3"
  },
  {
    "id": 9703,
    "content": "in an image, a voxel in a volume, a cell in a grid-based computation)"
  },
  {
    "id": 9705,
    "content": "threads in groups of parallel threads called warps"
  },
  {
    "id": 9706,
    "content": "(This term originates from weaving, the first parallel thread technology"
  },
  {
    "id": 9715,
    "content": "fail to launch"
  },
  {
    "id": 9716,
    "content": "Figure 4 Hardware Model  A set of SIMT multiprocessors with on-chip shared memory"
  },
  {
    "id": 9717,
    "content": "3"
  },
  {
    "id": 9718,
    "content": "2"
  },
  {
    "id": 9723,
    "content": "The local and global memory spaces are read-write regions of device memory"
  },
  {
    "id": 9724,
    "content": "4"
  },
  {
    "id": 9726,
    "content": "4"
  },
  {
    "id": 9727,
    "content": "1"
  },
  {
    "id": 9728,
    "content": "Source Format  Source modules are ASCII text"
  },
  {
    "id": 9731,
    "content": "Each PTX module must begin with a"
  },
  {
    "id": 9733,
    "content": "See PTX Module Directives for a more information on these directives"
  },
  {
    "id": 9734,
    "content": "4"
  },
  {
    "id": 9735,
    "content": "2"
  },
  {
    "id": 9737,
    "content": "4"
  },
  {
    "id": 9738,
    "content": "3"
  },
  {
    "id": 9739,
    "content": "Statements  A PTX statement is either a directive or an instruction"
  },
  {
    "id": 9740,
    "content": "Examples"
  },
  {
    "id": 9741,
    "content": "reg"
  },
  {
    "id": 9742,
    "content": "b32 r1, r2;"
  },
  {
    "id": 9743,
    "content": "global"
  },
  {
    "id": 9744,
    "content": "f32 array[N]; start: mov"
  },
  {
    "id": 9745,
    "content": "b32 r1, %tid"
  },
  {
    "id": 9746,
    "content": "x; shl"
  },
  {
    "id": 9747,
    "content": "b32 r1, r1, 2;   shift thread id by 2 bits ld"
  },
  {
    "id": 9748,
    "content": "global"
  },
  {
    "id": 9749,
    "content": "b32 r2, array[r1];   thread[tid] gets array[tid] add f32 r2, r2, 0 5;   add 1/2 4"
  },
  {
    "id": 9750,
    "content": "3"
  },
  {
    "id": 9751,
    "content": "1"
  },
  {
    "id": 9754,
    "content": "address_size"
  },
  {
    "id": 9755,
    "content": "explicitcluster"
  },
  {
    "id": 9756,
    "content": "maxnreg"
  },
  {
    "id": 9757,
    "content": "section"
  },
  {
    "id": 9758,
    "content": "alias"
  },
  {
    "id": 9759,
    "content": "extern"
  },
  {
    "id": 9760,
    "content": "maxntid"
  },
  {
    "id": 9761,
    "content": "shared"
  },
  {
    "id": 9762,
    "content": "align"
  },
  {
    "id": 9763,
    "content": "file"
  },
  {
    "id": 9764,
    "content": "minnctapersm"
  },
  {
    "id": 9765,
    "content": "sreg"
  },
  {
    "id": 9766,
    "content": "branchtargets"
  },
  {
    "id": 9767,
    "content": "func"
  },
  {
    "id": 9768,
    "content": "noreturn"
  },
  {
    "id": 9769,
    "content": "target"
  },
  {
    "id": 9770,
    "content": "callprototype"
  },
  {
    "id": 9771,
    "content": "global"
  },
  {
    "id": 9772,
    "content": "param"
  },
  {
    "id": 9773,
    "content": "tex"
  },
  {
    "id": 9774,
    "content": "calltargets"
  },
  {
    "id": 9775,
    "content": "loc"
  },
  {
    "id": 9776,
    "content": "pragma"
  },
  {
    "id": 9777,
    "content": "version"
  },
  {
    "id": 9778,
    "content": "common"
  },
  {
    "id": 9779,
    "content": "local"
  },
  {
    "id": 9780,
    "content": "reg"
  },
  {
    "id": 9781,
    "content": "visible"
  },
  {
    "id": 9782,
    "content": "const"
  },
  {
    "id": 9783,
    "content": "maxclusterrank"
  },
  {
    "id": 9784,
    "content": "reqnctapercluster"
  },
  {
    "id": 9785,
    "content": "weak"
  },
  {
    "id": 9786,
    "content": "entry"
  },
  {
    "id": 9787,
    "content": "maxnctapersm"
  },
  {
    "id": 9788,
    "content": "reqntid 4"
  },
  {
    "id": 9789,
    "content": "3"
  },
  {
    "id": 9790,
    "content": "2"
  },
  {
    "id": 9792,
    "content": "Operands may be register variables, constant expressions, address expressions, or label names"
  },
  {
    "id": 9796,
    "content": "setp vabsdiff4 4"
  },
  {
    "id": 9797,
    "content": "4"
  },
  {
    "id": 9801,
    "content": "g"
  },
  {
    "id": 9802,
    "content": ", between user-defined variable names and compiler-generated names"
  },
  {
    "id": 9804,
    "content": "Table 3 Predefined Identifiers  %clock %laneid %lanemask_gt %pm0,"
  },
  {
    "id": 9806,
    "content": "5"
  },
  {
    "id": 9808,
    "content": "e"
  },
  {
    "id": 9809,
    "content": ", zero values are False and non-zero values are True"
  },
  {
    "id": 9810,
    "content": "4"
  },
  {
    "id": 9811,
    "content": "5"
  },
  {
    "id": 9812,
    "content": "1"
  },
  {
    "id": 9813,
    "content": "Integer Constants  Integer constants are 64-bits in size and are either signed or unsigned, i"
  },
  {
    "id": 9814,
    "content": "e"
  },
  {
    "id": 9815,
    "content": ", every integer constant has type"
  },
  {
    "id": 9816,
    "content": "s64 or"
  },
  {
    "id": 9817,
    "content": "u64"
  },
  {
    "id": 9821,
    "content": "u64 )"
  },
  {
    "id": 9823,
    "content": "4"
  },
  {
    "id": 9824,
    "content": "5"
  },
  {
    "id": 9825,
    "content": "2"
  },
  {
    "id": 9829,
    "content": "single-precision floating point 0[dD]{hexdigit}{16} double-precision floating point Example mov"
  },
  {
    "id": 9830,
    "content": "f32 $f3, 0F3f800000;   1"
  },
  {
    "id": 9831,
    "content": "0 4"
  },
  {
    "id": 9832,
    "content": "5"
  },
  {
    "id": 9833,
    "content": "3"
  },
  {
    "id": 9835,
    "content": "e"
  },
  {
    "id": 9836,
    "content": ", zero values are False and non-zero values are True"
  },
  {
    "id": 9837,
    "content": "4"
  },
  {
    "id": 9838,
    "content": "5"
  },
  {
    "id": 9839,
    "content": "4"
  },
  {
    "id": 9842,
    "content": ": ), and parentheses"
  },
  {
    "id": 9843,
    "content": "Integer constant expressions also allow unary logical negation ("
  },
  {
    "id": 9845,
    "content": "Precedence  Kind Operator Symbols Operator Names Associates Primary () parenthesis n/a Unary +-"
  },
  {
    "id": 9846,
    "content": "~ plus, minus, negation, complement right ("
  },
  {
    "id": 9847,
    "content": "s64) ("
  },
  {
    "id": 9849,
    "content": "= equal, not equal & bitwise AND ^ bitwise XOR | bitwise OR && logical AND || logical OR Ternary"
  },
  {
    "id": 9850,
    "content": ": conditional right 4"
  },
  {
    "id": 9851,
    "content": "5"
  },
  {
    "id": 9852,
    "content": "5"
  },
  {
    "id": 9854,
    "content": "s64 versus unsigned"
  },
  {
    "id": 9855,
    "content": "u64 ) of each sub-expression"
  },
  {
    "id": 9863,
    "content": "s64 ) and ("
  },
  {
    "id": 9864,
    "content": "u64 ) casts"
  },
  {
    "id": 9865,
    "content": "For the conditional operator ("
  },
  {
    "id": 9867,
    "content": "4"
  },
  {
    "id": 9868,
    "content": "5"
  },
  {
    "id": 9869,
    "content": "6"
  },
  {
    "id": 9871,
    "content": "u64 ,"
  },
  {
    "id": 9872,
    "content": "s64 , or"
  },
  {
    "id": 9873,
    "content": "f64 Unary +- any type same as source same as source"
  },
  {
    "id": 9874,
    "content": "integer zero or non-zero s64 ~ integer"
  },
  {
    "id": 9875,
    "content": "u64 u64 Cast ( u64) integer u64 u64 ( s64) integer s64 s64 Binary +- * /"
  },
  {
    "id": 9877,
    "content": "="
  },
  {
    "id": 9878,
    "content": "f64 f64"
  },
  {
    "id": 9879,
    "content": "s64 integer use usual conversions s64 % integer"
  },
  {
    "id": 9880,
    "content": "u64"
  },
  {
    "id": 9881,
    "content": "s64 >> =10 bits)"
  },
  {
    "id": 9882,
    "content": "They are supported as source or destination formats by certain instructions"
  },
  {
    "id": 9883,
    "content": "5"
  },
  {
    "id": 9884,
    "content": "2"
  },
  {
    "id": 9885,
    "content": "4"
  },
  {
    "id": 9887,
    "content": "5"
  },
  {
    "id": 9888,
    "content": "2"
  },
  {
    "id": 9889,
    "content": "4"
  },
  {
    "id": 9890,
    "content": "1"
  },
  {
    "id": 9892,
    "content": "bf16x2 ,"
  },
  {
    "id": 9893,
    "content": "e4m3x2 and"
  },
  {
    "id": 9895,
    "content": "A register variable containing"
  },
  {
    "id": 9896,
    "content": "e4m3x2 or"
  },
  {
    "id": 9897,
    "content": "e5m2x2 data must be declared with"
  },
  {
    "id": 9898,
    "content": "b16 type"
  },
  {
    "id": 9899,
    "content": "5"
  },
  {
    "id": 9900,
    "content": "2"
  },
  {
    "id": 9901,
    "content": "4"
  },
  {
    "id": 9902,
    "content": "2"
  },
  {
    "id": 9903,
    "content": "Packed Integer Data Types  PTX supports two variants of packed integer data types:"
  },
  {
    "id": 9904,
    "content": "u16x2 and"
  },
  {
    "id": 9905,
    "content": "s16x2"
  },
  {
    "id": 9906,
    "content": "They are supported as instruction types on certain instructions"
  },
  {
    "id": 9907,
    "content": "5"
  },
  {
    "id": 9908,
    "content": "3"
  },
  {
    "id": 9913,
    "content": "e"
  },
  {
    "id": 9915,
    "content": "Opaque variables may not appear in initializers, e"
  },
  {
    "id": 9916,
    "content": "g"
  },
  {
    "id": 9918,
    "content": "1 and requires target sm_20 or later"
  },
  {
    "id": 9919,
    "content": "In the unified mode, texture and sampler information is accessed through a single"
  },
  {
    "id": 9920,
    "content": "texref handle"
  },
  {
    "id": 9922,
    "content": "texref type that describe sampler properties are ignored, since these properties are defined by"
  },
  {
    "id": 9923,
    "content": "samplerref variables"
  },
  {
    "id": 9927,
    "content": "3"
  },
  {
    "id": 9928,
    "content": "1"
  },
  {
    "id": 9930,
    "content": "types currently supported in PTX"
  },
  {
    "id": 9931,
    "content": "5"
  },
  {
    "id": 9932,
    "content": "3"
  },
  {
    "id": 9933,
    "content": "2"
  },
  {
    "id": 9935,
    "content": "0, 1"
  },
  {
    "id": 9936,
    "content": "0) instead of unnormalized coordinates in the range [0, N)"
  },
  {
    "id": 9940,
    "content": "Variables using these types may be declared at module scope or within kernel entry parameter lists"
  },
  {
    "id": 9941,
    "content": "Example"
  },
  {
    "id": 9942,
    "content": "global"
  },
  {
    "id": 9943,
    "content": "texref my_texture_name;"
  },
  {
    "id": 9944,
    "content": "global"
  },
  {
    "id": 9945,
    "content": "samplerref my_sampler_name;"
  },
  {
    "id": 9946,
    "content": "global"
  },
  {
    "id": 9948,
    "content": "Example"
  },
  {
    "id": 9949,
    "content": "global"
  },
  {
    "id": 9950,
    "content": "texref tex1;"
  },
  {
    "id": 9951,
    "content": "global"
  },
  {
    "id": 9952,
    "content": "samplerref tsamp1 = { addr_mode_0 = clamp_to_border, filter_mode = nearest }; 5"
  },
  {
    "id": 9953,
    "content": "3"
  },
  {
    "id": 9954,
    "content": "3"
  },
  {
    "id": 9956,
    "content": "Table 12 and Table 11 show the enumeration values defined in OpenCL version 1"
  },
  {
    "id": 9957,
    "content": "0 for channel data type and channel order"
  },
  {
    "id": 9958,
    "content": "Table 11 OpenCL 1"
  },
  {
    "id": 9961,
    "content": "4"
  },
  {
    "id": 9962,
    "content": "Variables  In PTX, a variable declaration describes both the variable’s type and its state space"
  },
  {
    "id": 9964,
    "content": "5"
  },
  {
    "id": 9965,
    "content": "4"
  },
  {
    "id": 9966,
    "content": "1"
  },
  {
    "id": 9968,
    "content": "Examples"
  },
  {
    "id": 9969,
    "content": "global"
  },
  {
    "id": 9970,
    "content": "u32 loc;"
  },
  {
    "id": 9971,
    "content": "reg"
  },
  {
    "id": 9972,
    "content": "s32 i;"
  },
  {
    "id": 9973,
    "content": "const"
  },
  {
    "id": 9974,
    "content": "f32 bias[] = {-1"
  },
  {
    "id": 9975,
    "content": "0, 1"
  },
  {
    "id": 9976,
    "content": "0};"
  },
  {
    "id": 9977,
    "content": "global"
  },
  {
    "id": 9978,
    "content": "u8 bg[4] = {0, 0, 0, 0};"
  },
  {
    "id": 9979,
    "content": "reg"
  },
  {
    "id": 9980,
    "content": "v4"
  },
  {
    "id": 9981,
    "content": "f32 accel;"
  },
  {
    "id": 9982,
    "content": "reg"
  },
  {
    "id": 9983,
    "content": "pred p, q, r; 5"
  },
  {
    "id": 9984,
    "content": "4"
  },
  {
    "id": 9985,
    "content": "2"
  },
  {
    "id": 9987,
    "content": "v2 or"
  },
  {
    "id": 9988,
    "content": "v4"
  },
  {
    "id": 9989,
    "content": "Three-element vectors may be handled by using a"
  },
  {
    "id": 9990,
    "content": "v4 vector, where the fourth element provides padding"
  },
  {
    "id": 9991,
    "content": "Examples"
  },
  {
    "id": 9992,
    "content": "global"
  },
  {
    "id": 9993,
    "content": "v4"
  },
  {
    "id": 9994,
    "content": "f32 V;   a length-4 vector of floats"
  },
  {
    "id": 9995,
    "content": "shared"
  },
  {
    "id": 9996,
    "content": "v2"
  },
  {
    "id": 9997,
    "content": "u16 uv;   a length-2 vector of unsigned ints"
  },
  {
    "id": 9998,
    "content": "global"
  },
  {
    "id": 9999,
    "content": "v4"
  },
  {
    "id": 10001,
    "content": "5"
  },
  {
    "id": 10002,
    "content": "4"
  },
  {
    "id": 10003,
    "content": "3"
  },
  {
    "id": 10005,
    "content": "Examples"
  },
  {
    "id": 10006,
    "content": "local"
  },
  {
    "id": 10007,
    "content": "u16 kernel[19][19];"
  },
  {
    "id": 10008,
    "content": "shared"
  },
  {
    "id": 10010,
    "content": "Examples"
  },
  {
    "id": 10011,
    "content": "global"
  },
  {
    "id": 10012,
    "content": "u32 index[] = { 0, 1, 2, 3, 4, 5, 6, 7 };"
  },
  {
    "id": 10013,
    "content": "global"
  },
  {
    "id": 10015,
    "content": "5"
  },
  {
    "id": 10016,
    "content": "4"
  },
  {
    "id": 10017,
    "content": "4"
  },
  {
    "id": 10020,
    "content": "As in C, array initializers may be incomplete, i"
  },
  {
    "id": 10021,
    "content": "e"
  },
  {
    "id": 10023,
    "content": "Examples"
  },
  {
    "id": 10024,
    "content": "const"
  },
  {
    "id": 10025,
    "content": "f32 vals[8] = { 0"
  },
  {
    "id": 10026,
    "content": "33, 0"
  },
  {
    "id": 10027,
    "content": "25, 0"
  },
  {
    "id": 10028,
    "content": "125 };"
  },
  {
    "id": 10029,
    "content": "global"
  },
  {
    "id": 10030,
    "content": "s32 x[3][2] = { {1,2}, {3} }; is equivalent to"
  },
  {
    "id": 10031,
    "content": "const"
  },
  {
    "id": 10032,
    "content": "f32 vals[8] = { 0"
  },
  {
    "id": 10033,
    "content": "33, 0"
  },
  {
    "id": 10034,
    "content": "25, 0"
  },
  {
    "id": 10035,
    "content": "125, 0"
  },
  {
    "id": 10036,
    "content": "0, 0"
  },
  {
    "id": 10037,
    "content": "0, 0"
  },
  {
    "id": 10038,
    "content": "0, 0"
  },
  {
    "id": 10039,
    "content": "0, 0"
  },
  {
    "id": 10040,
    "content": "0 };"
  },
  {
    "id": 10043,
    "content": "Starting PTX ISA version 7"
  },
  {
    "id": 10045,
    "content": "starting position of the bits to be extracted is specified by the integer immediate mask"
  },
  {
    "id": 10046,
    "content": "PTX ISA version 7"
  },
  {
    "id": 10047,
    "content": "1 only supports extracting a single byte starting at byte boundary from the address of the variable"
  },
  {
    "id": 10048,
    "content": "PTX ISA version 7"
  },
  {
    "id": 10049,
    "content": "3 supports Integer constant expression as an operand in the mask() operator"
  },
  {
    "id": 10054,
    "content": "Variables that hold addresses of variables or functions should be of type"
  },
  {
    "id": 10055,
    "content": "u8 or u32 or"
  },
  {
    "id": 10056,
    "content": "u64"
  },
  {
    "id": 10057,
    "content": "Examples"
  },
  {
    "id": 10058,
    "content": "global"
  },
  {
    "id": 10059,
    "content": "s32 n = 10;"
  },
  {
    "id": 10060,
    "content": "global"
  },
  {
    "id": 10061,
    "content": "f32 blur_kernel[][3] = {{"
  },
  {
    "id": 10062,
    "content": "05,"
  },
  {
    "id": 10063,
    "content": "1,"
  },
  {
    "id": 10064,
    "content": "05},{"
  },
  {
    "id": 10065,
    "content": "1,"
  },
  {
    "id": 10066,
    "content": "4,"
  },
  {
    "id": 10067,
    "content": "1},{"
  },
  {
    "id": 10068,
    "content": "05,"
  },
  {
    "id": 10069,
    "content": "1,"
  },
  {
    "id": 10070,
    "content": "05}};"
  },
  {
    "id": 10071,
    "content": "global"
  },
  {
    "id": 10072,
    "content": "u32 foo[] = { 2, 3, 5, 7, 9, 11 };"
  },
  {
    "id": 10073,
    "content": "global"
  },
  {
    "id": 10074,
    "content": "u64 ptr = generic(foo);   generic address of foo[0]"
  },
  {
    "id": 10075,
    "content": "global"
  },
  {
    "id": 10076,
    "content": "u64 ptr = generic(foo)+8;   generic address of foo[2] 5"
  },
  {
    "id": 10077,
    "content": "4"
  },
  {
    "id": 10078,
    "content": "5"
  },
  {
    "id": 10080,
    "content": "align byte-count specifier immediately following the state-space specifier"
  },
  {
    "id": 10082,
    "content": "const"
  },
  {
    "id": 10083,
    "content": "align 4"
  },
  {
    "id": 10085,
    "content": "v4"
  },
  {
    "id": 10086,
    "content": "b32 is 16 bytes, while the access size of atom f16x2 is 4 bytes"
  },
  {
    "id": 10087,
    "content": "5"
  },
  {
    "id": 10088,
    "content": "4"
  },
  {
    "id": 10089,
    "content": "6"
  },
  {
    "id": 10092,
    "content": "For example, suppose a program uses a large number, say one hundred, of"
  },
  {
    "id": 10093,
    "content": "b32 variables, named %r0 , %r1 , …, %r99"
  },
  {
    "id": 10094,
    "content": "These 100 register variables can be declared as follows:"
  },
  {
    "id": 10095,
    "content": "reg"
  },
  {
    "id": 10096,
    "content": "b32 %r;   declare %r0, %r1,"
  },
  {
    "id": 10098,
    "content": "Array variables cannot be declared this way, nor are initializers permitted"
  },
  {
    "id": 10099,
    "content": "5"
  },
  {
    "id": 10100,
    "content": "4"
  },
  {
    "id": 10101,
    "content": "7"
  },
  {
    "id": 10103,
    "content": "5"
  },
  {
    "id": 10104,
    "content": "4"
  },
  {
    "id": 10105,
    "content": "8"
  },
  {
    "id": 10109,
    "content": "This attribute can only be used on device functions or on variables in the"
  },
  {
    "id": 10110,
    "content": "global state space"
  },
  {
    "id": 10111,
    "content": "Variables with"
  },
  {
    "id": 10112,
    "content": "unified attribute are read-only and must be loaded by specifying"
  },
  {
    "id": 10113,
    "content": "unified qualifier on the address operand of ld instruction, otherwise the behavior is undefined"
  },
  {
    "id": 10114,
    "content": "Examples"
  },
  {
    "id": 10115,
    "content": "global"
  },
  {
    "id": 10116,
    "content": "attribute("
  },
  {
    "id": 10117,
    "content": "managed)"
  },
  {
    "id": 10118,
    "content": "s32 g;"
  },
  {
    "id": 10119,
    "content": "global"
  },
  {
    "id": 10120,
    "content": "attribute("
  },
  {
    "id": 10121,
    "content": "managed)"
  },
  {
    "id": 10122,
    "content": "u64 x;"
  },
  {
    "id": 10123,
    "content": "global"
  },
  {
    "id": 10124,
    "content": "attribute("
  },
  {
    "id": 10125,
    "content": "unified(19,95))"
  },
  {
    "id": 10126,
    "content": "f32 f;"
  },
  {
    "id": 10127,
    "content": "func"
  },
  {
    "id": 10128,
    "content": "attribute("
  },
  {
    "id": 10129,
    "content": "unified(0xAB, 0xCD)) bar() {"
  },
  {
    "id": 10130,
    "content": "} 5"
  },
  {
    "id": 10131,
    "content": "5"
  },
  {
    "id": 10133,
    "content": "destination tensor data with the source The Tensor data can be operated on by various wmma"
  },
  {
    "id": 10134,
    "content": "mma , mma and wgmma"
  },
  {
    "id": 10135,
    "content": "mma_async instructions"
  },
  {
    "id": 10137,
    "content": "5"
  },
  {
    "id": 10138,
    "content": "5"
  },
  {
    "id": 10139,
    "content": "1"
  },
  {
    "id": 10140,
    "content": "Tensor Dimension, size and format  Tensors can have dimensions: 1D, 2D, 3D, 4D or 5D"
  },
  {
    "id": 10141,
    "content": "The elements can have one the following types: Bit-sized type:"
  },
  {
    "id": 10142,
    "content": "b32 ,"
  },
  {
    "id": 10143,
    "content": "b64 Integer:"
  },
  {
    "id": 10144,
    "content": "u8 ,"
  },
  {
    "id": 10145,
    "content": "u16 ,"
  },
  {
    "id": 10146,
    "content": "u32 ,"
  },
  {
    "id": 10147,
    "content": "s32 ,"
  },
  {
    "id": 10148,
    "content": "u64 ,"
  },
  {
    "id": 10149,
    "content": "s64 Floating point and alternate floating point:"
  },
  {
    "id": 10150,
    "content": "f16 ,"
  },
  {
    "id": 10151,
    "content": "bf16 ,"
  },
  {
    "id": 10152,
    "content": "tf32 ,"
  },
  {
    "id": 10153,
    "content": "f32 ,"
  },
  {
    "id": 10154,
    "content": "f64 (rounded to nearest even)"
  },
  {
    "id": 10156,
    "content": "5"
  },
  {
    "id": 10157,
    "content": "5"
  },
  {
    "id": 10158,
    "content": "2"
  },
  {
    "id": 10160,
    "content": "Refer here for more details"
  },
  {
    "id": 10161,
    "content": "5"
  },
  {
    "id": 10162,
    "content": "5"
  },
  {
    "id": 10163,
    "content": "3"
  },
  {
    "id": 10165,
    "content": "box information together are used to determine the elements which are to be accessed"
  },
  {
    "id": 10166,
    "content": "5"
  },
  {
    "id": 10167,
    "content": "5"
  },
  {
    "id": 10168,
    "content": "3"
  },
  {
    "id": 10169,
    "content": "2"
  },
  {
    "id": 10173,
    "content": "5"
  },
  {
    "id": 10174,
    "content": "4"
  },
  {
    "id": 10175,
    "content": "1"
  },
  {
    "id": 10183,
    "content": "5"
  },
  {
    "id": 10184,
    "content": "4"
  },
  {
    "id": 10185,
    "content": "2"
  },
  {
    "id": 10188,
    "content": "traversal stride example  5"
  },
  {
    "id": 10189,
    "content": "5"
  },
  {
    "id": 10190,
    "content": "4"
  },
  {
    "id": 10191,
    "content": "3"
  },
  {
    "id": 10193,
    "content": "Similar to tiled mode, zero fill or OOB-NaN fill can be performed based on the Fill-Mode specified"
  },
  {
    "id": 10194,
    "content": "5"
  },
  {
    "id": 10195,
    "content": "5"
  },
  {
    "id": 10196,
    "content": "5"
  },
  {
    "id": 10198,
    "content": "quantities"
  },
  {
    "id": 10200,
    "content": "Interleaved layouts are supported only for the dimensionalities : 3D, 4D and 5D"
  },
  {
    "id": 10201,
    "content": "5"
  },
  {
    "id": 10202,
    "content": "5"
  },
  {
    "id": 10203,
    "content": "6"
  },
  {
    "id": 10210,
    "content": "const space or param (kernel function parameter) space or"
  },
  {
    "id": 10213,
    "content": "6"
  },
  {
    "id": 10214,
    "content": "2"
  },
  {
    "id": 10216,
    "content": "reg register state space"
  },
  {
    "id": 10219,
    "content": "6"
  },
  {
    "id": 10220,
    "content": "3"
  },
  {
    "id": 10222,
    "content": "6"
  },
  {
    "id": 10223,
    "content": "4"
  },
  {
    "id": 10225,
    "content": "6"
  },
  {
    "id": 10226,
    "content": "4"
  },
  {
    "id": 10227,
    "content": "1"
  },
  {
    "id": 10233,
    "content": "Load and store operations move data between registers and locations in addressable state spaces"
  },
  {
    "id": 10236,
    "content": "Here are a few examples:"
  },
  {
    "id": 10237,
    "content": "shared"
  },
  {
    "id": 10238,
    "content": "u16 x;"
  },
  {
    "id": 10239,
    "content": "reg"
  },
  {
    "id": 10240,
    "content": "u16 r0;"
  },
  {
    "id": 10241,
    "content": "global"
  },
  {
    "id": 10242,
    "content": "v4"
  },
  {
    "id": 10243,
    "content": "f32 V;"
  },
  {
    "id": 10244,
    "content": "reg"
  },
  {
    "id": 10245,
    "content": "v4"
  },
  {
    "id": 10246,
    "content": "f32 W;"
  },
  {
    "id": 10247,
    "content": "const"
  },
  {
    "id": 10248,
    "content": "s32 tbl[256];"
  },
  {
    "id": 10249,
    "content": "reg"
  },
  {
    "id": 10250,
    "content": "b32 p;"
  },
  {
    "id": 10251,
    "content": "reg"
  },
  {
    "id": 10252,
    "content": "s32 q; ld"
  },
  {
    "id": 10253,
    "content": "shared"
  },
  {
    "id": 10254,
    "content": "u16 r0,[x]; ld"
  },
  {
    "id": 10255,
    "content": "global"
  },
  {
    "id": 10256,
    "content": "v4"
  },
  {
    "id": 10257,
    "content": "f32 W, [V]; ld"
  },
  {
    "id": 10258,
    "content": "const"
  },
  {
    "id": 10259,
    "content": "s32 q, [tbl+12]; mov u32 p, tbl; 6"
  },
  {
    "id": 10260,
    "content": "4"
  },
  {
    "id": 10261,
    "content": "1"
  },
  {
    "id": 10262,
    "content": "1"
  },
  {
    "id": 10264,
    "content": "const , Kernel Function Parameters ("
  },
  {
    "id": 10265,
    "content": "param ),"
  },
  {
    "id": 10266,
    "content": "local and"
  },
  {
    "id": 10267,
    "content": "shared are modeled as windows within the generic address space"
  },
  {
    "id": 10269,
    "content": "6"
  },
  {
    "id": 10270,
    "content": "4"
  },
  {
    "id": 10271,
    "content": "2"
  },
  {
    "id": 10274,
    "content": "If more complicated indexing is desired, it must be written as an address calculation prior to use"
  },
  {
    "id": 10275,
    "content": "Examples are: ld"
  },
  {
    "id": 10276,
    "content": "global"
  },
  {
    "id": 10277,
    "content": "u32 s, a[0]; ld"
  },
  {
    "id": 10278,
    "content": "global"
  },
  {
    "id": 10279,
    "content": "u32 s, a[N-1]; mov u32 s, a[1];   move address of a[1] into s 6"
  },
  {
    "id": 10280,
    "content": "4"
  },
  {
    "id": 10281,
    "content": "3"
  },
  {
    "id": 10283,
    "content": "Vector elements can be extracted from the vector with the suffixes"
  },
  {
    "id": 10284,
    "content": "x ,"
  },
  {
    "id": 10285,
    "content": "y ,"
  },
  {
    "id": 10286,
    "content": "z and"
  },
  {
    "id": 10287,
    "content": "w , as well as the typical color fields"
  },
  {
    "id": 10288,
    "content": "r ,"
  },
  {
    "id": 10289,
    "content": "g ,"
  },
  {
    "id": 10290,
    "content": "b and"
  },
  {
    "id": 10291,
    "content": "a"
  },
  {
    "id": 10292,
    "content": "reg"
  },
  {
    "id": 10293,
    "content": "v4"
  },
  {
    "id": 10294,
    "content": "f32 V;"
  },
  {
    "id": 10295,
    "content": "reg"
  },
  {
    "id": 10296,
    "content": "f32 a, b, c, d; mov"
  },
  {
    "id": 10297,
    "content": "v4"
  },
  {
    "id": 10300,
    "content": "Here are examples: ld"
  },
  {
    "id": 10301,
    "content": "global"
  },
  {
    "id": 10302,
    "content": "v4"
  },
  {
    "id": 10303,
    "content": "f32 {a,b,c,d}, [addr+16]; ld"
  },
  {
    "id": 10304,
    "content": "global"
  },
  {
    "id": 10306,
    "content": "x = V"
  },
  {
    "id": 10307,
    "content": "r Rb = V"
  },
  {
    "id": 10308,
    "content": "y = V"
  },
  {
    "id": 10309,
    "content": "g Rc = V"
  },
  {
    "id": 10310,
    "content": "z = V"
  },
  {
    "id": 10311,
    "content": "b Rd = V"
  },
  {
    "id": 10312,
    "content": "w = V"
  },
  {
    "id": 10313,
    "content": "a 6"
  },
  {
    "id": 10314,
    "content": "4"
  },
  {
    "id": 10315,
    "content": "4"
  },
  {
    "id": 10316,
    "content": "Labels and Function Names as Operands  Labels and function names can be used only in bra / brx"
  },
  {
    "id": 10317,
    "content": "idx and call instructions respectively"
  },
  {
    "id": 10319,
    "content": "Beginning in PTX ISA version 3"
  },
  {
    "id": 10321,
    "content": "This feature is part of the support for CUDA Dynamic Parallelism"
  },
  {
    "id": 10322,
    "content": "6"
  },
  {
    "id": 10323,
    "content": "5"
  },
  {
    "id": 10325,
    "content": "6"
  },
  {
    "id": 10326,
    "content": "5"
  },
  {
    "id": 10327,
    "content": "1"
  },
  {
    "id": 10332,
    "content": "For example, cvt"
  },
  {
    "id": 10333,
    "content": "s16"
  },
  {
    "id": 10334,
    "content": "u32 targeting a 32-bit register first chops to 16-bit, then sign-extends to 32-bit"
  },
  {
    "id": 10335,
    "content": "6"
  },
  {
    "id": 10336,
    "content": "5"
  },
  {
    "id": 10337,
    "content": "2"
  },
  {
    "id": 10341,
    "content": "6"
  },
  {
    "id": 10347,
    "content": "7"
  },
  {
    "id": 10348,
    "content": "1"
  },
  {
    "id": 10349,
    "content": "Function Declarations and Definitions  In PTX, functions are declared and defined using the"
  },
  {
    "id": 10350,
    "content": "func directive"
  },
  {
    "id": 10354,
    "content": "Example"
  },
  {
    "id": 10355,
    "content": "func ("
  },
  {
    "id": 10356,
    "content": "reg"
  },
  {
    "id": 10357,
    "content": "u32 %res) inc_ptr ("
  },
  {
    "id": 10358,
    "content": "reg"
  },
  {
    "id": 10359,
    "content": "u32 %ptr,"
  },
  {
    "id": 10360,
    "content": "reg"
  },
  {
    "id": 10361,
    "content": "u32 %inc ) { add u32 %res, %ptr, %inc; ret; }"
  },
  {
    "id": 10362,
    "content": "Subword scalar objects in the source language should be promoted to 32-bit registers in PTX, or use"
  },
  {
    "id": 10365,
    "content": "f64 field are aligned"
  },
  {
    "id": 10366,
    "content": "The"
  },
  {
    "id": 10367,
    "content": "param state space is used to pass the structure by value: Example"
  },
  {
    "id": 10368,
    "content": "func ("
  },
  {
    "id": 10369,
    "content": "reg"
  },
  {
    "id": 10370,
    "content": "s32 out) bar ("
  },
  {
    "id": 10371,
    "content": "reg"
  },
  {
    "id": 10372,
    "content": "s32 x,"
  },
  {
    "id": 10373,
    "content": "param"
  },
  {
    "id": 10374,
    "content": "align 8"
  },
  {
    "id": 10375,
    "content": "b8 y[12]) {"
  },
  {
    "id": 10376,
    "content": "reg"
  },
  {
    "id": 10377,
    "content": "f64 f1;"
  },
  {
    "id": 10378,
    "content": "reg"
  },
  {
    "id": 10379,
    "content": "b32 c1, c2, c3, c4;"
  },
  {
    "id": 10380,
    "content": "ld"
  },
  {
    "id": 10381,
    "content": "param"
  },
  {
    "id": 10382,
    "content": "f64 f1, [y+0]; ld"
  },
  {
    "id": 10383,
    "content": "param"
  },
  {
    "id": 10384,
    "content": "b8 c1, [y+8]; ld"
  },
  {
    "id": 10385,
    "content": "param"
  },
  {
    "id": 10386,
    "content": "b8 c2, [y+9]; ld"
  },
  {
    "id": 10387,
    "content": "param"
  },
  {
    "id": 10388,
    "content": "b8 c3, [y+10]; ld"
  },
  {
    "id": 10389,
    "content": "param"
  },
  {
    "id": 10390,
    "content": "b8 c4, [y+11]; computation using x,f1,c1,c2,c3,c4; } {"
  },
  {
    "id": 10391,
    "content": "param"
  },
  {
    "id": 10392,
    "content": "b8"
  },
  {
    "id": 10393,
    "content": "align 8 py[12];"
  },
  {
    "id": 10394,
    "content": "st"
  },
  {
    "id": 10395,
    "content": "param"
  },
  {
    "id": 10396,
    "content": "b64 [py+ 0], %rd; st"
  },
  {
    "id": 10397,
    "content": "param"
  },
  {
    "id": 10398,
    "content": "b8 [py+ 8], %rc1; st"
  },
  {
    "id": 10399,
    "content": "param"
  },
  {
    "id": 10400,
    "content": "b8 [py+ 9], %rc2; st"
  },
  {
    "id": 10401,
    "content": "param"
  },
  {
    "id": 10402,
    "content": "b8 [py+10], %rc1; st"
  },
  {
    "id": 10403,
    "content": "param"
  },
  {
    "id": 10404,
    "content": "b8 [py+11], %rc2;   scalar args in"
  },
  {
    "id": 10405,
    "content": "reg space, byte array in"
  },
  {
    "id": 10406,
    "content": "param space call (%out), bar, (%x, py);"
  },
  {
    "id": 10407,
    "content": "First, a"
  },
  {
    "id": 10408,
    "content": "param variable y is used in function definition bar to represent a formal parameter"
  },
  {
    "id": 10409,
    "content": "Second, a"
  },
  {
    "id": 10411,
    "content": "The following is a conceptual way to think about the"
  },
  {
    "id": 10412,
    "content": "param state space use in device functions"
  },
  {
    "id": 10413,
    "content": "For a caller, The"
  },
  {
    "id": 10415,
    "content": "Typically, a"
  },
  {
    "id": 10416,
    "content": "param byte array is used to collect together fields of a structure being passed by value"
  },
  {
    "id": 10417,
    "content": "For a callee, The"
  },
  {
    "id": 10418,
    "content": "param state space is used to receive parameter values and/or pass return values back to the caller"
  },
  {
    "id": 10419,
    "content": "In the case of"
  },
  {
    "id": 10421,
    "content": "In the case of"
  },
  {
    "id": 10423,
    "content": "In the case of"
  },
  {
    "id": 10424,
    "content": "reg space formal parameters, the corresponding argument may be either a"
  },
  {
    "id": 10425,
    "content": "param or"
  },
  {
    "id": 10427,
    "content": "All st"
  },
  {
    "id": 10429,
    "content": "This enables compiler optimization and ensures that the"
  },
  {
    "id": 10431,
    "content": "g"
  },
  {
    "id": 10433,
    "content": "The"
  },
  {
    "id": 10435,
    "content": "Note that the choice of"
  },
  {
    "id": 10436,
    "content": "reg or"
  },
  {
    "id": 10438,
    "content": "7"
  },
  {
    "id": 10439,
    "content": "1"
  },
  {
    "id": 10440,
    "content": "1"
  },
  {
    "id": 10441,
    "content": "Changes from PTX ISA Version 1 x  In PTX ISA version 1"
  },
  {
    "id": 10442,
    "content": "x, formal parameters were restricted to"
  },
  {
    "id": 10443,
    "content": "reg state space, and there was no support for array parameters"
  },
  {
    "id": 10444,
    "content": "Objects such as C structures were flattened and passed or returned using multiple registers"
  },
  {
    "id": 10445,
    "content": "Beginning with PTX ISA version 2"
  },
  {
    "id": 10446,
    "content": "0, formal parameters may be in either"
  },
  {
    "id": 10447,
    "content": "reg or"
  },
  {
    "id": 10448,
    "content": "param state space, and param space parameters support arrays"
  },
  {
    "id": 10449,
    "content": "For targets sm_20 or higher, PTX restricts functions to a single return value, and a"
  },
  {
    "id": 10450,
    "content": "param byte array should be used to return objects that do not fit into a register"
  },
  {
    "id": 10451,
    "content": "PTX ISA versions prior to 3"
  },
  {
    "id": 10452,
    "content": "0 permitted variables in"
  },
  {
    "id": 10453,
    "content": "reg and"
  },
  {
    "id": 10454,
    "content": "local state spaces to be defined at module scope"
  },
  {
    "id": 10455,
    "content": "When compiling to use the ABI, PTX ISA version 3"
  },
  {
    "id": 10456,
    "content": "0 and later disallows module-scoped"
  },
  {
    "id": 10457,
    "content": "reg and"
  },
  {
    "id": 10458,
    "content": "local variables and restricts their use to within function scope"
  },
  {
    "id": 10459,
    "content": "When compiling without use of the ABI, module-scoped"
  },
  {
    "id": 10460,
    "content": "reg and"
  },
  {
    "id": 10461,
    "content": "local variables are supported as before"
  },
  {
    "id": 10462,
    "content": "When compiling legacy PTX code (ISA versions prior to 3"
  },
  {
    "id": 10463,
    "content": "0) containing module-scoped"
  },
  {
    "id": 10464,
    "content": "reg or"
  },
  {
    "id": 10465,
    "content": "local variables, the compiler silently disables use of the ABI"
  },
  {
    "id": 10466,
    "content": "7"
  },
  {
    "id": 10467,
    "content": "2"
  },
  {
    "id": 10469,
    "content": "PTX version 6"
  },
  {
    "id": 10474,
    "content": "3"
  },
  {
    "id": 10476,
    "content": "8"
  },
  {
    "id": 10478,
    "content": "forbidden between the orders observed by different threads"
  },
  {
    "id": 10480,
    "content": "8"
  },
  {
    "id": 10481,
    "content": "1"
  },
  {
    "id": 10483,
    "content": "global"
  },
  {
    "id": 10484,
    "content": "nc ) and surface accesses"
  },
  {
    "id": 10485,
    "content": "8"
  },
  {
    "id": 10486,
    "content": "1"
  },
  {
    "id": 10487,
    "content": "1"
  },
  {
    "id": 10489,
    "content": "8"
  },
  {
    "id": 10490,
    "content": "2"
  },
  {
    "id": 10494,
    "content": "memory location"
  },
  {
    "id": 10495,
    "content": "8"
  },
  {
    "id": 10496,
    "content": "2"
  },
  {
    "id": 10497,
    "content": "1"
  },
  {
    "id": 10499,
    "content": "otherwise"
  },
  {
    "id": 10500,
    "content": "8"
  },
  {
    "id": 10501,
    "content": "2"
  },
  {
    "id": 10502,
    "content": "2"
  },
  {
    "id": 10504,
    "content": "8"
  },
  {
    "id": 10505,
    "content": "2"
  },
  {
    "id": 10506,
    "content": "3"
  },
  {
    "id": 10508,
    "content": "8"
  },
  {
    "id": 10509,
    "content": "2"
  },
  {
    "id": 10510,
    "content": "4"
  },
  {
    "id": 10512,
    "content": "8"
  },
  {
    "id": 10513,
    "content": "2"
  },
  {
    "id": 10514,
    "content": "5"
  },
  {
    "id": 10516,
    "content": "8"
  },
  {
    "id": 10517,
    "content": "2"
  },
  {
    "id": 10518,
    "content": "6"
  },
  {
    "id": 10520,
    "content": "8"
  },
  {
    "id": 10521,
    "content": "3"
  },
  {
    "id": 10524,
    "content": "relaxed"
  },
  {
    "id": 10525,
    "content": "shared"
  },
  {
    "id": 10526,
    "content": "sys is identical to that of ld"
  },
  {
    "id": 10527,
    "content": "relaxed"
  },
  {
    "id": 10528,
    "content": "shared"
  },
  {
    "id": 10530,
    "content": "8"
  },
  {
    "id": 10531,
    "content": "4"
  },
  {
    "id": 10534,
    "content": "relaxed ,"
  },
  {
    "id": 10535,
    "content": "acquire ,"
  },
  {
    "id": 10536,
    "content": "release ,"
  },
  {
    "id": 10537,
    "content": "acq_rel ,"
  },
  {
    "id": 10538,
    "content": "volatile , or"
  },
  {
    "id": 10539,
    "content": "mmio qualifier"
  },
  {
    "id": 10541,
    "content": "8"
  },
  {
    "id": 10542,
    "content": "4"
  },
  {
    "id": 10543,
    "content": "1"
  },
  {
    "id": 10544,
    "content": "mmio Operation  An mmio operation is a memory operation with mmio qualifier specified"
  },
  {
    "id": 10549,
    "content": "8"
  },
  {
    "id": 10550,
    "content": "5"
  },
  {
    "id": 10552,
    "content": "There are four scopes: Table 18 Scopes  Scope Description"
  },
  {
    "id": 10555,
    "content": "8"
  },
  {
    "id": 10556,
    "content": "6"
  },
  {
    "id": 10559,
    "content": "8"
  },
  {
    "id": 10560,
    "content": "7"
  },
  {
    "id": 10562,
    "content": "consistency model depend on relations between morally strong operations"
  },
  {
    "id": 10563,
    "content": "8"
  },
  {
    "id": 10564,
    "content": "7"
  },
  {
    "id": 10565,
    "content": "1"
  },
  {
    "id": 10567,
    "content": "8"
  },
  {
    "id": 10568,
    "content": "7"
  },
  {
    "id": 10569,
    "content": "2"
  },
  {
    "id": 10573,
    "content": "8"
  },
  {
    "id": 10574,
    "content": "8"
  },
  {
    "id": 10577,
    "content": "g"
  },
  {
    "id": 10578,
    "content": ": st"
  },
  {
    "id": 10579,
    "content": "release [M]; or atom"
  },
  {
    "id": 10580,
    "content": "acq_rel [M]; or mbarrier"
  },
  {
    "id": 10581,
    "content": "arrive"
  },
  {
    "id": 10582,
    "content": "release [M]; Or a release operation on M followed by a strong write on M in program order E"
  },
  {
    "id": 10583,
    "content": "g"
  },
  {
    "id": 10584,
    "content": ": st release [M] ; st"
  },
  {
    "id": 10585,
    "content": "relaxed [M]; Or a memory fence followed by a strong write on M in program order E"
  },
  {
    "id": 10586,
    "content": "g"
  },
  {
    "id": 10587,
    "content": ": fence; st"
  },
  {
    "id": 10589,
    "content": "An acquire pattern on a location M consists of one of the following: An acquire operation on M E"
  },
  {
    "id": 10590,
    "content": "g"
  },
  {
    "id": 10591,
    "content": ": ld"
  },
  {
    "id": 10592,
    "content": "acquire [M]; or atom"
  },
  {
    "id": 10593,
    "content": "acq_rel [M]; or mbarrier"
  },
  {
    "id": 10594,
    "content": "test_wait"
  },
  {
    "id": 10595,
    "content": "acquire [M]; Or a strong read on M followed by an acquire operation on M in program order E"
  },
  {
    "id": 10596,
    "content": "g"
  },
  {
    "id": 10597,
    "content": ": ld relaxed [M]; ld"
  },
  {
    "id": 10598,
    "content": "acquire [M]; Or a strong read on M followed by a memory fence in program order E"
  },
  {
    "id": 10599,
    "content": "g"
  },
  {
    "id": 10600,
    "content": ": ld"
  },
  {
    "id": 10602,
    "content": "8"
  },
  {
    "id": 10603,
    "content": "9"
  },
  {
    "id": 10605,
    "content": "order on the one hand, and causality order and program order on the other"
  },
  {
    "id": 10606,
    "content": "8"
  },
  {
    "id": 10607,
    "content": "9"
  },
  {
    "id": 10608,
    "content": "1"
  },
  {
    "id": 10610,
    "content": "8"
  },
  {
    "id": 10611,
    "content": "9"
  },
  {
    "id": 10612,
    "content": "1"
  },
  {
    "id": 10613,
    "content": "1"
  },
  {
    "id": 10614,
    "content": "Asynchronous Operations  Some PTX instructions (all variants of cp async , cp async bulk , cp"
  },
  {
    "id": 10615,
    "content": "reduce"
  },
  {
    "id": 10616,
    "content": "async"
  },
  {
    "id": 10617,
    "content": "bulk , wgmma"
  },
  {
    "id": 10619,
    "content": "Instead, they provide weaker ordering guarantees as documented in the instruction description"
  },
  {
    "id": 10620,
    "content": "For example, the loads and stores performed as part of a cp"
  },
  {
    "id": 10622,
    "content": "mbarrier"
  },
  {
    "id": 10623,
    "content": "arrive The asynchronous mbarrier arrive-on operation performed by a cp"
  },
  {
    "id": 10624,
    "content": "async"
  },
  {
    "id": 10625,
    "content": "mbarrier"
  },
  {
    "id": 10627,
    "content": "reduce"
  },
  {
    "id": 10628,
    "content": "async"
  },
  {
    "id": 10630,
    "content": "8"
  },
  {
    "id": 10631,
    "content": "9"
  },
  {
    "id": 10632,
    "content": "2"
  },
  {
    "id": 10634,
    "content": "8"
  },
  {
    "id": 10635,
    "content": "9"
  },
  {
    "id": 10636,
    "content": "3"
  },
  {
    "id": 10638,
    "content": "8"
  },
  {
    "id": 10639,
    "content": "9"
  },
  {
    "id": 10640,
    "content": "4"
  },
  {
    "id": 10643,
    "content": "A bar{"
  },
  {
    "id": 10644,
    "content": "cta}"
  },
  {
    "id": 10645,
    "content": "sync or bar{"
  },
  {
    "id": 10646,
    "content": "cta}"
  },
  {
    "id": 10647,
    "content": "red or bar{"
  },
  {
    "id": 10648,
    "content": "cta}"
  },
  {
    "id": 10649,
    "content": "arrive operation synchronizes with a bar{"
  },
  {
    "id": 10650,
    "content": "cta}"
  },
  {
    "id": 10651,
    "content": "sync or bar{"
  },
  {
    "id": 10652,
    "content": "cta}"
  },
  {
    "id": 10658,
    "content": "8"
  },
  {
    "id": 10659,
    "content": "9"
  },
  {
    "id": 10660,
    "content": "5"
  },
  {
    "id": 10665,
    "content": "transitivity of base causality order accounts for the “cumulativity” of synchronizing operations"
  },
  {
    "id": 10666,
    "content": "8"
  },
  {
    "id": 10667,
    "content": "9"
  },
  {
    "id": 10668,
    "content": "6"
  },
  {
    "id": 10671,
    "content": "8"
  },
  {
    "id": 10672,
    "content": "9"
  },
  {
    "id": 10673,
    "content": "7"
  },
  {
    "id": 10676,
    "content": "8"
  },
  {
    "id": 10677,
    "content": "10"
  },
  {
    "id": 10678,
    "content": "Axioms  8"
  },
  {
    "id": 10679,
    "content": "10"
  },
  {
    "id": 10680,
    "content": "1"
  },
  {
    "id": 10682,
    "content": "8"
  },
  {
    "id": 10683,
    "content": "10"
  },
  {
    "id": 10684,
    "content": "2"
  },
  {
    "id": 10686,
    "content": "8"
  },
  {
    "id": 10687,
    "content": "10"
  },
  {
    "id": 10688,
    "content": "3"
  },
  {
    "id": 10692,
    "content": "8"
  },
  {
    "id": 10693,
    "content": "10"
  },
  {
    "id": 10694,
    "content": "4"
  },
  {
    "id": 10701,
    "content": "8"
  },
  {
    "id": 10702,
    "content": "10"
  },
  {
    "id": 10703,
    "content": "5"
  },
  {
    "id": 10705,
    "content": "e"
  },
  {
    "id": 10709,
    "content": "execution"
  },
  {
    "id": 10710,
    "content": "8"
  },
  {
    "id": 10711,
    "content": "10"
  },
  {
    "id": 10712,
    "content": "6"
  },
  {
    "id": 10714,
    "content": "W’ that precedes W in coherence order"
  },
  {
    "id": 10716,
    "content": "A vast majority of useful programs can be reduced to sequenced applications of this pattern"
  },
  {
    "id": 10719,
    "content": "If R1 observes W2, then the release pattern “F1; W2” synchronizes with the acquire pattern “R1; F2”"
  },
  {
    "id": 10723,
    "content": "sc"
  },
  {
    "id": 10726,
    "content": "acq_rel instruction, then this outcome is not guaranteed"
  },
  {
    "id": 10728,
    "content": "e"
  },
  {
    "id": 10730,
    "content": "9"
  },
  {
    "id": 10731,
    "content": "Instruction Set  9"
  },
  {
    "id": 10732,
    "content": "1"
  },
  {
    "id": 10734,
    "content": "9"
  },
  {
    "id": 10735,
    "content": "2"
  },
  {
    "id": 10738,
    "content": "isNaN(a) && isNaN(b) eq a"
  },
  {
    "id": 10739,
    "content": "= b &&"
  },
  {
    "id": 10743,
    "content": "3"
  },
  {
    "id": 10744,
    "content": "2"
  },
  {
    "id": 10747,
    "content": "4"
  },
  {
    "id": 10749,
    "content": "reg"
  },
  {
    "id": 10751,
    "content": "For example:"
  },
  {
    "id": 10752,
    "content": "reg"
  },
  {
    "id": 10753,
    "content": "u16 a;"
  },
  {
    "id": 10754,
    "content": "reg"
  },
  {
    "id": 10755,
    "content": "f32 d; cvt f32"
  },
  {
    "id": 10758,
    "content": "e"
  },
  {
    "id": 10759,
    "content": ", they must match exactly"
  },
  {
    "id": 10760,
    "content": "Table 23 Type Checking Rules  Operand Type"
  },
  {
    "id": 10761,
    "content": "bX"
  },
  {
    "id": 10762,
    "content": "sX"
  },
  {
    "id": 10763,
    "content": "uX"
  },
  {
    "id": 10764,
    "content": "fX Instruction Type"
  },
  {
    "id": 10766,
    "content": "For example, the shift amount operand for left and right shift instructions always has type"
  },
  {
    "id": 10774,
    "content": "9"
  },
  {
    "id": 10775,
    "content": "5"
  },
  {
    "id": 10778,
    "content": "uni suffix"
  },
  {
    "id": 10780,
    "content": "9"
  },
  {
    "id": 10781,
    "content": "6"
  },
  {
    "id": 10783,
    "content": "The semantics are described using C, until C is not expressive enough"
  },
  {
    "id": 10784,
    "content": "9"
  },
  {
    "id": 10785,
    "content": "6"
  },
  {
    "id": 10786,
    "content": "1"
  },
  {
    "id": 10793,
    "content": "9"
  },
  {
    "id": 10794,
    "content": "7"
  },
  {
    "id": 10795,
    "content": "Instructions  All PTX instructions may be predicated"
  },
  {
    "id": 10796,
    "content": "In the following descriptions, the optional guard predicate is omitted from the syntax"
  },
  {
    "id": 10797,
    "content": "9"
  },
  {
    "id": 10798,
    "content": "7"
  },
  {
    "id": 10799,
    "content": "1"
  },
  {
    "id": 10801,
    "content": "7"
  },
  {
    "id": 10802,
    "content": "1"
  },
  {
    "id": 10803,
    "content": "1"
  },
  {
    "id": 10804,
    "content": "Syntax add type d, a, b; add{"
  },
  {
    "id": 10805,
    "content": "sat}"
  },
  {
    "id": 10806,
    "content": "s32 d, a, b;"
  },
  {
    "id": 10807,
    "content": "sat applies only to"
  },
  {
    "id": 10808,
    "content": "s32"
  },
  {
    "id": 10809,
    "content": "type = {"
  },
  {
    "id": 10810,
    "content": "u16,"
  },
  {
    "id": 10811,
    "content": "u32,"
  },
  {
    "id": 10812,
    "content": "u64,"
  },
  {
    "id": 10813,
    "content": "s16,"
  },
  {
    "id": 10814,
    "content": "s32,"
  },
  {
    "id": 10815,
    "content": "s64,"
  },
  {
    "id": 10816,
    "content": "u16x2,"
  },
  {
    "id": 10817,
    "content": "s16x2 }; Description Performs addition and writes the resulting value into a destination register"
  },
  {
    "id": 10818,
    "content": "For"
  },
  {
    "id": 10819,
    "content": "u16x2 ,"
  },
  {
    "id": 10821,
    "content": "u16x2 ,"
  },
  {
    "id": 10824,
    "content": "If"
  },
  {
    "id": 10825,
    "content": "hi or"
  },
  {
    "id": 10827,
    "content": "If"
  },
  {
    "id": 10829,
    "content": "Examples mul"
  },
  {
    "id": 10830,
    "content": "wide"
  },
  {
    "id": 10831,
    "content": "s16 fa,fxs,fys;   16*16 bits yields 32 bits mul"
  },
  {
    "id": 10832,
    "content": "lo"
  },
  {
    "id": 10833,
    "content": "s16 fa,fxs,fys;   16*16 bits, save only the low 16 bits mul"
  },
  {
    "id": 10834,
    "content": "wide"
  },
  {
    "id": 10835,
    "content": "s32 z,x,y;   32*32 bits, creates 64 bit result 9"
  },
  {
    "id": 10836,
    "content": "7"
  },
  {
    "id": 10837,
    "content": "1"
  },
  {
    "id": 10838,
    "content": "4"
  },
  {
    "id": 10840,
    "content": "mode"
  },
  {
    "id": 10841,
    "content": "type d, a, b, c; mad"
  },
  {
    "id": 10842,
    "content": "hi"
  },
  {
    "id": 10843,
    "content": "sat"
  },
  {
    "id": 10844,
    "content": "s32 d, a, b, c;"
  },
  {
    "id": 10845,
    "content": "mode = {"
  },
  {
    "id": 10846,
    "content": "hi,"
  },
  {
    "id": 10847,
    "content": "lo,"
  },
  {
    "id": 10848,
    "content": "wide };"
  },
  {
    "id": 10849,
    "content": "type = {"
  },
  {
    "id": 10850,
    "content": "u16,"
  },
  {
    "id": 10851,
    "content": "u32,"
  },
  {
    "id": 10852,
    "content": "u64,"
  },
  {
    "id": 10853,
    "content": "s16,"
  },
  {
    "id": 10854,
    "content": "s32,"
  },
  {
    "id": 10856,
    "content": "Semantics t = a * b; n = bitwidth of type; d = t + c;   for"
  },
  {
    "id": 10857,
    "content": "wide d = t + c;   for"
  },
  {
    "id": 10859,
    "content": "If"
  },
  {
    "id": 10860,
    "content": "hi or"
  },
  {
    "id": 10862,
    "content": "If"
  },
  {
    "id": 10864,
    "content": "Saturation modifier:"
  },
  {
    "id": 10865,
    "content": "sat limits result to MININT"
  },
  {
    "id": 10866,
    "content": "MAXINT (no overflow) for the size of the operation"
  },
  {
    "id": 10867,
    "content": "Syntax mul24"
  },
  {
    "id": 10868,
    "content": "mode"
  },
  {
    "id": 10869,
    "content": "type d, a, b;"
  },
  {
    "id": 10870,
    "content": "mode = {"
  },
  {
    "id": 10871,
    "content": "hi,"
  },
  {
    "id": 10872,
    "content": "lo };"
  },
  {
    "id": 10873,
    "content": "type = {"
  },
  {
    "id": 10874,
    "content": "u32,"
  },
  {
    "id": 10876,
    "content": "Semantics t = a * b; d = t;   for"
  },
  {
    "id": 10878,
    "content": "e"
  },
  {
    "id": 10879,
    "content": ", 48-bits"
  },
  {
    "id": 10880,
    "content": "Examples mul24"
  },
  {
    "id": 10881,
    "content": "lo"
  },
  {
    "id": 10882,
    "content": "s32 d,a,b;   low 32-bits of 24x24-bit signed multiply"
  },
  {
    "id": 10883,
    "content": "9"
  },
  {
    "id": 10884,
    "content": "7"
  },
  {
    "id": 10885,
    "content": "1"
  },
  {
    "id": 10886,
    "content": "6"
  },
  {
    "id": 10888,
    "content": "mode"
  },
  {
    "id": 10889,
    "content": "type d, a, b, c; mad24"
  },
  {
    "id": 10890,
    "content": "hi"
  },
  {
    "id": 10891,
    "content": "sat"
  },
  {
    "id": 10892,
    "content": "s32 d, a, b, c;"
  },
  {
    "id": 10893,
    "content": "mode = {"
  },
  {
    "id": 10894,
    "content": "hi,"
  },
  {
    "id": 10895,
    "content": "lo };"
  },
  {
    "id": 10896,
    "content": "type = {"
  },
  {
    "id": 10897,
    "content": "u32,"
  },
  {
    "id": 10899,
    "content": "Semantics t = a * b; d = t + c;   for"
  },
  {
    "id": 10901,
    "content": "e"
  },
  {
    "id": 10902,
    "content": ", 48-bits"
  },
  {
    "id": 10903,
    "content": "mad24"
  },
  {
    "id": 10904,
    "content": "hi performs a 24x24-bit multiply and adds the high 32 bits of the 48-bit result to a third value"
  },
  {
    "id": 10905,
    "content": "mad24"
  },
  {
    "id": 10906,
    "content": "lo performs a 24x24-bit multiply and adds the low 32 bits of the 48-bit result to a third value"
  },
  {
    "id": 10907,
    "content": "Saturation modifier:"
  },
  {
    "id": 10908,
    "content": "sat limits result of 32-bit signed addition to MININT"
  },
  {
    "id": 10909,
    "content": "MAXINT (no overflow)"
  },
  {
    "id": 10910,
    "content": "Examples mad24"
  },
  {
    "id": 10911,
    "content": "lo"
  },
  {
    "id": 10912,
    "content": "s32 d,a,b,c;   low 32-bits of 24x24-bit signed multiply"
  },
  {
    "id": 10913,
    "content": "9"
  },
  {
    "id": 10914,
    "content": "7"
  },
  {
    "id": 10915,
    "content": "1"
  },
  {
    "id": 10916,
    "content": "7"
  },
  {
    "id": 10917,
    "content": "Integer Arithmetic Instructions: sad  sad Sum of absolute differences Syntax sad"
  },
  {
    "id": 10918,
    "content": "type d, a, b, c; type = {"
  },
  {
    "id": 10919,
    "content": "u16,"
  },
  {
    "id": 10920,
    "content": "u32,"
  },
  {
    "id": 10921,
    "content": "u64,"
  },
  {
    "id": 10922,
    "content": "s16,"
  },
  {
    "id": 10923,
    "content": "s32,"
  },
  {
    "id": 10924,
    "content": "s64 }; Description Adds the absolute value of a-b to c and writes the resulting value into d"
  },
  {
    "id": 10925,
    "content": "Semantics d = c + ((a iB[i]) iA[i] : iB[i]; } } else { d = (a > b)"
  },
  {
    "id": 10926,
    "content": "a : b;   Integer (signed and unsigned) } Notes Signed and unsigned differ"
  },
  {
    "id": 10927,
    "content": "Syntax popc"
  },
  {
    "id": 10928,
    "content": "type d, a; type = {"
  },
  {
    "id": 10929,
    "content": "b32,"
  },
  {
    "id": 10931,
    "content": "Semantics"
  },
  {
    "id": 10932,
    "content": "u32 d = 0; while (a"
  },
  {
    "id": 10933,
    "content": "= 0) { if (a & 0x1) d++; a = a >> 1; } PTX ISA Notes Introduced in PTX ISA version 2"
  },
  {
    "id": 10934,
    "content": "0"
  },
  {
    "id": 10935,
    "content": "Syntax clz"
  },
  {
    "id": 10936,
    "content": "type d, a; type = {"
  },
  {
    "id": 10937,
    "content": "b32,"
  },
  {
    "id": 10939,
    "content": "Semantics"
  },
  {
    "id": 10940,
    "content": "u32 d = 0; if ("
  },
  {
    "id": 10941,
    "content": "type =="
  },
  {
    "id": 10943,
    "content": "1 : -1; while ((pos >= 0) && (pos = 32 &&"
  },
  {
    "id": 10944,
    "content": "mode =="
  },
  {
    "id": 10945,
    "content": "clamp)"
  },
  {
    "id": 10947,
    "content": "6"
  },
  {
    "id": 10948,
    "content": "Examples szext"
  },
  {
    "id": 10949,
    "content": "clamp"
  },
  {
    "id": 10950,
    "content": "s32 rd, ra, rb; szext"
  },
  {
    "id": 10951,
    "content": "wrap"
  },
  {
    "id": 10952,
    "content": "u32 rd, 0xffffffff, 0;   Result is 0"
  },
  {
    "id": 10953,
    "content": "9"
  },
  {
    "id": 10954,
    "content": "7"
  },
  {
    "id": 10955,
    "content": "1"
  },
  {
    "id": 10956,
    "content": "22"
  },
  {
    "id": 10957,
    "content": "Integer Arithmetic Instructions: bmsk  bmsk Bit Field Mask Syntax bmsk"
  },
  {
    "id": 10958,
    "content": "mode"
  },
  {
    "id": 10959,
    "content": "b32 d, a, b;"
  },
  {
    "id": 10960,
    "content": "mode = {"
  },
  {
    "id": 10961,
    "content": "clamp,"
  },
  {
    "id": 10963,
    "content": "The resulting bitmask is 0 in the following cases: When the value of a is 32 or higher and"
  },
  {
    "id": 10964,
    "content": "mode is"
  },
  {
    "id": 10965,
    "content": "clamp"
  },
  {
    "id": 10966,
    "content": "When either the specified value of b or the wrapped value of b (when mode is specified as"
  },
  {
    "id": 10967,
    "content": "wrap ) is 0"
  },
  {
    "id": 10968,
    "content": "Semantics a1 = a & 0x1f; mask0 = (~0) = 32"
  },
  {
    "id": 10969,
    "content": "true : false; bit-position-overflow = false; bit-width-overflow = false; if ("
  },
  {
    "id": 10970,
    "content": "mode =="
  },
  {
    "id": 10972,
    "content": "32 in"
  },
  {
    "id": 10973,
    "content": "clamp mode and to range 0"
  },
  {
    "id": 10974,
    "content": "31 in"
  },
  {
    "id": 10975,
    "content": "wrap mode"
  },
  {
    "id": 10976,
    "content": "Examples bmsk"
  },
  {
    "id": 10977,
    "content": "clamp"
  },
  {
    "id": 10978,
    "content": "b32 rd, ra, rb; bmsk"
  },
  {
    "id": 10979,
    "content": "wrap"
  },
  {
    "id": 10980,
    "content": "b32 rd, 1, 2;   Creates a bitmask of 0x00000006"
  },
  {
    "id": 10981,
    "content": "9"
  },
  {
    "id": 10982,
    "content": "7"
  },
  {
    "id": 10983,
    "content": "1"
  },
  {
    "id": 10984,
    "content": "23"
  },
  {
    "id": 10985,
    "content": "Integer Arithmetic Instructions: dp4a  dp4a Four-way byte dot product-accumulate Syntax dp4a"
  },
  {
    "id": 10986,
    "content": "atype"
  },
  {
    "id": 10987,
    "content": "btype d, a, b, c;"
  },
  {
    "id": 10988,
    "content": "atype ="
  },
  {
    "id": 10989,
    "content": "btype = {"
  },
  {
    "id": 10990,
    "content": "u32,"
  },
  {
    "id": 10992,
    "content": "Semantics d = c;   Extract 4 bytes from a 32bit input and sign or zero extend   based on input type"
  },
  {
    "id": 10993,
    "content": "Va = extractAndSignOrZeroExt_4(a, atype); Vb = extractAndSignOrZeroExt_4(b,"
  },
  {
    "id": 10996,
    "content": "hi,"
  },
  {
    "id": 10997,
    "content": "lo}{"
  },
  {
    "id": 10998,
    "content": "cc}"
  },
  {
    "id": 10999,
    "content": "type d, a, b, c; type = {"
  },
  {
    "id": 11000,
    "content": "u32,"
  },
  {
    "id": 11001,
    "content": "s32,"
  },
  {
    "id": 11002,
    "content": "u64,"
  },
  {
    "id": 11004,
    "content": "Semantics t = a * b; d = t + c + CC"
  },
  {
    "id": 11005,
    "content": "CF;   for"
  },
  {
    "id": 11006,
    "content": "hi variant d = t + c + CC"
  },
  {
    "id": 11007,
    "content": "CF;   for"
  },
  {
    "id": 11008,
    "content": "lo variant if"
  },
  {
    "id": 11009,
    "content": "cc specified, carry-out from addition is written to CC"
  },
  {
    "id": 11010,
    "content": "CF Notes Generally used in combination with mad"
  },
  {
    "id": 11011,
    "content": "cc and addc to implement extended-precision multi-word multiplication"
  },
  {
    "id": 11012,
    "content": "Examples   extended-precision multiply: [r3,r2,r1,r0] = [r5,r4] * [r7,r6] mul"
  },
  {
    "id": 11013,
    "content": "lo"
  },
  {
    "id": 11014,
    "content": "u32 r0,r4,r6;   r0=(r4*r6)"
  },
  {
    "id": 11015,
    "content": "[63:32]+carry-in,   may carry-out addc u32 r3,0,0;   r3 = carry-in, no carry-out mad"
  },
  {
    "id": 11016,
    "content": "lo"
  },
  {
    "id": 11017,
    "content": "cc"
  },
  {
    "id": 11018,
    "content": "u32 r2,r5,r7,r2;   r2+=(r5*r7)"
  },
  {
    "id": 11019,
    "content": "Floating-Point Instructions  Floating-point instructions operate on"
  },
  {
    "id": 11020,
    "content": "f32 and"
  },
  {
    "id": 11021,
    "content": "f64 register operands and constant immediate values"
  },
  {
    "id": 11024,
    "content": "The optional"
  },
  {
    "id": 11026,
    "content": "0, 1"
  },
  {
    "id": 11027,
    "content": "0], with NaN s being flushed to positive zero"
  },
  {
    "id": 11028,
    "content": "NaN payloads are supported for double-precision instructions (except for rcp"
  },
  {
    "id": 11029,
    "content": "approx"
  },
  {
    "id": 11030,
    "content": "ftz"
  },
  {
    "id": 11031,
    "content": "f64 and rsqrt"
  },
  {
    "id": 11032,
    "content": "approx"
  },
  {
    "id": 11033,
    "content": "ftz"
  },
  {
    "id": 11035,
    "content": "Table 26 Summary of Floating-Point Instructions  Instruction"
  },
  {
    "id": 11036,
    "content": "rn"
  },
  {
    "id": 11037,
    "content": "rz"
  },
  {
    "id": 11038,
    "content": "rm"
  },
  {
    "id": 11039,
    "content": "rp"
  },
  {
    "id": 11040,
    "content": "ftz"
  },
  {
    "id": 11041,
    "content": "sat Notes {add,sub,mul}"
  },
  {
    "id": 11042,
    "content": "rnd"
  },
  {
    "id": 11043,
    "content": "f32 x x x x x x If no rounding modifier is specified, default is"
  },
  {
    "id": 11044,
    "content": "rn and instructions may be folded into a multiply-add {add,sub,mul}"
  },
  {
    "id": 11045,
    "content": "rnd"
  },
  {
    "id": 11046,
    "content": "f64 x x x x n/a n/a If no rounding modifier is specified, default is"
  },
  {
    "id": 11047,
    "content": "rn and instructions may be folded into a multiply-add"
  },
  {
    "id": 11048,
    "content": "{div,rcp,sqrt}"
  },
  {
    "id": 11049,
    "content": "approx"
  },
  {
    "id": 11050,
    "content": "f32 n/a n/a n/a n/a x n/a n/a rcp"
  },
  {
    "id": 11051,
    "content": "approx"
  },
  {
    "id": 11052,
    "content": "ftz"
  },
  {
    "id": 11053,
    "content": "f64 n/a n/a n/a n/a x n/a"
  },
  {
    "id": 11054,
    "content": "target sm_20 or higher {div,rcp,sqrt}"
  },
  {
    "id": 11055,
    "content": "rnd"
  },
  {
    "id": 11056,
    "content": "f32 x x x x x n/a"
  },
  {
    "id": 11057,
    "content": "target sm_20 or higher {div,rcp,sqrt}"
  },
  {
    "id": 11058,
    "content": "rnd"
  },
  {
    "id": 11059,
    "content": "f64 x x x x n/a n/a"
  },
  {
    "id": 11060,
    "content": "target sm_20 or higher {abs,neg,min,max} f32 n/a n/a n/a n/a x n/a {abs,neg,min,max}"
  },
  {
    "id": 11061,
    "content": "f64 n/a n/a n/a n/a n/a n/a rsqrt"
  },
  {
    "id": 11062,
    "content": "approx"
  },
  {
    "id": 11063,
    "content": "f32 n/a n/a n/a n/a x n/a rsqrt"
  },
  {
    "id": 11064,
    "content": "approx"
  },
  {
    "id": 11065,
    "content": "f64 n/a n/a n/a n/a n/a n/a rsqrt"
  },
  {
    "id": 11066,
    "content": "approx"
  },
  {
    "id": 11067,
    "content": "ftz"
  },
  {
    "id": 11068,
    "content": "f64 n/a n/a n/a n/a x n/a"
  },
  {
    "id": 11069,
    "content": "target sm_20 or higher {sin,cos,lg2,ex2}"
  },
  {
    "id": 11070,
    "content": "approx"
  },
  {
    "id": 11071,
    "content": "f32 n/a n/a n/a n/a x n/a tanh"
  },
  {
    "id": 11072,
    "content": "approx"
  },
  {
    "id": 11073,
    "content": "f32 n/a n/a n/a n/a n/a n/a"
  },
  {
    "id": 11074,
    "content": "target sm_75 or higher 9"
  },
  {
    "id": 11075,
    "content": "7"
  },
  {
    "id": 11076,
    "content": "3"
  },
  {
    "id": 11077,
    "content": "1"
  },
  {
    "id": 11078,
    "content": "Syntax testp"
  },
  {
    "id": 11079,
    "content": "op"
  },
  {
    "id": 11080,
    "content": "type p, a;   result is"
  },
  {
    "id": 11081,
    "content": "pred"
  },
  {
    "id": 11082,
    "content": "op = {"
  },
  {
    "id": 11083,
    "content": "finite,"
  },
  {
    "id": 11084,
    "content": "infinite,"
  },
  {
    "id": 11085,
    "content": "number,"
  },
  {
    "id": 11086,
    "content": "notanumber,"
  },
  {
    "id": 11087,
    "content": "normal,"
  },
  {
    "id": 11088,
    "content": "subnormal };"
  },
  {
    "id": 11089,
    "content": "type = {"
  },
  {
    "id": 11090,
    "content": "f32,"
  },
  {
    "id": 11093,
    "content": "Syntax copysign"
  },
  {
    "id": 11094,
    "content": "type d, a, b; type = {"
  },
  {
    "id": 11095,
    "content": "f32,"
  },
  {
    "id": 11096,
    "content": "f64 }; Description Copy sign bit of a into value of b , and return the result as d"
  },
  {
    "id": 11097,
    "content": "Syntax add{"
  },
  {
    "id": 11098,
    "content": "rnd}{"
  },
  {
    "id": 11099,
    "content": "ftz}{"
  },
  {
    "id": 11100,
    "content": "sat}"
  },
  {
    "id": 11101,
    "content": "f32 d, a, b; add{"
  },
  {
    "id": 11102,
    "content": "rnd}"
  },
  {
    "id": 11103,
    "content": "f64 d, a, b;"
  },
  {
    "id": 11104,
    "content": "rnd = {"
  },
  {
    "id": 11105,
    "content": "rn,"
  },
  {
    "id": 11106,
    "content": "rz,"
  },
  {
    "id": 11107,
    "content": "rm,"
  },
  {
    "id": 11108,
    "content": "rp }; Description Performs addition and writes the resulting value into a destination register"
  },
  {
    "id": 11109,
    "content": "Semantics d = a + b; Notes Rounding modifiers:"
  },
  {
    "id": 11112,
    "content": "f64 , requires sm_13 or higher"
  },
  {
    "id": 11113,
    "content": "Syntax sub{"
  },
  {
    "id": 11114,
    "content": "rnd}{"
  },
  {
    "id": 11115,
    "content": "ftz}{"
  },
  {
    "id": 11116,
    "content": "sat}"
  },
  {
    "id": 11117,
    "content": "f32 d, a, b; sub{"
  },
  {
    "id": 11118,
    "content": "rnd}"
  },
  {
    "id": 11119,
    "content": "f64 d, a, b;"
  },
  {
    "id": 11120,
    "content": "rnd = {"
  },
  {
    "id": 11121,
    "content": "rn,"
  },
  {
    "id": 11122,
    "content": "rz,"
  },
  {
    "id": 11123,
    "content": "rm,"
  },
  {
    "id": 11124,
    "content": "rp }; Description Performs subtraction and writes the resulting value into a destination register"
  },
  {
    "id": 11125,
    "content": "Semantics d = a - b; Notes Rounding modifiers:"
  },
  {
    "id": 11128,
    "content": "f64 , requires sm_13 or higher"
  },
  {
    "id": 11129,
    "content": "Syntax mul{"
  },
  {
    "id": 11130,
    "content": "rnd}{"
  },
  {
    "id": 11131,
    "content": "ftz}{"
  },
  {
    "id": 11132,
    "content": "sat}"
  },
  {
    "id": 11133,
    "content": "f32 d, a, b; mul{"
  },
  {
    "id": 11134,
    "content": "rnd}"
  },
  {
    "id": 11135,
    "content": "f64 d, a, b;"
  },
  {
    "id": 11136,
    "content": "rnd = {"
  },
  {
    "id": 11137,
    "content": "rn,"
  },
  {
    "id": 11138,
    "content": "rz,"
  },
  {
    "id": 11139,
    "content": "rm,"
  },
  {
    "id": 11140,
    "content": "rp }; Description Compute the product of two values"
  },
  {
    "id": 11141,
    "content": "Semantics d = a * b; Notes For floating-point multiplication, all operands must be the same size"
  },
  {
    "id": 11142,
    "content": "Rounding modifiers:"
  },
  {
    "id": 11145,
    "content": "f64 , requires sm_13 or higher"
  },
  {
    "id": 11146,
    "content": "Syntax fma"
  },
  {
    "id": 11147,
    "content": "rnd{"
  },
  {
    "id": 11148,
    "content": "ftz}{"
  },
  {
    "id": 11149,
    "content": "sat}"
  },
  {
    "id": 11150,
    "content": "f32 d, a, b, c; fma"
  },
  {
    "id": 11151,
    "content": "rnd"
  },
  {
    "id": 11152,
    "content": "f64 d, a, b, c;"
  },
  {
    "id": 11153,
    "content": "rnd = {"
  },
  {
    "id": 11154,
    "content": "rn,"
  },
  {
    "id": 11155,
    "content": "rz,"
  },
  {
    "id": 11156,
    "content": "rm,"
  },
  {
    "id": 11158,
    "content": "Semantics d = a*b + c; Notes fma"
  },
  {
    "id": 11160,
    "content": "rnd"
  },
  {
    "id": 11161,
    "content": "fma"
  },
  {
    "id": 11163,
    "content": "rnd"
  },
  {
    "id": 11164,
    "content": "Rounding modifiers (no default):"
  },
  {
    "id": 11166,
    "content": "Syntax mad{"
  },
  {
    "id": 11167,
    "content": "ftz}{"
  },
  {
    "id": 11168,
    "content": "sat}"
  },
  {
    "id": 11169,
    "content": "f32 d, a, b, c;"
  },
  {
    "id": 11170,
    "content": "target sm_1x mad"
  },
  {
    "id": 11171,
    "content": "rnd{"
  },
  {
    "id": 11172,
    "content": "ftz}{"
  },
  {
    "id": 11173,
    "content": "sat}"
  },
  {
    "id": 11174,
    "content": "f32 d, a, b, c;"
  },
  {
    "id": 11175,
    "content": "target sm_20 mad"
  },
  {
    "id": 11176,
    "content": "rnd"
  },
  {
    "id": 11177,
    "content": "f64 d, a, b, c;"
  },
  {
    "id": 11178,
    "content": "target sm_13 and higher"
  },
  {
    "id": 11179,
    "content": "rnd = {"
  },
  {
    "id": 11180,
    "content": "rn,"
  },
  {
    "id": 11181,
    "content": "rz,"
  },
  {
    "id": 11182,
    "content": "rm,"
  },
  {
    "id": 11184,
    "content": "Semantics d = a*b + c; Notes For"
  },
  {
    "id": 11185,
    "content": "target sm_20 and higher: mad"
  },
  {
    "id": 11187,
    "content": "mad"
  },
  {
    "id": 11189,
    "content": "For"
  },
  {
    "id": 11190,
    "content": "target sm_1x : mad"
  },
  {
    "id": 11192,
    "content": "The exception for mad"
  },
  {
    "id": 11193,
    "content": "f32 is when c = +/-0"
  },
  {
    "id": 11194,
    "content": "0 , mad"
  },
  {
    "id": 11195,
    "content": "f32 is identical to the result computed using separate mul and add instructions"
  },
  {
    "id": 11196,
    "content": "When JIT-compiled for SM 2"
  },
  {
    "id": 11197,
    "content": "0 devices, mad"
  },
  {
    "id": 11198,
    "content": "f32 is implemented as a fused multiply-add (i"
  },
  {
    "id": 11199,
    "content": "e"
  },
  {
    "id": 11200,
    "content": ", fma"
  },
  {
    "id": 11201,
    "content": "rn"
  },
  {
    "id": 11202,
    "content": "ftz"
  },
  {
    "id": 11203,
    "content": "f32 )"
  },
  {
    "id": 11205,
    "content": "In PTX ISA versions 2"
  },
  {
    "id": 11206,
    "content": "0 and later, a rounding modifier is required for mad"
  },
  {
    "id": 11207,
    "content": "f32 for sm_20 and higher targets"
  },
  {
    "id": 11208,
    "content": "However for PTX ISA version 3"
  },
  {
    "id": 11209,
    "content": "0 and earlier, ptxas does not enforce this requirement and mad f32 silently defaults to mad"
  },
  {
    "id": 11210,
    "content": "rn"
  },
  {
    "id": 11211,
    "content": "f32"
  },
  {
    "id": 11212,
    "content": "For PTX ISA version 3"
  },
  {
    "id": 11213,
    "content": "1, ptxas generates a warning and defaults to mad"
  },
  {
    "id": 11214,
    "content": "rn"
  },
  {
    "id": 11215,
    "content": "f32 , and in subsequent releases ptxas will enforce the requirement for PTX ISA version 3"
  },
  {
    "id": 11216,
    "content": "2 and later"
  },
  {
    "id": 11217,
    "content": "Rounding modifiers have the following target requirements:"
  },
  {
    "id": 11218,
    "content": "rn ,"
  },
  {
    "id": 11219,
    "content": "rz ,"
  },
  {
    "id": 11220,
    "content": "rm ,"
  },
  {
    "id": 11221,
    "content": "rp for mad"
  },
  {
    "id": 11222,
    "content": "f64 , requires sm_13 or higher"
  },
  {
    "id": 11223,
    "content": "Syntax div"
  },
  {
    "id": 11224,
    "content": "approx{"
  },
  {
    "id": 11225,
    "content": "ftz}"
  },
  {
    "id": 11226,
    "content": "f32 d, a, b;   fast, approximate divide div"
  },
  {
    "id": 11227,
    "content": "full{"
  },
  {
    "id": 11228,
    "content": "ftz}"
  },
  {
    "id": 11229,
    "content": "f32 d, a, b;   full-range approximate divide div"
  },
  {
    "id": 11230,
    "content": "rnd{"
  },
  {
    "id": 11231,
    "content": "ftz}"
  },
  {
    "id": 11232,
    "content": "f32 d, a, b;   IEEE 754 compliant rounding div"
  },
  {
    "id": 11233,
    "content": "rnd"
  },
  {
    "id": 11234,
    "content": "f64 d, a, b;   IEEE 754 compliant rounding"
  },
  {
    "id": 11235,
    "content": "rnd = {"
  },
  {
    "id": 11236,
    "content": "rn,"
  },
  {
    "id": 11237,
    "content": "rz,"
  },
  {
    "id": 11238,
    "content": "rm,"
  },
  {
    "id": 11240,
    "content": "approx"
  },
  {
    "id": 11241,
    "content": "f32 implements a fast approximation to divide, computed as d = a * (1/b)"
  },
  {
    "id": 11242,
    "content": "Examples @p min"
  },
  {
    "id": 11243,
    "content": "ftz"
  },
  {
    "id": 11244,
    "content": "f32 z,z,x; min f64 a,b,c;   fp32 min with NaN min NaN f32 f0,f1,f2;   fp32 min with"
  },
  {
    "id": 11245,
    "content": "xorsign"
  },
  {
    "id": 11246,
    "content": "abs min"
  },
  {
    "id": 11247,
    "content": "xorsign"
  },
  {
    "id": 11248,
    "content": "abs"
  },
  {
    "id": 11249,
    "content": "f32 Rd, Ra, Rb; 9"
  },
  {
    "id": 11250,
    "content": "7"
  },
  {
    "id": 11251,
    "content": "3"
  },
  {
    "id": 11252,
    "content": "12"
  },
  {
    "id": 11253,
    "content": "Syntax max{"
  },
  {
    "id": 11254,
    "content": "ftz}{"
  },
  {
    "id": 11255,
    "content": "NaN}{"
  },
  {
    "id": 11256,
    "content": "xorsign"
  },
  {
    "id": 11257,
    "content": "abs}"
  },
  {
    "id": 11258,
    "content": "f32 d, a, b; max"
  },
  {
    "id": 11259,
    "content": "f64 d, a, b; Description Store the maximum of a and b in d"
  },
  {
    "id": 11260,
    "content": "If"
  },
  {
    "id": 11261,
    "content": "NaN modifier is specified, the result is canonical NaN if either of the inputs is NaN"
  },
  {
    "id": 11262,
    "content": "If"
  },
  {
    "id": 11264,
    "content": "If"
  },
  {
    "id": 11266,
    "content": "Modifiers"
  },
  {
    "id": 11267,
    "content": "abs and"
  },
  {
    "id": 11269,
    "content": "abs operation"
  },
  {
    "id": 11270,
    "content": "Semantics if ("
  },
  {
    "id": 11271,
    "content": "xorsign) { xorsign = getSignBit(a) ^ getSignBit(b); if ("
  },
  {
    "id": 11274,
    "content": "Examples max"
  },
  {
    "id": 11275,
    "content": "ftz"
  },
  {
    "id": 11276,
    "content": "f32 f0,f1,f2; max f64 a,b,c;   fp32 max with NaN max NaN f32 f0,f1,f2;   fp32 max with"
  },
  {
    "id": 11277,
    "content": "xorsign"
  },
  {
    "id": 11278,
    "content": "abs max"
  },
  {
    "id": 11279,
    "content": "xorsign"
  },
  {
    "id": 11280,
    "content": "abs"
  },
  {
    "id": 11281,
    "content": "f32 Rd, Ra, Rb; 9"
  },
  {
    "id": 11282,
    "content": "7"
  },
  {
    "id": 11283,
    "content": "3"
  },
  {
    "id": 11284,
    "content": "13"
  },
  {
    "id": 11285,
    "content": "Syntax rcp"
  },
  {
    "id": 11286,
    "content": "approx{"
  },
  {
    "id": 11287,
    "content": "ftz}"
  },
  {
    "id": 11288,
    "content": "f32 d, a;   fast, approximate reciprocal rcp"
  },
  {
    "id": 11289,
    "content": "rnd{"
  },
  {
    "id": 11290,
    "content": "ftz}"
  },
  {
    "id": 11291,
    "content": "f32 d, a;   IEEE 754 compliant rounding rcp"
  },
  {
    "id": 11292,
    "content": "rnd"
  },
  {
    "id": 11293,
    "content": "f64 d, a;   IEEE 754 compliant rounding"
  },
  {
    "id": 11294,
    "content": "rnd = {"
  },
  {
    "id": 11295,
    "content": "rn,"
  },
  {
    "id": 11296,
    "content": "rz,"
  },
  {
    "id": 11297,
    "content": "rm,"
  },
  {
    "id": 11298,
    "content": "rp }; Description Compute 1/a , store result in d"
  },
  {
    "id": 11299,
    "content": "Semantics d = 1 / a; Notes Fast, approximate single-precision reciprocal: rcp"
  },
  {
    "id": 11300,
    "content": "approx"
  },
  {
    "id": 11301,
    "content": "f32 implements a fast approximation to reciprocal"
  },
  {
    "id": 11302,
    "content": "Input Result -Inf -0 0 -subnormal -Inf -0 0 -Inf +0 0 +Inf +subnormal +Inf +Inf +0"
  },
  {
    "id": 11303,
    "content": "0 NaN NaN Reciprocal with IEEE 754 compliant rounding: Rounding modifiers (no default):"
  },
  {
    "id": 11305,
    "content": "rcp"
  },
  {
    "id": 11306,
    "content": "rn"
  },
  {
    "id": 11307,
    "content": "f64 and explicit modifiers"
  },
  {
    "id": 11308,
    "content": "approx and"
  },
  {
    "id": 11309,
    "content": "ftz were introduced in PTX ISA version 1"
  },
  {
    "id": 11310,
    "content": "4"
  },
  {
    "id": 11311,
    "content": "For PTX ISA versions 1"
  },
  {
    "id": 11312,
    "content": "0 through 1"
  },
  {
    "id": 11313,
    "content": "3, rcp f32 defaults to rcp"
  },
  {
    "id": 11314,
    "content": "approx"
  },
  {
    "id": 11315,
    "content": "ftz"
  },
  {
    "id": 11316,
    "content": "f32 , and rcp f64 defaults to rcp"
  },
  {
    "id": 11317,
    "content": "rn"
  },
  {
    "id": 11318,
    "content": "f64"
  },
  {
    "id": 11319,
    "content": "Floating Point Instructions: rcp"
  },
  {
    "id": 11320,
    "content": "approx"
  },
  {
    "id": 11321,
    "content": "ftz"
  },
  {
    "id": 11322,
    "content": "f64  rcp"
  },
  {
    "id": 11323,
    "content": "approx"
  },
  {
    "id": 11324,
    "content": "ftz"
  },
  {
    "id": 11325,
    "content": "f64 Compute a fast, gross approximation to the reciprocal of a value"
  },
  {
    "id": 11326,
    "content": "Syntax rcp"
  },
  {
    "id": 11327,
    "content": "approx"
  },
  {
    "id": 11328,
    "content": "ftz"
  },
  {
    "id": 11330,
    "content": "11"
  },
  {
    "id": 11331,
    "content": "20 IEEE floating-point format (i"
  },
  {
    "id": 11332,
    "content": "e"
  },
  {
    "id": 11334,
    "content": "11"
  },
  {
    "id": 11336,
    "content": "f64 destination d"
  },
  {
    "id": 11337,
    "content": "Semantics tmp = a[63:32];   upper word of a, 1"
  },
  {
    "id": 11338,
    "content": "11"
  },
  {
    "id": 11339,
    "content": "20 format d[63:32] = 1"
  },
  {
    "id": 11340,
    "content": "0 / tmp; d[31:0] = 0x00000000; Notes rcp"
  },
  {
    "id": 11341,
    "content": "approx"
  },
  {
    "id": 11342,
    "content": "ftz"
  },
  {
    "id": 11343,
    "content": "f64 implements a fast, gross approximation to reciprocal"
  },
  {
    "id": 11345,
    "content": "0 NaN NaN Input NaN s map to a canonical NaN with encoding 0x7fffffff00000000"
  },
  {
    "id": 11346,
    "content": "Syntax sqrt"
  },
  {
    "id": 11347,
    "content": "approx{"
  },
  {
    "id": 11348,
    "content": "ftz}"
  },
  {
    "id": 11349,
    "content": "f32 d, a;   fast, approximate square root sqrt"
  },
  {
    "id": 11350,
    "content": "rnd{"
  },
  {
    "id": 11351,
    "content": "ftz}"
  },
  {
    "id": 11352,
    "content": "f32 d, a;   IEEE 754 compliant rounding sqrt"
  },
  {
    "id": 11353,
    "content": "rnd"
  },
  {
    "id": 11354,
    "content": "f64 d, a;   IEEE 754 compliant rounding"
  },
  {
    "id": 11355,
    "content": "rnd = {"
  },
  {
    "id": 11356,
    "content": "rn,"
  },
  {
    "id": 11357,
    "content": "rz,"
  },
  {
    "id": 11358,
    "content": "rm,"
  },
  {
    "id": 11359,
    "content": "rp }; Description Compute sqrt( a ) and store the result in d Semantics d = sqrt(a); Notes sqrt"
  },
  {
    "id": 11360,
    "content": "approx"
  },
  {
    "id": 11361,
    "content": "f32 implements a fast approximation to square root"
  },
  {
    "id": 11362,
    "content": "Input Result -Inf NaN -normal NaN -subnormal -0"
  },
  {
    "id": 11363,
    "content": "0 -0"
  },
  {
    "id": 11364,
    "content": "0 -0"
  },
  {
    "id": 11365,
    "content": "0 +0"
  },
  {
    "id": 11366,
    "content": "0 +0"
  },
  {
    "id": 11367,
    "content": "0 +subnormal +0"
  },
  {
    "id": 11368,
    "content": "0 +Inf +Inf NaN NaN Square root with IEEE 754 compliant rounding: Rounding modifiers (no default):"
  },
  {
    "id": 11370,
    "content": "sqrt"
  },
  {
    "id": 11371,
    "content": "rn"
  },
  {
    "id": 11372,
    "content": "f64 and explicit modifiers"
  },
  {
    "id": 11373,
    "content": "approx and"
  },
  {
    "id": 11374,
    "content": "ftz were introduced in PTX ISA version 1"
  },
  {
    "id": 11375,
    "content": "4"
  },
  {
    "id": 11376,
    "content": "For PTX ISA versions 1"
  },
  {
    "id": 11377,
    "content": "0 through 1"
  },
  {
    "id": 11378,
    "content": "3, sqrt f32 defaults to sqrt"
  },
  {
    "id": 11379,
    "content": "approx"
  },
  {
    "id": 11380,
    "content": "ftz"
  },
  {
    "id": 11381,
    "content": "f32 , and sqrt f64 defaults to sqrt"
  },
  {
    "id": 11382,
    "content": "rn"
  },
  {
    "id": 11383,
    "content": "f64"
  },
  {
    "id": 11385,
    "content": "approx{"
  },
  {
    "id": 11386,
    "content": "ftz}"
  },
  {
    "id": 11387,
    "content": "f32 d, a; rsqrt"
  },
  {
    "id": 11388,
    "content": "approx"
  },
  {
    "id": 11390,
    "content": "approx implements an approximation to the reciprocal square root"
  },
  {
    "id": 11392,
    "content": "f32 is 2 -22"
  },
  {
    "id": 11393,
    "content": "4 over the range 1"
  },
  {
    "id": 11394,
    "content": "0-4"
  },
  {
    "id": 11395,
    "content": "0"
  },
  {
    "id": 11396,
    "content": "For PTX ISA versions 1"
  },
  {
    "id": 11397,
    "content": "0 through 1"
  },
  {
    "id": 11398,
    "content": "3, rsqrt f32 defaults to rsqrt"
  },
  {
    "id": 11399,
    "content": "approx"
  },
  {
    "id": 11400,
    "content": "ftz"
  },
  {
    "id": 11401,
    "content": "f32 , and rsqrt f64 defaults to rsqrt"
  },
  {
    "id": 11402,
    "content": "approx"
  },
  {
    "id": 11403,
    "content": "f64"
  },
  {
    "id": 11404,
    "content": "Floating Point Instructions: rsqrt"
  },
  {
    "id": 11405,
    "content": "approx"
  },
  {
    "id": 11406,
    "content": "ftz"
  },
  {
    "id": 11407,
    "content": "f64  rsqrt"
  },
  {
    "id": 11408,
    "content": "approx"
  },
  {
    "id": 11409,
    "content": "ftz"
  },
  {
    "id": 11410,
    "content": "f64 Compute an approximation of the square root reciprocal of a value"
  },
  {
    "id": 11411,
    "content": "Syntax rsqrt"
  },
  {
    "id": 11412,
    "content": "approx"
  },
  {
    "id": 11413,
    "content": "ftz"
  },
  {
    "id": 11415,
    "content": "Semantics tmp = a[63:32];   upper word of a, 1"
  },
  {
    "id": 11416,
    "content": "11"
  },
  {
    "id": 11417,
    "content": "20 format d[63:32] = 1"
  },
  {
    "id": 11418,
    "content": "0 / sqrt(tmp); d[31:0] = 0x00000000; Notes rsqrt"
  },
  {
    "id": 11419,
    "content": "approx"
  },
  {
    "id": 11420,
    "content": "ftz"
  },
  {
    "id": 11421,
    "content": "f64 implements a fast approximation of the square root reciprocal of a value"
  },
  {
    "id": 11423,
    "content": "0 -0"
  },
  {
    "id": 11424,
    "content": "0 -0"
  },
  {
    "id": 11425,
    "content": "0 +0"
  },
  {
    "id": 11426,
    "content": "0 +0"
  },
  {
    "id": 11427,
    "content": "0 +subnormal +0"
  },
  {
    "id": 11428,
    "content": "0 +Inf NaN NaN NaN The maximum absolute error is 2 -20"
  },
  {
    "id": 11429,
    "content": "9 in quadrant 00"
  },
  {
    "id": 11430,
    "content": "Syntax cos"
  },
  {
    "id": 11431,
    "content": "approx{"
  },
  {
    "id": 11432,
    "content": "ftz}"
  },
  {
    "id": 11433,
    "content": "f32 d, a; Description Find the cosine of the angle a (in radians)"
  },
  {
    "id": 11434,
    "content": "Input Result -Inf NaN -subnormal +1"
  },
  {
    "id": 11435,
    "content": "0 -0"
  },
  {
    "id": 11436,
    "content": "0 +1"
  },
  {
    "id": 11437,
    "content": "0 +0"
  },
  {
    "id": 11438,
    "content": "0 +1"
  },
  {
    "id": 11439,
    "content": "0 +subnormal +1"
  },
  {
    "id": 11440,
    "content": "0 +Inf NaN NaN NaN The maximum absolute error is 2 -20"
  },
  {
    "id": 11441,
    "content": "9 in quadrant 00"
  },
  {
    "id": 11442,
    "content": "Semantics d = log(a) / log(2); Notes lg2"
  },
  {
    "id": 11443,
    "content": "approx"
  },
  {
    "id": 11444,
    "content": "f32 implements a fast approximation to log 2 (a)"
  },
  {
    "id": 11446,
    "content": "6 for mantissa"
  },
  {
    "id": 11447,
    "content": "Input Result -Inf +0"
  },
  {
    "id": 11448,
    "content": "0 -subnormal +1"
  },
  {
    "id": 11449,
    "content": "0 -0"
  },
  {
    "id": 11450,
    "content": "0 +1"
  },
  {
    "id": 11451,
    "content": "0 +0"
  },
  {
    "id": 11452,
    "content": "0 +1"
  },
  {
    "id": 11453,
    "content": "0 +subnormal +1"
  },
  {
    "id": 11454,
    "content": "0 +Inf +Inf NaN NaN The maximum absolute error is 2 -22"
  },
  {
    "id": 11455,
    "content": "5 for fraction in the primary range"
  },
  {
    "id": 11457,
    "content": "approx"
  },
  {
    "id": 11458,
    "content": "f32 d, a; Description Take hyperbolic tangent value of a"
  },
  {
    "id": 11459,
    "content": "Semantics d = tanh(a); Notes tanh"
  },
  {
    "id": 11460,
    "content": "approx"
  },
  {
    "id": 11461,
    "content": "f32 implements a fast approximation to FP32 hyperbolic-tangent"
  },
  {
    "id": 11463,
    "content": "0 -0"
  },
  {
    "id": 11464,
    "content": "0 +0"
  },
  {
    "id": 11465,
    "content": "0 +0"
  },
  {
    "id": 11467,
    "content": "Half Precision Floating-Point Instructions  Half precision floating-point instructions operate on"
  },
  {
    "id": 11468,
    "content": "f16 and"
  },
  {
    "id": 11469,
    "content": "f16x2 register operands"
  },
  {
    "id": 11471,
    "content": "0, 1"
  },
  {
    "id": 11472,
    "content": "0], with NaN s being flushed to positive zero Half-precision instructions return an unspecified NaN"
  },
  {
    "id": 11473,
    "content": "9"
  },
  {
    "id": 11474,
    "content": "7"
  },
  {
    "id": 11475,
    "content": "4"
  },
  {
    "id": 11476,
    "content": "1"
  },
  {
    "id": 11477,
    "content": "Half Precision Floating Point Instructions: add  add Add two values Syntax add{"
  },
  {
    "id": 11478,
    "content": "rnd}{"
  },
  {
    "id": 11479,
    "content": "ftz}{"
  },
  {
    "id": 11480,
    "content": "sat}"
  },
  {
    "id": 11481,
    "content": "f16 d, a, b; add{"
  },
  {
    "id": 11482,
    "content": "rnd}{"
  },
  {
    "id": 11483,
    "content": "ftz}{"
  },
  {
    "id": 11484,
    "content": "sat}"
  },
  {
    "id": 11485,
    "content": "f16x2 d, a, b; add{"
  },
  {
    "id": 11486,
    "content": "rnd}"
  },
  {
    "id": 11487,
    "content": "bf16 d, a, b; add{"
  },
  {
    "id": 11488,
    "content": "rnd}"
  },
  {
    "id": 11489,
    "content": "bf16x2 d, a, b;"
  },
  {
    "id": 11490,
    "content": "rnd = {"
  },
  {
    "id": 11491,
    "content": "rn }; Description Performs addition and writes the resulting value into a destination register"
  },
  {
    "id": 11492,
    "content": "For"
  },
  {
    "id": 11493,
    "content": "f16x2 and"
  },
  {
    "id": 11495,
    "content": "f16x2 or"
  },
  {
    "id": 11496,
    "content": "bf16x2 result in destination"
  },
  {
    "id": 11498,
    "content": "0"
  },
  {
    "id": 11499,
    "content": "Examples min"
  },
  {
    "id": 11500,
    "content": "ftz"
  },
  {
    "id": 11501,
    "content": "f16 h0,h1,h2; min"
  },
  {
    "id": 11503,
    "content": "7"
  },
  {
    "id": 11504,
    "content": "4"
  },
  {
    "id": 11505,
    "content": "8"
  },
  {
    "id": 11506,
    "content": "Syntax max{"
  },
  {
    "id": 11507,
    "content": "ftz}{"
  },
  {
    "id": 11508,
    "content": "NaN}{"
  },
  {
    "id": 11509,
    "content": "xorsign"
  },
  {
    "id": 11510,
    "content": "abs}"
  },
  {
    "id": 11511,
    "content": "f16 d, a, b; max{"
  },
  {
    "id": 11512,
    "content": "ftz}{"
  },
  {
    "id": 11513,
    "content": "NaN}{"
  },
  {
    "id": 11514,
    "content": "xorsign"
  },
  {
    "id": 11515,
    "content": "abs}"
  },
  {
    "id": 11516,
    "content": "f16x2 d, a, b; max{"
  },
  {
    "id": 11517,
    "content": "NaN}{"
  },
  {
    "id": 11518,
    "content": "xorsign"
  },
  {
    "id": 11519,
    "content": "abs}"
  },
  {
    "id": 11520,
    "content": "bf16 d, a, b; max{"
  },
  {
    "id": 11521,
    "content": "NaN}{"
  },
  {
    "id": 11522,
    "content": "xorsign"
  },
  {
    "id": 11523,
    "content": "abs}"
  },
  {
    "id": 11524,
    "content": "bf16x2 d, a, b; Description Store the maximum of a and b in d"
  },
  {
    "id": 11525,
    "content": "For"
  },
  {
    "id": 11526,
    "content": "f16x2 and"
  },
  {
    "id": 11528,
    "content": "f16x2 or"
  },
  {
    "id": 11529,
    "content": "bf16x2 result in destination"
  },
  {
    "id": 11530,
    "content": "Semantics if (type == f16 || type == bf16) { if ("
  },
  {
    "id": 11531,
    "content": "xorsign) { xorsign = getSignBit(a) ^ getSignBit(b); if ("
  },
  {
    "id": 11534,
    "content": "Examples max"
  },
  {
    "id": 11535,
    "content": "ftz"
  },
  {
    "id": 11537,
    "content": "7"
  },
  {
    "id": 11538,
    "content": "4"
  },
  {
    "id": 11539,
    "content": "9"
  },
  {
    "id": 11541,
    "content": "approx"
  },
  {
    "id": 11542,
    "content": "type d, a; type = {"
  },
  {
    "id": 11543,
    "content": "f16,"
  },
  {
    "id": 11544,
    "content": "f16x2,"
  },
  {
    "id": 11545,
    "content": "bf16,"
  },
  {
    "id": 11546,
    "content": "bf16x2} Description Take hyperbolic tangent value of a"
  },
  {
    "id": 11547,
    "content": "For"
  },
  {
    "id": 11548,
    "content": "f16x2 or"
  },
  {
    "id": 11550,
    "content": "f16x2 or"
  },
  {
    "id": 11551,
    "content": "bf16x2"
  },
  {
    "id": 11552,
    "content": "Semantics if ("
  },
  {
    "id": 11553,
    "content": "type =="
  },
  {
    "id": 11554,
    "content": "f16 ||"
  },
  {
    "id": 11555,
    "content": "type =="
  },
  {
    "id": 11556,
    "content": "bf16) { d = tanh(a) } else if ("
  },
  {
    "id": 11557,
    "content": "type =="
  },
  {
    "id": 11558,
    "content": "f16x2 ||"
  },
  {
    "id": 11559,
    "content": "type =="
  },
  {
    "id": 11560,
    "content": "bf16x2) { fA[0] = a[0:15]; fA[1] = a[16:31]; d[0] = tanh(fA[0]) d[1] = tanh(fA[1]) } Notes tanh"
  },
  {
    "id": 11561,
    "content": "approx"
  },
  {
    "id": 11562,
    "content": "{f16, f16x2, bf16, bf16x2} implements an approximate hyperbolic tangent in the target format"
  },
  {
    "id": 11563,
    "content": "Results of tanh for various corner-case inputs are as follows: Input Result -Inf -1"
  },
  {
    "id": 11564,
    "content": "0 -0"
  },
  {
    "id": 11565,
    "content": "0 -0"
  },
  {
    "id": 11566,
    "content": "0 +0"
  },
  {
    "id": 11567,
    "content": "0 +0"
  },
  {
    "id": 11568,
    "content": "0 +Inf 1"
  },
  {
    "id": 11569,
    "content": "0 NaN NaN The maximum absolute error for"
  },
  {
    "id": 11570,
    "content": "f16 type is 2-10"
  },
  {
    "id": 11571,
    "content": "987"
  },
  {
    "id": 11572,
    "content": "Examples tanh"
  },
  {
    "id": 11573,
    "content": "approx"
  },
  {
    "id": 11574,
    "content": "f16 h1, h0; tanh"
  },
  {
    "id": 11575,
    "content": "approx"
  },
  {
    "id": 11576,
    "content": "f16x2 hd1, hd0; tanh"
  },
  {
    "id": 11577,
    "content": "approx"
  },
  {
    "id": 11578,
    "content": "bf16 b1, b0; tanh"
  },
  {
    "id": 11579,
    "content": "approx"
  },
  {
    "id": 11580,
    "content": "bf16x2 hb1, hb0; 9"
  },
  {
    "id": 11581,
    "content": "7"
  },
  {
    "id": 11582,
    "content": "4"
  },
  {
    "id": 11583,
    "content": "10"
  },
  {
    "id": 11584,
    "content": "Syntax ex2"
  },
  {
    "id": 11585,
    "content": "approx"
  },
  {
    "id": 11586,
    "content": "atype d, a; ex2"
  },
  {
    "id": 11587,
    "content": "approx"
  },
  {
    "id": 11588,
    "content": "ftz"
  },
  {
    "id": 11589,
    "content": "btype d, a;"
  },
  {
    "id": 11590,
    "content": "atype = {"
  },
  {
    "id": 11591,
    "content": "f16,"
  },
  {
    "id": 11592,
    "content": "f16x2}"
  },
  {
    "id": 11593,
    "content": "btype = {"
  },
  {
    "id": 11594,
    "content": "bf16,"
  },
  {
    "id": 11595,
    "content": "bf16x2} Description Raise 2 to the power a"
  },
  {
    "id": 11596,
    "content": "Semantics if ("
  },
  {
    "id": 11597,
    "content": "type =="
  },
  {
    "id": 11598,
    "content": "f16 ||"
  },
  {
    "id": 11599,
    "content": "type =="
  },
  {
    "id": 11600,
    "content": "bf16) { d = 2 ^ a } else if ("
  },
  {
    "id": 11601,
    "content": "type =="
  },
  {
    "id": 11602,
    "content": "f16x2 ||"
  },
  {
    "id": 11603,
    "content": "type =="
  },
  {
    "id": 11604,
    "content": "bf16x2) { fA[0] = a[0:15]; fA[1] = a[16:31]; d[0] = 2 ^ fA[0] d[1] = 2 ^ fA[1] } Notes ex2"
  },
  {
    "id": 11605,
    "content": "approx"
  },
  {
    "id": 11606,
    "content": "Results of ex2"
  },
  {
    "id": 11607,
    "content": "approx"
  },
  {
    "id": 11608,
    "content": "ftz"
  },
  {
    "id": 11609,
    "content": "bf16 for various corner-case inputs are as follows: Input Result -Inf +0"
  },
  {
    "id": 11610,
    "content": "0 -subnormal +1"
  },
  {
    "id": 11611,
    "content": "0 -0"
  },
  {
    "id": 11612,
    "content": "0 +1"
  },
  {
    "id": 11613,
    "content": "0 +0"
  },
  {
    "id": 11614,
    "content": "0 +1"
  },
  {
    "id": 11615,
    "content": "0 +subnormal +1"
  },
  {
    "id": 11616,
    "content": "0 +Inf +Inf NaN NaN Results of ex2"
  },
  {
    "id": 11617,
    "content": "approx"
  },
  {
    "id": 11618,
    "content": "f16 for various corner-case inputs are as follows: Input Result -Inf +0"
  },
  {
    "id": 11619,
    "content": "0 -0"
  },
  {
    "id": 11620,
    "content": "0 +1"
  },
  {
    "id": 11621,
    "content": "0 +0"
  },
  {
    "id": 11622,
    "content": "0 +1"
  },
  {
    "id": 11623,
    "content": "0 +Inf +Inf NaN NaN The maximum relative error for"
  },
  {
    "id": 11624,
    "content": "f16 type is 2-9"
  },
  {
    "id": 11625,
    "content": "9"
  },
  {
    "id": 11626,
    "content": "Examples ex2"
  },
  {
    "id": 11627,
    "content": "approx"
  },
  {
    "id": 11628,
    "content": "f16 h1, h0; ex2"
  },
  {
    "id": 11629,
    "content": "approx"
  },
  {
    "id": 11630,
    "content": "f16x2 hd1, hd0; ex2"
  },
  {
    "id": 11631,
    "content": "approx"
  },
  {
    "id": 11632,
    "content": "ftz"
  },
  {
    "id": 11633,
    "content": "bf16 b1, b2; ex2"
  },
  {
    "id": 11634,
    "content": "approx"
  },
  {
    "id": 11635,
    "content": "ftz"
  },
  {
    "id": 11636,
    "content": "bf16x2 hb1, hb2; 9"
  },
  {
    "id": 11637,
    "content": "7"
  },
  {
    "id": 11638,
    "content": "5"
  },
  {
    "id": 11640,
    "content": "The optional"
  },
  {
    "id": 11642,
    "content": "9"
  },
  {
    "id": 11643,
    "content": "7"
  },
  {
    "id": 11644,
    "content": "5"
  },
  {
    "id": 11645,
    "content": "1"
  },
  {
    "id": 11647,
    "content": "CmpOp{"
  },
  {
    "id": 11648,
    "content": "ftz}"
  },
  {
    "id": 11649,
    "content": "dtype"
  },
  {
    "id": 11650,
    "content": "stype d, a, b; set"
  },
  {
    "id": 11651,
    "content": "CmpOp"
  },
  {
    "id": 11652,
    "content": "BoolOp{"
  },
  {
    "id": 11653,
    "content": "ftz}"
  },
  {
    "id": 11654,
    "content": "dtype"
  },
  {
    "id": 11655,
    "content": "stype d, a, b, {"
  },
  {
    "id": 11656,
    "content": "}c;"
  },
  {
    "id": 11657,
    "content": "CmpOp = { eq, ne, lt, le, gt, ge, lo, ls, hi, hs, equ, neu, ltu, leu, gtu, geu, num, nan };"
  },
  {
    "id": 11658,
    "content": "BoolOp = { and, or, xor };"
  },
  {
    "id": 11659,
    "content": "dtype = {"
  },
  {
    "id": 11660,
    "content": "u32,"
  },
  {
    "id": 11661,
    "content": "s32,"
  },
  {
    "id": 11662,
    "content": "f32 };"
  },
  {
    "id": 11663,
    "content": "stype = {"
  },
  {
    "id": 11664,
    "content": "b16,"
  },
  {
    "id": 11665,
    "content": "b32,"
  },
  {
    "id": 11666,
    "content": "b64,"
  },
  {
    "id": 11667,
    "content": "u16,"
  },
  {
    "id": 11668,
    "content": "u32,"
  },
  {
    "id": 11669,
    "content": "u64,"
  },
  {
    "id": 11670,
    "content": "s16,"
  },
  {
    "id": 11671,
    "content": "s32,"
  },
  {
    "id": 11672,
    "content": "s64,"
  },
  {
    "id": 11673,
    "content": "f32,"
  },
  {
    "id": 11675,
    "content": "If this result is True , 1"
  },
  {
    "id": 11677,
    "content": "Operand d has type dtype ; operands a and b have type stype ; operand c has type"
  },
  {
    "id": 11678,
    "content": "pred"
  },
  {
    "id": 11679,
    "content": "Semantics t = (a CmpOp b)"
  },
  {
    "id": 11680,
    "content": "1 : 0; if (isFloat(dtype)) d = BoolOp(t, c)"
  },
  {
    "id": 11681,
    "content": "1"
  },
  {
    "id": 11686,
    "content": "CmpOp{"
  },
  {
    "id": 11687,
    "content": "ftz}"
  },
  {
    "id": 11688,
    "content": "type p[|q], a, b; setp"
  },
  {
    "id": 11689,
    "content": "CmpOp"
  },
  {
    "id": 11690,
    "content": "BoolOp{"
  },
  {
    "id": 11691,
    "content": "ftz}"
  },
  {
    "id": 11692,
    "content": "type p[|q], a, b, {"
  },
  {
    "id": 11693,
    "content": "}c;"
  },
  {
    "id": 11694,
    "content": "CmpOp = { eq, ne, lt, le, gt, ge, lo, ls, hi, hs, equ, neu, ltu, leu, gtu, geu, num, nan };"
  },
  {
    "id": 11695,
    "content": "BoolOp = { and, or, xor };"
  },
  {
    "id": 11696,
    "content": "type = {"
  },
  {
    "id": 11697,
    "content": "b16,"
  },
  {
    "id": 11698,
    "content": "b32,"
  },
  {
    "id": 11699,
    "content": "b64,"
  },
  {
    "id": 11700,
    "content": "u16,"
  },
  {
    "id": 11701,
    "content": "u32,"
  },
  {
    "id": 11702,
    "content": "u64,"
  },
  {
    "id": 11703,
    "content": "s16,"
  },
  {
    "id": 11704,
    "content": "s32,"
  },
  {
    "id": 11705,
    "content": "s64,"
  },
  {
    "id": 11706,
    "content": "f32,"
  },
  {
    "id": 11709,
    "content": "1 : 0; p = BoolOp(t, c); q = BoolOp("
  },
  {
    "id": 11710,
    "content": "t, c); Integer Notes The signed and unsigned comparison operators are eq , ne , lt , le , gt , ge"
  },
  {
    "id": 11712,
    "content": "type d, a, b, c; type = {"
  },
  {
    "id": 11713,
    "content": "b16,"
  },
  {
    "id": 11714,
    "content": "b32,"
  },
  {
    "id": 11715,
    "content": "b64,"
  },
  {
    "id": 11716,
    "content": "u16,"
  },
  {
    "id": 11717,
    "content": "u32,"
  },
  {
    "id": 11718,
    "content": "u64,"
  },
  {
    "id": 11719,
    "content": "s16,"
  },
  {
    "id": 11720,
    "content": "s32,"
  },
  {
    "id": 11721,
    "content": "s64,"
  },
  {
    "id": 11722,
    "content": "f32,"
  },
  {
    "id": 11724,
    "content": "dtype"
  },
  {
    "id": 11725,
    "content": "s32 d, a, b, c; slct{"
  },
  {
    "id": 11726,
    "content": "ftz}"
  },
  {
    "id": 11727,
    "content": "dtype"
  },
  {
    "id": 11728,
    "content": "f32 d, a, b, c;"
  },
  {
    "id": 11729,
    "content": "dtype = {"
  },
  {
    "id": 11730,
    "content": "b16,"
  },
  {
    "id": 11731,
    "content": "b32,"
  },
  {
    "id": 11732,
    "content": "b64,"
  },
  {
    "id": 11733,
    "content": "u16,"
  },
  {
    "id": 11734,
    "content": "u32,"
  },
  {
    "id": 11735,
    "content": "u64,"
  },
  {
    "id": 11736,
    "content": "s16,"
  },
  {
    "id": 11737,
    "content": "s32,"
  },
  {
    "id": 11738,
    "content": "s64,"
  },
  {
    "id": 11739,
    "content": "f32,"
  },
  {
    "id": 11740,
    "content": "f64 }; Description Conditional selection"
  },
  {
    "id": 11742,
    "content": "s32 or"
  },
  {
    "id": 11743,
    "content": "f32 )"
  },
  {
    "id": 11744,
    "content": "Semantics d = (c >= 0)"
  },
  {
    "id": 11745,
    "content": "a : b; Floating Point Notes For"
  },
  {
    "id": 11746,
    "content": "f32 comparisons, negative zero equals zero"
  },
  {
    "id": 11747,
    "content": "slct"
  },
  {
    "id": 11748,
    "content": "ftz"
  },
  {
    "id": 11749,
    "content": "dtype"
  },
  {
    "id": 11750,
    "content": "f32 flushes subnormal values of operand c to sign-preserving zero, and operand a is selected"
  },
  {
    "id": 11751,
    "content": "sm_1x slct"
  },
  {
    "id": 11752,
    "content": "dtype"
  },
  {
    "id": 11753,
    "content": "f32 flushes subnormal values of operand c to sign-preserving zero, and operand a is selected"
  },
  {
    "id": 11754,
    "content": "Half Precision Comparison Instructions  The comparison instructions are: set setp 9"
  },
  {
    "id": 11755,
    "content": "7"
  },
  {
    "id": 11756,
    "content": "6"
  },
  {
    "id": 11757,
    "content": "1"
  },
  {
    "id": 11760,
    "content": "u32 /"
  },
  {
    "id": 11761,
    "content": "s32"
  },
  {
    "id": 11762,
    "content": "1"
  },
  {
    "id": 11763,
    "content": "0 in target precision floating point format is written for destination type"
  },
  {
    "id": 11764,
    "content": "f16 ,"
  },
  {
    "id": 11765,
    "content": "bf16"
  },
  {
    "id": 11766,
    "content": "0"
  },
  {
    "id": 11767,
    "content": "0 in target precision floating point format is written for destination type"
  },
  {
    "id": 11768,
    "content": "f16 ,"
  },
  {
    "id": 11769,
    "content": "bf16"
  },
  {
    "id": 11770,
    "content": "If the source type is"
  },
  {
    "id": 11771,
    "content": "f16x2 or"
  },
  {
    "id": 11772,
    "content": "bf16x2 then result of individual operations are packed in the 32-bit destination operand"
  },
  {
    "id": 11773,
    "content": "Semantics if (stype == f16x2 || stype =="
  },
  {
    "id": 11775,
    "content": "1 : 0; if (dtype =="
  },
  {
    "id": 11776,
    "content": "f16x2 || stype =="
  },
  {
    "id": 11777,
    "content": "bf16x2) { for (i = 0; i > (32-n)); case shf"
  },
  {
    "id": 11780,
    "content": "31 distance"
  },
  {
    "id": 11781,
    "content": "To shift data sizes greater than 64 bits to the right, use repeated shf"
  },
  {
    "id": 11783,
    "content": "To shift data sizes greater than 64 bits to the left, use repeated shf"
  },
  {
    "id": 11786,
    "content": "Example shf"
  },
  {
    "id": 11787,
    "content": "l"
  },
  {
    "id": 11788,
    "content": "clamp"
  },
  {
    "id": 11789,
    "content": "b32 r3,r1,r0,16;   128-bit left shift; n > n shf"
  },
  {
    "id": 11790,
    "content": "r"
  },
  {
    "id": 11791,
    "content": "clamp"
  },
  {
    "id": 11792,
    "content": "b32 r4,r0,r1,n; shf"
  },
  {
    "id": 11793,
    "content": "r"
  },
  {
    "id": 11794,
    "content": "clamp"
  },
  {
    "id": 11795,
    "content": "b32 r5,r1,r2,n; shf"
  },
  {
    "id": 11796,
    "content": "r"
  },
  {
    "id": 11797,
    "content": "clamp"
  },
  {
    "id": 11798,
    "content": "b32 r6,r2,r3,n; shr s32 r7,r3,n;   result is sign-extended shf"
  },
  {
    "id": 11799,
    "content": "r"
  },
  {
    "id": 11800,
    "content": "clamp"
  },
  {
    "id": 11802,
    "content": "The sizes of the destination and first source operand must match, but not necessarily the type"
  },
  {
    "id": 11804,
    "content": "spaces The Data Movement and Conversion Instructions are: mov shfl"
  },
  {
    "id": 11805,
    "content": "sync prmt ld ldu st st"
  },
  {
    "id": 11806,
    "content": "async multimem ld_reduce , multimem st , multimem"
  },
  {
    "id": 11807,
    "content": "red prefetch , prefetchu isspacep cvta cvt cvt"
  },
  {
    "id": 11808,
    "content": "pack cp async cp async commit_group cp async wait_group , cp async wait_all cp async bulk cp"
  },
  {
    "id": 11809,
    "content": "reduce"
  },
  {
    "id": 11810,
    "content": "async"
  },
  {
    "id": 11811,
    "content": "bulk cp"
  },
  {
    "id": 11812,
    "content": "async"
  },
  {
    "id": 11813,
    "content": "bulk"
  },
  {
    "id": 11814,
    "content": "prefetch cp"
  },
  {
    "id": 11815,
    "content": "async"
  },
  {
    "id": 11816,
    "content": "bulk"
  },
  {
    "id": 11817,
    "content": "tensor cp"
  },
  {
    "id": 11818,
    "content": "reduce"
  },
  {
    "id": 11819,
    "content": "async"
  },
  {
    "id": 11820,
    "content": "bulk"
  },
  {
    "id": 11821,
    "content": "tensor cp"
  },
  {
    "id": 11822,
    "content": "async"
  },
  {
    "id": 11823,
    "content": "bulk"
  },
  {
    "id": 11824,
    "content": "prefetch"
  },
  {
    "id": 11825,
    "content": "tensor cp"
  },
  {
    "id": 11826,
    "content": "async"
  },
  {
    "id": 11827,
    "content": "bulk"
  },
  {
    "id": 11828,
    "content": "commit_group cp"
  },
  {
    "id": 11829,
    "content": "async"
  },
  {
    "id": 11830,
    "content": "bulk"
  },
  {
    "id": 11831,
    "content": "wait_group tensormap"
  },
  {
    "id": 11832,
    "content": "replace 9"
  },
  {
    "id": 11833,
    "content": "7"
  },
  {
    "id": 11834,
    "content": "8"
  },
  {
    "id": 11835,
    "content": "1"
  },
  {
    "id": 11838,
    "content": "ca Cache at all levels, likely to be accessed again"
  },
  {
    "id": 11839,
    "content": "The default load instruction cache operation is ld"
  },
  {
    "id": 11840,
    "content": "ca, which allocates cache lines in all levels (L1 and L2) with normal eviction policy"
  },
  {
    "id": 11843,
    "content": "may be accessed once or twice The compiler/programmer may use ld"
  },
  {
    "id": 11845,
    "content": "The ld lu instruction performs a load cached streaming operation ( ld"
  },
  {
    "id": 11846,
    "content": "cs ) on global addresses"
  },
  {
    "id": 11847,
    "content": "The ld"
  },
  {
    "id": 11849,
    "content": "Table 28 Cache Operators for Memory Store Instructions  Operator Meaning"
  },
  {
    "id": 11850,
    "content": "wb Cache write-back all coherent levels"
  },
  {
    "id": 11854,
    "content": "9"
  },
  {
    "id": 11855,
    "content": "7"
  },
  {
    "id": 11856,
    "content": "8"
  },
  {
    "id": 11857,
    "content": "2"
  },
  {
    "id": 11859,
    "content": "It is supported for"
  },
  {
    "id": 11860,
    "content": "global state space and generic addresses where the address points to global state space"
  },
  {
    "id": 11863,
    "content": "9"
  },
  {
    "id": 11864,
    "content": "7"
  },
  {
    "id": 11865,
    "content": "8"
  },
  {
    "id": 11866,
    "content": "3"
  },
  {
    "id": 11868,
    "content": "address of entry function mov u64 d, kernel; get address of entry function type = {"
  },
  {
    "id": 11869,
    "content": "pred,"
  },
  {
    "id": 11870,
    "content": "b16,"
  },
  {
    "id": 11871,
    "content": "b32,"
  },
  {
    "id": 11872,
    "content": "b64,"
  },
  {
    "id": 11873,
    "content": "u16,"
  },
  {
    "id": 11874,
    "content": "u32,"
  },
  {
    "id": 11875,
    "content": "u64,"
  },
  {
    "id": 11876,
    "content": "s16,"
  },
  {
    "id": 11877,
    "content": "s32,"
  },
  {
    "id": 11878,
    "content": "s64,"
  },
  {
    "id": 11879,
    "content": "f32,"
  },
  {
    "id": 11881,
    "content": "For variables declared in"
  },
  {
    "id": 11882,
    "content": "const ,"
  },
  {
    "id": 11883,
    "content": "global ,"
  },
  {
    "id": 11884,
    "content": "local , and"
  },
  {
    "id": 11885,
    "content": "shared state spaces, mov places the non-generic address of the variable (i"
  },
  {
    "id": 11886,
    "content": "e"
  },
  {
    "id": 11889,
    "content": "e"
  },
  {
    "id": 11891,
    "content": "When moving address of a kernel or a device function, only"
  },
  {
    "id": 11892,
    "content": "u32 or"
  },
  {
    "id": 11893,
    "content": "u64 instruction types are allowed"
  },
  {
    "id": 11896,
    "content": "7"
  },
  {
    "id": 11897,
    "content": "8"
  },
  {
    "id": 11898,
    "content": "4"
  },
  {
    "id": 11900,
    "content": "type d, a; type = {"
  },
  {
    "id": 11901,
    "content": "b16,"
  },
  {
    "id": 11902,
    "content": "b32,"
  },
  {
    "id": 11903,
    "content": "b64,"
  },
  {
    "id": 11906,
    "content": "b16 d = a"
  },
  {
    "id": 11907,
    "content": "x | (a"
  },
  {
    "id": 11908,
    "content": "y = maxLane); break; case down: j = lane + bval; pval = (j = maxLane); break; case"
  },
  {
    "id": 11910,
    "content": "ISA version 2"
  },
  {
    "id": 11911,
    "content": "0"
  },
  {
    "id": 11913,
    "content": "If no sub-qualifier is specified with"
  },
  {
    "id": 11914,
    "content": "shared state space, then ::cta is assumed by default"
  },
  {
    "id": 11917,
    "content": "For ld"
  },
  {
    "id": 11919,
    "content": "For ld"
  },
  {
    "id": 11921,
    "content": "The"
  },
  {
    "id": 11922,
    "content": "relaxed and"
  },
  {
    "id": 11923,
    "content": "acquire qualifiers indicate memory synchronization as described in the Memory Consistency Model"
  },
  {
    "id": 11924,
    "content": "The"
  },
  {
    "id": 11925,
    "content": "scope qualifier indicates the set of threads with which an ld relaxed or ld"
  },
  {
    "id": 11926,
    "content": "acquire instruction can directly synchronize 1"
  },
  {
    "id": 11928,
    "content": "An ld"
  },
  {
    "id": 11930,
    "content": "The qualifiers"
  },
  {
    "id": 11931,
    "content": "volatile ,"
  },
  {
    "id": 11932,
    "content": "relaxed and"
  },
  {
    "id": 11933,
    "content": "acquire may be used only with"
  },
  {
    "id": 11934,
    "content": "global and"
  },
  {
    "id": 11935,
    "content": "shared spaces and with generic addressing, where the address points to"
  },
  {
    "id": 11936,
    "content": "global or"
  },
  {
    "id": 11937,
    "content": "shared space"
  },
  {
    "id": 11938,
    "content": "The qualifier"
  },
  {
    "id": 11939,
    "content": "mmio may be used only with"
  },
  {
    "id": 11940,
    "content": "global space and with generic addressing, where the address points to global space"
  },
  {
    "id": 11941,
    "content": "The optional qualifier"
  },
  {
    "id": 11943,
    "content": "The qualifier"
  },
  {
    "id": 11944,
    "content": "level::eviction_priority specifies the eviction policy that will be used during memory access"
  },
  {
    "id": 11947,
    "content": "When the optional argument cache-policy is specified, the qualifier"
  },
  {
    "id": 11948,
    "content": "level::cache_hint is required"
  },
  {
    "id": 11950,
    "content": "The qualifiers"
  },
  {
    "id": 11951,
    "content": "unified and"
  },
  {
    "id": 11952,
    "content": "level::cache_hint are only supported for"
  },
  {
    "id": 11953,
    "content": "global state space and for generic addressing where the address points to the global state space"
  },
  {
    "id": 11956,
    "content": "reg state space"
  },
  {
    "id": 11958,
    "content": "f16 data may be loaded using ld"
  },
  {
    "id": 11959,
    "content": "b16 , and then converted to"
  },
  {
    "id": 11960,
    "content": "f32 or"
  },
  {
    "id": 11961,
    "content": "f64 using cvt or can be used in half precision floating point instructions"
  },
  {
    "id": 11962,
    "content": "f16x2 data may be loaded using ld"
  },
  {
    "id": 11963,
    "content": "b32 and then used in half precision floating point instructions"
  },
  {
    "id": 11964,
    "content": "Support for scope qualifier,"
  },
  {
    "id": 11965,
    "content": "relaxed ,"
  },
  {
    "id": 11966,
    "content": "acquire ,"
  },
  {
    "id": 11967,
    "content": "weak qualifiers introduced in PTX ISA version 6"
  },
  {
    "id": 11968,
    "content": "0"
  },
  {
    "id": 11969,
    "content": "Support for"
  },
  {
    "id": 11971,
    "content": "4"
  },
  {
    "id": 11972,
    "content": "Support for ::entry and ::func sub-qualifiers on"
  },
  {
    "id": 11973,
    "content": "param space introduced in PTX ISA version 8"
  },
  {
    "id": 11974,
    "content": "3"
  },
  {
    "id": 11975,
    "content": "Support for scope qualifier,"
  },
  {
    "id": 11976,
    "content": "relaxed ,"
  },
  {
    "id": 11977,
    "content": "acquire ,"
  },
  {
    "id": 11978,
    "content": "weak qualifiers require sm_70 or higher"
  },
  {
    "id": 11979,
    "content": "Data Movement and Conversion Instructions: ld"
  },
  {
    "id": 11980,
    "content": "global"
  },
  {
    "id": 11981,
    "content": "nc  ld"
  },
  {
    "id": 11984,
    "content": "level::eviction_priority specifies the eviction policy that will be used during memory access"
  },
  {
    "id": 11985,
    "content": "Examples ld"
  },
  {
    "id": 11986,
    "content": "global"
  },
  {
    "id": 11987,
    "content": "nc"
  },
  {
    "id": 11988,
    "content": "f32 d, [a]; ld"
  },
  {
    "id": 11989,
    "content": "gloal"
  },
  {
    "id": 11990,
    "content": "nc"
  },
  {
    "id": 11991,
    "content": "L1::evict_last"
  },
  {
    "id": 11992,
    "content": "u32 d, [a]; createpolicy"
  },
  {
    "id": 11993,
    "content": "fractional"
  },
  {
    "id": 11994,
    "content": "L2::evict_last"
  },
  {
    "id": 11995,
    "content": "b64 cache-policy, 0"
  },
  {
    "id": 11996,
    "content": "5; ld"
  },
  {
    "id": 11997,
    "content": "global"
  },
  {
    "id": 11998,
    "content": "nc"
  },
  {
    "id": 11999,
    "content": "L2::cache_hint"
  },
  {
    "id": 12000,
    "content": "f32 d, [a], cache-policy; ld"
  },
  {
    "id": 12001,
    "content": "global"
  },
  {
    "id": 12002,
    "content": "nc"
  },
  {
    "id": 12003,
    "content": "L2::64B b32 d, [a];   Prefetch 64B to L2 ld"
  },
  {
    "id": 12004,
    "content": "global"
  },
  {
    "id": 12005,
    "content": "nc"
  },
  {
    "id": 12006,
    "content": "L2::256B f64 d, [a];   Prefetch 256B to L2 ld"
  },
  {
    "id": 12007,
    "content": "global"
  },
  {
    "id": 12008,
    "content": "nc"
  },
  {
    "id": 12009,
    "content": "b128 d, [a]; 9"
  },
  {
    "id": 12010,
    "content": "7"
  },
  {
    "id": 12011,
    "content": "8"
  },
  {
    "id": 12012,
    "content": "10"
  },
  {
    "id": 12014,
    "content": "ss}"
  },
  {
    "id": 12015,
    "content": "type d, [a];   load from address ldu{"
  },
  {
    "id": 12016,
    "content": "ss}"
  },
  {
    "id": 12017,
    "content": "vec type d, [a];   vec load from address"
  },
  {
    "id": 12018,
    "content": "ss = {"
  },
  {
    "id": 12019,
    "content": "global };   state space"
  },
  {
    "id": 12020,
    "content": "vec = {"
  },
  {
    "id": 12021,
    "content": "v2,"
  },
  {
    "id": 12022,
    "content": "v4 };"
  },
  {
    "id": 12023,
    "content": "type = {"
  },
  {
    "id": 12024,
    "content": "b8,"
  },
  {
    "id": 12025,
    "content": "b16,"
  },
  {
    "id": 12026,
    "content": "b32,"
  },
  {
    "id": 12027,
    "content": "b64,"
  },
  {
    "id": 12028,
    "content": "b128,"
  },
  {
    "id": 12029,
    "content": "u8,"
  },
  {
    "id": 12030,
    "content": "u16,"
  },
  {
    "id": 12031,
    "content": "u32,"
  },
  {
    "id": 12032,
    "content": "u64,"
  },
  {
    "id": 12033,
    "content": "s8,"
  },
  {
    "id": 12034,
    "content": "s16,"
  },
  {
    "id": 12035,
    "content": "s32,"
  },
  {
    "id": 12036,
    "content": "s64,"
  },
  {
    "id": 12037,
    "content": "f32,"
  },
  {
    "id": 12040,
    "content": "f16 data may be loaded using ldu"
  },
  {
    "id": 12041,
    "content": "b16 , and then converted to"
  },
  {
    "id": 12042,
    "content": "f32 or"
  },
  {
    "id": 12043,
    "content": "f64 using cvt or can be used in half precision floating point instructions"
  },
  {
    "id": 12044,
    "content": "f16x2 data may be loaded using ldu"
  },
  {
    "id": 12045,
    "content": "b32 and then used in half precision floating point instructions"
  },
  {
    "id": 12046,
    "content": "Examples ldu"
  },
  {
    "id": 12047,
    "content": "global"
  },
  {
    "id": 12048,
    "content": "f32 d,[a]; ldu"
  },
  {
    "id": 12049,
    "content": "global"
  },
  {
    "id": 12050,
    "content": "b32 d,[p+4]; ldu"
  },
  {
    "id": 12051,
    "content": "global"
  },
  {
    "id": 12052,
    "content": "v4"
  },
  {
    "id": 12053,
    "content": "f32 Q,[p]; ldu"
  },
  {
    "id": 12054,
    "content": "global"
  },
  {
    "id": 12055,
    "content": "b128 d,[a]; 9"
  },
  {
    "id": 12056,
    "content": "7"
  },
  {
    "id": 12057,
    "content": "8"
  },
  {
    "id": 12058,
    "content": "11"
  },
  {
    "id": 12061,
    "content": "param is specified without any sub-qualifiers then it defaults to param::func"
  },
  {
    "id": 12062,
    "content": "Instruction st"
  },
  {
    "id": 12063,
    "content": "param{::func} used for passing arguments to device function cannot be predicated"
  },
  {
    "id": 12065,
    "content": "param"
  },
  {
    "id": 12066,
    "content": "The qualifiers"
  },
  {
    "id": 12067,
    "content": "relaxed and"
  },
  {
    "id": 12068,
    "content": "release indicate memory synchronization as described in the Memory Consistency Model"
  },
  {
    "id": 12069,
    "content": "The"
  },
  {
    "id": 12070,
    "content": "scope qualifier indicates the set of threads with which an st relaxed or st"
  },
  {
    "id": 12071,
    "content": "release instruction can directly synchronize 1"
  },
  {
    "id": 12072,
    "content": "An st"
  },
  {
    "id": 12074,
    "content": "The qualifiers"
  },
  {
    "id": 12075,
    "content": "volatile ,"
  },
  {
    "id": 12076,
    "content": "relaxed and"
  },
  {
    "id": 12077,
    "content": "release may be used only with"
  },
  {
    "id": 12078,
    "content": "global and"
  },
  {
    "id": 12079,
    "content": "shared spaces and with generic addressing, where the address points to"
  },
  {
    "id": 12080,
    "content": "global or"
  },
  {
    "id": 12081,
    "content": "shared space"
  },
  {
    "id": 12082,
    "content": "The qualifier"
  },
  {
    "id": 12083,
    "content": "level::cache_hint is only supported for"
  },
  {
    "id": 12084,
    "content": "global state space and for generic addressing where the address points to the global state space"
  },
  {
    "id": 12086,
    "content": "reg state space"
  },
  {
    "id": 12087,
    "content": "Support for scope qualifier,"
  },
  {
    "id": 12088,
    "content": "relaxed ,"
  },
  {
    "id": 12089,
    "content": "release ,"
  },
  {
    "id": 12090,
    "content": "weak qualifiers introduced in PTX ISA version 6"
  },
  {
    "id": 12091,
    "content": "0"
  },
  {
    "id": 12092,
    "content": "Support for"
  },
  {
    "id": 12093,
    "content": "level::eviction_priority and level::cache_hint qualifiers introduced in PTX ISA version 7"
  },
  {
    "id": 12094,
    "content": "4"
  },
  {
    "id": 12095,
    "content": "Support for scope qualifier,"
  },
  {
    "id": 12096,
    "content": "relaxed ,"
  },
  {
    "id": 12097,
    "content": "release ,"
  },
  {
    "id": 12098,
    "content": "weak qualifiers require sm_70 or higher"
  },
  {
    "id": 12099,
    "content": "Examples st"
  },
  {
    "id": 12100,
    "content": "global"
  },
  {
    "id": 12101,
    "content": "f32 [a],b; st"
  },
  {
    "id": 12102,
    "content": "local"
  },
  {
    "id": 12103,
    "content": "b32 [q+4],a; st"
  },
  {
    "id": 12104,
    "content": "global"
  },
  {
    "id": 12105,
    "content": "v4"
  },
  {
    "id": 12106,
    "content": "s32 [p],Q; st"
  },
  {
    "id": 12107,
    "content": "local"
  },
  {
    "id": 12108,
    "content": "b32 [q+-8],a;   negative offset st"
  },
  {
    "id": 12109,
    "content": "local"
  },
  {
    "id": 12110,
    "content": "s32 [100],r7;   immediate address cvt"
  },
  {
    "id": 12111,
    "content": "f16"
  },
  {
    "id": 12112,
    "content": "f32 %r,%r;   %r is 32-bit register st b16 [fs],%r;   store lower st"
  },
  {
    "id": 12113,
    "content": "global"
  },
  {
    "id": 12114,
    "content": "relaxed"
  },
  {
    "id": 12115,
    "content": "sys"
  },
  {
    "id": 12116,
    "content": "u32 [gbl], %r0; st"
  },
  {
    "id": 12117,
    "content": "shared"
  },
  {
    "id": 12118,
    "content": "release"
  },
  {
    "id": 12119,
    "content": "cta"
  },
  {
    "id": 12120,
    "content": "u32 [sh], %r1; st"
  },
  {
    "id": 12121,
    "content": "global"
  },
  {
    "id": 12122,
    "content": "relaxed"
  },
  {
    "id": 12123,
    "content": "cluster"
  },
  {
    "id": 12124,
    "content": "u32 [gbl], %r2; st"
  },
  {
    "id": 12125,
    "content": "shared::cta"
  },
  {
    "id": 12126,
    "content": "release"
  },
  {
    "id": 12127,
    "content": "cta"
  },
  {
    "id": 12128,
    "content": "u32 [sh + 4], %r1; st"
  },
  {
    "id": 12129,
    "content": "shared::cluster"
  },
  {
    "id": 12130,
    "content": "u32 [sh + 8], %r1; st"
  },
  {
    "id": 12131,
    "content": "global"
  },
  {
    "id": 12132,
    "content": "mmio"
  },
  {
    "id": 12133,
    "content": "relaxed"
  },
  {
    "id": 12134,
    "content": "sys"
  },
  {
    "id": 12135,
    "content": "u32 [gbl], %r1; st"
  },
  {
    "id": 12136,
    "content": "global"
  },
  {
    "id": 12137,
    "content": "L1::no_allocate"
  },
  {
    "id": 12138,
    "content": "f32 [p], a; createpolicy"
  },
  {
    "id": 12139,
    "content": "fractional"
  },
  {
    "id": 12140,
    "content": "L2::evict_last"
  },
  {
    "id": 12141,
    "content": "b64 cache-policy, 0"
  },
  {
    "id": 12142,
    "content": "25; st"
  },
  {
    "id": 12143,
    "content": "global"
  },
  {
    "id": 12144,
    "content": "L2::cache_hint"
  },
  {
    "id": 12145,
    "content": "b32 [a], b, cache-policy; st"
  },
  {
    "id": 12146,
    "content": "param::func"
  },
  {
    "id": 12147,
    "content": "b64 [param1], %rp1; st"
  },
  {
    "id": 12148,
    "content": "global"
  },
  {
    "id": 12149,
    "content": "b128 [a], b;   128-bit store 9"
  },
  {
    "id": 12150,
    "content": "7"
  },
  {
    "id": 12151,
    "content": "8"
  },
  {
    "id": 12152,
    "content": "12"
  },
  {
    "id": 12154,
    "content": "weak}{"
  },
  {
    "id": 12155,
    "content": "ss}{"
  },
  {
    "id": 12156,
    "content": "completion_mechanism}{"
  },
  {
    "id": 12157,
    "content": "vec}"
  },
  {
    "id": 12158,
    "content": "type [a], b, [mbar];"
  },
  {
    "id": 12159,
    "content": "ss = {"
  },
  {
    "id": 12160,
    "content": "shared::cluster };"
  },
  {
    "id": 12161,
    "content": "type = {"
  },
  {
    "id": 12162,
    "content": "b32,"
  },
  {
    "id": 12163,
    "content": "b64,"
  },
  {
    "id": 12164,
    "content": "u32,"
  },
  {
    "id": 12165,
    "content": "u64,"
  },
  {
    "id": 12166,
    "content": "s32,"
  },
  {
    "id": 12167,
    "content": "s64,"
  },
  {
    "id": 12168,
    "content": "f32,"
  },
  {
    "id": 12169,
    "content": "f64 };"
  },
  {
    "id": 12170,
    "content": "vec = {"
  },
  {
    "id": 12171,
    "content": "v2,"
  },
  {
    "id": 12172,
    "content": "v4 };"
  },
  {
    "id": 12173,
    "content": "completion_mechanism = {"
  },
  {
    "id": 12174,
    "content": "mbarrier::complete_tx::bytes }; Description st"
  },
  {
    "id": 12176,
    "content": "The modifier"
  },
  {
    "id": 12179,
    "content": "The state space of the address {"
  },
  {
    "id": 12180,
    "content": "ss} , if specified, is applicable to both operands a and mbar"
  },
  {
    "id": 12181,
    "content": "If the generic addresses specified do not fall within the address window of"
  },
  {
    "id": 12182,
    "content": "shared::cluster state space, then the behaviour is undefined"
  },
  {
    "id": 12184,
    "content": "release semantics at the"
  },
  {
    "id": 12185,
    "content": "cluster scope as described in the Memory Consistency Model"
  },
  {
    "id": 12186,
    "content": "Examples st"
  },
  {
    "id": 12187,
    "content": "async"
  },
  {
    "id": 12188,
    "content": "shared::cluster"
  },
  {
    "id": 12189,
    "content": "mbarrier::complete_tx::bytes"
  },
  {
    "id": 12190,
    "content": "u32 [addr], b, [mbar_addr] 9"
  },
  {
    "id": 12191,
    "content": "7"
  },
  {
    "id": 12192,
    "content": "8"
  },
  {
    "id": 12193,
    "content": "13"
  },
  {
    "id": 12198,
    "content": "If the address specified by a does not fall within the address window of"
  },
  {
    "id": 12199,
    "content": "global state space then the behavior is undefined"
  },
  {
    "id": 12200,
    "content": "For floating-point type multi- operations, the size of the specified type along with"
  },
  {
    "id": 12201,
    "content": "vec must equal either 32-bits or 64-bits or 128-bits"
  },
  {
    "id": 12202,
    "content": "The following table describes the valid combinations of"
  },
  {
    "id": 12203,
    "content": "op and base type: op Base type"
  },
  {
    "id": 12204,
    "content": "add"
  },
  {
    "id": 12205,
    "content": "u32 ,"
  },
  {
    "id": 12206,
    "content": "u64 ,"
  },
  {
    "id": 12207,
    "content": "s32"
  },
  {
    "id": 12208,
    "content": "f16 ,"
  },
  {
    "id": 12209,
    "content": "f16x2 ,"
  },
  {
    "id": 12210,
    "content": "bf16 ,"
  },
  {
    "id": 12211,
    "content": "bf16x2"
  },
  {
    "id": 12212,
    "content": "f32 ,"
  },
  {
    "id": 12213,
    "content": "f64"
  },
  {
    "id": 12214,
    "content": "and ,"
  },
  {
    "id": 12215,
    "content": "or ,"
  },
  {
    "id": 12216,
    "content": "xor"
  },
  {
    "id": 12217,
    "content": "b32 ,"
  },
  {
    "id": 12218,
    "content": "b64"
  },
  {
    "id": 12219,
    "content": "min ,"
  },
  {
    "id": 12220,
    "content": "max"
  },
  {
    "id": 12221,
    "content": "u32 ,"
  },
  {
    "id": 12222,
    "content": "s32 ,"
  },
  {
    "id": 12223,
    "content": "u64 ,"
  },
  {
    "id": 12224,
    "content": "s644"
  },
  {
    "id": 12225,
    "content": "f16 ,"
  },
  {
    "id": 12226,
    "content": "f16x2 ,"
  },
  {
    "id": 12227,
    "content": "bf16 ,"
  },
  {
    "id": 12228,
    "content": "bf16x2 For multimem"
  },
  {
    "id": 12229,
    "content": "ld_reduce , the default precision of the intermediate accumulation is same as the specified type"
  },
  {
    "id": 12230,
    "content": "Optionally for"
  },
  {
    "id": 12231,
    "content": "f16 ,"
  },
  {
    "id": 12232,
    "content": "f16x2 ,"
  },
  {
    "id": 12233,
    "content": "bf16 and"
  },
  {
    "id": 12234,
    "content": "bf16x2 types,"
  },
  {
    "id": 12235,
    "content": "acc::f32 can be specified to change the precision of the intermediate accumulation to f32"
  },
  {
    "id": 12236,
    "content": "Optional qualifiers"
  },
  {
    "id": 12237,
    "content": "ldsem ,"
  },
  {
    "id": 12238,
    "content": "stsem and"
  },
  {
    "id": 12239,
    "content": "redsem specify the memory synchronizing effect of the multimem ld_reduce , multimem st and multimem"
  },
  {
    "id": 12240,
    "content": "red respectively, as described in Memory Consistency Model"
  },
  {
    "id": 12241,
    "content": "If explicit semantics qualifiers are not specified, then multimem ld_reduce and multimem"
  },
  {
    "id": 12242,
    "content": "st default to"
  },
  {
    "id": 12243,
    "content": "weak and multimem"
  },
  {
    "id": 12244,
    "content": "red defaults to"
  },
  {
    "id": 12245,
    "content": "relaxed"
  },
  {
    "id": 12246,
    "content": "The optional"
  },
  {
    "id": 12248,
    "content": "If the"
  },
  {
    "id": 12249,
    "content": "scope qualifier is not specified for multimem"
  },
  {
    "id": 12250,
    "content": "red then"
  },
  {
    "id": 12251,
    "content": "sys scope is assumed by default"
  },
  {
    "id": 12252,
    "content": "Examples multimem"
  },
  {
    "id": 12253,
    "content": "ld_reduce"
  },
  {
    "id": 12254,
    "content": "and"
  },
  {
    "id": 12255,
    "content": "b32 val1_b32, [addr1]; multimem"
  },
  {
    "id": 12256,
    "content": "ld_reduce"
  },
  {
    "id": 12257,
    "content": "acquire"
  },
  {
    "id": 12258,
    "content": "gpu"
  },
  {
    "id": 12259,
    "content": "global"
  },
  {
    "id": 12260,
    "content": "add"
  },
  {
    "id": 12261,
    "content": "u32 val2_u32, [addr2]; multimem"
  },
  {
    "id": 12262,
    "content": "st"
  },
  {
    "id": 12263,
    "content": "relaxed"
  },
  {
    "id": 12264,
    "content": "gpu"
  },
  {
    "id": 12265,
    "content": "b32 [addr3], val3_b32; multimem"
  },
  {
    "id": 12266,
    "content": "st"
  },
  {
    "id": 12267,
    "content": "release"
  },
  {
    "id": 12268,
    "content": "cta"
  },
  {
    "id": 12269,
    "content": "global"
  },
  {
    "id": 12270,
    "content": "u32 [addr4], val4_u32; multimem"
  },
  {
    "id": 12271,
    "content": "red"
  },
  {
    "id": 12272,
    "content": "relaxed"
  },
  {
    "id": 12273,
    "content": "gpu"
  },
  {
    "id": 12274,
    "content": "max"
  },
  {
    "id": 12275,
    "content": "f64 [addr5], val5_f64; multimem"
  },
  {
    "id": 12276,
    "content": "red"
  },
  {
    "id": 12277,
    "content": "release"
  },
  {
    "id": 12278,
    "content": "cta"
  },
  {
    "id": 12279,
    "content": "global"
  },
  {
    "id": 12280,
    "content": "add"
  },
  {
    "id": 12281,
    "content": "v4"
  },
  {
    "id": 12282,
    "content": "f32 [addr6], {val6, val7, val8, val9}; multimem"
  },
  {
    "id": 12283,
    "content": "ld_reduce"
  },
  {
    "id": 12284,
    "content": "add"
  },
  {
    "id": 12285,
    "content": "acc::f32"
  },
  {
    "id": 12286,
    "content": "v2"
  },
  {
    "id": 12287,
    "content": "f16x2 {val_10, val_11}, [addr7]; 9"
  },
  {
    "id": 12288,
    "content": "7"
  },
  {
    "id": 12289,
    "content": "8"
  },
  {
    "id": 12290,
    "content": "14"
  },
  {
    "id": 12292,
    "content": "space}"
  },
  {
    "id": 12293,
    "content": "level [a];   prefetch to data cache prefetch"
  },
  {
    "id": 12294,
    "content": "global"
  },
  {
    "id": 12296,
    "content": "tensormap_space}"
  },
  {
    "id": 12297,
    "content": "tensormap [a];   prefetch the tensormap"
  },
  {
    "id": 12298,
    "content": "space = {"
  },
  {
    "id": 12299,
    "content": "global,"
  },
  {
    "id": 12300,
    "content": "local };"
  },
  {
    "id": 12301,
    "content": "level = {"
  },
  {
    "id": 12302,
    "content": "L1,"
  },
  {
    "id": 12303,
    "content": "L2 };"
  },
  {
    "id": 12304,
    "content": "level::eviction_priority = {"
  },
  {
    "id": 12305,
    "content": "L2::evict_last, L2::evict_normal };"
  },
  {
    "id": 12306,
    "content": "tensormap_space = {"
  },
  {
    "id": 12307,
    "content": "const,"
  },
  {
    "id": 12309,
    "content": "If the"
  },
  {
    "id": 12311,
    "content": "const or"
  },
  {
    "id": 12312,
    "content": "param memory state space for subsequent use by the cp"
  },
  {
    "id": 12313,
    "content": "async"
  },
  {
    "id": 12314,
    "content": "bulk"
  },
  {
    "id": 12315,
    "content": "tensor instruction"
  },
  {
    "id": 12317,
    "content": "level::eviction_priority"
  },
  {
    "id": 12319,
    "content": "prefetch"
  },
  {
    "id": 12320,
    "content": "global"
  },
  {
    "id": 12321,
    "content": "L1 [ptr]; prefetch"
  },
  {
    "id": 12322,
    "content": "global"
  },
  {
    "id": 12323,
    "content": "L2::evict_last [ptr]; prefetchu"
  },
  {
    "id": 12324,
    "content": "L1 [addr]; prefetch"
  },
  {
    "id": 12325,
    "content": "global"
  },
  {
    "id": 12326,
    "content": "tensormap [ptr]; 9"
  },
  {
    "id": 12327,
    "content": "7"
  },
  {
    "id": 12328,
    "content": "8"
  },
  {
    "id": 12329,
    "content": "15"
  },
  {
    "id": 12331,
    "content": "global}"
  },
  {
    "id": 12332,
    "content": "level::eviction_priority [a], size; level::eviction_priority = {"
  },
  {
    "id": 12335,
    "content": "global state space then the behavior is undefined"
  },
  {
    "id": 12337,
    "content": "cache at the specified address and cache level Syntax discard{"
  },
  {
    "id": 12338,
    "content": "global}"
  },
  {
    "id": 12339,
    "content": "level [a], size; level = {"
  },
  {
    "id": 12340,
    "content": "L2 }; Description The discard instruction invalidates the data at the address range [a"
  },
  {
    "id": 12342,
    "content": "cache level Syntax Range-based policy createpolicy range{"
  },
  {
    "id": 12343,
    "content": "global}"
  },
  {
    "id": 12344,
    "content": "level::primary_priority{ level::secondary_priority}"
  },
  {
    "id": 12345,
    "content": "b64 cache-policy, [a], primary-size, total-size;   Fraction-based policy createpolicy"
  },
  {
    "id": 12346,
    "content": "fractional"
  },
  {
    "id": 12347,
    "content": "level::primary_priority{ level::secondary_priority}"
  },
  {
    "id": 12348,
    "content": "b64 cache-policy{, fraction};   Converting the access property from CUDA APIs createpolicy"
  },
  {
    "id": 12349,
    "content": "cvt"
  },
  {
    "id": 12350,
    "content": "L2"
  },
  {
    "id": 12351,
    "content": "b64 cache-policy, access-property;"
  },
  {
    "id": 12352,
    "content": "level::primary_priority = {"
  },
  {
    "id": 12353,
    "content": "L2::evict_last, L2::evict_normal, L2::evict_first, L2::evict_unchanged };"
  },
  {
    "id": 12354,
    "content": "level::secondary_priority = {"
  },
  {
    "id": 12355,
    "content": "L2::evict_first,"
  },
  {
    "id": 12357,
    "content": "level::cache_hint qualifier"
  },
  {
    "id": 12359,
    "content": "primary range, the eviction priority specified by"
  },
  {
    "id": 12360,
    "content": "L2::primary_priority is applied"
  },
  {
    "id": 12361,
    "content": "If the memory address falls in any of the secondary ranges, the eviction priority specified by"
  },
  {
    "id": 12364,
    "content": "L2::secondary_priority"
  },
  {
    "id": 12366,
    "content": "L2::primary_priority"
  },
  {
    "id": 12368,
    "content": "cvt"
  },
  {
    "id": 12369,
    "content": "Examples createpolicy"
  },
  {
    "id": 12370,
    "content": "fractional"
  },
  {
    "id": 12371,
    "content": "L2::evict_last"
  },
  {
    "id": 12372,
    "content": "b64 policy, 1"
  },
  {
    "id": 12373,
    "content": "0; createpolicy"
  },
  {
    "id": 12374,
    "content": "fractional"
  },
  {
    "id": 12375,
    "content": "L2::evict_last L2::evict_unchanged"
  },
  {
    "id": 12376,
    "content": "b64 policy, 0"
  },
  {
    "id": 12377,
    "content": "5; createpolicy"
  },
  {
    "id": 12378,
    "content": "range"
  },
  {
    "id": 12379,
    "content": "L2::evict_last L2::evict_first"
  },
  {
    "id": 12380,
    "content": "b64 policy, [ptr], 0x100000, 0x200000;   access-prop is created by CUDA APIs"
  },
  {
    "id": 12382,
    "content": "space p, a;   result is"
  },
  {
    "id": 12383,
    "content": "pred"
  },
  {
    "id": 12384,
    "content": "space = { const,"
  },
  {
    "id": 12385,
    "content": "global,"
  },
  {
    "id": 12386,
    "content": "local,"
  },
  {
    "id": 12387,
    "content": "shared{::cta, ::cluster},"
  },
  {
    "id": 12389,
    "content": "isspacep"
  },
  {
    "id": 12391,
    "content": "isspacep"
  },
  {
    "id": 12392,
    "content": "global returns 1 for Kernel Function Parameters as"
  },
  {
    "id": 12393,
    "content": "param window is contained within the global window"
  },
  {
    "id": 12396,
    "content": "7"
  },
  {
    "id": 12397,
    "content": "8"
  },
  {
    "id": 12398,
    "content": "19"
  },
  {
    "id": 12399,
    "content": "Data Movement and Conversion Instructions: cvta  cvta Convert address from"
  },
  {
    "id": 12400,
    "content": "const , Kernel Function Parameters ("
  },
  {
    "id": 12401,
    "content": "param ),"
  },
  {
    "id": 12402,
    "content": "global ,"
  },
  {
    "id": 12403,
    "content": "local , or"
  },
  {
    "id": 12404,
    "content": "shared state space to generic, or vice-versa Take the generic address of a variable declared in"
  },
  {
    "id": 12405,
    "content": "const , Kernel Function Parameters ("
  },
  {
    "id": 12406,
    "content": "param ),"
  },
  {
    "id": 12407,
    "content": "global ,"
  },
  {
    "id": 12408,
    "content": "local , or"
  },
  {
    "id": 12409,
    "content": "shared state space"
  },
  {
    "id": 12410,
    "content": "Syntax   convert const, global, local, or shared address to generic address cvta"
  },
  {
    "id": 12411,
    "content": "space"
  },
  {
    "id": 12412,
    "content": "size p, a;   source address in register a cvta"
  },
  {
    "id": 12413,
    "content": "space"
  },
  {
    "id": 12414,
    "content": "size p, var;   get generic address of var cvta"
  },
  {
    "id": 12415,
    "content": "space"
  },
  {
    "id": 12417,
    "content": "to"
  },
  {
    "id": 12418,
    "content": "space"
  },
  {
    "id": 12419,
    "content": "size p, a;"
  },
  {
    "id": 12420,
    "content": "space = {"
  },
  {
    "id": 12421,
    "content": "const,"
  },
  {
    "id": 12422,
    "content": "global,"
  },
  {
    "id": 12423,
    "content": "local,"
  },
  {
    "id": 12424,
    "content": "shared{::cta, ::cluster},"
  },
  {
    "id": 12425,
    "content": "param{::entry} };"
  },
  {
    "id": 12426,
    "content": "size = {"
  },
  {
    "id": 12427,
    "content": "u32,"
  },
  {
    "id": 12428,
    "content": "u64 }; Description Convert a const , Kernel Function Parameters ("
  },
  {
    "id": 12429,
    "content": "param ), global , local , or shared address to a generic address, or vice-versa"
  },
  {
    "id": 12430,
    "content": "For variables declared in"
  },
  {
    "id": 12431,
    "content": "const , Kernel Function Parameters ("
  },
  {
    "id": 12432,
    "content": "param ),"
  },
  {
    "id": 12433,
    "content": "global ,"
  },
  {
    "id": 12434,
    "content": "local , or"
  },
  {
    "id": 12435,
    "content": "shared state space, the generic address of the variable may be taken using cvta"
  },
  {
    "id": 12436,
    "content": "The source is either a register or a variable defined in const , Kernel Function Parameters ("
  },
  {
    "id": 12437,
    "content": "param ), global , local , or shared memory with an optional offset"
  },
  {
    "id": 12439,
    "content": "For cvta with"
  },
  {
    "id": 12442,
    "content": "Examples cvta"
  },
  {
    "id": 12443,
    "content": "const"
  },
  {
    "id": 12444,
    "content": "u32 ptr,cvar; cvta"
  },
  {
    "id": 12445,
    "content": "local"
  },
  {
    "id": 12446,
    "content": "u32 ptr,lptr; cvta"
  },
  {
    "id": 12447,
    "content": "shared::cta"
  },
  {
    "id": 12448,
    "content": "u32 p,As+4; cvta"
  },
  {
    "id": 12449,
    "content": "shared::cluster"
  },
  {
    "id": 12450,
    "content": "u32 ptr, As; cvta"
  },
  {
    "id": 12451,
    "content": "to"
  },
  {
    "id": 12452,
    "content": "global"
  },
  {
    "id": 12453,
    "content": "u32 p,gptr; cvta"
  },
  {
    "id": 12454,
    "content": "param"
  },
  {
    "id": 12455,
    "content": "u64 ptr,pvar; cvta"
  },
  {
    "id": 12456,
    "content": "to"
  },
  {
    "id": 12457,
    "content": "param::entry"
  },
  {
    "id": 12458,
    "content": "u64 epptr, ptr; 9"
  },
  {
    "id": 12459,
    "content": "7"
  },
  {
    "id": 12460,
    "content": "8"
  },
  {
    "id": 12461,
    "content": "20"
  },
  {
    "id": 12463,
    "content": "irnd}{"
  },
  {
    "id": 12464,
    "content": "ftz}{"
  },
  {
    "id": 12465,
    "content": "sat}"
  },
  {
    "id": 12466,
    "content": "dtype"
  },
  {
    "id": 12467,
    "content": "atype d, a;   integer rounding cvt{"
  },
  {
    "id": 12468,
    "content": "frnd}{"
  },
  {
    "id": 12469,
    "content": "ftz}{"
  },
  {
    "id": 12470,
    "content": "sat}"
  },
  {
    "id": 12471,
    "content": "dtype"
  },
  {
    "id": 12472,
    "content": "atype d, a;   fp rounding cvt"
  },
  {
    "id": 12473,
    "content": "frnd2{"
  },
  {
    "id": 12474,
    "content": "relu}{"
  },
  {
    "id": 12475,
    "content": "satfinite}"
  },
  {
    "id": 12476,
    "content": "f16"
  },
  {
    "id": 12477,
    "content": "f32 d, a; cvt"
  },
  {
    "id": 12478,
    "content": "frnd2{"
  },
  {
    "id": 12479,
    "content": "relu}{"
  },
  {
    "id": 12480,
    "content": "satfinite}"
  },
  {
    "id": 12481,
    "content": "f16x2"
  },
  {
    "id": 12482,
    "content": "f32 d, a, b; cvt"
  },
  {
    "id": 12483,
    "content": "frnd2{"
  },
  {
    "id": 12484,
    "content": "relu}{"
  },
  {
    "id": 12485,
    "content": "satfinite}"
  },
  {
    "id": 12486,
    "content": "bf16"
  },
  {
    "id": 12487,
    "content": "f32 d, a; cvt"
  },
  {
    "id": 12488,
    "content": "frnd2{"
  },
  {
    "id": 12489,
    "content": "relu}{"
  },
  {
    "id": 12490,
    "content": "satfinite}"
  },
  {
    "id": 12491,
    "content": "bf16x2"
  },
  {
    "id": 12492,
    "content": "f32 d, a, b; cvt"
  },
  {
    "id": 12493,
    "content": "rna{"
  },
  {
    "id": 12494,
    "content": "satfinite}"
  },
  {
    "id": 12495,
    "content": "tf32"
  },
  {
    "id": 12496,
    "content": "f32 d, a; cvt"
  },
  {
    "id": 12497,
    "content": "frnd2{"
  },
  {
    "id": 12498,
    "content": "relu}"
  },
  {
    "id": 12499,
    "content": "tf32"
  },
  {
    "id": 12500,
    "content": "f32 d, a; cvt"
  },
  {
    "id": 12501,
    "content": "rn"
  },
  {
    "id": 12502,
    "content": "satfinite{"
  },
  {
    "id": 12503,
    "content": "relu}"
  },
  {
    "id": 12504,
    "content": "f8x2type"
  },
  {
    "id": 12505,
    "content": "f32 d, a, b; cvt"
  },
  {
    "id": 12506,
    "content": "rn"
  },
  {
    "id": 12507,
    "content": "satfinite{"
  },
  {
    "id": 12508,
    "content": "relu}"
  },
  {
    "id": 12509,
    "content": "f8x2type"
  },
  {
    "id": 12510,
    "content": "f16x2 d, a; cvt"
  },
  {
    "id": 12511,
    "content": "rn"
  },
  {
    "id": 12512,
    "content": "{"
  },
  {
    "id": 12513,
    "content": "relu}"
  },
  {
    "id": 12514,
    "content": "f16x2"
  },
  {
    "id": 12515,
    "content": "f8x2type d, a;"
  },
  {
    "id": 12516,
    "content": "irnd = {"
  },
  {
    "id": 12517,
    "content": "rni,"
  },
  {
    "id": 12518,
    "content": "rzi,"
  },
  {
    "id": 12519,
    "content": "rmi,"
  },
  {
    "id": 12520,
    "content": "rpi };"
  },
  {
    "id": 12521,
    "content": "frnd = {"
  },
  {
    "id": 12522,
    "content": "rn,"
  },
  {
    "id": 12523,
    "content": "rz,"
  },
  {
    "id": 12524,
    "content": "rm,"
  },
  {
    "id": 12525,
    "content": "rp };"
  },
  {
    "id": 12526,
    "content": "frnd2 = {"
  },
  {
    "id": 12527,
    "content": "rn,"
  },
  {
    "id": 12528,
    "content": "rz };"
  },
  {
    "id": 12529,
    "content": "dtype ="
  },
  {
    "id": 12530,
    "content": "atype = {"
  },
  {
    "id": 12531,
    "content": "u8,"
  },
  {
    "id": 12532,
    "content": "u16,"
  },
  {
    "id": 12533,
    "content": "u32,"
  },
  {
    "id": 12534,
    "content": "u64,"
  },
  {
    "id": 12535,
    "content": "s8,"
  },
  {
    "id": 12536,
    "content": "s16,"
  },
  {
    "id": 12537,
    "content": "s32,"
  },
  {
    "id": 12538,
    "content": "s64,"
  },
  {
    "id": 12539,
    "content": "bf16,"
  },
  {
    "id": 12540,
    "content": "f16,"
  },
  {
    "id": 12541,
    "content": "f32,"
  },
  {
    "id": 12542,
    "content": "f64 };"
  },
  {
    "id": 12543,
    "content": "f8x2type = {"
  },
  {
    "id": 12544,
    "content": "e4m3x2,"
  },
  {
    "id": 12545,
    "content": "e5m2x2 }; Description Convert between different types and sizes"
  },
  {
    "id": 12546,
    "content": "For"
  },
  {
    "id": 12547,
    "content": "f16x2 and"
  },
  {
    "id": 12548,
    "content": "bf16x2 instruction type, two inputs a and b of"
  },
  {
    "id": 12549,
    "content": "f32 type are converted into"
  },
  {
    "id": 12550,
    "content": "f16 or"
  },
  {
    "id": 12552,
    "content": "f16x2 instruction type, destination operand d has f16x2 or b32 type"
  },
  {
    "id": 12553,
    "content": "When converting to"
  },
  {
    "id": 12554,
    "content": "e4m3x2 /"
  },
  {
    "id": 12555,
    "content": "e5m2x2 data formats, the destination operand d has"
  },
  {
    "id": 12556,
    "content": "b16 type"
  },
  {
    "id": 12557,
    "content": "When converting two"
  },
  {
    "id": 12558,
    "content": "f32 inputs to"
  },
  {
    "id": 12559,
    "content": "e4m3x2 /"
  },
  {
    "id": 12561,
    "content": "When converting an"
  },
  {
    "id": 12562,
    "content": "f16x2 input to"
  },
  {
    "id": 12563,
    "content": "e4m3x2 /"
  },
  {
    "id": 12564,
    "content": "e5m2x2 , each"
  },
  {
    "id": 12568,
    "content": "f16x2 ,"
  },
  {
    "id": 12569,
    "content": "e4m3x2,"
  },
  {
    "id": 12570,
    "content": "e5m2x2,"
  },
  {
    "id": 12571,
    "content": "bf16x2 and"
  },
  {
    "id": 12573,
    "content": "e4m3x2 and"
  },
  {
    "id": 12574,
    "content": "e5m2x2 destination types"
  },
  {
    "id": 12575,
    "content": "tf32 as destination type with rounding mode specified as round to nearest, ties away from zero"
  },
  {
    "id": 12576,
    "content": "Semantics if (/* inst type is"
  },
  {
    "id": 12577,
    "content": "f16x2 or"
  },
  {
    "id": 12580,
    "content": "For cvt"
  },
  {
    "id": 12581,
    "content": "ftz"
  },
  {
    "id": 12582,
    "content": "dtype"
  },
  {
    "id": 12583,
    "content": "f32 float-to-integer conversions and cvt"
  },
  {
    "id": 12584,
    "content": "ftz"
  },
  {
    "id": 12586,
    "content": "Modifier"
  },
  {
    "id": 12587,
    "content": "ftz can only be specified when either"
  },
  {
    "id": 12588,
    "content": "dtype or"
  },
  {
    "id": 12589,
    "content": "atype is"
  },
  {
    "id": 12590,
    "content": "f32 and applies only to single precision ( f32 ) inputs and results"
  },
  {
    "id": 12591,
    "content": "sm_1x For cvt"
  },
  {
    "id": 12592,
    "content": "ftz"
  },
  {
    "id": 12593,
    "content": "dtype"
  },
  {
    "id": 12594,
    "content": "f32 float-to-integer conversions and cvt"
  },
  {
    "id": 12595,
    "content": "ftz"
  },
  {
    "id": 12597,
    "content": "Note: In PTX ISA versions 1"
  },
  {
    "id": 12599,
    "content": "Saturation modifier:"
  },
  {
    "id": 12600,
    "content": "sat For integer destination types, sat limits the result to MININT"
  },
  {
    "id": 12601,
    "content": "MAXINT for the size of the operation"
  },
  {
    "id": 12603,
    "content": "e"
  },
  {
    "id": 12604,
    "content": ", the"
  },
  {
    "id": 12606,
    "content": "For float-to-integer conversions, the result is clamped to the destination range by default; i"
  },
  {
    "id": 12607,
    "content": "e,"
  },
  {
    "id": 12608,
    "content": "sat is redundant"
  },
  {
    "id": 12611,
    "content": "Modifier"
  },
  {
    "id": 12612,
    "content": "ftz may be specified to flush single-precision subnormal inputs and results to sign-preserving zero"
  },
  {
    "id": 12613,
    "content": "Note: In PTX ISA versions 1"
  },
  {
    "id": 12615,
    "content": "f64"
  },
  {
    "id": 12616,
    "content": "Specifically, if the PTX ISA version is 1"
  },
  {
    "id": 12618,
    "content": "f32"
  },
  {
    "id": 12619,
    "content": "f16 , cvt f16 f32 , and cvt f32 f32 instructions"
  },
  {
    "id": 12620,
    "content": "Saturation modifier:"
  },
  {
    "id": 12621,
    "content": "sat : For floating-point destination types, sat limits the result to the range [0"
  },
  {
    "id": 12622,
    "content": "0, 1"
  },
  {
    "id": 12623,
    "content": "0]"
  },
  {
    "id": 12624,
    "content": "relu : For"
  },
  {
    "id": 12625,
    "content": "f16 ,"
  },
  {
    "id": 12626,
    "content": "f16x2 ,"
  },
  {
    "id": 12627,
    "content": "bf16 ,"
  },
  {
    "id": 12628,
    "content": "bf16x2 ,"
  },
  {
    "id": 12629,
    "content": "e4m3x2 ,"
  },
  {
    "id": 12630,
    "content": "e5m2x2 and"
  },
  {
    "id": 12631,
    "content": "tf32 destination types,"
  },
  {
    "id": 12632,
    "content": "relu clamps the result to 0 if negative"
  },
  {
    "id": 12633,
    "content": "satfinite : For"
  },
  {
    "id": 12634,
    "content": "f16 ,"
  },
  {
    "id": 12635,
    "content": "f16x2 ,"
  },
  {
    "id": 12636,
    "content": "bf16 ,"
  },
  {
    "id": 12637,
    "content": "bf16x2 ,"
  },
  {
    "id": 12638,
    "content": "e4m3x2 ,"
  },
  {
    "id": 12639,
    "content": "e5m2x2 and"
  },
  {
    "id": 12642,
    "content": "bf16 or"
  },
  {
    "id": 12643,
    "content": "bf16x2 format"
  },
  {
    "id": 12646,
    "content": "bf16 ,"
  },
  {
    "id": 12647,
    "content": "bf16x2 or"
  },
  {
    "id": 12648,
    "content": "tf32 format"
  },
  {
    "id": 12650,
    "content": "relu modifier and {"
  },
  {
    "id": 12651,
    "content": "f16x2 ,"
  },
  {
    "id": 12652,
    "content": "bf16 ,"
  },
  {
    "id": 12653,
    "content": "bf16x2 ,"
  },
  {
    "id": 12654,
    "content": "tf32 } destination formats introduced in PTX ISA version 7"
  },
  {
    "id": 12655,
    "content": "0"
  },
  {
    "id": 12656,
    "content": "relu modifier and {"
  },
  {
    "id": 12657,
    "content": "f16x2 ,"
  },
  {
    "id": 12658,
    "content": "bf16 ,"
  },
  {
    "id": 12659,
    "content": "bf16x2 ,"
  },
  {
    "id": 12660,
    "content": "tf32 } destination formats require sm_80 or higher"
  },
  {
    "id": 12662,
    "content": "sat"
  },
  {
    "id": 12663,
    "content": "convertType"
  },
  {
    "id": 12664,
    "content": "abType d, a, b;"
  },
  {
    "id": 12665,
    "content": "convertType = {"
  },
  {
    "id": 12666,
    "content": "u16,"
  },
  {
    "id": 12667,
    "content": "s16 }"
  },
  {
    "id": 12668,
    "content": "abType = {"
  },
  {
    "id": 12669,
    "content": "s32 } cvt"
  },
  {
    "id": 12670,
    "content": "pack"
  },
  {
    "id": 12671,
    "content": "sat"
  },
  {
    "id": 12672,
    "content": "convertType"
  },
  {
    "id": 12673,
    "content": "abType"
  },
  {
    "id": 12674,
    "content": "cType d, a, b, c;"
  },
  {
    "id": 12675,
    "content": "convertType = {"
  },
  {
    "id": 12676,
    "content": "u2,"
  },
  {
    "id": 12677,
    "content": "s2,"
  },
  {
    "id": 12678,
    "content": "u4,"
  },
  {
    "id": 12679,
    "content": "s4,"
  },
  {
    "id": 12680,
    "content": "u8,"
  },
  {
    "id": 12681,
    "content": "s8 }"
  },
  {
    "id": 12682,
    "content": "abType = {"
  },
  {
    "id": 12683,
    "content": "s32 }"
  },
  {
    "id": 12684,
    "content": "cType = {"
  },
  {
    "id": 12686,
    "content": "cType"
  },
  {
    "id": 12687,
    "content": "The inputs a and b are converted to values of type specified by"
  },
  {
    "id": 12689,
    "content": "reduce"
  },
  {
    "id": 12690,
    "content": "async"
  },
  {
    "id": 12691,
    "content": "bulk  cp"
  },
  {
    "id": 12692,
    "content": "reduce"
  },
  {
    "id": 12693,
    "content": "async"
  },
  {
    "id": 12694,
    "content": "bulk Initiates an asynchronous reduction operation"
  },
  {
    "id": 12696,
    "content": "redOp"
  },
  {
    "id": 12698,
    "content": "dst"
  },
  {
    "id": 12700,
    "content": "The operations supported by redOp are classified as follows: The bit-size operations are"
  },
  {
    "id": 12701,
    "content": "and , or , and"
  },
  {
    "id": 12702,
    "content": "xor"
  },
  {
    "id": 12703,
    "content": "The"
  },
  {
    "id": 12704,
    "content": "inc and"
  },
  {
    "id": 12705,
    "content": "dec operations return a result in the range [0"
  },
  {
    "id": 12706,
    "content": "x] where x is the value at the source state space"
  },
  {
    "id": 12707,
    "content": "The current implementation of cp"
  },
  {
    "id": 12708,
    "content": "reduce"
  },
  {
    "id": 12709,
    "content": "async"
  },
  {
    "id": 12710,
    "content": "bulk"
  },
  {
    "id": 12711,
    "content": "add"
  },
  {
    "id": 12712,
    "content": "f32 flushes subnormal inputs and results to sign-preserving zero"
  },
  {
    "id": 12713,
    "content": "The cp"
  },
  {
    "id": 12714,
    "content": "reduce"
  },
  {
    "id": 12715,
    "content": "async"
  },
  {
    "id": 12716,
    "content": "bulk"
  },
  {
    "id": 12717,
    "content": "add"
  },
  {
    "id": 12718,
    "content": "f16 and cp"
  },
  {
    "id": 12719,
    "content": "reduce"
  },
  {
    "id": 12720,
    "content": "async"
  },
  {
    "id": 12721,
    "content": "bulk"
  },
  {
    "id": 12722,
    "content": "add"
  },
  {
    "id": 12723,
    "content": "bf16 operations require"
  },
  {
    "id": 12724,
    "content": "noftz qualifier"
  },
  {
    "id": 12725,
    "content": "The following table describes the valid combinations of"
  },
  {
    "id": 12726,
    "content": "redOp and element type:"
  },
  {
    "id": 12727,
    "content": "dst"
  },
  {
    "id": 12728,
    "content": "redOp Element type"
  },
  {
    "id": 12729,
    "content": "shared::cluster"
  },
  {
    "id": 12730,
    "content": "add"
  },
  {
    "id": 12731,
    "content": "u32 ,"
  },
  {
    "id": 12732,
    "content": "s32 ,"
  },
  {
    "id": 12733,
    "content": "u64"
  },
  {
    "id": 12734,
    "content": "min ,"
  },
  {
    "id": 12735,
    "content": "max"
  },
  {
    "id": 12736,
    "content": "u32 ,"
  },
  {
    "id": 12737,
    "content": "s32"
  },
  {
    "id": 12738,
    "content": "inc ,"
  },
  {
    "id": 12739,
    "content": "dec"
  },
  {
    "id": 12740,
    "content": "u32"
  },
  {
    "id": 12741,
    "content": "and ,"
  },
  {
    "id": 12742,
    "content": "or ,"
  },
  {
    "id": 12743,
    "content": "xor"
  },
  {
    "id": 12744,
    "content": "b32"
  },
  {
    "id": 12745,
    "content": "global"
  },
  {
    "id": 12746,
    "content": "add"
  },
  {
    "id": 12747,
    "content": "u32 ,"
  },
  {
    "id": 12748,
    "content": "s32 ,"
  },
  {
    "id": 12749,
    "content": "u64 ,"
  },
  {
    "id": 12750,
    "content": "f32 ,"
  },
  {
    "id": 12751,
    "content": "f64 ,"
  },
  {
    "id": 12752,
    "content": "f16 ,"
  },
  {
    "id": 12753,
    "content": "bf16"
  },
  {
    "id": 12754,
    "content": "min ,"
  },
  {
    "id": 12755,
    "content": "max"
  },
  {
    "id": 12756,
    "content": "u32 ,"
  },
  {
    "id": 12757,
    "content": "s32 ,"
  },
  {
    "id": 12758,
    "content": "u64 ,"
  },
  {
    "id": 12759,
    "content": "s64 ,"
  },
  {
    "id": 12760,
    "content": "f16 ,"
  },
  {
    "id": 12761,
    "content": "bf16"
  },
  {
    "id": 12762,
    "content": "inc ,"
  },
  {
    "id": 12763,
    "content": "dec"
  },
  {
    "id": 12764,
    "content": "u32"
  },
  {
    "id": 12765,
    "content": "and ,"
  },
  {
    "id": 12766,
    "content": "or ,"
  },
  {
    "id": 12767,
    "content": "xor"
  },
  {
    "id": 12768,
    "content": "b32 ,"
  },
  {
    "id": 12769,
    "content": "b64 The modifier"
  },
  {
    "id": 12771,
    "content": "dst"
  },
  {
    "id": 12772,
    "content": "src Description"
  },
  {
    "id": 12773,
    "content": "mbarrier::"
  },
  {
    "id": 12774,
    "content": "shared::cluster"
  },
  {
    "id": 12775,
    "content": "global mbarrier based completion mechanism"
  },
  {
    "id": 12776,
    "content": "shared::cluster shared::cta"
  },
  {
    "id": 12777,
    "content": "bulk_group"
  },
  {
    "id": 12778,
    "content": "global"
  },
  {
    "id": 12779,
    "content": "shared::cta Bulk async-group based completion mechanism The modifier"
  },
  {
    "id": 12780,
    "content": "mbarrier::complete_tx::bytes specifies that the cp"
  },
  {
    "id": 12781,
    "content": "reduce"
  },
  {
    "id": 12782,
    "content": "async"
  },
  {
    "id": 12783,
    "content": "bulk variant uses mbarrier based completion mechanism"
  },
  {
    "id": 12785,
    "content": "The modifier"
  },
  {
    "id": 12786,
    "content": "bulk_group specifies that the cp"
  },
  {
    "id": 12787,
    "content": "reduce"
  },
  {
    "id": 12788,
    "content": "async bulk variant uses bulk async-group based completion mechanism"
  },
  {
    "id": 12789,
    "content": "The qualifier"
  },
  {
    "id": 12790,
    "content": "level::cache_hint is only supported when at least one of the"
  },
  {
    "id": 12791,
    "content": "src or"
  },
  {
    "id": 12792,
    "content": "dst statespaces is"
  },
  {
    "id": 12793,
    "content": "global state space"
  },
  {
    "id": 12794,
    "content": "Each reduction operation performed by the cp"
  },
  {
    "id": 12795,
    "content": "reduce"
  },
  {
    "id": 12796,
    "content": "async"
  },
  {
    "id": 12797,
    "content": "bulk has individually"
  },
  {
    "id": 12798,
    "content": "relaxed"
  },
  {
    "id": 12799,
    "content": "gpu memory ordering semantics"
  },
  {
    "id": 12800,
    "content": "The load operations in cp"
  },
  {
    "id": 12801,
    "content": "reduce"
  },
  {
    "id": 12802,
    "content": "async"
  },
  {
    "id": 12803,
    "content": "bulk are treated as weak memory operation and the complete-tx operation on the mbarrier has"
  },
  {
    "id": 12804,
    "content": "release semantics at the"
  },
  {
    "id": 12805,
    "content": "cluster scope as described in the Memory Consistency Model"
  },
  {
    "id": 12806,
    "content": "Examples cp"
  },
  {
    "id": 12807,
    "content": "reduce"
  },
  {
    "id": 12808,
    "content": "async"
  },
  {
    "id": 12809,
    "content": "bulk"
  },
  {
    "id": 12810,
    "content": "shared::cluster shared::cta"
  },
  {
    "id": 12811,
    "content": "mbarrier::complete_tx::bytes"
  },
  {
    "id": 12812,
    "content": "add"
  },
  {
    "id": 12813,
    "content": "u64 [dstMem], [srcMem], size, [mbar]; cp"
  },
  {
    "id": 12814,
    "content": "reduce"
  },
  {
    "id": 12815,
    "content": "async"
  },
  {
    "id": 12816,
    "content": "bulk"
  },
  {
    "id": 12817,
    "content": "shared::cluster shared::cta"
  },
  {
    "id": 12818,
    "content": "mbarrier::complete_tx::bytes"
  },
  {
    "id": 12819,
    "content": "min"
  },
  {
    "id": 12820,
    "content": "s32 [dstMem], [srcMem], size, [mbar]; cp"
  },
  {
    "id": 12821,
    "content": "reduce"
  },
  {
    "id": 12822,
    "content": "async"
  },
  {
    "id": 12823,
    "content": "bulk"
  },
  {
    "id": 12824,
    "content": "global"
  },
  {
    "id": 12825,
    "content": "shared::cta"
  },
  {
    "id": 12826,
    "content": "bulk_group"
  },
  {
    "id": 12827,
    "content": "min"
  },
  {
    "id": 12828,
    "content": "f16 [dstMem], [srcMem], size; cp"
  },
  {
    "id": 12829,
    "content": "reduce"
  },
  {
    "id": 12830,
    "content": "async"
  },
  {
    "id": 12831,
    "content": "bulk"
  },
  {
    "id": 12832,
    "content": "global"
  },
  {
    "id": 12833,
    "content": "shared::cta"
  },
  {
    "id": 12834,
    "content": "bulk_group"
  },
  {
    "id": 12835,
    "content": "L2::cache_hint"
  },
  {
    "id": 12836,
    "content": "xor"
  },
  {
    "id": 12837,
    "content": "s32 [dstMem], [srcMem], size, policy; cp"
  },
  {
    "id": 12838,
    "content": "reduce"
  },
  {
    "id": 12839,
    "content": "async"
  },
  {
    "id": 12840,
    "content": "bulk"
  },
  {
    "id": 12841,
    "content": "global"
  },
  {
    "id": 12842,
    "content": "shared::cta"
  },
  {
    "id": 12843,
    "content": "bulk_group"
  },
  {
    "id": 12844,
    "content": "add"
  },
  {
    "id": 12845,
    "content": "noftz"
  },
  {
    "id": 12846,
    "content": "f16 [dstMem], [srcMem], size; 9"
  },
  {
    "id": 12847,
    "content": "7"
  },
  {
    "id": 12848,
    "content": "8"
  },
  {
    "id": 12849,
    "content": "24"
  },
  {
    "id": 12850,
    "content": "8"
  },
  {
    "id": 12851,
    "content": "Data Movement and Conversion Instructions: cp"
  },
  {
    "id": 12852,
    "content": "async"
  },
  {
    "id": 12853,
    "content": "bulk"
  },
  {
    "id": 12854,
    "content": "prefetch  cp"
  },
  {
    "id": 12855,
    "content": "async"
  },
  {
    "id": 12856,
    "content": "bulk"
  },
  {
    "id": 12857,
    "content": "prefetch Provides a hint to the system to initiate the asynchronous prefetch of data to the cache"
  },
  {
    "id": 12858,
    "content": "Syntax cp"
  },
  {
    "id": 12859,
    "content": "async"
  },
  {
    "id": 12860,
    "content": "bulk"
  },
  {
    "id": 12861,
    "content": "prefetch"
  },
  {
    "id": 12862,
    "content": "L2"
  },
  {
    "id": 12863,
    "content": "src{"
  },
  {
    "id": 12864,
    "content": "level::cache_hint} [srcMem], size {, cache-policy}"
  },
  {
    "id": 12865,
    "content": "src = {"
  },
  {
    "id": 12866,
    "content": "global }"
  },
  {
    "id": 12867,
    "content": "level::cache_hint = { L2::cache_hint } Description cp"
  },
  {
    "id": 12868,
    "content": "async"
  },
  {
    "id": 12869,
    "content": "bulk"
  },
  {
    "id": 12871,
    "content": "src statespace, to the L2 cache"
  },
  {
    "id": 12872,
    "content": "The 32-bit operand size specifies the amount of memory to be prefetched in terms of number of bytes"
  },
  {
    "id": 12873,
    "content": "Examples cp"
  },
  {
    "id": 12874,
    "content": "async"
  },
  {
    "id": 12875,
    "content": "bulk"
  },
  {
    "id": 12876,
    "content": "prefetch"
  },
  {
    "id": 12877,
    "content": "L2"
  },
  {
    "id": 12878,
    "content": "global [srcMem], size; cp"
  },
  {
    "id": 12879,
    "content": "async"
  },
  {
    "id": 12880,
    "content": "bulk"
  },
  {
    "id": 12881,
    "content": "prefetch"
  },
  {
    "id": 12882,
    "content": "L2"
  },
  {
    "id": 12883,
    "content": "global"
  },
  {
    "id": 12884,
    "content": "L2::cache_hint [srcMem], size, policy; 9"
  },
  {
    "id": 12885,
    "content": "7"
  },
  {
    "id": 12886,
    "content": "8"
  },
  {
    "id": 12887,
    "content": "24"
  },
  {
    "id": 12888,
    "content": "9"
  },
  {
    "id": 12889,
    "content": "Data Movement and Conversion Instructions: cp"
  },
  {
    "id": 12890,
    "content": "async"
  },
  {
    "id": 12891,
    "content": "bulk"
  },
  {
    "id": 12892,
    "content": "tensor  cp"
  },
  {
    "id": 12893,
    "content": "async"
  },
  {
    "id": 12894,
    "content": "bulk"
  },
  {
    "id": 12895,
    "content": "tensor Initiates an asynchronous copy operation on the tensor data from one state space to another"
  },
  {
    "id": 12898,
    "content": "dim"
  },
  {
    "id": 12899,
    "content": "The modifier"
  },
  {
    "id": 12901,
    "content": "dst"
  },
  {
    "id": 12902,
    "content": "src Description"
  },
  {
    "id": 12903,
    "content": "mbarrier::"
  },
  {
    "id": 12904,
    "content": "shared::cluster"
  },
  {
    "id": 12905,
    "content": "global mbarrier based completion mechanism"
  },
  {
    "id": 12906,
    "content": "bulk_group"
  },
  {
    "id": 12907,
    "content": "global"
  },
  {
    "id": 12908,
    "content": "shared::cta Bulk async-group based completion mechanism The modifier"
  },
  {
    "id": 12909,
    "content": "mbarrier::complete_tx::bytes specifies that the cp"
  },
  {
    "id": 12910,
    "content": "async"
  },
  {
    "id": 12911,
    "content": "bulk"
  },
  {
    "id": 12912,
    "content": "tensor variant uses mbarrier based completion mechanism"
  },
  {
    "id": 12913,
    "content": "The modifier"
  },
  {
    "id": 12914,
    "content": "bulk_group specifies that the cp"
  },
  {
    "id": 12915,
    "content": "async"
  },
  {
    "id": 12916,
    "content": "bulk tensor variant uses bulk async-group based completion mechanism"
  },
  {
    "id": 12917,
    "content": "The qualifier"
  },
  {
    "id": 12918,
    "content": "load_mode specifies how the data in the source location is copied into the destination location"
  },
  {
    "id": 12919,
    "content": "In"
  },
  {
    "id": 12920,
    "content": "tile mode, the multi-dimensional layout of the source tensor is preserved at the destination"
  },
  {
    "id": 12921,
    "content": "In"
  },
  {
    "id": 12923,
    "content": "The length of the vector operand im2colOffsets is two less than the number of dimension"
  },
  {
    "id": 12924,
    "content": "dim of the tensor operation"
  },
  {
    "id": 12925,
    "content": "The modifier"
  },
  {
    "id": 12926,
    "content": "im2col_no_offs is the same as"
  },
  {
    "id": 12927,
    "content": "im2col mode except there is no im2colOffsets vector involved"
  },
  {
    "id": 12928,
    "content": "The optional modifier"
  },
  {
    "id": 12930,
    "content": "signal is also multicast to the same offset as mbar in the shared memory of the destination CTA"
  },
  {
    "id": 12931,
    "content": "The copy operation in cp"
  },
  {
    "id": 12932,
    "content": "async"
  },
  {
    "id": 12933,
    "content": "bulk"
  },
  {
    "id": 12934,
    "content": "tensor is treated as a weak memory operation and the complete-tx operation on the mbarrier has"
  },
  {
    "id": 12935,
    "content": "release semantics at the"
  },
  {
    "id": 12936,
    "content": "cluster scope as described in the Memory Consistency Model"
  },
  {
    "id": 12937,
    "content": "Notes"
  },
  {
    "id": 12939,
    "content": "Examples"
  },
  {
    "id": 12940,
    "content": "reg"
  },
  {
    "id": 12941,
    "content": "b16 ctaMask;"
  },
  {
    "id": 12942,
    "content": "reg"
  },
  {
    "id": 12943,
    "content": "u16 i2cOffW, i2cOffH, i2cOffD;"
  },
  {
    "id": 12944,
    "content": "reg"
  },
  {
    "id": 12945,
    "content": "b64 l2CachePolicy; cp"
  },
  {
    "id": 12946,
    "content": "async"
  },
  {
    "id": 12947,
    "content": "bulk"
  },
  {
    "id": 12948,
    "content": "tensor"
  },
  {
    "id": 12949,
    "content": "1d"
  },
  {
    "id": 12950,
    "content": "shared::cluster"
  },
  {
    "id": 12951,
    "content": "global"
  },
  {
    "id": 12952,
    "content": "tile [sMem0], [tensorMap0, {tc0}], [mbar0]; @p cp"
  },
  {
    "id": 12953,
    "content": "async"
  },
  {
    "id": 12954,
    "content": "bulk"
  },
  {
    "id": 12955,
    "content": "tensor"
  },
  {
    "id": 12956,
    "content": "2d"
  },
  {
    "id": 12957,
    "content": "shared::cluster"
  },
  {
    "id": 12958,
    "content": "global"
  },
  {
    "id": 12959,
    "content": "mbarrier::complete_tx::bytes"
  },
  {
    "id": 12960,
    "content": "multicast::cluster [sMem1], [tensorMap1, {tc0, tc1}], [mbar2], ctaMask; @p cp"
  },
  {
    "id": 12961,
    "content": "async"
  },
  {
    "id": 12962,
    "content": "bulk"
  },
  {
    "id": 12963,
    "content": "tensor"
  },
  {
    "id": 12964,
    "content": "5d"
  },
  {
    "id": 12965,
    "content": "shared::cluster"
  },
  {
    "id": 12966,
    "content": "global"
  },
  {
    "id": 12967,
    "content": "im2col"
  },
  {
    "id": 12969,
    "content": "async"
  },
  {
    "id": 12970,
    "content": "bulk"
  },
  {
    "id": 12971,
    "content": "tensor"
  },
  {
    "id": 12972,
    "content": "3d"
  },
  {
    "id": 12973,
    "content": "im2col"
  },
  {
    "id": 12974,
    "content": "shared::cluster"
  },
  {
    "id": 12975,
    "content": "global"
  },
  {
    "id": 12976,
    "content": "mbarrier::complete_tx::bytes"
  },
  {
    "id": 12977,
    "content": "L2::cache_hint [sMem3], [tensorMap3, {tc0, tc1, tc2}], [mbar3], {i2cOffW}, policy; @p cp"
  },
  {
    "id": 12978,
    "content": "async"
  },
  {
    "id": 12979,
    "content": "bulk"
  },
  {
    "id": 12980,
    "content": "tensor"
  },
  {
    "id": 12981,
    "content": "1d"
  },
  {
    "id": 12982,
    "content": "global"
  },
  {
    "id": 12983,
    "content": "shared::cta"
  },
  {
    "id": 12984,
    "content": "bulk_group [tensorMap3, {tc0}], [sMem3]; 9"
  },
  {
    "id": 12985,
    "content": "7"
  },
  {
    "id": 12986,
    "content": "8"
  },
  {
    "id": 12987,
    "content": "24"
  },
  {
    "id": 12988,
    "content": "10"
  },
  {
    "id": 12989,
    "content": "Data Movement and Conversion Instructions: cp"
  },
  {
    "id": 12990,
    "content": "reduce"
  },
  {
    "id": 12991,
    "content": "async"
  },
  {
    "id": 12992,
    "content": "bulk"
  },
  {
    "id": 12993,
    "content": "tensor  cp"
  },
  {
    "id": 12994,
    "content": "reduce"
  },
  {
    "id": 12995,
    "content": "async"
  },
  {
    "id": 12996,
    "content": "bulk"
  },
  {
    "id": 12997,
    "content": "tensor Initiates an asynchronous reduction operation on the tensor data"
  },
  {
    "id": 12998,
    "content": "Syntax   shared::cta -> global: cp"
  },
  {
    "id": 12999,
    "content": "reduce"
  },
  {
    "id": 13000,
    "content": "async"
  },
  {
    "id": 13001,
    "content": "bulk"
  },
  {
    "id": 13002,
    "content": "tensor"
  },
  {
    "id": 13003,
    "content": "dim"
  },
  {
    "id": 13004,
    "content": "dst"
  },
  {
    "id": 13005,
    "content": "src"
  },
  {
    "id": 13006,
    "content": "redOp{"
  },
  {
    "id": 13007,
    "content": "load_mode}"
  },
  {
    "id": 13008,
    "content": "completion_mechanism{"
  },
  {
    "id": 13009,
    "content": "level::cache_hint} [tensorMap, tensorCoords], [srcMem] {,cache-policy}"
  },
  {
    "id": 13010,
    "content": "dst = {"
  },
  {
    "id": 13011,
    "content": "global }"
  },
  {
    "id": 13012,
    "content": "src = {"
  },
  {
    "id": 13013,
    "content": "shared::cta }"
  },
  {
    "id": 13014,
    "content": "dim = {"
  },
  {
    "id": 13015,
    "content": "1d,"
  },
  {
    "id": 13016,
    "content": "2d,"
  },
  {
    "id": 13017,
    "content": "3d,"
  },
  {
    "id": 13018,
    "content": "4d,"
  },
  {
    "id": 13019,
    "content": "5d }"
  },
  {
    "id": 13020,
    "content": "completion_mechanism = {"
  },
  {
    "id": 13021,
    "content": "bulk_group }"
  },
  {
    "id": 13022,
    "content": "load_mode = {"
  },
  {
    "id": 13023,
    "content": "tile,"
  },
  {
    "id": 13024,
    "content": "im2col_no_offs }"
  },
  {
    "id": 13025,
    "content": "redOp = {"
  },
  {
    "id": 13026,
    "content": "add,"
  },
  {
    "id": 13027,
    "content": "min,"
  },
  {
    "id": 13028,
    "content": "max,"
  },
  {
    "id": 13029,
    "content": "inc,"
  },
  {
    "id": 13030,
    "content": "dec,"
  },
  {
    "id": 13031,
    "content": "and,"
  },
  {
    "id": 13032,
    "content": "or,"
  },
  {
    "id": 13033,
    "content": "xor} Description cp"
  },
  {
    "id": 13034,
    "content": "reduce"
  },
  {
    "id": 13035,
    "content": "async"
  },
  {
    "id": 13036,
    "content": "bulk"
  },
  {
    "id": 13039,
    "content": "The following table describes the valid combinations of"
  },
  {
    "id": 13040,
    "content": "redOp and element type: redOp Element type"
  },
  {
    "id": 13041,
    "content": "add"
  },
  {
    "id": 13042,
    "content": "u32 ,"
  },
  {
    "id": 13043,
    "content": "s32 ,"
  },
  {
    "id": 13044,
    "content": "u64 ,"
  },
  {
    "id": 13045,
    "content": "f32 ,"
  },
  {
    "id": 13046,
    "content": "f16 ,"
  },
  {
    "id": 13047,
    "content": "bf16"
  },
  {
    "id": 13048,
    "content": "min ,"
  },
  {
    "id": 13049,
    "content": "max"
  },
  {
    "id": 13050,
    "content": "u32 ,"
  },
  {
    "id": 13051,
    "content": "s32 ,"
  },
  {
    "id": 13052,
    "content": "u64 ,"
  },
  {
    "id": 13053,
    "content": "s64 ,"
  },
  {
    "id": 13054,
    "content": "f16 ,"
  },
  {
    "id": 13055,
    "content": "bf16"
  },
  {
    "id": 13056,
    "content": "inc ,"
  },
  {
    "id": 13057,
    "content": "dec"
  },
  {
    "id": 13058,
    "content": "u32"
  },
  {
    "id": 13059,
    "content": "and ,"
  },
  {
    "id": 13060,
    "content": "or ,"
  },
  {
    "id": 13061,
    "content": "xor"
  },
  {
    "id": 13062,
    "content": "b32 ,"
  },
  {
    "id": 13063,
    "content": "b64 The modifier"
  },
  {
    "id": 13065,
    "content": "Value"
  },
  {
    "id": 13066,
    "content": "bulk_group of the modifier"
  },
  {
    "id": 13067,
    "content": "completion_mechanism specifies that cp"
  },
  {
    "id": 13068,
    "content": "reduce"
  },
  {
    "id": 13069,
    "content": "async"
  },
  {
    "id": 13070,
    "content": "bulk tensor instruction uses bulk async-group based completion mechanism"
  },
  {
    "id": 13071,
    "content": "In"
  },
  {
    "id": 13073,
    "content": "Each reduction operation performed by cp"
  },
  {
    "id": 13074,
    "content": "reduce"
  },
  {
    "id": 13075,
    "content": "async"
  },
  {
    "id": 13076,
    "content": "bulk"
  },
  {
    "id": 13077,
    "content": "tensor has individually"
  },
  {
    "id": 13078,
    "content": "relaxed"
  },
  {
    "id": 13079,
    "content": "gpu memory ordering semantics"
  },
  {
    "id": 13080,
    "content": "The load operations in cp"
  },
  {
    "id": 13081,
    "content": "reduce"
  },
  {
    "id": 13082,
    "content": "async"
  },
  {
    "id": 13083,
    "content": "bulk"
  },
  {
    "id": 13084,
    "content": "tensor are treated as weak memory operations and the complete-tx operation on the mbarrier has"
  },
  {
    "id": 13085,
    "content": "release semantics at the"
  },
  {
    "id": 13086,
    "content": "cluster scope as described in the Memory Consistency Model"
  },
  {
    "id": 13087,
    "content": "Examples cp"
  },
  {
    "id": 13088,
    "content": "reduce"
  },
  {
    "id": 13089,
    "content": "async"
  },
  {
    "id": 13090,
    "content": "bulk"
  },
  {
    "id": 13091,
    "content": "tensor"
  },
  {
    "id": 13092,
    "content": "1d"
  },
  {
    "id": 13093,
    "content": "global"
  },
  {
    "id": 13094,
    "content": "shared::cta"
  },
  {
    "id": 13095,
    "content": "add"
  },
  {
    "id": 13096,
    "content": "tile"
  },
  {
    "id": 13097,
    "content": "bulk_group [tensorMap0, {tc0}], [sMem0]; cp"
  },
  {
    "id": 13098,
    "content": "reduce"
  },
  {
    "id": 13099,
    "content": "async"
  },
  {
    "id": 13100,
    "content": "bulk"
  },
  {
    "id": 13101,
    "content": "tensor"
  },
  {
    "id": 13102,
    "content": "2d"
  },
  {
    "id": 13103,
    "content": "global"
  },
  {
    "id": 13104,
    "content": "shared::cta"
  },
  {
    "id": 13105,
    "content": "and"
  },
  {
    "id": 13106,
    "content": "bulk_group"
  },
  {
    "id": 13107,
    "content": "L2::cache_hint [tensorMap1, {tc0, tc1}], [sMem1] , policy; cp"
  },
  {
    "id": 13108,
    "content": "reduce"
  },
  {
    "id": 13109,
    "content": "async"
  },
  {
    "id": 13110,
    "content": "bulk"
  },
  {
    "id": 13111,
    "content": "tensor"
  },
  {
    "id": 13112,
    "content": "3d"
  },
  {
    "id": 13113,
    "content": "global"
  },
  {
    "id": 13114,
    "content": "shared::cta"
  },
  {
    "id": 13115,
    "content": "xor"
  },
  {
    "id": 13116,
    "content": "im2col"
  },
  {
    "id": 13117,
    "content": "bulk_group [tensorMap2, {tc0, tc1, tc2}], [sMem2] 9"
  },
  {
    "id": 13118,
    "content": "7"
  },
  {
    "id": 13119,
    "content": "8"
  },
  {
    "id": 13120,
    "content": "24"
  },
  {
    "id": 13121,
    "content": "11"
  },
  {
    "id": 13122,
    "content": "Data Movement and Conversion Instructions: cp"
  },
  {
    "id": 13123,
    "content": "async"
  },
  {
    "id": 13124,
    "content": "bulk"
  },
  {
    "id": 13125,
    "content": "prefetch"
  },
  {
    "id": 13126,
    "content": "tensor  cp"
  },
  {
    "id": 13127,
    "content": "async"
  },
  {
    "id": 13128,
    "content": "bulk"
  },
  {
    "id": 13130,
    "content": "Syntax   global -> shared::cluster: cp"
  },
  {
    "id": 13131,
    "content": "async"
  },
  {
    "id": 13132,
    "content": "bulk"
  },
  {
    "id": 13133,
    "content": "prefetch"
  },
  {
    "id": 13134,
    "content": "tensor"
  },
  {
    "id": 13135,
    "content": "dim"
  },
  {
    "id": 13136,
    "content": "L2"
  },
  {
    "id": 13137,
    "content": "src{"
  },
  {
    "id": 13138,
    "content": "load_mode}{"
  },
  {
    "id": 13139,
    "content": "level::cache_hint} [tensorMap, tensorCoords] {, im2colOffsets } {, cache-policy}"
  },
  {
    "id": 13140,
    "content": "src = {"
  },
  {
    "id": 13141,
    "content": "global }"
  },
  {
    "id": 13142,
    "content": "dim = {"
  },
  {
    "id": 13143,
    "content": "1d,"
  },
  {
    "id": 13144,
    "content": "2d,"
  },
  {
    "id": 13145,
    "content": "3d,"
  },
  {
    "id": 13146,
    "content": "4d,"
  },
  {
    "id": 13147,
    "content": "5d }"
  },
  {
    "id": 13148,
    "content": "load_mode = {"
  },
  {
    "id": 13149,
    "content": "tile,"
  },
  {
    "id": 13150,
    "content": "im2col }"
  },
  {
    "id": 13151,
    "content": "level::cache_hint = { L2::cache_hint } Description cp"
  },
  {
    "id": 13152,
    "content": "async"
  },
  {
    "id": 13153,
    "content": "bulk"
  },
  {
    "id": 13155,
    "content": "src statespace to the L2 cache"
  },
  {
    "id": 13156,
    "content": "cp"
  },
  {
    "id": 13157,
    "content": "async"
  },
  {
    "id": 13158,
    "content": "bulk"
  },
  {
    "id": 13159,
    "content": "prefetch"
  },
  {
    "id": 13160,
    "content": "tensor is treated as a weak memory operation in the Memory Consistency Model"
  },
  {
    "id": 13161,
    "content": "Examples"
  },
  {
    "id": 13162,
    "content": "reg"
  },
  {
    "id": 13163,
    "content": "b16 ctaMask;"
  },
  {
    "id": 13164,
    "content": "reg"
  },
  {
    "id": 13165,
    "content": "u16 i2cOffW, i2cOffH, i2cOffD;"
  },
  {
    "id": 13166,
    "content": "reg"
  },
  {
    "id": 13167,
    "content": "b64 l2CachePolicy; cp"
  },
  {
    "id": 13168,
    "content": "async"
  },
  {
    "id": 13169,
    "content": "bulk"
  },
  {
    "id": 13170,
    "content": "prefetch"
  },
  {
    "id": 13171,
    "content": "tensor"
  },
  {
    "id": 13172,
    "content": "1d"
  },
  {
    "id": 13173,
    "content": "L2"
  },
  {
    "id": 13174,
    "content": "global"
  },
  {
    "id": 13175,
    "content": "tile [tensorMap0, {tc0}]; @p cp"
  },
  {
    "id": 13176,
    "content": "async"
  },
  {
    "id": 13177,
    "content": "bulk"
  },
  {
    "id": 13178,
    "content": "prefetch"
  },
  {
    "id": 13179,
    "content": "tensor"
  },
  {
    "id": 13180,
    "content": "2d"
  },
  {
    "id": 13181,
    "content": "L2"
  },
  {
    "id": 13182,
    "content": "global [tensorMap1, {tc0, tc1}]; @p cp"
  },
  {
    "id": 13183,
    "content": "async"
  },
  {
    "id": 13184,
    "content": "bulk"
  },
  {
    "id": 13185,
    "content": "prefetch"
  },
  {
    "id": 13186,
    "content": "tensor"
  },
  {
    "id": 13187,
    "content": "5d"
  },
  {
    "id": 13188,
    "content": "L2"
  },
  {
    "id": 13189,
    "content": "global"
  },
  {
    "id": 13190,
    "content": "im2col [tensorMap2, {tc0, tc1, tc2, tc3, tc4}], {i2cOffW, i2cOffH, i2cOffD}; @p cp"
  },
  {
    "id": 13191,
    "content": "async"
  },
  {
    "id": 13192,
    "content": "bulk"
  },
  {
    "id": 13193,
    "content": "prefetch"
  },
  {
    "id": 13194,
    "content": "tensor"
  },
  {
    "id": 13195,
    "content": "3d"
  },
  {
    "id": 13196,
    "content": "L2"
  },
  {
    "id": 13197,
    "content": "global"
  },
  {
    "id": 13198,
    "content": "im2col"
  },
  {
    "id": 13199,
    "content": "L2::cache_hint [tensorMap3, {tc0, tc1, tc2}], {i2cOffW}, policy; 9"
  },
  {
    "id": 13200,
    "content": "7"
  },
  {
    "id": 13201,
    "content": "8"
  },
  {
    "id": 13202,
    "content": "24"
  },
  {
    "id": 13203,
    "content": "12"
  },
  {
    "id": 13204,
    "content": "Data Movement and Conversion Instructions: cp"
  },
  {
    "id": 13205,
    "content": "async"
  },
  {
    "id": 13206,
    "content": "bulk"
  },
  {
    "id": 13207,
    "content": "commit_group  cp"
  },
  {
    "id": 13208,
    "content": "async"
  },
  {
    "id": 13209,
    "content": "bulk"
  },
  {
    "id": 13210,
    "content": "commit_group Commits all prior initiated but uncommitted cp"
  },
  {
    "id": 13211,
    "content": "async"
  },
  {
    "id": 13212,
    "content": "bulk instructions into a cp"
  },
  {
    "id": 13213,
    "content": "async"
  },
  {
    "id": 13214,
    "content": "bulk-group"
  },
  {
    "id": 13215,
    "content": "Syntax cp"
  },
  {
    "id": 13216,
    "content": "async"
  },
  {
    "id": 13217,
    "content": "bulk"
  },
  {
    "id": 13218,
    "content": "commit_group; Description cp"
  },
  {
    "id": 13219,
    "content": "async"
  },
  {
    "id": 13220,
    "content": "bulk commit_group instruction creates a new per-thread bulk async-group and batches all prior cp{"
  },
  {
    "id": 13221,
    "content": "reduce}"
  },
  {
    "id": 13222,
    "content": "async"
  },
  {
    "id": 13223,
    "content": "bulk"
  },
  {
    "id": 13224,
    "content": "{"
  },
  {
    "id": 13225,
    "content": "prefetch}{"
  },
  {
    "id": 13227,
    "content": "reduce}"
  },
  {
    "id": 13228,
    "content": "async"
  },
  {
    "id": 13229,
    "content": "bulk"
  },
  {
    "id": 13230,
    "content": "{"
  },
  {
    "id": 13231,
    "content": "prefetch}{"
  },
  {
    "id": 13233,
    "content": "{"
  },
  {
    "id": 13234,
    "content": "prefetch}{"
  },
  {
    "id": 13235,
    "content": "tensor} instructions then cp"
  },
  {
    "id": 13236,
    "content": "async"
  },
  {
    "id": 13237,
    "content": "bulk commit_group results in an empty bulk async-group"
  },
  {
    "id": 13238,
    "content": "Data Movement and Conversion Instructions: cp"
  },
  {
    "id": 13239,
    "content": "async"
  },
  {
    "id": 13240,
    "content": "bulk"
  },
  {
    "id": 13241,
    "content": "wait_group  cp"
  },
  {
    "id": 13242,
    "content": "async"
  },
  {
    "id": 13243,
    "content": "bulk wait_group Wait for completion of bulk async-groups"
  },
  {
    "id": 13244,
    "content": "Syntax cp"
  },
  {
    "id": 13245,
    "content": "async"
  },
  {
    "id": 13246,
    "content": "bulk"
  },
  {
    "id": 13247,
    "content": "wait_group{"
  },
  {
    "id": 13248,
    "content": "read} N; Description cp"
  },
  {
    "id": 13249,
    "content": "async"
  },
  {
    "id": 13251,
    "content": "By default, cp"
  },
  {
    "id": 13252,
    "content": "async"
  },
  {
    "id": 13254,
    "content": "The optional"
  },
  {
    "id": 13257,
    "content": "mode"
  },
  {
    "id": 13258,
    "content": "field1{"
  },
  {
    "id": 13259,
    "content": "ss}"
  },
  {
    "id": 13260,
    "content": "b1024"
  },
  {
    "id": 13261,
    "content": "type [addr], new_val; tensormap"
  },
  {
    "id": 13262,
    "content": "replace"
  },
  {
    "id": 13263,
    "content": "mode"
  },
  {
    "id": 13264,
    "content": "field2{"
  },
  {
    "id": 13265,
    "content": "ss}"
  },
  {
    "id": 13266,
    "content": "b1024"
  },
  {
    "id": 13267,
    "content": "type [addr], ord, new_val; tensormap"
  },
  {
    "id": 13268,
    "content": "replace"
  },
  {
    "id": 13269,
    "content": "mode"
  },
  {
    "id": 13270,
    "content": "field3{"
  },
  {
    "id": 13271,
    "content": "ss}"
  },
  {
    "id": 13272,
    "content": "b1024"
  },
  {
    "id": 13273,
    "content": "type [addr], new_val;"
  },
  {
    "id": 13274,
    "content": "mode = {"
  },
  {
    "id": 13275,
    "content": "tile }"
  },
  {
    "id": 13276,
    "content": "field1 = {"
  },
  {
    "id": 13277,
    "content": "global_address,"
  },
  {
    "id": 13278,
    "content": "rank }"
  },
  {
    "id": 13279,
    "content": "field2 = {"
  },
  {
    "id": 13280,
    "content": "box_dim,"
  },
  {
    "id": 13281,
    "content": "global_dim,"
  },
  {
    "id": 13282,
    "content": "global_stride,"
  },
  {
    "id": 13283,
    "content": "element_stride }"
  },
  {
    "id": 13284,
    "content": "field3 = {"
  },
  {
    "id": 13285,
    "content": "elemtype,"
  },
  {
    "id": 13286,
    "content": "interleave_layout,"
  },
  {
    "id": 13287,
    "content": "swizzle_mode,"
  },
  {
    "id": 13288,
    "content": "fill_mode }"
  },
  {
    "id": 13289,
    "content": "ss = {"
  },
  {
    "id": 13290,
    "content": "global,"
  },
  {
    "id": 13291,
    "content": "shared::cta }"
  },
  {
    "id": 13292,
    "content": "type = {"
  },
  {
    "id": 13293,
    "content": "b32,"
  },
  {
    "id": 13294,
    "content": "b64 } Description The tensormap"
  },
  {
    "id": 13297,
    "content": "When"
  },
  {
    "id": 13299,
    "content": "elemtype"
  },
  {
    "id": 13300,
    "content": "interleave_layout"
  },
  {
    "id": 13301,
    "content": "swizzle_mode"
  },
  {
    "id": 13302,
    "content": "fill_mode 0"
  },
  {
    "id": 13304,
    "content": "u64 x x x 5"
  },
  {
    "id": 13305,
    "content": "s64 x x x 6"
  },
  {
    "id": 13306,
    "content": "f16 x x x 7"
  },
  {
    "id": 13307,
    "content": "f32 x x x 8 f32"
  },
  {
    "id": 13308,
    "content": "ftz x x x 9"
  },
  {
    "id": 13309,
    "content": "f64 x x x 10"
  },
  {
    "id": 13310,
    "content": "bf16 x x x 11"
  },
  {
    "id": 13311,
    "content": "tf32 x x x 12 tf32"
  },
  {
    "id": 13312,
    "content": "ftz x x x If no state space is specified then Generic Addressing is used"
  },
  {
    "id": 13313,
    "content": "If the address specified by addr does not fall within the address window of"
  },
  {
    "id": 13314,
    "content": "global or"
  },
  {
    "id": 13315,
    "content": "shared::cta state space then the behavior is undefined"
  },
  {
    "id": 13316,
    "content": "tensormap"
  },
  {
    "id": 13318,
    "content": "Examples tensormap"
  },
  {
    "id": 13319,
    "content": "replace"
  },
  {
    "id": 13320,
    "content": "tile"
  },
  {
    "id": 13321,
    "content": "global_address"
  },
  {
    "id": 13322,
    "content": "shared::cta"
  },
  {
    "id": 13323,
    "content": "b1024"
  },
  {
    "id": 13324,
    "content": "b64 [sMem], new_val; 9"
  },
  {
    "id": 13325,
    "content": "7"
  },
  {
    "id": 13326,
    "content": "9"
  },
  {
    "id": 13328,
    "content": "9"
  },
  {
    "id": 13329,
    "content": "7"
  },
  {
    "id": 13330,
    "content": "9"
  },
  {
    "id": 13331,
    "content": "1"
  },
  {
    "id": 13334,
    "content": "mode Textures 128 256 Samplers 16 32 Surfaces 8 16 The texturing mode is selected using"
  },
  {
    "id": 13335,
    "content": "target options texmode_unified and texmode_independent"
  },
  {
    "id": 13336,
    "content": "Example : calculate an element’s power contribution as element’s power/total number of elements"
  },
  {
    "id": 13337,
    "content": "target texmode_independent"
  },
  {
    "id": 13338,
    "content": "global"
  },
  {
    "id": 13339,
    "content": "samplerref tsamp1 = { addr_mode_0 = clamp_to_border, filter_mode = nearest };"
  },
  {
    "id": 13340,
    "content": "entry compute_power ("
  },
  {
    "id": 13341,
    "content": "param"
  },
  {
    "id": 13342,
    "content": "texref tex1 ) { txq"
  },
  {
    "id": 13343,
    "content": "width b32 r6, [tex1];   get tex1's width txq"
  },
  {
    "id": 13344,
    "content": "height b32 r5, [tex1];   get tex1's height tex"
  },
  {
    "id": 13345,
    "content": "2d"
  },
  {
    "id": 13346,
    "content": "v4"
  },
  {
    "id": 13347,
    "content": "f32 f32 {r1,r2,r3,r4}, [tex1, tsamp1, {f1,f2}]; mul"
  },
  {
    "id": 13348,
    "content": "u32 r5, r5, r6; add"
  },
  {
    "id": 13349,
    "content": "f32 r1, r1, r2; add f32 r3, r3, r4; add f32 r1, r1, r3; cvt f32"
  },
  {
    "id": 13350,
    "content": "u32 r5, r5; div f32 r1, r1, r5; } 9"
  },
  {
    "id": 13351,
    "content": "7"
  },
  {
    "id": 13352,
    "content": "9"
  },
  {
    "id": 13353,
    "content": "2"
  },
  {
    "id": 13355,
    "content": "Mipmaps are used in graphics applications to improve rendering speed and reduce aliasing artifacts"
  },
  {
    "id": 13362,
    "content": "In gradmode, two floating-point vector arguments provide partials (e"
  },
  {
    "id": 13363,
    "content": "g"
  },
  {
    "id": 13370,
    "content": "When using depth compare operand, the elements in texture coordinate vector c have"
  },
  {
    "id": 13371,
    "content": "f32 type"
  },
  {
    "id": 13373,
    "content": "e"
  },
  {
    "id": 13376,
    "content": "coordinates within the selected texture, as follows: For 1d texture arrays, operand c has type"
  },
  {
    "id": 13377,
    "content": "v2"
  },
  {
    "id": 13378,
    "content": "b32"
  },
  {
    "id": 13380,
    "content": "ctype"
  },
  {
    "id": 13382,
    "content": "ctype"
  },
  {
    "id": 13384,
    "content": "f32 type"
  },
  {
    "id": 13388,
    "content": "When accessing a cubemap, the texture coordinate vector c has type"
  },
  {
    "id": 13389,
    "content": "v4"
  },
  {
    "id": 13392,
    "content": "cube face"
  },
  {
    "id": 13393,
    "content": "operand f is"
  },
  {
    "id": 13394,
    "content": "f32 scalar value that specifies depth compare value for cubemap depth textures"
  },
  {
    "id": 13396,
    "content": "e"
  },
  {
    "id": 13397,
    "content": ", the total number of layers is a multiple of six"
  },
  {
    "id": 13399,
    "content": "Operand f is"
  },
  {
    "id": 13400,
    "content": "f32 scalar value that specifies depth compare value for cubemap depth textures"
  },
  {
    "id": 13403,
    "content": "multi-sample texture array, texture coordinate vector c has type"
  },
  {
    "id": 13404,
    "content": "v4"
  },
  {
    "id": 13405,
    "content": "b32"
  },
  {
    "id": 13407,
    "content": "s32 ) 2d texture coordinates"
  },
  {
    "id": 13409,
    "content": "f32 vectors, dPdx and dPdy , that specify the partials"
  },
  {
    "id": 13412,
    "content": "u64 register holding the address of a"
  },
  {
    "id": 13413,
    "content": "texref variable"
  },
  {
    "id": 13414,
    "content": "Notes For compatibility with prior versions of PTX, the square brackets are not required and"
  },
  {
    "id": 13415,
    "content": "v4 coordinate vectors are allowed for any geometry, with the extra elements being ignored"
  },
  {
    "id": 13416,
    "content": "Extension using opaque"
  },
  {
    "id": 13417,
    "content": "texref and"
  },
  {
    "id": 13418,
    "content": "samplerref types and independent mode texturing introduced in PTX ISA version 1"
  },
  {
    "id": 13419,
    "content": "5"
  },
  {
    "id": 13421,
    "content": "comp"
  },
  {
    "id": 13422,
    "content": "2d"
  },
  {
    "id": 13423,
    "content": "v4"
  },
  {
    "id": 13424,
    "content": "dtype"
  },
  {
    "id": 13425,
    "content": "f32 d[|p], [a, c] {, e} {, f}; tld4"
  },
  {
    "id": 13426,
    "content": "comp"
  },
  {
    "id": 13427,
    "content": "geom"
  },
  {
    "id": 13428,
    "content": "v4"
  },
  {
    "id": 13429,
    "content": "dtype"
  },
  {
    "id": 13430,
    "content": "f32 d[|p], [a, b, c] {, e} {, f};   explicit sampler"
  },
  {
    "id": 13431,
    "content": "comp = {"
  },
  {
    "id": 13432,
    "content": "r,"
  },
  {
    "id": 13433,
    "content": "g,"
  },
  {
    "id": 13434,
    "content": "b,"
  },
  {
    "id": 13435,
    "content": "a };"
  },
  {
    "id": 13436,
    "content": "geom = {"
  },
  {
    "id": 13437,
    "content": "2d,"
  },
  {
    "id": 13438,
    "content": "a2d,"
  },
  {
    "id": 13439,
    "content": "cube,"
  },
  {
    "id": 13440,
    "content": "acube };"
  },
  {
    "id": 13441,
    "content": "dtype = {"
  },
  {
    "id": 13442,
    "content": "u32,"
  },
  {
    "id": 13443,
    "content": "s32,"
  },
  {
    "id": 13445,
    "content": "tld4"
  },
  {
    "id": 13447,
    "content": "tld4"
  },
  {
    "id": 13451,
    "content": "Examples  Example of unified mode texturing tld4"
  },
  {
    "id": 13452,
    "content": "r"
  },
  {
    "id": 13453,
    "content": "2d"
  },
  {
    "id": 13454,
    "content": "v4"
  },
  {
    "id": 13455,
    "content": "s32"
  },
  {
    "id": 13456,
    "content": "f32 {r1,r2,r3,r4}, [tex_a,{f1,f2}];   Example of independent mode texturing tld4"
  },
  {
    "id": 13457,
    "content": "r"
  },
  {
    "id": 13458,
    "content": "2d"
  },
  {
    "id": 13459,
    "content": "v4"
  },
  {
    "id": 13460,
    "content": "u32"
  },
  {
    "id": 13461,
    "content": "f32 {u1,u2,u3,u4}, [tex_a,smpl_x,{f1,f2}];   Example of unified mode texturing using offset tld4"
  },
  {
    "id": 13462,
    "content": "r"
  },
  {
    "id": 13463,
    "content": "2d"
  },
  {
    "id": 13464,
    "content": "v4"
  },
  {
    "id": 13465,
    "content": "s32"
  },
  {
    "id": 13467,
    "content": "r"
  },
  {
    "id": 13468,
    "content": "2d"
  },
  {
    "id": 13469,
    "content": "v4"
  },
  {
    "id": 13470,
    "content": "f32 f32 {f1,f2,f3,f4}, [tex_a,{f5,f6}], f7;   Example of optional destination predicate tld4"
  },
  {
    "id": 13471,
    "content": "r"
  },
  {
    "id": 13472,
    "content": "2d"
  },
  {
    "id": 13473,
    "content": "v4"
  },
  {
    "id": 13474,
    "content": "f32 f32 {f1,f2,f3,f4}|p, [tex_a,{f5,f6}], f7; 9"
  },
  {
    "id": 13475,
    "content": "7"
  },
  {
    "id": 13476,
    "content": "9"
  },
  {
    "id": 13477,
    "content": "5"
  },
  {
    "id": 13478,
    "content": "Syntax txq"
  },
  {
    "id": 13479,
    "content": "tquery"
  },
  {
    "id": 13480,
    "content": "b32 d, [a];   texture attributes txq"
  },
  {
    "id": 13481,
    "content": "level"
  },
  {
    "id": 13482,
    "content": "tlquery"
  },
  {
    "id": 13483,
    "content": "b32 d, [a], lod;   texture attributes txq"
  },
  {
    "id": 13484,
    "content": "squery"
  },
  {
    "id": 13485,
    "content": "b32 d, [a];   sampler attributes"
  },
  {
    "id": 13486,
    "content": "tquery = {"
  },
  {
    "id": 13487,
    "content": "width,"
  },
  {
    "id": 13488,
    "content": "height,"
  },
  {
    "id": 13489,
    "content": "depth,"
  },
  {
    "id": 13490,
    "content": "channel_data_type,"
  },
  {
    "id": 13491,
    "content": "channel_order,"
  },
  {
    "id": 13492,
    "content": "normalized_coords,"
  },
  {
    "id": 13493,
    "content": "array_size,"
  },
  {
    "id": 13494,
    "content": "num_mipmap_levels,"
  },
  {
    "id": 13495,
    "content": "num_samples};"
  },
  {
    "id": 13496,
    "content": "tlquery = {"
  },
  {
    "id": 13497,
    "content": "width,"
  },
  {
    "id": 13498,
    "content": "height,"
  },
  {
    "id": 13499,
    "content": "depth };"
  },
  {
    "id": 13500,
    "content": "squery = {"
  },
  {
    "id": 13501,
    "content": "force_unnormalized_coords,"
  },
  {
    "id": 13502,
    "content": "filter_mode,"
  },
  {
    "id": 13504,
    "content": "width"
  },
  {
    "id": 13505,
    "content": "height"
  },
  {
    "id": 13506,
    "content": "depth value in elements"
  },
  {
    "id": 13508,
    "content": "Overrides the normalized_coords field of a"
  },
  {
    "id": 13509,
    "content": "texref variable used with a"
  },
  {
    "id": 13510,
    "content": "samplerref in a tex instruction"
  },
  {
    "id": 13511,
    "content": "filter_mode Integer from enum { nearest, linear }"
  },
  {
    "id": 13512,
    "content": "addr_mode_0"
  },
  {
    "id": 13513,
    "content": "addr_mode_1"
  },
  {
    "id": 13514,
    "content": "addr_mode_2 Integer from enum { wrap, mirror, clamp_ogl, clamp_to_edge, clamp_to_border }"
  },
  {
    "id": 13517,
    "content": "txq level txq"
  },
  {
    "id": 13519,
    "content": "array_size ,"
  },
  {
    "id": 13520,
    "content": "num_mipmap_levels ,"
  },
  {
    "id": 13521,
    "content": "num_samples samples queries were added in PTX ISA version 4"
  },
  {
    "id": 13522,
    "content": "1"
  },
  {
    "id": 13523,
    "content": "Examples txq"
  },
  {
    "id": 13524,
    "content": "width"
  },
  {
    "id": 13525,
    "content": "b32 %r1, [tex_A]; txq"
  },
  {
    "id": 13526,
    "content": "filter_mode"
  },
  {
    "id": 13527,
    "content": "b32 %r1, [tex_A];   unified mode txq"
  },
  {
    "id": 13528,
    "content": "addr_mode_0"
  },
  {
    "id": 13529,
    "content": "b32 %r1, [smpl_B];   independent mode txq"
  },
  {
    "id": 13530,
    "content": "level"
  },
  {
    "id": 13531,
    "content": "width"
  },
  {
    "id": 13532,
    "content": "b32 %r1, [tex_A], %r_lod; 9"
  },
  {
    "id": 13533,
    "content": "7"
  },
  {
    "id": 13534,
    "content": "9"
  },
  {
    "id": 13535,
    "content": "6"
  },
  {
    "id": 13537,
    "content": "type p, a;   result is"
  },
  {
    "id": 13538,
    "content": "pred"
  },
  {
    "id": 13539,
    "content": "type = {"
  },
  {
    "id": 13540,
    "content": "texref,"
  },
  {
    "id": 13541,
    "content": "samplerref,"
  },
  {
    "id": 13543,
    "content": "Examples istypep texref istex, tptr; istypep samplerref issampler, sptr; istypep"
  },
  {
    "id": 13544,
    "content": "surfref issurface, surfptr; 9"
  },
  {
    "id": 13545,
    "content": "7"
  },
  {
    "id": 13546,
    "content": "10"
  },
  {
    "id": 13548,
    "content": "Syntax suld"
  },
  {
    "id": 13549,
    "content": "b"
  },
  {
    "id": 13550,
    "content": "geom{"
  },
  {
    "id": 13551,
    "content": "cop}"
  },
  {
    "id": 13552,
    "content": "vec"
  },
  {
    "id": 13553,
    "content": "dtype"
  },
  {
    "id": 13554,
    "content": "clamp d, [a, b];   unformatted"
  },
  {
    "id": 13555,
    "content": "geom = {"
  },
  {
    "id": 13556,
    "content": "1d,"
  },
  {
    "id": 13557,
    "content": "2d,"
  },
  {
    "id": 13558,
    "content": "3d,"
  },
  {
    "id": 13559,
    "content": "a1d,"
  },
  {
    "id": 13560,
    "content": "a2d };"
  },
  {
    "id": 13561,
    "content": "cop = {"
  },
  {
    "id": 13562,
    "content": "ca,"
  },
  {
    "id": 13563,
    "content": "cg,"
  },
  {
    "id": 13564,
    "content": "cs,"
  },
  {
    "id": 13565,
    "content": "cv };   cache operation"
  },
  {
    "id": 13566,
    "content": "vec = { none,"
  },
  {
    "id": 13567,
    "content": "v2,"
  },
  {
    "id": 13568,
    "content": "v4 };"
  },
  {
    "id": 13569,
    "content": "dtype = {"
  },
  {
    "id": 13570,
    "content": "b8 ,"
  },
  {
    "id": 13571,
    "content": "b16,"
  },
  {
    "id": 13572,
    "content": "b32,"
  },
  {
    "id": 13573,
    "content": "b64 };"
  },
  {
    "id": 13574,
    "content": "clamp = {"
  },
  {
    "id": 13575,
    "content": "trap,"
  },
  {
    "id": 13576,
    "content": "clamp,"
  },
  {
    "id": 13577,
    "content": "zero }; Description suld"
  },
  {
    "id": 13578,
    "content": "b"
  },
  {
    "id": 13583,
    "content": "v2"
  },
  {
    "id": 13584,
    "content": "b32"
  },
  {
    "id": 13586,
    "content": "s32"
  },
  {
    "id": 13588,
    "content": "s32"
  },
  {
    "id": 13592,
    "content": "u64 register holding the address of a"
  },
  {
    "id": 13593,
    "content": "surfref variable"
  },
  {
    "id": 13594,
    "content": "Examples suld"
  },
  {
    "id": 13595,
    "content": "b"
  },
  {
    "id": 13596,
    "content": "1d"
  },
  {
    "id": 13597,
    "content": "v4"
  },
  {
    "id": 13598,
    "content": "b32"
  },
  {
    "id": 13599,
    "content": "trap {s1,s2,s3,s4}, [surf_B, {x}]; suld"
  },
  {
    "id": 13600,
    "content": "b"
  },
  {
    "id": 13601,
    "content": "3d"
  },
  {
    "id": 13602,
    "content": "v2"
  },
  {
    "id": 13603,
    "content": "b64"
  },
  {
    "id": 13604,
    "content": "trap {r1,r2}, [surf_A, {x,y,z,w}]; suld"
  },
  {
    "id": 13605,
    "content": "b"
  },
  {
    "id": 13606,
    "content": "a1d"
  },
  {
    "id": 13607,
    "content": "v2"
  },
  {
    "id": 13608,
    "content": "b32 {r0,r1}, [surf_C, {idx,x}]; suld"
  },
  {
    "id": 13609,
    "content": "b"
  },
  {
    "id": 13610,
    "content": "a2d"
  },
  {
    "id": 13611,
    "content": "b32 r0, [surf_D, {idx,x,y,z}];   z ignored 9"
  },
  {
    "id": 13612,
    "content": "7"
  },
  {
    "id": 13613,
    "content": "10"
  },
  {
    "id": 13614,
    "content": "2"
  },
  {
    "id": 13615,
    "content": "{a1d,a2d}{"
  },
  {
    "id": 13616,
    "content": "cop}"
  },
  {
    "id": 13617,
    "content": "vec"
  },
  {
    "id": 13618,
    "content": "ctype"
  },
  {
    "id": 13619,
    "content": "clamp [a, b], c;   unformatted"
  },
  {
    "id": 13620,
    "content": "cop = {"
  },
  {
    "id": 13621,
    "content": "wb,"
  },
  {
    "id": 13622,
    "content": "cg,"
  },
  {
    "id": 13623,
    "content": "cs,"
  },
  {
    "id": 13624,
    "content": "wt };   cache operation"
  },
  {
    "id": 13625,
    "content": "vec = { none,"
  },
  {
    "id": 13626,
    "content": "v2,"
  },
  {
    "id": 13627,
    "content": "v4 };"
  },
  {
    "id": 13628,
    "content": "ctype = {"
  },
  {
    "id": 13629,
    "content": "b8 ,"
  },
  {
    "id": 13630,
    "content": "b16,"
  },
  {
    "id": 13631,
    "content": "b32,"
  },
  {
    "id": 13632,
    "content": "b64 };"
  },
  {
    "id": 13633,
    "content": "clamp = {"
  },
  {
    "id": 13634,
    "content": "trap,"
  },
  {
    "id": 13635,
    "content": "clamp,"
  },
  {
    "id": 13636,
    "content": "zero }; Description sust"
  },
  {
    "id": 13638,
    "content": "The lowest dimension coordinate represents a byte offset into the surface and is not scaled"
  },
  {
    "id": 13642,
    "content": "sust"
  },
  {
    "id": 13643,
    "content": "p , additional clamp modifiers, and cache operations introduced in PTX ISA version 2"
  },
  {
    "id": 13644,
    "content": "0"
  },
  {
    "id": 13645,
    "content": "Examples sust"
  },
  {
    "id": 13646,
    "content": "p"
  },
  {
    "id": 13647,
    "content": "1d"
  },
  {
    "id": 13648,
    "content": "v4"
  },
  {
    "id": 13649,
    "content": "b32"
  },
  {
    "id": 13650,
    "content": "trap [surf_B, {x}], {f1,f2,f3,f4}; sust"
  },
  {
    "id": 13651,
    "content": "b"
  },
  {
    "id": 13652,
    "content": "3d"
  },
  {
    "id": 13653,
    "content": "v2"
  },
  {
    "id": 13654,
    "content": "b64"
  },
  {
    "id": 13655,
    "content": "trap [surf_A, {x,y,z,w}], {r1,r2}; sust"
  },
  {
    "id": 13656,
    "content": "b"
  },
  {
    "id": 13657,
    "content": "a1d"
  },
  {
    "id": 13658,
    "content": "v2"
  },
  {
    "id": 13659,
    "content": "b64 [surf_C, {idx,x}], {r1,r2}; sust"
  },
  {
    "id": 13660,
    "content": "b"
  },
  {
    "id": 13661,
    "content": "a2d"
  },
  {
    "id": 13662,
    "content": "b32 [surf_D, {idx,x,y,z}], r0;   z ignored 9"
  },
  {
    "id": 13663,
    "content": "7"
  },
  {
    "id": 13664,
    "content": "10"
  },
  {
    "id": 13665,
    "content": "3"
  },
  {
    "id": 13666,
    "content": "Syntax sured"
  },
  {
    "id": 13667,
    "content": "b"
  },
  {
    "id": 13668,
    "content": "op"
  },
  {
    "id": 13669,
    "content": "geom"
  },
  {
    "id": 13670,
    "content": "ctype"
  },
  {
    "id": 13671,
    "content": "clamp [a,b],c;   byte addressing sured"
  },
  {
    "id": 13672,
    "content": "p"
  },
  {
    "id": 13673,
    "content": "op"
  },
  {
    "id": 13674,
    "content": "geom"
  },
  {
    "id": 13675,
    "content": "ctype"
  },
  {
    "id": 13676,
    "content": "clamp [a,b],c;   sample addressing"
  },
  {
    "id": 13677,
    "content": "op = {"
  },
  {
    "id": 13678,
    "content": "add,"
  },
  {
    "id": 13679,
    "content": "min,"
  },
  {
    "id": 13680,
    "content": "max,"
  },
  {
    "id": 13681,
    "content": "and,"
  },
  {
    "id": 13682,
    "content": "or };"
  },
  {
    "id": 13683,
    "content": "geom = {"
  },
  {
    "id": 13684,
    "content": "1d,"
  },
  {
    "id": 13685,
    "content": "2d,"
  },
  {
    "id": 13686,
    "content": "3d };"
  },
  {
    "id": 13687,
    "content": "ctype = {"
  },
  {
    "id": 13688,
    "content": "u32,"
  },
  {
    "id": 13689,
    "content": "u64,"
  },
  {
    "id": 13690,
    "content": "s32,"
  },
  {
    "id": 13691,
    "content": "b32,"
  },
  {
    "id": 13692,
    "content": "s64 };   for sured"
  },
  {
    "id": 13693,
    "content": "b"
  },
  {
    "id": 13694,
    "content": "ctype = {"
  },
  {
    "id": 13695,
    "content": "b32,"
  },
  {
    "id": 13696,
    "content": "b64 };   for sured"
  },
  {
    "id": 13697,
    "content": "p"
  },
  {
    "id": 13698,
    "content": "clamp = {"
  },
  {
    "id": 13699,
    "content": "trap,"
  },
  {
    "id": 13700,
    "content": "clamp,"
  },
  {
    "id": 13702,
    "content": "Operation add applies to"
  },
  {
    "id": 13703,
    "content": "u32 ,"
  },
  {
    "id": 13704,
    "content": "u64 , and"
  },
  {
    "id": 13705,
    "content": "s32 types; min and max apply to"
  },
  {
    "id": 13706,
    "content": "u32 ,"
  },
  {
    "id": 13707,
    "content": "s32 ,"
  },
  {
    "id": 13708,
    "content": "u64 and"
  },
  {
    "id": 13709,
    "content": "s64 types; operations and and or apply to"
  },
  {
    "id": 13710,
    "content": "b32 type For type b32 , the data is interpreted as"
  },
  {
    "id": 13711,
    "content": "u32 or"
  },
  {
    "id": 13713,
    "content": "For type"
  },
  {
    "id": 13715,
    "content": "Examples sured"
  },
  {
    "id": 13716,
    "content": "b"
  },
  {
    "id": 13717,
    "content": "add"
  },
  {
    "id": 13718,
    "content": "2d"
  },
  {
    "id": 13719,
    "content": "u32"
  },
  {
    "id": 13720,
    "content": "trap [surf_A, {x,y}], r1; sured"
  },
  {
    "id": 13721,
    "content": "p"
  },
  {
    "id": 13722,
    "content": "min"
  },
  {
    "id": 13723,
    "content": "1d"
  },
  {
    "id": 13724,
    "content": "u32"
  },
  {
    "id": 13725,
    "content": "trap [surf_B, {x}], r1; sured"
  },
  {
    "id": 13726,
    "content": "b"
  },
  {
    "id": 13727,
    "content": "max"
  },
  {
    "id": 13728,
    "content": "1d"
  },
  {
    "id": 13729,
    "content": "u64"
  },
  {
    "id": 13730,
    "content": "trap [surf_C, {x}], r1; sured"
  },
  {
    "id": 13731,
    "content": "p"
  },
  {
    "id": 13732,
    "content": "min"
  },
  {
    "id": 13733,
    "content": "1d"
  },
  {
    "id": 13734,
    "content": "b64"
  },
  {
    "id": 13735,
    "content": "trap [surf_D, {x}], r1; 9"
  },
  {
    "id": 13736,
    "content": "7"
  },
  {
    "id": 13737,
    "content": "10"
  },
  {
    "id": 13738,
    "content": "4"
  },
  {
    "id": 13739,
    "content": "Syntax suq"
  },
  {
    "id": 13740,
    "content": "query"
  },
  {
    "id": 13741,
    "content": "b32 d, [a];"
  },
  {
    "id": 13742,
    "content": "query = {"
  },
  {
    "id": 13743,
    "content": "width,"
  },
  {
    "id": 13744,
    "content": "height,"
  },
  {
    "id": 13745,
    "content": "depth,"
  },
  {
    "id": 13746,
    "content": "channel_data_type,"
  },
  {
    "id": 13747,
    "content": "channel_order,"
  },
  {
    "id": 13748,
    "content": "array_size,"
  },
  {
    "id": 13751,
    "content": "7"
  },
  {
    "id": 13752,
    "content": "11"
  },
  {
    "id": 13753,
    "content": "1"
  },
  {
    "id": 13756,
    "content": "Examples setp"
  },
  {
    "id": 13757,
    "content": "eq"
  },
  {
    "id": 13758,
    "content": "f32 p,y,0;   is y zero"
  },
  {
    "id": 13759,
    "content": "@"
  },
  {
    "id": 13760,
    "content": "p div"
  },
  {
    "id": 13761,
    "content": "f32 ratio,x,y   avoid division by zero @q bra L23;   conditional branch 9"
  },
  {
    "id": 13762,
    "content": "7"
  },
  {
    "id": 13763,
    "content": "11"
  },
  {
    "id": 13764,
    "content": "3"
  },
  {
    "id": 13766,
    "content": "Unimplemented indirect branch introduced in PTX ISA version 2"
  },
  {
    "id": 13767,
    "content": "1 has been removed from the spec"
  },
  {
    "id": 13768,
    "content": "Examples bra uni L_exit;   uniform unconditional jump @q bra L23;   conditional branch 9"
  },
  {
    "id": 13769,
    "content": "7"
  },
  {
    "id": 13770,
    "content": "11"
  },
  {
    "id": 13771,
    "content": "4"
  },
  {
    "id": 13774,
    "content": "Behaviour is undefined if the value of index is greater than or equal to the length of tlist The"
  },
  {
    "id": 13775,
    "content": "branchtargets directive must be defined in the local function scope before it is used"
  },
  {
    "id": 13776,
    "content": "Semantics if (p) { if (index = s)"
  },
  {
    "id": 13777,
    "content": "0 : r+1; dec(r, s) = (r==0 || r > s)"
  },
  {
    "id": 13778,
    "content": "s : r-1; exch(r, s) = s; cas(r,s,t) = (r == s)"
  },
  {
    "id": 13779,
    "content": "t : r; Notes Simple reductions may be specified by using the bit bucket destination operand _"
  },
  {
    "id": 13780,
    "content": "Per-element atomicity of atom"
  },
  {
    "id": 13781,
    "content": "f16x2 clarified in PTX ISA version 6 3, with retrospective effect from PTX ISA version 6"
  },
  {
    "id": 13782,
    "content": "2"
  },
  {
    "id": 13784,
    "content": "vec_16_bit"
  },
  {
    "id": 13785,
    "content": "half_word_type [a], b{, cache-policy}; red{"
  },
  {
    "id": 13786,
    "content": "sem}{"
  },
  {
    "id": 13787,
    "content": "scope}{"
  },
  {
    "id": 13788,
    "content": "global}"
  },
  {
    "id": 13789,
    "content": "op"
  },
  {
    "id": 13790,
    "content": "noftz{"
  },
  {
    "id": 13791,
    "content": "level::cache_hint}"
  },
  {
    "id": 13792,
    "content": "vec_32_bit"
  },
  {
    "id": 13793,
    "content": "packed_type [a], b {, cache-policy};"
  },
  {
    "id": 13794,
    "content": "sem = {"
  },
  {
    "id": 13795,
    "content": "relaxed,"
  },
  {
    "id": 13796,
    "content": "release };"
  },
  {
    "id": 13797,
    "content": "scope = {"
  },
  {
    "id": 13798,
    "content": "cta,"
  },
  {
    "id": 13799,
    "content": "cluster,"
  },
  {
    "id": 13800,
    "content": "gpu,"
  },
  {
    "id": 13801,
    "content": "sys };"
  },
  {
    "id": 13802,
    "content": "op = {"
  },
  {
    "id": 13803,
    "content": "add,"
  },
  {
    "id": 13804,
    "content": "min,"
  },
  {
    "id": 13805,
    "content": "max };"
  },
  {
    "id": 13806,
    "content": "half_word_type = {"
  },
  {
    "id": 13807,
    "content": "f16,"
  },
  {
    "id": 13808,
    "content": "bf16 };"
  },
  {
    "id": 13809,
    "content": "packed_type = {"
  },
  {
    "id": 13810,
    "content": "f16x2,"
  },
  {
    "id": 13811,
    "content": "bf16x2 };"
  },
  {
    "id": 13812,
    "content": "vec_16_bit = {"
  },
  {
    "id": 13813,
    "content": "v2,"
  },
  {
    "id": 13814,
    "content": "v4,"
  },
  {
    "id": 13815,
    "content": "v8 }"
  },
  {
    "id": 13816,
    "content": "vec_32_bit = {"
  },
  {
    "id": 13817,
    "content": "v2,"
  },
  {
    "id": 13818,
    "content": "v4 };"
  },
  {
    "id": 13820,
    "content": "red with scalar type may be used only with"
  },
  {
    "id": 13821,
    "content": "global and"
  },
  {
    "id": 13822,
    "content": "shared spaces and with generic addressing, where the address points to"
  },
  {
    "id": 13823,
    "content": "global or"
  },
  {
    "id": 13824,
    "content": "shared space"
  },
  {
    "id": 13825,
    "content": "red with vector type may be used only with"
  },
  {
    "id": 13826,
    "content": "global space and with generic addressing where the address points to global space"
  },
  {
    "id": 13828,
    "content": "The optional"
  },
  {
    "id": 13829,
    "content": "sem qualifier specifies a memory synchronizing effect as described in the Memory Consistency Model"
  },
  {
    "id": 13830,
    "content": "The optional"
  },
  {
    "id": 13833,
    "content": "f16 / bf16"
  },
  {
    "id": 13834,
    "content": "f16x2 / bf16x2"
  },
  {
    "id": 13835,
    "content": "f32"
  },
  {
    "id": 13836,
    "content": "v2"
  },
  {
    "id": 13837,
    "content": "add ,"
  },
  {
    "id": 13838,
    "content": "min ,"
  },
  {
    "id": 13839,
    "content": "max"
  },
  {
    "id": 13840,
    "content": "add ,"
  },
  {
    "id": 13841,
    "content": "min ,"
  },
  {
    "id": 13842,
    "content": "max"
  },
  {
    "id": 13843,
    "content": "add"
  },
  {
    "id": 13844,
    "content": "v4"
  },
  {
    "id": 13845,
    "content": "add ,"
  },
  {
    "id": 13846,
    "content": "min ,"
  },
  {
    "id": 13847,
    "content": "max"
  },
  {
    "id": 13848,
    "content": "add ,"
  },
  {
    "id": 13849,
    "content": "min ,"
  },
  {
    "id": 13850,
    "content": "max"
  },
  {
    "id": 13851,
    "content": "add"
  },
  {
    "id": 13852,
    "content": "v8"
  },
  {
    "id": 13853,
    "content": "add ,"
  },
  {
    "id": 13854,
    "content": "min ,"
  },
  {
    "id": 13858,
    "content": "g"
  },
  {
    "id": 13861,
    "content": "and , or , and"
  },
  {
    "id": 13862,
    "content": "xor"
  },
  {
    "id": 13863,
    "content": "Current implementation of red"
  },
  {
    "id": 13864,
    "content": "add"
  },
  {
    "id": 13865,
    "content": "f32 on global memory flushes subnormal inputs and results to sign-preserving zero; whereas red"
  },
  {
    "id": 13866,
    "content": "add"
  },
  {
    "id": 13867,
    "content": "f32 on shared memory supports subnormal inputs and results and doesn’t flush them to zero"
  },
  {
    "id": 13868,
    "content": "red"
  },
  {
    "id": 13869,
    "content": "add"
  },
  {
    "id": 13870,
    "content": "f16 , red"
  },
  {
    "id": 13871,
    "content": "add"
  },
  {
    "id": 13872,
    "content": "f16x2 , red"
  },
  {
    "id": 13873,
    "content": "add"
  },
  {
    "id": 13874,
    "content": "bf16 and red"
  },
  {
    "id": 13875,
    "content": "add"
  },
  {
    "id": 13876,
    "content": "bf16x2 operation requires the"
  },
  {
    "id": 13877,
    "content": "noftz qualifier; it preserves subnormal inputs and results, and does not flush them to zero"
  },
  {
    "id": 13878,
    "content": "Semantics *a = operation(*a, b); where inc(r, s) = (r >= s)"
  },
  {
    "id": 13879,
    "content": "s : r-1; PTX ISA Notes Introduced in PTX ISA version 1"
  },
  {
    "id": 13880,
    "content": "2"
  },
  {
    "id": 13881,
    "content": "Per-element atomicity of red"
  },
  {
    "id": 13882,
    "content": "f16x2 clarified in PTX ISA version 6 3, with retrospective effect from PTX ISA version 6"
  },
  {
    "id": 13883,
    "content": "2 Support for"
  },
  {
    "id": 13884,
    "content": "level::cache_hint qualifier introduced in PTX ISA version 7"
  },
  {
    "id": 13885,
    "content": "4"
  },
  {
    "id": 13888,
    "content": "With"
  },
  {
    "id": 13891,
    "content": "release semantics at the"
  },
  {
    "id": 13892,
    "content": "cluster scope as described in the Memory Consistency Model"
  },
  {
    "id": 13893,
    "content": "Examples red"
  },
  {
    "id": 13894,
    "content": "async"
  },
  {
    "id": 13895,
    "content": "relaxed"
  },
  {
    "id": 13896,
    "content": "cluster shared::cluster"
  },
  {
    "id": 13897,
    "content": "mbarrier::complete_tx::bytes"
  },
  {
    "id": 13898,
    "content": "min"
  },
  {
    "id": 13899,
    "content": "u32 [addr], b, [mbar_addr]; 9"
  },
  {
    "id": 13900,
    "content": "7"
  },
  {
    "id": 13901,
    "content": "12"
  },
  {
    "id": 13902,
    "content": "8"
  },
  {
    "id": 13904,
    "content": "mode"
  },
  {
    "id": 13905,
    "content": "pred d, {"
  },
  {
    "id": 13906,
    "content": "}a; vote"
  },
  {
    "id": 13907,
    "content": "ballot"
  },
  {
    "id": 13908,
    "content": "b32 d, {"
  },
  {
    "id": 13909,
    "content": "}a;   'ballot' form, returns bitmask"
  },
  {
    "id": 13910,
    "content": "mode = {"
  },
  {
    "id": 13911,
    "content": "all,"
  },
  {
    "id": 13912,
    "content": "any,"
  },
  {
    "id": 13913,
    "content": "uni }; Deprecation Note The vote instruction without a"
  },
  {
    "id": 13914,
    "content": "sync qualifier is deprecated in PTX ISA version 6"
  },
  {
    "id": 13915,
    "content": "0"
  },
  {
    "id": 13916,
    "content": "Support for this instruction with"
  },
  {
    "id": 13917,
    "content": "target lower than sm_70 may be removed in a future PTX ISA version"
  },
  {
    "id": 13918,
    "content": "Removal Note Support for vote instruction without a"
  },
  {
    "id": 13919,
    "content": "sync qualifier is removed in PTX ISA version 6"
  },
  {
    "id": 13920,
    "content": "4 for"
  },
  {
    "id": 13921,
    "content": "target sm_70 or higher"
  },
  {
    "id": 13923,
    "content": "In the ballot form, vote ballot"
  },
  {
    "id": 13925,
    "content": "An inactive thread in warp will contribute a 0 for its entry when participating in vote"
  },
  {
    "id": 13926,
    "content": "ballot"
  },
  {
    "id": 13927,
    "content": "b32"
  },
  {
    "id": 13929,
    "content": "all"
  },
  {
    "id": 13930,
    "content": "pred p,q; vote"
  },
  {
    "id": 13931,
    "content": "uni"
  },
  {
    "id": 13932,
    "content": "pred p,q; vote"
  },
  {
    "id": 13933,
    "content": "ballot b32 r1,p;   get 'ballot' across warp 9"
  },
  {
    "id": 13934,
    "content": "7"
  },
  {
    "id": 13935,
    "content": "12"
  },
  {
    "id": 13936,
    "content": "9"
  },
  {
    "id": 13938,
    "content": "mode"
  },
  {
    "id": 13939,
    "content": "pred d, {"
  },
  {
    "id": 13940,
    "content": "}a, membermask; vote"
  },
  {
    "id": 13941,
    "content": "sync"
  },
  {
    "id": 13942,
    "content": "ballot"
  },
  {
    "id": 13943,
    "content": "b32 d, {"
  },
  {
    "id": 13944,
    "content": "}a, membermask;   'ballot' form, returns bitmask"
  },
  {
    "id": 13945,
    "content": "mode = {"
  },
  {
    "id": 13946,
    "content": "all,"
  },
  {
    "id": 13947,
    "content": "any,"
  },
  {
    "id": 13950,
    "content": "membermask In this form, vote sync"
  },
  {
    "id": 13951,
    "content": "ballot"
  },
  {
    "id": 13953,
    "content": "sync"
  },
  {
    "id": 13954,
    "content": "ballot"
  },
  {
    "id": 13955,
    "content": "b32"
  },
  {
    "id": 13956,
    "content": "Note For"
  },
  {
    "id": 13958,
    "content": "ballot b32 r1,p,0xffffffff;   get 'ballot' across warp 9"
  },
  {
    "id": 13959,
    "content": "7"
  },
  {
    "id": 13960,
    "content": "12"
  },
  {
    "id": 13961,
    "content": "10"
  },
  {
    "id": 13963,
    "content": "any"
  },
  {
    "id": 13964,
    "content": "sync"
  },
  {
    "id": 13965,
    "content": "type d, a, membermask; match"
  },
  {
    "id": 13966,
    "content": "all"
  },
  {
    "id": 13967,
    "content": "sync"
  },
  {
    "id": 13968,
    "content": "type d[|p], a, membermask; type = {"
  },
  {
    "id": 13969,
    "content": "b32,"
  },
  {
    "id": 13972,
    "content": "The matching operation modes are:"
  },
  {
    "id": 13974,
    "content": "The behavior of match"
  },
  {
    "id": 13975,
    "content": "sync is undefined if the executing thread is not in the membermask"
  },
  {
    "id": 13976,
    "content": "Release Notes Note that match"
  },
  {
    "id": 13977,
    "content": "sync applies to threads in a single warp, not across an entire CTA"
  },
  {
    "id": 13980,
    "content": "op"
  },
  {
    "id": 13981,
    "content": "type dst, src, membermask;"
  },
  {
    "id": 13982,
    "content": "op = {"
  },
  {
    "id": 13983,
    "content": "add,"
  },
  {
    "id": 13984,
    "content": "min,"
  },
  {
    "id": 13985,
    "content": "max}"
  },
  {
    "id": 13986,
    "content": "type = {"
  },
  {
    "id": 13987,
    "content": "u32,"
  },
  {
    "id": 13988,
    "content": "s32} redux"
  },
  {
    "id": 13989,
    "content": "sync"
  },
  {
    "id": 13990,
    "content": "op"
  },
  {
    "id": 13991,
    "content": "b32 dst, src, membermask;"
  },
  {
    "id": 13992,
    "content": "op = {"
  },
  {
    "id": 13993,
    "content": "and,"
  },
  {
    "id": 13994,
    "content": "or,"
  },
  {
    "id": 13996,
    "content": "operation in"
  },
  {
    "id": 13997,
    "content": "and ,"
  },
  {
    "id": 13998,
    "content": "or , xor or arithmetic operation in"
  },
  {
    "id": 13999,
    "content": "add ,"
  },
  {
    "id": 14000,
    "content": "min ,"
  },
  {
    "id": 14001,
    "content": "max"
  },
  {
    "id": 14002,
    "content": "The behavior of redux"
  },
  {
    "id": 14003,
    "content": "sync is undefined if the executing thread is not in the membermask"
  },
  {
    "id": 14004,
    "content": "Release Notes Note that redux"
  },
  {
    "id": 14005,
    "content": "sync applies to threads in a single warp, not across an entire CTA"
  },
  {
    "id": 14006,
    "content": "Examples"
  },
  {
    "id": 14007,
    "content": "reg"
  },
  {
    "id": 14008,
    "content": "b32 dst, src, init, mask; redux"
  },
  {
    "id": 14009,
    "content": "sync"
  },
  {
    "id": 14010,
    "content": "add"
  },
  {
    "id": 14011,
    "content": "s32 dst, src, 0xff; redux"
  },
  {
    "id": 14012,
    "content": "sync"
  },
  {
    "id": 14013,
    "content": "xor"
  },
  {
    "id": 14014,
    "content": "b32 dst, src, mask; 9"
  },
  {
    "id": 14015,
    "content": "7"
  },
  {
    "id": 14016,
    "content": "12"
  },
  {
    "id": 14017,
    "content": "13"
  },
  {
    "id": 14019,
    "content": "action; action = {"
  },
  {
    "id": 14020,
    "content": "launch_dependents,"
  },
  {
    "id": 14025,
    "content": "specifies a 32-bit integer indicating the set of threads from which a leader is to be elected"
  },
  {
    "id": 14026,
    "content": "The mandatory"
  },
  {
    "id": 14031,
    "content": "pending_count cp"
  },
  {
    "id": 14032,
    "content": "async"
  },
  {
    "id": 14034,
    "content": "Unlike bar{"
  },
  {
    "id": 14037,
    "content": "9"
  },
  {
    "id": 14038,
    "content": "7"
  },
  {
    "id": 14039,
    "content": "12"
  },
  {
    "id": 14040,
    "content": "15"
  },
  {
    "id": 14041,
    "content": "1"
  },
  {
    "id": 14043,
    "content": "b64 8"
  },
  {
    "id": 14044,
    "content": "shared 9"
  },
  {
    "id": 14045,
    "content": "7"
  },
  {
    "id": 14046,
    "content": "12"
  },
  {
    "id": 14047,
    "content": "15"
  },
  {
    "id": 14048,
    "content": "2"
  },
  {
    "id": 14051,
    "content": "7"
  },
  {
    "id": 14052,
    "content": "12"
  },
  {
    "id": 14053,
    "content": "15"
  },
  {
    "id": 14054,
    "content": "3"
  },
  {
    "id": 14055,
    "content": "An mbarrier object must be invalidated to repurpose its memory"
  },
  {
    "id": 14056,
    "content": "9"
  },
  {
    "id": 14057,
    "content": "7"
  },
  {
    "id": 14058,
    "content": "12"
  },
  {
    "id": 14059,
    "content": "15"
  },
  {
    "id": 14060,
    "content": "4"
  },
  {
    "id": 14064,
    "content": "9"
  },
  {
    "id": 14065,
    "content": "7"
  },
  {
    "id": 14066,
    "content": "12"
  },
  {
    "id": 14067,
    "content": "15"
  },
  {
    "id": 14068,
    "content": "5"
  },
  {
    "id": 14071,
    "content": "phase"
  },
  {
    "id": 14072,
    "content": "9"
  },
  {
    "id": 14073,
    "content": "7"
  },
  {
    "id": 14074,
    "content": "12"
  },
  {
    "id": 14075,
    "content": "15"
  },
  {
    "id": 14076,
    "content": "5"
  },
  {
    "id": 14077,
    "content": "1"
  },
  {
    "id": 14079,
    "content": "9"
  },
  {
    "id": 14080,
    "content": "7"
  },
  {
    "id": 14081,
    "content": "12"
  },
  {
    "id": 14082,
    "content": "15"
  },
  {
    "id": 14083,
    "content": "5"
  },
  {
    "id": 14084,
    "content": "2"
  },
  {
    "id": 14087,
    "content": "9"
  },
  {
    "id": 14088,
    "content": "7"
  },
  {
    "id": 14089,
    "content": "12"
  },
  {
    "id": 14090,
    "content": "15"
  },
  {
    "id": 14091,
    "content": "6"
  },
  {
    "id": 14094,
    "content": "9"
  },
  {
    "id": 14095,
    "content": "7"
  },
  {
    "id": 14096,
    "content": "12"
  },
  {
    "id": 14097,
    "content": "15"
  },
  {
    "id": 14098,
    "content": "7"
  },
  {
    "id": 14101,
    "content": "9"
  },
  {
    "id": 14102,
    "content": "7"
  },
  {
    "id": 14103,
    "content": "12"
  },
  {
    "id": 14104,
    "content": "15"
  },
  {
    "id": 14105,
    "content": "8"
  },
  {
    "id": 14107,
    "content": "Not supported 9"
  },
  {
    "id": 14108,
    "content": "7"
  },
  {
    "id": 14109,
    "content": "12"
  },
  {
    "id": 14110,
    "content": "15"
  },
  {
    "id": 14111,
    "content": "9"
  },
  {
    "id": 14113,
    "content": "shared{::cta}}"
  },
  {
    "id": 14115,
    "content": "shared::cta state space then the behavior is undefined"
  },
  {
    "id": 14116,
    "content": "Examples"
  },
  {
    "id": 14117,
    "content": "shared"
  },
  {
    "id": 14118,
    "content": "b64 shMem, shMem2;"
  },
  {
    "id": 14119,
    "content": "reg"
  },
  {
    "id": 14120,
    "content": "b64 addr;"
  },
  {
    "id": 14121,
    "content": "reg"
  },
  {
    "id": 14122,
    "content": "b32 %r1; cvta"
  },
  {
    "id": 14123,
    "content": "shared"
  },
  {
    "id": 14124,
    "content": "u64 addr, shMem2; mbarrier"
  },
  {
    "id": 14125,
    "content": "init"
  },
  {
    "id": 14126,
    "content": "b64 [addr], %r1; bar"
  },
  {
    "id": 14127,
    "content": "cta"
  },
  {
    "id": 14128,
    "content": "sync 0;"
  },
  {
    "id": 14129,
    "content": "other mbarrier operations on addr mbarrier"
  },
  {
    "id": 14130,
    "content": "init"
  },
  {
    "id": 14131,
    "content": "shared::cta"
  },
  {
    "id": 14132,
    "content": "b64 [shMem], 12; bar"
  },
  {
    "id": 14133,
    "content": "sync 0;"
  },
  {
    "id": 14135,
    "content": "shared{::cta}}"
  },
  {
    "id": 14137,
    "content": "Examples"
  },
  {
    "id": 14138,
    "content": "shared"
  },
  {
    "id": 14139,
    "content": "b64 shmem;"
  },
  {
    "id": 14140,
    "content": "reg"
  },
  {
    "id": 14141,
    "content": "b64 addr;"
  },
  {
    "id": 14142,
    "content": "reg"
  },
  {
    "id": 14143,
    "content": "b32 %r1;"
  },
  {
    "id": 14144,
    "content": "reg"
  },
  {
    "id": 14145,
    "content": "pred t0;   Example 1 : bar sync 0; @t0 mbarrier"
  },
  {
    "id": 14146,
    "content": "init"
  },
  {
    "id": 14147,
    "content": "b64 [addr], %r1; other mbarrier operations on addr bar sync 0; @t0 mbarrier"
  },
  {
    "id": 14148,
    "content": "inval"
  },
  {
    "id": 14149,
    "content": "b64 [addr];   Example 2 : bar"
  },
  {
    "id": 14150,
    "content": "cta"
  },
  {
    "id": 14151,
    "content": "sync 0; mbarrier"
  },
  {
    "id": 14152,
    "content": "init"
  },
  {
    "id": 14153,
    "content": "shared"
  },
  {
    "id": 14154,
    "content": "b64 [shmem], 12; other mbarrier operations on shmem bar"
  },
  {
    "id": 14155,
    "content": "cta"
  },
  {
    "id": 14156,
    "content": "sync 0; @t0 mbarrier"
  },
  {
    "id": 14157,
    "content": "inval"
  },
  {
    "id": 14158,
    "content": "shared"
  },
  {
    "id": 14159,
    "content": "b64 [shmem];   shmem can be reused here for unrelated use : bar"
  },
  {
    "id": 14160,
    "content": "cta"
  },
  {
    "id": 14161,
    "content": "sync 0; st"
  },
  {
    "id": 14162,
    "content": "shared"
  },
  {
    "id": 14163,
    "content": "b64 [shmem], ;   shmem can be re-initialized as mbarrier object : bar"
  },
  {
    "id": 14164,
    "content": "cta"
  },
  {
    "id": 14165,
    "content": "sync 0; @t0 mbarrier"
  },
  {
    "id": 14166,
    "content": "init"
  },
  {
    "id": 14167,
    "content": "shared"
  },
  {
    "id": 14168,
    "content": "b64 [shmem], 24; other mbarrier operations on shmem bar"
  },
  {
    "id": 14169,
    "content": "cta"
  },
  {
    "id": 14170,
    "content": "sync 0; @t0 mbarrier"
  },
  {
    "id": 14171,
    "content": "inval"
  },
  {
    "id": 14172,
    "content": "shared::cta"
  },
  {
    "id": 14173,
    "content": "b64 [shmem]; 9"
  },
  {
    "id": 14174,
    "content": "7"
  },
  {
    "id": 14175,
    "content": "12"
  },
  {
    "id": 14176,
    "content": "15"
  },
  {
    "id": 14177,
    "content": "11"
  },
  {
    "id": 14179,
    "content": "sem}{"
  },
  {
    "id": 14180,
    "content": "scope}{"
  },
  {
    "id": 14181,
    "content": "space}"
  },
  {
    "id": 14182,
    "content": "b64 [addr], txCount;"
  },
  {
    "id": 14183,
    "content": "sem = {"
  },
  {
    "id": 14184,
    "content": "relaxed }"
  },
  {
    "id": 14185,
    "content": "scope = {"
  },
  {
    "id": 14186,
    "content": "cta,"
  },
  {
    "id": 14187,
    "content": "cluster }"
  },
  {
    "id": 14188,
    "content": "space = {"
  },
  {
    "id": 14189,
    "content": "shared{::cta}, shared::cluster } Description A thread executing mbarrier"
  },
  {
    "id": 14191,
    "content": "shared::cta or shared::cluster state space then the behavior is undefined"
  },
  {
    "id": 14192,
    "content": "This operation does not provide any memory ordering semantics and thus is a relaxed operation"
  },
  {
    "id": 14193,
    "content": "Examples mbarrier"
  },
  {
    "id": 14194,
    "content": "expect_tx"
  },
  {
    "id": 14195,
    "content": "b64 [addr], 32; mbarrier"
  },
  {
    "id": 14196,
    "content": "expect_tx"
  },
  {
    "id": 14197,
    "content": "relaxed"
  },
  {
    "id": 14198,
    "content": "cta"
  },
  {
    "id": 14199,
    "content": "shared"
  },
  {
    "id": 14200,
    "content": "b64 [mbarObj1], 512; mbarrier"
  },
  {
    "id": 14201,
    "content": "expect_tx"
  },
  {
    "id": 14202,
    "content": "relaxed"
  },
  {
    "id": 14203,
    "content": "cta"
  },
  {
    "id": 14204,
    "content": "shared"
  },
  {
    "id": 14205,
    "content": "b64 [mbarObj2], 512; 9"
  },
  {
    "id": 14206,
    "content": "7"
  },
  {
    "id": 14207,
    "content": "12"
  },
  {
    "id": 14208,
    "content": "15"
  },
  {
    "id": 14209,
    "content": "12"
  },
  {
    "id": 14211,
    "content": "sem}{"
  },
  {
    "id": 14212,
    "content": "scope}{"
  },
  {
    "id": 14213,
    "content": "space}"
  },
  {
    "id": 14214,
    "content": "b64 [addr], txCount;"
  },
  {
    "id": 14215,
    "content": "sem = {"
  },
  {
    "id": 14216,
    "content": "relaxed }"
  },
  {
    "id": 14217,
    "content": "scope = {"
  },
  {
    "id": 14218,
    "content": "cta,"
  },
  {
    "id": 14219,
    "content": "cluster }"
  },
  {
    "id": 14220,
    "content": "space = {"
  },
  {
    "id": 14221,
    "content": "shared{::cta}, shared::cluster } Description A thread executing mbarrier"
  },
  {
    "id": 14223,
    "content": "signaling to the mbarrier object Examples mbarrier complete_tx b64 [addr], 32; mbarrier complete_tx"
  },
  {
    "id": 14224,
    "content": "shared"
  },
  {
    "id": 14225,
    "content": "b64 [mbarObj1], 512; mbarrier"
  },
  {
    "id": 14226,
    "content": "complete_tx"
  },
  {
    "id": 14227,
    "content": "relaxed"
  },
  {
    "id": 14228,
    "content": "cta"
  },
  {
    "id": 14229,
    "content": "b64 [addr2], 32; 9"
  },
  {
    "id": 14230,
    "content": "7"
  },
  {
    "id": 14231,
    "content": "12"
  },
  {
    "id": 14232,
    "content": "15"
  },
  {
    "id": 14233,
    "content": "13"
  },
  {
    "id": 14235,
    "content": "sem}{"
  },
  {
    "id": 14236,
    "content": "scope}{"
  },
  {
    "id": 14237,
    "content": "shared{::cta}}"
  },
  {
    "id": 14238,
    "content": "b64 state, [addr]{, count}; mbarrier"
  },
  {
    "id": 14239,
    "content": "arrive{"
  },
  {
    "id": 14240,
    "content": "sem}{"
  },
  {
    "id": 14241,
    "content": "scope}{"
  },
  {
    "id": 14242,
    "content": "shared::cluster}"
  },
  {
    "id": 14243,
    "content": "b64 _, [addr] {,count} mbarrier"
  },
  {
    "id": 14244,
    "content": "arrive"
  },
  {
    "id": 14245,
    "content": "expect_tx{"
  },
  {
    "id": 14246,
    "content": "sem}{"
  },
  {
    "id": 14247,
    "content": "scope}{"
  },
  {
    "id": 14248,
    "content": "shared{::cta}}"
  },
  {
    "id": 14249,
    "content": "b64 state, [addr], txCount; mbarrier"
  },
  {
    "id": 14250,
    "content": "arrive"
  },
  {
    "id": 14251,
    "content": "expect_tx{"
  },
  {
    "id": 14252,
    "content": "sem}{"
  },
  {
    "id": 14253,
    "content": "scope}{"
  },
  {
    "id": 14254,
    "content": "shared::cluster}"
  },
  {
    "id": 14255,
    "content": "b64 _, [addr], txCount; mbarrier"
  },
  {
    "id": 14256,
    "content": "arrive"
  },
  {
    "id": 14257,
    "content": "noComplete{"
  },
  {
    "id": 14258,
    "content": "sem}{"
  },
  {
    "id": 14259,
    "content": "cta}{ shared{::cta}}"
  },
  {
    "id": 14260,
    "content": "b64 state, [addr], count;"
  },
  {
    "id": 14261,
    "content": "sem = {"
  },
  {
    "id": 14262,
    "content": "release }"
  },
  {
    "id": 14263,
    "content": "scope = {"
  },
  {
    "id": 14264,
    "content": "cta,"
  },
  {
    "id": 14265,
    "content": "cluster } Description A thread executing mbarrier"
  },
  {
    "id": 14267,
    "content": "The optional qualifier"
  },
  {
    "id": 14268,
    "content": "expect_tx specifies that an expect-tx operation is performed prior to the arrive-on operation"
  },
  {
    "id": 14269,
    "content": "When both qualifiers"
  },
  {
    "id": 14271,
    "content": "A mbarrier"
  },
  {
    "id": 14272,
    "content": "arrive operation with"
  },
  {
    "id": 14275,
    "content": "shared::cluster but not in shared::cta cannot return a value"
  },
  {
    "id": 14276,
    "content": "The optional"
  },
  {
    "id": 14278,
    "content": "Support for sink symbol ‘_’ as the destination operand is introduced in PTX ISA version 7"
  },
  {
    "id": 14279,
    "content": "1"
  },
  {
    "id": 14280,
    "content": "Support for count argument without the modifier"
  },
  {
    "id": 14281,
    "content": "noComplete introduced in PTX ISA version 7"
  },
  {
    "id": 14282,
    "content": "8"
  },
  {
    "id": 14283,
    "content": "Support for"
  },
  {
    "id": 14284,
    "content": "scope and"
  },
  {
    "id": 14285,
    "content": "sem qualifiers introduced in PTX ISA version 8"
  },
  {
    "id": 14286,
    "content": "0 Target ISA Notes Requires sm_80 or higher"
  },
  {
    "id": 14287,
    "content": "Examples"
  },
  {
    "id": 14288,
    "content": "reg"
  },
  {
    "id": 14289,
    "content": "b32 cnt, remoteAddr32, remoteCTAId, addr32;"
  },
  {
    "id": 14290,
    "content": "reg"
  },
  {
    "id": 14291,
    "content": "b64 %r, addr, remoteAddr64;"
  },
  {
    "id": 14292,
    "content": "shared"
  },
  {
    "id": 14293,
    "content": "b64 shMem, shMem2; cvta"
  },
  {
    "id": 14294,
    "content": "shared"
  },
  {
    "id": 14295,
    "content": "u64 addr, shMem2; mov b32 addr32, shMem2; mapa"
  },
  {
    "id": 14296,
    "content": "shared::cluster"
  },
  {
    "id": 14297,
    "content": "u32 remoteAddr32, addr32, remoteCTAId; mapa u64 remoteAddr64, addr, remoteCTAId; cvta"
  },
  {
    "id": 14298,
    "content": "shared"
  },
  {
    "id": 14299,
    "content": "u64 addr, shMem2; mbarrier"
  },
  {
    "id": 14300,
    "content": "arrive"
  },
  {
    "id": 14301,
    "content": "shared"
  },
  {
    "id": 14302,
    "content": "b64 %r0, [shMem]; mbarrier"
  },
  {
    "id": 14303,
    "content": "arrive"
  },
  {
    "id": 14304,
    "content": "shared::cta"
  },
  {
    "id": 14305,
    "content": "b64 %r0, [shMem2]; mbarrier"
  },
  {
    "id": 14306,
    "content": "arrive"
  },
  {
    "id": 14307,
    "content": "release"
  },
  {
    "id": 14308,
    "content": "cta"
  },
  {
    "id": 14309,
    "content": "shared::cluster"
  },
  {
    "id": 14310,
    "content": "b64 _, [remoteAddr32]; mbarrier"
  },
  {
    "id": 14311,
    "content": "arrive"
  },
  {
    "id": 14312,
    "content": "release"
  },
  {
    "id": 14313,
    "content": "cluster"
  },
  {
    "id": 14314,
    "content": "b64 _, [remoteAddr64], cnt; mbarrier"
  },
  {
    "id": 14315,
    "content": "arrive"
  },
  {
    "id": 14316,
    "content": "expect_tx"
  },
  {
    "id": 14317,
    "content": "release"
  },
  {
    "id": 14318,
    "content": "cluster"
  },
  {
    "id": 14319,
    "content": "b64 _, [remoteAddr64], tx_count; mbarrier"
  },
  {
    "id": 14320,
    "content": "arrive"
  },
  {
    "id": 14321,
    "content": "noComplete"
  },
  {
    "id": 14322,
    "content": "b64 %r1, [addr], 2; mbarrier"
  },
  {
    "id": 14323,
    "content": "arrive"
  },
  {
    "id": 14324,
    "content": "b64 %r2, [addr], cnt; 9"
  },
  {
    "id": 14325,
    "content": "7"
  },
  {
    "id": 14326,
    "content": "12"
  },
  {
    "id": 14327,
    "content": "15"
  },
  {
    "id": 14328,
    "content": "14"
  },
  {
    "id": 14330,
    "content": "sem}{"
  },
  {
    "id": 14331,
    "content": "scope}{"
  },
  {
    "id": 14332,
    "content": "shared{::cta}}"
  },
  {
    "id": 14333,
    "content": "b64 state, [addr]{, count}; mbarrier"
  },
  {
    "id": 14334,
    "content": "arrive_drop{"
  },
  {
    "id": 14335,
    "content": "sem}{"
  },
  {
    "id": 14336,
    "content": "scope}{"
  },
  {
    "id": 14337,
    "content": "shared::cluster}"
  },
  {
    "id": 14338,
    "content": "b64 _, [addr] {,count}; mbarrier"
  },
  {
    "id": 14339,
    "content": "arrive_drop"
  },
  {
    "id": 14340,
    "content": "expect_tx{"
  },
  {
    "id": 14341,
    "content": "shared{::cta}}{"
  },
  {
    "id": 14342,
    "content": "sem}{"
  },
  {
    "id": 14343,
    "content": "scope}"
  },
  {
    "id": 14344,
    "content": "b64 state, [addr], tx_count; mbarrier"
  },
  {
    "id": 14345,
    "content": "arrive_drop"
  },
  {
    "id": 14346,
    "content": "expect_tx{"
  },
  {
    "id": 14347,
    "content": "shared::cluster}{"
  },
  {
    "id": 14348,
    "content": "sem}{"
  },
  {
    "id": 14349,
    "content": "scope}"
  },
  {
    "id": 14350,
    "content": "b64 _, [addr], tx_count; mbarrier"
  },
  {
    "id": 14351,
    "content": "arrive_drop"
  },
  {
    "id": 14352,
    "content": "noComplete{"
  },
  {
    "id": 14353,
    "content": "sem}{"
  },
  {
    "id": 14354,
    "content": "cta}{ shared{::cta}}"
  },
  {
    "id": 14355,
    "content": "b64 state, [addr], count;"
  },
  {
    "id": 14356,
    "content": "sem = {"
  },
  {
    "id": 14357,
    "content": "release }"
  },
  {
    "id": 14358,
    "content": "scope = {"
  },
  {
    "id": 14359,
    "content": "cta,"
  },
  {
    "id": 14360,
    "content": "cluster } Description A thread executing mbarrier"
  },
  {
    "id": 14362,
    "content": "When both qualifiers"
  },
  {
    "id": 14364,
    "content": "mbarrier"
  },
  {
    "id": 14366,
    "content": "The optional"
  },
  {
    "id": 14367,
    "content": "scope qualifier indicates the set of threads that an mbarrier"
  },
  {
    "id": 14368,
    "content": "arrive_drop instruction can directly synchronize"
  },
  {
    "id": 14369,
    "content": "A mbarrier"
  },
  {
    "id": 14370,
    "content": "arrive_drop with"
  },
  {
    "id": 14371,
    "content": "noComplete qualifier must not complete the mbarrier, otherwise the behavior is undefined"
  },
  {
    "id": 14374,
    "content": "shared::cluster but not in shared::cta cannot return a value"
  },
  {
    "id": 14375,
    "content": "Examples"
  },
  {
    "id": 14376,
    "content": "reg"
  },
  {
    "id": 14377,
    "content": "b32 cnt;"
  },
  {
    "id": 14378,
    "content": "reg"
  },
  {
    "id": 14379,
    "content": "b64 %r1;"
  },
  {
    "id": 14380,
    "content": "shared"
  },
  {
    "id": 14381,
    "content": "b64 shMem;   Example 1 @p mbarrier"
  },
  {
    "id": 14382,
    "content": "arrive_drop"
  },
  {
    "id": 14383,
    "content": "shared"
  },
  {
    "id": 14384,
    "content": "b64 _, [shMem]; @p exit; @p2 mbarrier"
  },
  {
    "id": 14385,
    "content": "arrive_drop"
  },
  {
    "id": 14386,
    "content": "noComplete"
  },
  {
    "id": 14387,
    "content": "shared"
  },
  {
    "id": 14388,
    "content": "b64 _, [shMem], %a; @p2 exit;"
  },
  {
    "id": 14389,
    "content": "@"
  },
  {
    "id": 14390,
    "content": "p mbarrier"
  },
  {
    "id": 14391,
    "content": "arrive"
  },
  {
    "id": 14392,
    "content": "shared"
  },
  {
    "id": 14393,
    "content": "b64 %r1, [shMem]; @"
  },
  {
    "id": 14394,
    "content": "p mbarrier"
  },
  {
    "id": 14395,
    "content": "test_wait"
  },
  {
    "id": 14396,
    "content": "shared"
  },
  {
    "id": 14397,
    "content": "b64 q, [shMem], %r1;   Example 2 mbarrier"
  },
  {
    "id": 14398,
    "content": "arrive_drop"
  },
  {
    "id": 14399,
    "content": "shared::cluster"
  },
  {
    "id": 14400,
    "content": "b64 _, [addr]; mbarrier"
  },
  {
    "id": 14401,
    "content": "arrive_drop"
  },
  {
    "id": 14402,
    "content": "shared::cta"
  },
  {
    "id": 14403,
    "content": "release"
  },
  {
    "id": 14404,
    "content": "cluster"
  },
  {
    "id": 14405,
    "content": "b64 _, [addr], cnt;   Example 3 mbarrier"
  },
  {
    "id": 14406,
    "content": "arrive_drop"
  },
  {
    "id": 14407,
    "content": "expect_tx"
  },
  {
    "id": 14408,
    "content": "shared::cta"
  },
  {
    "id": 14409,
    "content": "release"
  },
  {
    "id": 14410,
    "content": "cta"
  },
  {
    "id": 14411,
    "content": "b64 state, [addr], tx_count; 9"
  },
  {
    "id": 14412,
    "content": "7"
  },
  {
    "id": 14413,
    "content": "12"
  },
  {
    "id": 14414,
    "content": "15 15"
  },
  {
    "id": 14415,
    "content": "Parallel Synchronization and Communication Instructions: cp"
  },
  {
    "id": 14416,
    "content": "async"
  },
  {
    "id": 14417,
    "content": "mbarrier"
  },
  {
    "id": 14418,
    "content": "arrive  cp"
  },
  {
    "id": 14419,
    "content": "async"
  },
  {
    "id": 14420,
    "content": "mbarrier arrive Makes the mbarrier object track all prior cp"
  },
  {
    "id": 14421,
    "content": "async operations initiated by the executing thread"
  },
  {
    "id": 14422,
    "content": "Syntax cp"
  },
  {
    "id": 14423,
    "content": "async"
  },
  {
    "id": 14424,
    "content": "mbarrier"
  },
  {
    "id": 14425,
    "content": "arrive{"
  },
  {
    "id": 14426,
    "content": "noinc}{"
  },
  {
    "id": 14427,
    "content": "shared{::cta}}"
  },
  {
    "id": 14429,
    "content": "async operations initiated by the executing thread"
  },
  {
    "id": 14430,
    "content": "When"
  },
  {
    "id": 14432,
    "content": "When the"
  },
  {
    "id": 14434,
    "content": "cp"
  },
  {
    "id": 14435,
    "content": "async"
  },
  {
    "id": 14436,
    "content": "ca"
  },
  {
    "id": 14437,
    "content": "shared"
  },
  {
    "id": 14438,
    "content": "global [shard1], [gbl1], 4; cp"
  },
  {
    "id": 14439,
    "content": "async"
  },
  {
    "id": 14440,
    "content": "cg"
  },
  {
    "id": 14441,
    "content": "shared"
  },
  {
    "id": 14442,
    "content": "global [shard2], [gbl2], 16;"
  },
  {
    "id": 14443,
    "content": "mbarrier"
  },
  {
    "id": 14444,
    "content": "arrive"
  },
  {
    "id": 14445,
    "content": "shared"
  },
  {
    "id": 14446,
    "content": "b64 state, [shMem]; waitLoop: mbarrier"
  },
  {
    "id": 14447,
    "content": "test_wait"
  },
  {
    "id": 14448,
    "content": "shared"
  },
  {
    "id": 14449,
    "content": "b64 p, [shMem], state; @"
  },
  {
    "id": 14450,
    "content": "p bra waitLoop;   Example 2: with"
  },
  {
    "id": 14451,
    "content": "noinc   Tracks arrive-on from mbarrier arrive and cp"
  },
  {
    "id": 14452,
    "content": "async"
  },
  {
    "id": 14453,
    "content": "mbarrier"
  },
  {
    "id": 14454,
    "content": "arrive"
  },
  {
    "id": 14455,
    "content": "All threads participating in the mbarrier perform cp"
  },
  {
    "id": 14456,
    "content": "async mov"
  },
  {
    "id": 14457,
    "content": "b32 copyOperationCnt, threadCount;   3 arrive-on operations will be triggered per-thread mul"
  },
  {
    "id": 14458,
    "content": "lo"
  },
  {
    "id": 14459,
    "content": "u32 copyArrivalCnt, copyOperationCnt, 3; add u32 totalCount, threadCount, copyArrivalCnt; mbarrier"
  },
  {
    "id": 14460,
    "content": "init"
  },
  {
    "id": 14461,
    "content": "shared"
  },
  {
    "id": 14462,
    "content": "b64 [shMem], totalCount;"
  },
  {
    "id": 14463,
    "content": "cp"
  },
  {
    "id": 14464,
    "content": "async"
  },
  {
    "id": 14465,
    "content": "ca"
  },
  {
    "id": 14466,
    "content": "shared"
  },
  {
    "id": 14467,
    "content": "global [shard1], [gbl1], 4; cp"
  },
  {
    "id": 14468,
    "content": "async"
  },
  {
    "id": 14469,
    "content": "cg"
  },
  {
    "id": 14470,
    "content": "shared"
  },
  {
    "id": 14471,
    "content": "global [shard2], [gbl2], 16;"
  },
  {
    "id": 14472,
    "content": "Presence of"
  },
  {
    "id": 14474,
    "content": "shared"
  },
  {
    "id": 14475,
    "content": "b64 [shMem];   1st instance"
  },
  {
    "id": 14476,
    "content": "cp"
  },
  {
    "id": 14477,
    "content": "async"
  },
  {
    "id": 14478,
    "content": "ca"
  },
  {
    "id": 14479,
    "content": "shared"
  },
  {
    "id": 14480,
    "content": "global [shard3], [gbl3], 4; cp"
  },
  {
    "id": 14481,
    "content": "async"
  },
  {
    "id": 14482,
    "content": "ca"
  },
  {
    "id": 14483,
    "content": "shared"
  },
  {
    "id": 14484,
    "content": "global [shard4], [gbl4], 16; cp"
  },
  {
    "id": 14485,
    "content": "async"
  },
  {
    "id": 14486,
    "content": "mbarrier"
  },
  {
    "id": 14487,
    "content": "arrive"
  },
  {
    "id": 14488,
    "content": "noinc"
  },
  {
    "id": 14489,
    "content": "shared::cta"
  },
  {
    "id": 14490,
    "content": "b64 [shMem];   2nd instance"
  },
  {
    "id": 14491,
    "content": "cp"
  },
  {
    "id": 14492,
    "content": "async"
  },
  {
    "id": 14493,
    "content": "ca"
  },
  {
    "id": 14494,
    "content": "shared"
  },
  {
    "id": 14495,
    "content": "global [shard5], [gbl5], 4; cp"
  },
  {
    "id": 14496,
    "content": "async"
  },
  {
    "id": 14497,
    "content": "cg"
  },
  {
    "id": 14498,
    "content": "shared"
  },
  {
    "id": 14499,
    "content": "global [shard6], [gbl6], 16; cp"
  },
  {
    "id": 14500,
    "content": "async"
  },
  {
    "id": 14501,
    "content": "mbarrier"
  },
  {
    "id": 14502,
    "content": "arrive"
  },
  {
    "id": 14503,
    "content": "noinc"
  },
  {
    "id": 14504,
    "content": "shared"
  },
  {
    "id": 14505,
    "content": "b64 [shMem];   3rd and last instance"
  },
  {
    "id": 14506,
    "content": "mbarrier"
  },
  {
    "id": 14507,
    "content": "arrive"
  },
  {
    "id": 14508,
    "content": "shared"
  },
  {
    "id": 14509,
    "content": "b64 state, [shMem]; waitLoop: mbarrier"
  },
  {
    "id": 14510,
    "content": "test_wait"
  },
  {
    "id": 14511,
    "content": "shared"
  },
  {
    "id": 14512,
    "content": "b64 p, [shMem], state; @"
  },
  {
    "id": 14513,
    "content": "p bra waitLoop; 9"
  },
  {
    "id": 14514,
    "content": "7"
  },
  {
    "id": 14515,
    "content": "12"
  },
  {
    "id": 14516,
    "content": "15"
  },
  {
    "id": 14517,
    "content": "16"
  },
  {
    "id": 14519,
    "content": "sem}{"
  },
  {
    "id": 14520,
    "content": "scope}{"
  },
  {
    "id": 14521,
    "content": "shared{::cta}}"
  },
  {
    "id": 14522,
    "content": "b64 waitComplete, [addr], state; mbarrier"
  },
  {
    "id": 14523,
    "content": "test_wait"
  },
  {
    "id": 14524,
    "content": "parity{"
  },
  {
    "id": 14525,
    "content": "sem}{"
  },
  {
    "id": 14526,
    "content": "scope}{"
  },
  {
    "id": 14527,
    "content": "shared{::cta}}"
  },
  {
    "id": 14528,
    "content": "b64 waitComplete, [addr], phaseParity; mbarrier"
  },
  {
    "id": 14529,
    "content": "try_wait{"
  },
  {
    "id": 14530,
    "content": "sem}{"
  },
  {
    "id": 14531,
    "content": "scope}{"
  },
  {
    "id": 14532,
    "content": "shared{::cta}}"
  },
  {
    "id": 14533,
    "content": "b64 waitComplete, [addr], state {, suspendTimeHint}; mbarrier"
  },
  {
    "id": 14534,
    "content": "try_wait"
  },
  {
    "id": 14535,
    "content": "parity{"
  },
  {
    "id": 14536,
    "content": "sem}{"
  },
  {
    "id": 14537,
    "content": "scope}{"
  },
  {
    "id": 14538,
    "content": "shared{::cta}}"
  },
  {
    "id": 14539,
    "content": "b64 waitComplete, [addr], phaseParity {, suspendTimeHint};"
  },
  {
    "id": 14540,
    "content": "sem = {"
  },
  {
    "id": 14541,
    "content": "acquire }"
  },
  {
    "id": 14542,
    "content": "scope = {"
  },
  {
    "id": 14543,
    "content": "cta,"
  },
  {
    "id": 14550,
    "content": "All cp async operations requested prior, in program order, to cp async"
  },
  {
    "id": 14551,
    "content": "mbarrier"
  },
  {
    "id": 14553,
    "content": "All cp"
  },
  {
    "id": 14554,
    "content": "async"
  },
  {
    "id": 14558,
    "content": ", in program order"
  },
  {
    "id": 14559,
    "content": "Support for"
  },
  {
    "id": 14560,
    "content": "scope and"
  },
  {
    "id": 14561,
    "content": "sem qualifiers introduced in PTX ISA version 8 0 Target ISA Notes mbarrier"
  },
  {
    "id": 14562,
    "content": "test_wait requires sm_80 or higher Examples   Example 1a, thread synchronization with test_wait:"
  },
  {
    "id": 14563,
    "content": "reg"
  },
  {
    "id": 14564,
    "content": "b64 %r1;"
  },
  {
    "id": 14565,
    "content": "shared"
  },
  {
    "id": 14566,
    "content": "b64 shMem; mbarrier"
  },
  {
    "id": 14567,
    "content": "init"
  },
  {
    "id": 14568,
    "content": "shared"
  },
  {
    "id": 14569,
    "content": "b64 [shMem], N;   N threads participating in the mbarrier mbarrier"
  },
  {
    "id": 14570,
    "content": "arrive"
  },
  {
    "id": 14571,
    "content": "shared"
  },
  {
    "id": 14572,
    "content": "b64 %r1, [shMem];   N threads executing mbarrier"
  },
  {
    "id": 14573,
    "content": "arrive   computation not requiring mbarrier synchronization waitLoop: mbarrier"
  },
  {
    "id": 14574,
    "content": "test_wait"
  },
  {
    "id": 14575,
    "content": "shared"
  },
  {
    "id": 14576,
    "content": "b64 complete, [shMem], %r1; @ complete nanosleep"
  },
  {
    "id": 14577,
    "content": "u32 20; @"
  },
  {
    "id": 14578,
    "content": "complete bra waitLoop;   Example 1b, thread synchronization with try_wait :"
  },
  {
    "id": 14579,
    "content": "reg"
  },
  {
    "id": 14580,
    "content": "b64 %r1;"
  },
  {
    "id": 14581,
    "content": "shared"
  },
  {
    "id": 14582,
    "content": "b64 shMem; mbarrier"
  },
  {
    "id": 14583,
    "content": "init"
  },
  {
    "id": 14584,
    "content": "shared"
  },
  {
    "id": 14585,
    "content": "b64 [shMem], N;   N threads participating in the mbarrier mbarrier"
  },
  {
    "id": 14586,
    "content": "arrive"
  },
  {
    "id": 14587,
    "content": "shared"
  },
  {
    "id": 14588,
    "content": "b64 %r1, [shMem];   N threads executing mbarrier"
  },
  {
    "id": 14589,
    "content": "arrive   computation not requiring mbarrier synchronization waitLoop: mbarrier"
  },
  {
    "id": 14590,
    "content": "try_wait"
  },
  {
    "id": 14591,
    "content": "shared"
  },
  {
    "id": 14592,
    "content": "b64 complete, [shMem], %r1; @"
  },
  {
    "id": 14593,
    "content": "complete bra waitLoop;   Example 2, thread synchronization using phase parity :"
  },
  {
    "id": 14594,
    "content": "reg"
  },
  {
    "id": 14595,
    "content": "b32 i, parArg;"
  },
  {
    "id": 14596,
    "content": "reg"
  },
  {
    "id": 14597,
    "content": "b64 %r1;"
  },
  {
    "id": 14598,
    "content": "shared"
  },
  {
    "id": 14599,
    "content": "b64 shMem; mov"
  },
  {
    "id": 14600,
    "content": "b32 i, 0; mbarrier"
  },
  {
    "id": 14601,
    "content": "init"
  },
  {
    "id": 14602,
    "content": "shared"
  },
  {
    "id": 14603,
    "content": "b64 [shMem], N;   N threads participating in the mbarrier"
  },
  {
    "id": 14604,
    "content": "loopStart :   One phase per loop iteration"
  },
  {
    "id": 14605,
    "content": "and"
  },
  {
    "id": 14606,
    "content": "b32 parArg, i, 1; waitLoop: mbarrier"
  },
  {
    "id": 14607,
    "content": "test_wait"
  },
  {
    "id": 14608,
    "content": "parity"
  },
  {
    "id": 14609,
    "content": "shared"
  },
  {
    "id": 14610,
    "content": "b64 complete, [shMem], parArg; @ complete nanosleep"
  },
  {
    "id": 14611,
    "content": "u32 20; @"
  },
  {
    "id": 14612,
    "content": "complete bra waitLoop;"
  },
  {
    "id": 14613,
    "content": "add"
  },
  {
    "id": 14614,
    "content": "u32 i, i, 1; setp"
  },
  {
    "id": 14615,
    "content": "lt"
  },
  {
    "id": 14616,
    "content": "u32 p, i, IterMax; @p bra loopStart;   Example 3, Asynchronous copy completion waiting :"
  },
  {
    "id": 14617,
    "content": "reg"
  },
  {
    "id": 14618,
    "content": "b64 state;"
  },
  {
    "id": 14619,
    "content": "shared"
  },
  {
    "id": 14620,
    "content": "b64 shMem2;"
  },
  {
    "id": 14621,
    "content": "shared"
  },
  {
    "id": 14622,
    "content": "b64 shard1, shard2;"
  },
  {
    "id": 14623,
    "content": "global"
  },
  {
    "id": 14624,
    "content": "b64 gbl1, gbl2; mbarrier"
  },
  {
    "id": 14625,
    "content": "init"
  },
  {
    "id": 14626,
    "content": "shared"
  },
  {
    "id": 14627,
    "content": "b64 [shMem2], threadCount;"
  },
  {
    "id": 14628,
    "content": "cp"
  },
  {
    "id": 14629,
    "content": "async"
  },
  {
    "id": 14630,
    "content": "ca"
  },
  {
    "id": 14631,
    "content": "shared"
  },
  {
    "id": 14632,
    "content": "global [shard1], [gbl1], 4; cp"
  },
  {
    "id": 14633,
    "content": "async"
  },
  {
    "id": 14634,
    "content": "cg"
  },
  {
    "id": 14635,
    "content": "shared"
  },
  {
    "id": 14636,
    "content": "global [shard2], [gbl2], 16;   Absence of"
  },
  {
    "id": 14637,
    "content": "noinc accounts for arrive-on from prior cp async operation cp async"
  },
  {
    "id": 14638,
    "content": "mbarrier"
  },
  {
    "id": 14639,
    "content": "arrive"
  },
  {
    "id": 14640,
    "content": "shared"
  },
  {
    "id": 14641,
    "content": "b64 [shMem2];"
  },
  {
    "id": 14642,
    "content": "mbarrier"
  },
  {
    "id": 14643,
    "content": "arrive"
  },
  {
    "id": 14644,
    "content": "shared"
  },
  {
    "id": 14645,
    "content": "b64 state, [shMem2]; waitLoop: mbarrier"
  },
  {
    "id": 14646,
    "content": "test_wait"
  },
  {
    "id": 14647,
    "content": "shared::cta"
  },
  {
    "id": 14648,
    "content": "b64 p, [shMem2], state; @"
  },
  {
    "id": 14649,
    "content": "p bra waitLoop;   Example 4, Synchronizing the CTA0 threads with cluster threads"
  },
  {
    "id": 14650,
    "content": "reg"
  },
  {
    "id": 14651,
    "content": "b64 %r1, addr, remAddr;"
  },
  {
    "id": 14652,
    "content": "shared"
  },
  {
    "id": 14653,
    "content": "b64 shMem; cvta"
  },
  {
    "id": 14654,
    "content": "shared"
  },
  {
    "id": 14656,
    "content": "init"
  },
  {
    "id": 14657,
    "content": "shared::cta"
  },
  {
    "id": 14659,
    "content": "release"
  },
  {
    "id": 14660,
    "content": "cluster"
  },
  {
    "id": 14661,
    "content": "b64 _, [remAddr];   computation not requiring mbarrier synchronization"
  },
  {
    "id": 14662,
    "content": "Only CTA0 threads executing the below wait operation waitLoop: mbarrier"
  },
  {
    "id": 14663,
    "content": "try_wait"
  },
  {
    "id": 14664,
    "content": "parity"
  },
  {
    "id": 14665,
    "content": "acquire"
  },
  {
    "id": 14666,
    "content": "cluser"
  },
  {
    "id": 14667,
    "content": "shared::cta"
  },
  {
    "id": 14668,
    "content": "b64 complete, [shMem], 0; @ complete bra waitLoop; 9"
  },
  {
    "id": 14669,
    "content": "7"
  },
  {
    "id": 14670,
    "content": "12"
  },
  {
    "id": 14671,
    "content": "15"
  },
  {
    "id": 14672,
    "content": "17"
  },
  {
    "id": 14674,
    "content": "mbarrier"
  },
  {
    "id": 14675,
    "content": "arrive"
  },
  {
    "id": 14676,
    "content": "noComplete or mbarrier"
  },
  {
    "id": 14677,
    "content": "arrive_drop"
  },
  {
    "id": 14678,
    "content": "noComplete instruction"
  },
  {
    "id": 14680,
    "content": "Examples"
  },
  {
    "id": 14681,
    "content": "reg"
  },
  {
    "id": 14682,
    "content": "b32 %r1;"
  },
  {
    "id": 14683,
    "content": "reg"
  },
  {
    "id": 14684,
    "content": "b64 state;"
  },
  {
    "id": 14685,
    "content": "shared"
  },
  {
    "id": 14686,
    "content": "b64 shMem; mbarrier"
  },
  {
    "id": 14687,
    "content": "arrive"
  },
  {
    "id": 14688,
    "content": "noComplete"
  },
  {
    "id": 14689,
    "content": "b64 state, [shMem], 1; mbarrier"
  },
  {
    "id": 14690,
    "content": "pending_count"
  },
  {
    "id": 14691,
    "content": "b64 %r1, state; 9"
  },
  {
    "id": 14692,
    "content": "7"
  },
  {
    "id": 14693,
    "content": "12"
  },
  {
    "id": 14694,
    "content": "15"
  },
  {
    "id": 14695,
    "content": "18"
  },
  {
    "id": 14697,
    "content": "cp_qualifiers"
  },
  {
    "id": 14698,
    "content": "fence_qualifiers"
  },
  {
    "id": 14699,
    "content": "sync"
  },
  {
    "id": 14700,
    "content": "aligned [dst], [src], size;"
  },
  {
    "id": 14701,
    "content": "cp_qualifiers = {"
  },
  {
    "id": 14702,
    "content": "global"
  },
  {
    "id": 14703,
    "content": "shared::cta }"
  },
  {
    "id": 14704,
    "content": "fence_qualifiers = {"
  },
  {
    "id": 14705,
    "content": "to_proxy::from_proxy"
  },
  {
    "id": 14706,
    "content": "release"
  },
  {
    "id": 14707,
    "content": "scope }"
  },
  {
    "id": 14708,
    "content": "to_proxy::from_proxy = {"
  },
  {
    "id": 14709,
    "content": "tensormap::generic }"
  },
  {
    "id": 14710,
    "content": "scope = {"
  },
  {
    "id": 14711,
    "content": "cta,"
  },
  {
    "id": 14712,
    "content": "cluster,"
  },
  {
    "id": 14713,
    "content": "gpu ,"
  },
  {
    "id": 14714,
    "content": "sys } Description The tensormap"
  },
  {
    "id": 14717,
    "content": "The optional"
  },
  {
    "id": 14719,
    "content": "The mandatory"
  },
  {
    "id": 14721,
    "content": "The mandatory"
  },
  {
    "id": 14722,
    "content": "aligned qualifier indicates that all threads in the warp must execute the same tensormap"
  },
  {
    "id": 14723,
    "content": "cp_fenceproxy instruction"
  },
  {
    "id": 14724,
    "content": "In conditionally executed code, an aligned tensormap"
  },
  {
    "id": 14726,
    "content": "Examples   Example: manipulate a tensor-map object and then consume it in cp"
  },
  {
    "id": 14727,
    "content": "async"
  },
  {
    "id": 14728,
    "content": "bulk"
  },
  {
    "id": 14729,
    "content": "tensor"
  },
  {
    "id": 14730,
    "content": "reg"
  },
  {
    "id": 14731,
    "content": "b64 new_addr;"
  },
  {
    "id": 14732,
    "content": "global"
  },
  {
    "id": 14733,
    "content": "align 128 b8 gbl[128];"
  },
  {
    "id": 14734,
    "content": "shared"
  },
  {
    "id": 14735,
    "content": "align 128 b8 sMem[128]; cp"
  },
  {
    "id": 14736,
    "content": "async"
  },
  {
    "id": 14737,
    "content": "bulk"
  },
  {
    "id": 14738,
    "content": "shared::cluster"
  },
  {
    "id": 14739,
    "content": "global"
  },
  {
    "id": 14740,
    "content": "mbarrier::complete_tx::bytes [sMem], [gMem], 128, [mbar];"
  },
  {
    "id": 14741,
    "content": "try_wait_loop: mbarrier"
  },
  {
    "id": 14742,
    "content": "try_wait"
  },
  {
    "id": 14743,
    "content": "shared"
  },
  {
    "id": 14744,
    "content": "b64 p, [mbar], state; @"
  },
  {
    "id": 14745,
    "content": "p bra try_wait loop; tensormap"
  },
  {
    "id": 14746,
    "content": "replace"
  },
  {
    "id": 14747,
    "content": "tile"
  },
  {
    "id": 14748,
    "content": "global_address"
  },
  {
    "id": 14749,
    "content": "shared"
  },
  {
    "id": 14750,
    "content": "b1024"
  },
  {
    "id": 14751,
    "content": "b64 [sMem], new_addr; tensormap"
  },
  {
    "id": 14752,
    "content": "cp_fenceproxy"
  },
  {
    "id": 14753,
    "content": "global"
  },
  {
    "id": 14754,
    "content": "shared::cta"
  },
  {
    "id": 14755,
    "content": "proxy"
  },
  {
    "id": 14756,
    "content": "tensormap::generic"
  },
  {
    "id": 14757,
    "content": "release"
  },
  {
    "id": 14758,
    "content": "gpu"
  },
  {
    "id": 14759,
    "content": "sync"
  },
  {
    "id": 14760,
    "content": "aligned [gbl], [sMem], 128; fence"
  },
  {
    "id": 14761,
    "content": "proxy"
  },
  {
    "id": 14762,
    "content": "tensormap::generic"
  },
  {
    "id": 14763,
    "content": "acquire"
  },
  {
    "id": 14764,
    "content": "gpu [gbl], 128; cp"
  },
  {
    "id": 14765,
    "content": "async"
  },
  {
    "id": 14766,
    "content": "bulk"
  },
  {
    "id": 14767,
    "content": "tensor"
  },
  {
    "id": 14768,
    "content": "1d"
  },
  {
    "id": 14769,
    "content": "shared::cluster"
  },
  {
    "id": 14770,
    "content": "global"
  },
  {
    "id": 14771,
    "content": "tile [addr0], [gbl, {tc0}], [mbar0]; 9"
  },
  {
    "id": 14772,
    "content": "7"
  },
  {
    "id": 14773,
    "content": "13"
  },
  {
    "id": 14775,
    "content": "follows: Load matrices A, B and C from memory into registers using the wmma"
  },
  {
    "id": 14779,
    "content": "9"
  },
  {
    "id": 14780,
    "content": "7"
  },
  {
    "id": 14781,
    "content": "13"
  },
  {
    "id": 14782,
    "content": "1"
  },
  {
    "id": 14785,
    "content": "u8 ,"
  },
  {
    "id": 14786,
    "content": "s8"
  },
  {
    "id": 14787,
    "content": "s32 Floating Point"
  },
  {
    "id": 14788,
    "content": "f16 f16 ,"
  },
  {
    "id": 14789,
    "content": "f32 Alternate floating Point"
  },
  {
    "id": 14790,
    "content": "bf16"
  },
  {
    "id": 14791,
    "content": "f32 Alternate floating Point"
  },
  {
    "id": 14792,
    "content": "tf32"
  },
  {
    "id": 14793,
    "content": "f32 Alternate floating Point"
  },
  {
    "id": 14794,
    "content": "e4m3 or"
  },
  {
    "id": 14795,
    "content": "e5m2"
  },
  {
    "id": 14796,
    "content": "f32 Floating Point"
  },
  {
    "id": 14797,
    "content": "f64 f64 Sub-byte integer both u4 or both"
  },
  {
    "id": 14798,
    "content": "s4"
  },
  {
    "id": 14799,
    "content": "s32 Single-bit integer"
  },
  {
    "id": 14800,
    "content": "b1"
  },
  {
    "id": 14801,
    "content": "s32 9"
  },
  {
    "id": 14802,
    "content": "7"
  },
  {
    "id": 14803,
    "content": "13"
  },
  {
    "id": 14804,
    "content": "3"
  },
  {
    "id": 14806,
    "content": "store instructions and the organization of various matrices invovled in these instruction"
  },
  {
    "id": 14807,
    "content": "9"
  },
  {
    "id": 14808,
    "content": "7"
  },
  {
    "id": 14809,
    "content": "13"
  },
  {
    "id": 14810,
    "content": "3"
  },
  {
    "id": 14811,
    "content": "1"
  },
  {
    "id": 14815,
    "content": "u8 or"
  },
  {
    "id": 14816,
    "content": "s8"
  },
  {
    "id": 14817,
    "content": "m16n16k16 A A vector expression of two"
  },
  {
    "id": 14818,
    "content": "b32 registers, with each register containing four elements from the matrix"
  },
  {
    "id": 14819,
    "content": "B A vector expression of two"
  },
  {
    "id": 14820,
    "content": "b32 registers, with each register containing four elements from the matrix"
  },
  {
    "id": 14822,
    "content": "four elements from the matrix"
  },
  {
    "id": 14823,
    "content": "Accumulators (C or D): Data-type Shape Fragment"
  },
  {
    "id": 14824,
    "content": "s32"
  },
  {
    "id": 14825,
    "content": "m16n16k16 A vector expression of eight"
  },
  {
    "id": 14826,
    "content": "s32 registers"
  },
  {
    "id": 14827,
    "content": "m8n32k16"
  },
  {
    "id": 14828,
    "content": "m32n8k16 Floating point fragments Data-type Matrix Fragment"
  },
  {
    "id": 14829,
    "content": "f16 A or B A vector expression of eight"
  },
  {
    "id": 14830,
    "content": "f16x2 registers"
  },
  {
    "id": 14831,
    "content": "Floating point fragments for"
  },
  {
    "id": 14832,
    "content": "bf16 data format Multiplicands (A or B): Data-type Shape Matrix Fragment bf16"
  },
  {
    "id": 14833,
    "content": "m16n16k16 A A vector expression of four"
  },
  {
    "id": 14834,
    "content": "b32 registers, with each register containing two elements from the matrix"
  },
  {
    "id": 14835,
    "content": "B"
  },
  {
    "id": 14837,
    "content": "two elements from the matrix"
  },
  {
    "id": 14838,
    "content": "Accumulators (C or D): Data-type Matrix Fragment"
  },
  {
    "id": 14839,
    "content": "f32 C or D A vector expression containing eight f32 registers"
  },
  {
    "id": 14840,
    "content": "Floating point fragments for"
  },
  {
    "id": 14841,
    "content": "tf32 data format Multiplicands (A or B): Data-type Shape Matrix Fragment tf32"
  },
  {
    "id": 14842,
    "content": "m16n16k8 A A vector expression of four"
  },
  {
    "id": 14843,
    "content": "b32 registers"
  },
  {
    "id": 14844,
    "content": "Accumulators (C or D): Data-type Shape Matrix Fragment"
  },
  {
    "id": 14845,
    "content": "f32"
  },
  {
    "id": 14846,
    "content": "m16n16k8 C or D A vector expression containing eight"
  },
  {
    "id": 14847,
    "content": "f32 registers"
  },
  {
    "id": 14848,
    "content": "Double precision floating point fragments Multiplicands (A or B): Data-type Shape Matrix Fragment"
  },
  {
    "id": 14849,
    "content": "f64"
  },
  {
    "id": 14850,
    "content": "m8n8k4 A or B A vector expression of single"
  },
  {
    "id": 14851,
    "content": "f64 register"
  },
  {
    "id": 14852,
    "content": "Accumulators (C or D): Data-type Shape Matrix Fragment"
  },
  {
    "id": 14853,
    "content": "f64"
  },
  {
    "id": 14854,
    "content": "m8n8k4 C or D A vector expression containing single"
  },
  {
    "id": 14855,
    "content": "f64 register"
  },
  {
    "id": 14856,
    "content": "Sub-byte integer and single-bit fragments Multiplicands (A or B): Data-type Shape Fragment"
  },
  {
    "id": 14857,
    "content": "u4 or"
  },
  {
    "id": 14858,
    "content": "s4"
  },
  {
    "id": 14860,
    "content": "b1"
  },
  {
    "id": 14862,
    "content": "Accumulators (C or D): Data-type Shape Fragment"
  },
  {
    "id": 14863,
    "content": "s32"
  },
  {
    "id": 14864,
    "content": "m8n8k32 A vector expression of two"
  },
  {
    "id": 14865,
    "content": "s32 registers"
  },
  {
    "id": 14868,
    "content": "Note that type conversion between"
  },
  {
    "id": 14869,
    "content": "f16 and"
  },
  {
    "id": 14870,
    "content": "f32 accumulator fragments is not supported in either direction"
  },
  {
    "id": 14871,
    "content": "The result is undefined even if the order of elements in the fragment remains unchanged"
  },
  {
    "id": 14872,
    "content": "9"
  },
  {
    "id": 14873,
    "content": "7"
  },
  {
    "id": 14874,
    "content": "13"
  },
  {
    "id": 14875,
    "content": "3"
  },
  {
    "id": 14876,
    "content": "2"
  },
  {
    "id": 14881,
    "content": "a"
  },
  {
    "id": 14882,
    "content": "sync"
  },
  {
    "id": 14883,
    "content": "aligned"
  },
  {
    "id": 14884,
    "content": "row"
  },
  {
    "id": 14885,
    "content": "m16n16k16"
  },
  {
    "id": 14886,
    "content": "f16 {x0,"
  },
  {
    "id": 14887,
    "content": ",x7}, [p], s; Fragment size in bytes = 32 (eight elements of type"
  },
  {
    "id": 14888,
    "content": "f16x2 ) Actual stride in bytes = 2 * s (since stride is specified in terms of"
  },
  {
    "id": 14891,
    "content": "7"
  },
  {
    "id": 14892,
    "content": "13"
  },
  {
    "id": 14893,
    "content": "3"
  },
  {
    "id": 14894,
    "content": "3"
  },
  {
    "id": 14895,
    "content": "wmma"
  },
  {
    "id": 14896,
    "content": "load operation may be used only with"
  },
  {
    "id": 14897,
    "content": "global and"
  },
  {
    "id": 14898,
    "content": "shared spaces and with generic addressing, where the address points to"
  },
  {
    "id": 14899,
    "content": "global or"
  },
  {
    "id": 14900,
    "content": "shared space"
  },
  {
    "id": 14901,
    "content": "The mutually exclusive qualifiers"
  },
  {
    "id": 14902,
    "content": "a ,"
  },
  {
    "id": 14903,
    "content": "b and"
  },
  {
    "id": 14905,
    "content": "indicates whether the matrix to be loaded is stored in row-major or column-major format"
  },
  {
    "id": 14908,
    "content": "The mandatory"
  },
  {
    "id": 14910,
    "content": "load instruction before resuming execution"
  },
  {
    "id": 14911,
    "content": "The mandatory"
  },
  {
    "id": 14912,
    "content": "aligned qualifier indicates that all threads in the warp must execute the same wmma"
  },
  {
    "id": 14913,
    "content": "load instruction"
  },
  {
    "id": 14914,
    "content": "In conditionally executed code, a wmma"
  },
  {
    "id": 14916,
    "content": "version 7"
  },
  {
    "id": 14917,
    "content": "0"
  },
  {
    "id": 14918,
    "content": "Modifier"
  },
  {
    "id": 14920,
    "content": "3"
  },
  {
    "id": 14921,
    "content": "Preview Feature: Sub-byte wmma and single-bit wmma are preview features in PTX ISA version 6"
  },
  {
    "id": 14922,
    "content": "3"
  },
  {
    "id": 14923,
    "content": "Examples   Load elements from f16 row-major matrix B"
  },
  {
    "id": 14924,
    "content": "reg"
  },
  {
    "id": 14925,
    "content": "b32 x; wmma"
  },
  {
    "id": 14926,
    "content": "load"
  },
  {
    "id": 14927,
    "content": "b"
  },
  {
    "id": 14928,
    "content": "sync"
  },
  {
    "id": 14929,
    "content": "aligned"
  },
  {
    "id": 14930,
    "content": "m16n16k16"
  },
  {
    "id": 14931,
    "content": "row"
  },
  {
    "id": 14932,
    "content": "f16 {x0,x1,x2,x3,x4,x5,x,x7}, [ptr];   Now use {x0, , x7} for the actual wmma"
  },
  {
    "id": 14933,
    "content": "mma   Load elements from f32 column-major matrix C and scale the values:"
  },
  {
    "id": 14934,
    "content": "reg"
  },
  {
    "id": 14935,
    "content": "b32 x; wmma"
  },
  {
    "id": 14936,
    "content": "load"
  },
  {
    "id": 14937,
    "content": "c"
  },
  {
    "id": 14938,
    "content": "sync"
  },
  {
    "id": 14939,
    "content": "aligned"
  },
  {
    "id": 14940,
    "content": "m16n16k16"
  },
  {
    "id": 14941,
    "content": "col"
  },
  {
    "id": 14942,
    "content": "f32 {x0,x1,x2,x3,x4,x5,x6,x7}, [ptr]; mul f32 x0, x0, 0"
  },
  {
    "id": 14943,
    "content": "1;   repeat for all registers x;"
  },
  {
    "id": 14944,
    "content": "mul"
  },
  {
    "id": 14945,
    "content": "f32 x7, x7, 0"
  },
  {
    "id": 14946,
    "content": "1;   Now use {x0,"
  },
  {
    "id": 14947,
    "content": ", x7} for the actual wmma"
  },
  {
    "id": 14948,
    "content": "mma   Load elements from integer matrix A:"
  },
  {
    "id": 14949,
    "content": "reg"
  },
  {
    "id": 14950,
    "content": "b32 x   destination registers x contain four packed"
  },
  {
    "id": 14951,
    "content": "u8 values each wmma"
  },
  {
    "id": 14952,
    "content": "load"
  },
  {
    "id": 14953,
    "content": "a"
  },
  {
    "id": 14954,
    "content": "sync"
  },
  {
    "id": 14955,
    "content": "aligned"
  },
  {
    "id": 14956,
    "content": "m32n8k16"
  },
  {
    "id": 14957,
    "content": "row"
  },
  {
    "id": 14958,
    "content": "u8 {x0,x1,x2,x3}, [ptr];   Load elements from sub-byte integer matrix A:"
  },
  {
    "id": 14959,
    "content": "reg"
  },
  {
    "id": 14960,
    "content": "b32 x0;   destination register x0 contains eight packed"
  },
  {
    "id": 14961,
    "content": "s4 values wmma"
  },
  {
    "id": 14962,
    "content": "load"
  },
  {
    "id": 14963,
    "content": "a"
  },
  {
    "id": 14964,
    "content": "sync"
  },
  {
    "id": 14965,
    "content": "aligned"
  },
  {
    "id": 14966,
    "content": "m8n8k32"
  },
  {
    "id": 14967,
    "content": "row"
  },
  {
    "id": 14968,
    "content": "s4 {x0}, [ptr];   Load elements from"
  },
  {
    "id": 14969,
    "content": "bf16 matrix A:"
  },
  {
    "id": 14970,
    "content": "reg"
  },
  {
    "id": 14971,
    "content": "b32 x; wmma"
  },
  {
    "id": 14972,
    "content": "load"
  },
  {
    "id": 14973,
    "content": "a"
  },
  {
    "id": 14974,
    "content": "sync"
  },
  {
    "id": 14975,
    "content": "aligned"
  },
  {
    "id": 14976,
    "content": "m16n16k16"
  },
  {
    "id": 14977,
    "content": "row"
  },
  {
    "id": 14978,
    "content": "bf16 {x0,x1,x2,x3}, [ptr];   Load elements from"
  },
  {
    "id": 14979,
    "content": "tf32 matrix A:"
  },
  {
    "id": 14980,
    "content": "reg"
  },
  {
    "id": 14981,
    "content": "b32 x; wmma"
  },
  {
    "id": 14982,
    "content": "load"
  },
  {
    "id": 14983,
    "content": "a"
  },
  {
    "id": 14984,
    "content": "sync"
  },
  {
    "id": 14985,
    "content": "aligned"
  },
  {
    "id": 14986,
    "content": "m16n16k8"
  },
  {
    "id": 14987,
    "content": "row"
  },
  {
    "id": 14988,
    "content": "tf32 {x0,x1,x2,x3}, [ptr];   Load elements from"
  },
  {
    "id": 14989,
    "content": "f64 matrix A:"
  },
  {
    "id": 14990,
    "content": "reg"
  },
  {
    "id": 14991,
    "content": "b32 x; wmma"
  },
  {
    "id": 14992,
    "content": "load"
  },
  {
    "id": 14993,
    "content": "a"
  },
  {
    "id": 14994,
    "content": "sync"
  },
  {
    "id": 14995,
    "content": "aligned"
  },
  {
    "id": 14996,
    "content": "m8n8k4"
  },
  {
    "id": 14997,
    "content": "row"
  },
  {
    "id": 14998,
    "content": "f64 {x0}, [ptr]; 9"
  },
  {
    "id": 14999,
    "content": "7"
  },
  {
    "id": 15000,
    "content": "13"
  },
  {
    "id": 15001,
    "content": "3"
  },
  {
    "id": 15002,
    "content": "4"
  },
  {
    "id": 15004,
    "content": "It must match the"
  },
  {
    "id": 15005,
    "content": "shape qualifier specified on the wmma"
  },
  {
    "id": 15006,
    "content": "mma instruction that produced the D matrix being stored"
  },
  {
    "id": 15007,
    "content": "The mandatory"
  },
  {
    "id": 15009,
    "content": "store instruction before resuming execution"
  },
  {
    "id": 15010,
    "content": "The mandatory"
  },
  {
    "id": 15011,
    "content": "aligned qualifier indicates that all threads in the warp must execute the same wmma"
  },
  {
    "id": 15012,
    "content": "store instruction"
  },
  {
    "id": 15013,
    "content": "In conditionally executed code, a wmma"
  },
  {
    "id": 15015,
    "content": "mma"
  },
  {
    "id": 15016,
    "content": "reg"
  },
  {
    "id": 15017,
    "content": "b32 x; wmma"
  },
  {
    "id": 15018,
    "content": "mma"
  },
  {
    "id": 15019,
    "content": "sync"
  },
  {
    "id": 15020,
    "content": "m16n16k16"
  },
  {
    "id": 15021,
    "content": "row"
  },
  {
    "id": 15022,
    "content": "col"
  },
  {
    "id": 15023,
    "content": "f32 f32 {d0, d1, d2, d3, d4, d5, d6, d7},"
  },
  {
    "id": 15024,
    "content": "; wmma"
  },
  {
    "id": 15025,
    "content": "store"
  },
  {
    "id": 15026,
    "content": "d"
  },
  {
    "id": 15027,
    "content": "sync"
  },
  {
    "id": 15028,
    "content": "m16n16k16"
  },
  {
    "id": 15029,
    "content": "row"
  },
  {
    "id": 15030,
    "content": "f32 [ptr], {d0, d1, d2, d3, d4, d5, d6, d7};   Store s32 accumulator for m16n16k16 shape:"
  },
  {
    "id": 15031,
    "content": "reg"
  },
  {
    "id": 15032,
    "content": "b32 d; wmma"
  },
  {
    "id": 15033,
    "content": "store"
  },
  {
    "id": 15034,
    "content": "d"
  },
  {
    "id": 15035,
    "content": "sync"
  },
  {
    "id": 15036,
    "content": "aligned"
  },
  {
    "id": 15037,
    "content": "m16n16k16"
  },
  {
    "id": 15038,
    "content": "row"
  },
  {
    "id": 15039,
    "content": "s32 [ptr], {d0, d1, d2, d3, d4, d5, d6, d7};   Store s32 accumulator for m8n8k128 shape:"
  },
  {
    "id": 15040,
    "content": "reg"
  },
  {
    "id": 15041,
    "content": "b32 d wmma"
  },
  {
    "id": 15042,
    "content": "store"
  },
  {
    "id": 15043,
    "content": "d"
  },
  {
    "id": 15044,
    "content": "sync"
  },
  {
    "id": 15045,
    "content": "aligned"
  },
  {
    "id": 15046,
    "content": "m8n8k128"
  },
  {
    "id": 15047,
    "content": "row"
  },
  {
    "id": 15048,
    "content": "s32 [ptr], {d0, d1};   Store f64 accumulator for m8n8k4 shape:"
  },
  {
    "id": 15049,
    "content": "reg"
  },
  {
    "id": 15050,
    "content": "f64 d; wmma"
  },
  {
    "id": 15051,
    "content": "store"
  },
  {
    "id": 15052,
    "content": "d"
  },
  {
    "id": 15053,
    "content": "sync"
  },
  {
    "id": 15054,
    "content": "aligned"
  },
  {
    "id": 15055,
    "content": "m8n8k4"
  },
  {
    "id": 15056,
    "content": "row"
  },
  {
    "id": 15057,
    "content": "f64 [ptr], {d0, d1}; 9"
  },
  {
    "id": 15058,
    "content": "7"
  },
  {
    "id": 15059,
    "content": "13"
  },
  {
    "id": 15060,
    "content": "3"
  },
  {
    "id": 15061,
    "content": "5"
  },
  {
    "id": 15063,
    "content": "dtype ,"
  },
  {
    "id": 15064,
    "content": "atype ,"
  },
  {
    "id": 15065,
    "content": "btype and"
  },
  {
    "id": 15066,
    "content": "ctype indicate the data-type of the elements in the matrices D, A, B and C respectively"
  },
  {
    "id": 15067,
    "content": "For wmma"
  },
  {
    "id": 15068,
    "content": "mma without explicit"
  },
  {
    "id": 15069,
    "content": "atype and"
  },
  {
    "id": 15070,
    "content": "btype :"
  },
  {
    "id": 15071,
    "content": "atype and"
  },
  {
    "id": 15072,
    "content": "btype are implicitly set to"
  },
  {
    "id": 15073,
    "content": "f16"
  },
  {
    "id": 15074,
    "content": "Also, the values for"
  },
  {
    "id": 15075,
    "content": "atype and"
  },
  {
    "id": 15076,
    "content": "btype must be the same, i"
  },
  {
    "id": 15077,
    "content": "e"
  },
  {
    "id": 15078,
    "content": ", either both are s8 or both are"
  },
  {
    "id": 15079,
    "content": "u8"
  },
  {
    "id": 15080,
    "content": "Also, the values for"
  },
  {
    "id": 15081,
    "content": "atype and"
  },
  {
    "id": 15082,
    "content": "btype must be the same; i"
  },
  {
    "id": 15083,
    "content": "e"
  },
  {
    "id": 15084,
    "content": ", either both are s4 , both are u4 , or both are"
  },
  {
    "id": 15085,
    "content": "b1"
  },
  {
    "id": 15087,
    "content": "xor"
  },
  {
    "id": 15089,
    "content": "The qualifiers"
  },
  {
    "id": 15090,
    "content": "alayout and"
  },
  {
    "id": 15091,
    "content": "blayout must match the layout specified on the wmma"
  },
  {
    "id": 15092,
    "content": "load instructions that produce the contents of operands a and b respectively"
  },
  {
    "id": 15093,
    "content": "Similarly, the qualifiers"
  },
  {
    "id": 15094,
    "content": "atype ,"
  },
  {
    "id": 15095,
    "content": "btype and"
  },
  {
    "id": 15096,
    "content": "ctype must match the corresponding qualifiers on the wmma"
  },
  {
    "id": 15097,
    "content": "load instructions that produce the contents of operands a , b and c respectively"
  },
  {
    "id": 15098,
    "content": "The"
  },
  {
    "id": 15099,
    "content": "shape qualifier must match the shape qualifier used on the wmma"
  },
  {
    "id": 15100,
    "content": "load instructions that produce the contents of all three input operands a , b and c respectively"
  },
  {
    "id": 15101,
    "content": "The destination operand d is a brace-enclosed vector expression that matches the"
  },
  {
    "id": 15102,
    "content": "shape of the fragment computed by the wmma"
  },
  {
    "id": 15103,
    "content": "mma instruction"
  },
  {
    "id": 15104,
    "content": "Saturation at the output: The optional qualifier"
  },
  {
    "id": 15107,
    "content": "When"
  },
  {
    "id": 15108,
    "content": "ctype or"
  },
  {
    "id": 15109,
    "content": "dtype is"
  },
  {
    "id": 15110,
    "content": "f32 , accumulation of the intermediate values is performed with at least single precision"
  },
  {
    "id": 15111,
    "content": "When both"
  },
  {
    "id": 15112,
    "content": "ctype and"
  },
  {
    "id": 15113,
    "content": "dtype are specified as"
  },
  {
    "id": 15114,
    "content": "f16 , the accumulation is performed with at least half precision Precision and rounding for"
  },
  {
    "id": 15115,
    "content": "bf16 ,"
  },
  {
    "id": 15117,
    "content": "Rounding modifiers on double precision wmma"
  },
  {
    "id": 15118,
    "content": "mma (default is"
  },
  {
    "id": 15121,
    "content": "mma instruction before resuming execution"
  },
  {
    "id": 15122,
    "content": "The mandatory"
  },
  {
    "id": 15123,
    "content": "aligned qualifier indicates that all threads in the warp must execute the same wmma"
  },
  {
    "id": 15124,
    "content": "mma instruction"
  },
  {
    "id": 15125,
    "content": "In conditionally executed code, a wmma"
  },
  {
    "id": 15127,
    "content": "Support for"
  },
  {
    "id": 15128,
    "content": "satfinite on floating point wmma"
  },
  {
    "id": 15129,
    "content": "mma is deprecated in PTX ISA version 6 4 and is removed from PTX ISA version 6"
  },
  {
    "id": 15130,
    "content": "5"
  },
  {
    "id": 15132,
    "content": "9"
  },
  {
    "id": 15133,
    "content": "7"
  },
  {
    "id": 15134,
    "content": "13"
  },
  {
    "id": 15135,
    "content": "4"
  },
  {
    "id": 15136,
    "content": "1"
  },
  {
    "id": 15137,
    "content": "Matrix Fragments for mma"
  },
  {
    "id": 15138,
    "content": "m8n8k4 with"
  },
  {
    "id": 15139,
    "content": "f16 floating point type  A warp executing mma"
  },
  {
    "id": 15140,
    "content": "m8n8k4 with"
  },
  {
    "id": 15141,
    "content": "f16 floating point type will compute 4 MMA operations of shape"
  },
  {
    "id": 15142,
    "content": "m8n8k4"
  },
  {
    "id": 15148,
    "content": "Figure 29 MMA"
  },
  {
    "id": 15150,
    "content": "ctype /"
  },
  {
    "id": 15151,
    "content": "dtype Fragment Elements (low to high)"
  },
  {
    "id": 15153,
    "content": "Figure 30 MMA"
  },
  {
    "id": 15154,
    "content": "m8n8k4 fragment layout for accumulator matrix C/D with"
  },
  {
    "id": 15156,
    "content": "7"
  },
  {
    "id": 15157,
    "content": "13"
  },
  {
    "id": 15158,
    "content": "4"
  },
  {
    "id": 15159,
    "content": "3"
  },
  {
    "id": 15161,
    "content": "Multiplicand A:"
  },
  {
    "id": 15162,
    "content": "atype Fragment Elements (low to high)"
  },
  {
    "id": 15163,
    "content": "s8 /"
  },
  {
    "id": 15164,
    "content": "u8 A vector expression containing a single b32 register, containing four"
  },
  {
    "id": 15165,
    "content": "s8 or"
  },
  {
    "id": 15166,
    "content": "u8 elements from the matrix A"
  },
  {
    "id": 15168,
    "content": "m8n8k16 fragment layout for matrix A with"
  },
  {
    "id": 15169,
    "content": "u8 /"
  },
  {
    "id": 15171,
    "content": ", 3 } Multiplicand B:"
  },
  {
    "id": 15172,
    "content": "btype Fragment Elements (low to high)"
  },
  {
    "id": 15173,
    "content": "s8 /"
  },
  {
    "id": 15174,
    "content": "u8 A vector expression containing a single b32 register, containing four"
  },
  {
    "id": 15175,
    "content": "s8 or"
  },
  {
    "id": 15176,
    "content": "u8 elements from the matrix B"
  },
  {
    "id": 15178,
    "content": "m8n8k16 fragment layout for matrix B with"
  },
  {
    "id": 15179,
    "content": "u8 /"
  },
  {
    "id": 15181,
    "content": ", 3 } col = groupID Accumulators (C or D):"
  },
  {
    "id": 15182,
    "content": "ctype /"
  },
  {
    "id": 15183,
    "content": "dtype Fragment Elements (low to high)"
  },
  {
    "id": 15184,
    "content": "s32 A vector expression containing of two s32 registers"
  },
  {
    "id": 15185,
    "content": "Figure 33 MMA"
  },
  {
    "id": 15186,
    "content": "m8n8k16 fragment layout for accumulator matrix C/D with"
  },
  {
    "id": 15188,
    "content": "7"
  },
  {
    "id": 15189,
    "content": "13"
  },
  {
    "id": 15190,
    "content": "4"
  },
  {
    "id": 15191,
    "content": "4"
  },
  {
    "id": 15193,
    "content": "Multiplicand A:"
  },
  {
    "id": 15194,
    "content": "atype Fragment Elements (low to high)"
  },
  {
    "id": 15195,
    "content": "s4 /"
  },
  {
    "id": 15196,
    "content": "u4 A vector expression containing a single b32 register, containing eight"
  },
  {
    "id": 15197,
    "content": "s4 or"
  },
  {
    "id": 15198,
    "content": "u4 elements from the matrix A"
  },
  {
    "id": 15200,
    "content": "m8n8k32 fragment layout for matrix A with"
  },
  {
    "id": 15201,
    "content": "u4 /"
  },
  {
    "id": 15203,
    "content": ", 7 } Multiplicand B:"
  },
  {
    "id": 15204,
    "content": "btype Fragment Elements (low to high)"
  },
  {
    "id": 15205,
    "content": "s4 /"
  },
  {
    "id": 15206,
    "content": "u4 A vector expression containing a single b32 register, containing eight"
  },
  {
    "id": 15207,
    "content": "s4 or"
  },
  {
    "id": 15208,
    "content": "u4 elements from the matrix B"
  },
  {
    "id": 15210,
    "content": "m8n8k32 fragment layout for matrix B with"
  },
  {
    "id": 15211,
    "content": "u4 /"
  },
  {
    "id": 15213,
    "content": ", 7 } col = groupID Accumulators (C or D):"
  },
  {
    "id": 15214,
    "content": "ctype /"
  },
  {
    "id": 15215,
    "content": "dtype Fragment Elements (low to high)"
  },
  {
    "id": 15216,
    "content": "s32 A vector expression of two s32 registers"
  },
  {
    "id": 15217,
    "content": "c0, c1 The layout of the fragments held by different threads is shown in Figure 36 : Figure 36 MMA"
  },
  {
    "id": 15218,
    "content": "m8n8k32 fragment layout for accumulator matrix C/D with"
  },
  {
    "id": 15220,
    "content": "7"
  },
  {
    "id": 15221,
    "content": "13"
  },
  {
    "id": 15222,
    "content": "4"
  },
  {
    "id": 15223,
    "content": "5"
  },
  {
    "id": 15225,
    "content": "Multiplicand A:"
  },
  {
    "id": 15226,
    "content": "atype Fragment Elements (low to high)"
  },
  {
    "id": 15228,
    "content": "a0, a1, … a30, a31 The layout of the fragments held by different threads is shown in Figure 37"
  },
  {
    "id": 15230,
    "content": ", 31 } Multiplicand B:"
  },
  {
    "id": 15231,
    "content": "btype Fragment Elements (low to high)"
  },
  {
    "id": 15234,
    "content": ", 31 } col = groupID Accumulators (C or D):"
  },
  {
    "id": 15235,
    "content": "ctype /"
  },
  {
    "id": 15236,
    "content": "dtype Fragment Elements (low to high)"
  },
  {
    "id": 15238,
    "content": "Figure 39 MMA"
  },
  {
    "id": 15239,
    "content": "m8n8k128 fragment layout for accumulator matrix C/D with"
  },
  {
    "id": 15241,
    "content": "7"
  },
  {
    "id": 15242,
    "content": "13"
  },
  {
    "id": 15243,
    "content": "4"
  },
  {
    "id": 15244,
    "content": "6"
  },
  {
    "id": 15246,
    "content": "Multiplicand A:"
  },
  {
    "id": 15247,
    "content": "tf32 :"
  },
  {
    "id": 15248,
    "content": "atype Fragment Elements (low to high)"
  },
  {
    "id": 15251,
    "content": "f64 :"
  },
  {
    "id": 15252,
    "content": "atype Fragment Elements (low to high)"
  },
  {
    "id": 15253,
    "content": "f64 A vector expression containing two f64 registers, containing two f64 elements from the matrix A"
  },
  {
    "id": 15255,
    "content": "tf32 :"
  },
  {
    "id": 15256,
    "content": "btype Fragment Elements (low to high)"
  },
  {
    "id": 15259,
    "content": "f64 :"
  },
  {
    "id": 15260,
    "content": "btype Fragment Elements (low to high)"
  },
  {
    "id": 15261,
    "content": "f64 A vector expression of a single f64 register, containing a single f64 element from the matrix B"
  },
  {
    "id": 15263,
    "content": "tf32 :"
  },
  {
    "id": 15264,
    "content": "ctype /"
  },
  {
    "id": 15265,
    "content": "dtype Fragment Elements (low to high)"
  },
  {
    "id": 15268,
    "content": ", 3 }"
  },
  {
    "id": 15269,
    "content": "f64 :"
  },
  {
    "id": 15270,
    "content": "ctype /"
  },
  {
    "id": 15271,
    "content": "dtype Fragment Elements (low to high)"
  },
  {
    "id": 15274,
    "content": ", 3 } 9"
  },
  {
    "id": 15275,
    "content": "7"
  },
  {
    "id": 15276,
    "content": "13"
  },
  {
    "id": 15277,
    "content": "4"
  },
  {
    "id": 15278,
    "content": "7"
  },
  {
    "id": 15280,
    "content": "Multiplicand A:"
  },
  {
    "id": 15281,
    "content": "f16 and"
  },
  {
    "id": 15282,
    "content": "bf16 :"
  },
  {
    "id": 15283,
    "content": "atype Fragment Elements (low to high)"
  },
  {
    "id": 15284,
    "content": "f16 /"
  },
  {
    "id": 15285,
    "content": "bf16 A vector expression containing two f16x2 registers, with each register containing two"
  },
  {
    "id": 15286,
    "content": "f16 /"
  },
  {
    "id": 15287,
    "content": "bf16 elements from the matrix A"
  },
  {
    "id": 15289,
    "content": ", 3 }"
  },
  {
    "id": 15290,
    "content": "tf32 :"
  },
  {
    "id": 15291,
    "content": "atype Fragment Elements (low to high)"
  },
  {
    "id": 15294,
    "content": "f64 :"
  },
  {
    "id": 15295,
    "content": "atype Fragment Elements (low to high)"
  },
  {
    "id": 15298,
    "content": "f16 and"
  },
  {
    "id": 15299,
    "content": "bf16 :"
  },
  {
    "id": 15300,
    "content": "btype Fragment Elements (low to high)"
  },
  {
    "id": 15301,
    "content": "f16 /"
  },
  {
    "id": 15302,
    "content": "bf16 A vector expression containing a single f16x2 register, containing two"
  },
  {
    "id": 15303,
    "content": "f16 /"
  },
  {
    "id": 15304,
    "content": "bf16 elements from the matrix B"
  },
  {
    "id": 15306,
    "content": "tf32 :"
  },
  {
    "id": 15307,
    "content": "btype Fragment Elements (low to high)"
  },
  {
    "id": 15310,
    "content": "f64 :"
  },
  {
    "id": 15311,
    "content": "btype Fragment Elements (low to high)"
  },
  {
    "id": 15312,
    "content": "f64 A vector expression containing two f64 registers, containing two f64 elements from the matrix B"
  },
  {
    "id": 15314,
    "content": "f16 ,"
  },
  {
    "id": 15315,
    "content": "bf16 and"
  },
  {
    "id": 15316,
    "content": "tf32 :"
  },
  {
    "id": 15317,
    "content": "ctype /"
  },
  {
    "id": 15318,
    "content": "dtype Fragment Elements (low to high)"
  },
  {
    "id": 15320,
    "content": "Figure 52 MMA"
  },
  {
    "id": 15321,
    "content": "m16n8k8 fragment layout for accumulator matrix C/D with"
  },
  {
    "id": 15322,
    "content": "f16x2 /"
  },
  {
    "id": 15323,
    "content": "f32 type"
  },
  {
    "id": 15325,
    "content": ", 3 }"
  },
  {
    "id": 15326,
    "content": "f64 :"
  },
  {
    "id": 15327,
    "content": "ctype /"
  },
  {
    "id": 15328,
    "content": "dtype Fragment Elements (low to high)"
  },
  {
    "id": 15329,
    "content": "f64 A vector expression of four f64 registers containing four f64 elements from the matrix C (or D)"
  },
  {
    "id": 15331,
    "content": ", 3 } 9"
  },
  {
    "id": 15332,
    "content": "7"
  },
  {
    "id": 15333,
    "content": "13"
  },
  {
    "id": 15334,
    "content": "4"
  },
  {
    "id": 15335,
    "content": "8"
  },
  {
    "id": 15337,
    "content": "Multiplicand A:"
  },
  {
    "id": 15338,
    "content": "f16 and"
  },
  {
    "id": 15339,
    "content": "bf16 :"
  },
  {
    "id": 15340,
    "content": "atype Fragment Elements (low to high)"
  },
  {
    "id": 15341,
    "content": "f16 /"
  },
  {
    "id": 15342,
    "content": "bf16 A vector expression containing four f16x2 registers, with each register containing two"
  },
  {
    "id": 15343,
    "content": "f16 /"
  },
  {
    "id": 15344,
    "content": "bf16 elements from the matrix A"
  },
  {
    "id": 15347,
    "content": "f64 :"
  },
  {
    "id": 15348,
    "content": "atype Fragment Elements (low to high)"
  },
  {
    "id": 15352,
    "content": "f16 and"
  },
  {
    "id": 15353,
    "content": "bf16 :"
  },
  {
    "id": 15354,
    "content": "btype Fragment Elements (low to high)"
  },
  {
    "id": 15355,
    "content": "f16 /"
  },
  {
    "id": 15356,
    "content": "bf16 A vector expression containing two f16x2 registers, with each register containing two"
  },
  {
    "id": 15357,
    "content": "f16 /"
  },
  {
    "id": 15358,
    "content": "bf16 elements from the matrix B"
  },
  {
    "id": 15359,
    "content": "b0, b1, b2, b3 The layout of the fragments held by different threads is shown in Figure 56"
  },
  {
    "id": 15361,
    "content": "f64 :"
  },
  {
    "id": 15362,
    "content": "atype Fragment Elements (low to high)"
  },
  {
    "id": 15364,
    "content": "b0, b1, b2, b3 The layout of the fragments held by different threads is shown in Figure 57"
  },
  {
    "id": 15366,
    "content": ", 3 } 9"
  },
  {
    "id": 15367,
    "content": "7"
  },
  {
    "id": 15368,
    "content": "13"
  },
  {
    "id": 15369,
    "content": "4"
  },
  {
    "id": 15370,
    "content": "9"
  },
  {
    "id": 15371,
    "content": "Matrix Fragments for mma m16n8k16 with integer type  A warp executing mma m16n8k16 with"
  },
  {
    "id": 15372,
    "content": "u8 or"
  },
  {
    "id": 15373,
    "content": "s8 integer type will compute an MMA operation of shape"
  },
  {
    "id": 15374,
    "content": "m16n8k16"
  },
  {
    "id": 15375,
    "content": "Multiplicand A:"
  },
  {
    "id": 15376,
    "content": "atype Fragment Elements (low to high)"
  },
  {
    "id": 15377,
    "content": "u8 /"
  },
  {
    "id": 15378,
    "content": "s8 A vector expression containing two b32 registers, with each register containing four"
  },
  {
    "id": 15379,
    "content": "u8 /"
  },
  {
    "id": 15380,
    "content": "s8 elements from the matrix A"
  },
  {
    "id": 15383,
    "content": ", 7 } Multiplicand B:"
  },
  {
    "id": 15384,
    "content": "btype Fragment Elements (low to high)"
  },
  {
    "id": 15385,
    "content": "u8 /"
  },
  {
    "id": 15386,
    "content": "s8 A vector expression containing a single b32 register, containing four"
  },
  {
    "id": 15387,
    "content": "u8 /"
  },
  {
    "id": 15388,
    "content": "s8 elements from the matrix B"
  },
  {
    "id": 15389,
    "content": "b0, b1, b2, b3 The layout of the fragments held by different threads is shown in Figure 60"
  },
  {
    "id": 15391,
    "content": ", 3 } col = groupID Accumulators (C or D):"
  },
  {
    "id": 15392,
    "content": "ctype /"
  },
  {
    "id": 15393,
    "content": "dtype Fragment Elements (low to high)"
  },
  {
    "id": 15395,
    "content": "c0, c1, c2, c3 The layout of the fragments held by different threads is shown in Figure 61"
  },
  {
    "id": 15397,
    "content": ", 3 } 9"
  },
  {
    "id": 15398,
    "content": "7"
  },
  {
    "id": 15399,
    "content": "13"
  },
  {
    "id": 15400,
    "content": "4"
  },
  {
    "id": 15401,
    "content": "10"
  },
  {
    "id": 15403,
    "content": "Multiplicand A:"
  },
  {
    "id": 15404,
    "content": "s4 or"
  },
  {
    "id": 15405,
    "content": "u4 :"
  },
  {
    "id": 15406,
    "content": "atype Fragment Elements (low to high)"
  },
  {
    "id": 15407,
    "content": "s4 /"
  },
  {
    "id": 15408,
    "content": "u4 A vector expression containing two b32 registers, with each register containing eight u4 /"
  },
  {
    "id": 15409,
    "content": "s4 elements from the matrix A"
  },
  {
    "id": 15410,
    "content": "a0, a1, …, a14, a15 The layout of the fragments held by different threads is shown in Figure 62"
  },
  {
    "id": 15412,
    "content": ", 15 }"
  },
  {
    "id": 15413,
    "content": "s8 or u8 or e4m3 or"
  },
  {
    "id": 15414,
    "content": "e5m2 :"
  },
  {
    "id": 15415,
    "content": "atype Fragment Elements (low to high)"
  },
  {
    "id": 15416,
    "content": "s8 /"
  },
  {
    "id": 15417,
    "content": "u8 A vector expression containing four b32 registers, with each register containing four"
  },
  {
    "id": 15418,
    "content": "s8 /"
  },
  {
    "id": 15419,
    "content": "u8 elements from the matrix A"
  },
  {
    "id": 15420,
    "content": "a0, a1,"
  },
  {
    "id": 15421,
    "content": ", a14, a15"
  },
  {
    "id": 15422,
    "content": "e4m3 /"
  },
  {
    "id": 15423,
    "content": "e5m2 A vector expression containing four b32 registers, with each register containing four"
  },
  {
    "id": 15424,
    "content": "e4m3 /"
  },
  {
    "id": 15425,
    "content": "e5m2 elements from the matrix A"
  },
  {
    "id": 15426,
    "content": "a0, a1, …, a14, a15 The layout of the fragments held by different threads is shown in Figure 63"
  },
  {
    "id": 15428,
    "content": "s4 or"
  },
  {
    "id": 15429,
    "content": "u4 :"
  },
  {
    "id": 15430,
    "content": "btype Fragment Elements (low to high)"
  },
  {
    "id": 15431,
    "content": "s4 /"
  },
  {
    "id": 15432,
    "content": "u4 A vector expression containing a single b32 register, containing eight"
  },
  {
    "id": 15433,
    "content": "s4 /"
  },
  {
    "id": 15434,
    "content": "u4 elements from the matrix B"
  },
  {
    "id": 15437,
    "content": "s8 or u8 or e4m3 or"
  },
  {
    "id": 15438,
    "content": "e5m2 :"
  },
  {
    "id": 15439,
    "content": "btype Fragment Elements (low to high)"
  },
  {
    "id": 15440,
    "content": "s8 /"
  },
  {
    "id": 15441,
    "content": "u8 A vector expression containing two b32 registers, with each register containing four"
  },
  {
    "id": 15442,
    "content": "s8 /"
  },
  {
    "id": 15443,
    "content": "u8 elements from the matrix B"
  },
  {
    "id": 15444,
    "content": "b0, b1, b2, b3, b4, b5, b6, b7"
  },
  {
    "id": 15445,
    "content": "e4m3 /"
  },
  {
    "id": 15446,
    "content": "e5m2 A vector expression containing two b32 registers, with each register containing four"
  },
  {
    "id": 15447,
    "content": "e4m3 /"
  },
  {
    "id": 15448,
    "content": "e5m2 elements from the matrix B"
  },
  {
    "id": 15451,
    "content": "ctype /"
  },
  {
    "id": 15452,
    "content": "dtype Fragment Elements (low to high)"
  },
  {
    "id": 15454,
    "content": "c0, c1, c2, c3"
  },
  {
    "id": 15456,
    "content": "c0, c1, c2, c3 The layout of the fragments held by different threads is shown in Figure 67"
  },
  {
    "id": 15458,
    "content": ", 3 } 9"
  },
  {
    "id": 15459,
    "content": "7"
  },
  {
    "id": 15460,
    "content": "13"
  },
  {
    "id": 15461,
    "content": "4"
  },
  {
    "id": 15462,
    "content": "11"
  },
  {
    "id": 15464,
    "content": "Multiplicand A:"
  },
  {
    "id": 15465,
    "content": "atype Fragment Elements (low to high)"
  },
  {
    "id": 15466,
    "content": "s4 /"
  },
  {
    "id": 15467,
    "content": "u4 A vector expression containing four b32 registers, with each register containing eight"
  },
  {
    "id": 15468,
    "content": "s4 /"
  },
  {
    "id": 15469,
    "content": "u4 elements from the matrix A"
  },
  {
    "id": 15470,
    "content": "a0, a1, …, a30, a31 The layout of the fragments held by different threads is shown in Figure 68"
  },
  {
    "id": 15472,
    "content": "btype Fragment Elements (low to high)"
  },
  {
    "id": 15473,
    "content": "s4 /"
  },
  {
    "id": 15474,
    "content": "u4 A vector expression containing two b32 registers, with each register containing eight"
  },
  {
    "id": 15475,
    "content": "s4 /"
  },
  {
    "id": 15476,
    "content": "u4 elements from the matrix B"
  },
  {
    "id": 15479,
    "content": "ctype /"
  },
  {
    "id": 15480,
    "content": "dtype Fragment Elements (low to high)"
  },
  {
    "id": 15482,
    "content": "c0, c1, c2, c3 The layout of the fragments held by different threads is shown in Figure 71"
  },
  {
    "id": 15484,
    "content": ", 3 } 9"
  },
  {
    "id": 15485,
    "content": "7"
  },
  {
    "id": 15486,
    "content": "13"
  },
  {
    "id": 15487,
    "content": "4"
  },
  {
    "id": 15488,
    "content": "12"
  },
  {
    "id": 15490,
    "content": "Multiplicand A:"
  },
  {
    "id": 15491,
    "content": "atype Fragment Elements (low to high)"
  },
  {
    "id": 15493,
    "content": "a0, a1, …, a62, a63 The layout of the fragments held by different threads is shown in Figure 72"
  },
  {
    "id": 15495,
    "content": ", 63 } Multiplicand B:"
  },
  {
    "id": 15496,
    "content": "btype Fragment Elements (low to high)"
  },
  {
    "id": 15499,
    "content": ", 31 } col = groupID Accumulators (C or D):"
  },
  {
    "id": 15500,
    "content": "ctype /"
  },
  {
    "id": 15501,
    "content": "dtype Fragment Elements (low to high)"
  },
  {
    "id": 15503,
    "content": "c0, c1, c2, c3 The layout of the fragments held by different threads is shown in Figure 74"
  },
  {
    "id": 15505,
    "content": "7"
  },
  {
    "id": 15506,
    "content": "13"
  },
  {
    "id": 15507,
    "content": "4"
  },
  {
    "id": 15508,
    "content": "13"
  },
  {
    "id": 15510,
    "content": "Multiplicand A:"
  },
  {
    "id": 15511,
    "content": "atype Fragment Elements (low to high)"
  },
  {
    "id": 15512,
    "content": "b1 A vector expression containing four"
  },
  {
    "id": 15513,
    "content": "b32 registers, with each register containing thirty two"
  },
  {
    "id": 15514,
    "content": "b1 elements from the matrix A"
  },
  {
    "id": 15515,
    "content": "a0, a1, …, a126, a127 The layout of the fragments held by different threads is shown in Figure 75"
  },
  {
    "id": 15517,
    "content": "btype Fragment Elements (low to high)"
  },
  {
    "id": 15520,
    "content": "ctype /"
  },
  {
    "id": 15521,
    "content": "dtype Fragment Elements (low to high)"
  },
  {
    "id": 15523,
    "content": "c0, c1, c2, c3 The layout of the fragments held by different threads is shown in Figure 78"
  },
  {
    "id": 15525,
    "content": "7"
  },
  {
    "id": 15526,
    "content": "13"
  },
  {
    "id": 15527,
    "content": "4"
  },
  {
    "id": 15528,
    "content": "14"
  },
  {
    "id": 15529,
    "content": "A warp executing mma"
  },
  {
    "id": 15530,
    "content": "sync"
  },
  {
    "id": 15531,
    "content": "m8n8k4 instruction computes 4 matrix multiply and accumulate operations"
  },
  {
    "id": 15532,
    "content": "Rest of the mma"
  },
  {
    "id": 15533,
    "content": "sync operations compute a single matrix mutliply and accumulate operation per warp"
  },
  {
    "id": 15535,
    "content": "xor"
  },
  {
    "id": 15538,
    "content": "The qualifiers"
  },
  {
    "id": 15539,
    "content": "dtype ,"
  },
  {
    "id": 15540,
    "content": "atype ,"
  },
  {
    "id": 15541,
    "content": "btype and"
  },
  {
    "id": 15542,
    "content": "ctype indicate the data-type of the elements in the matrices D, A, B and C respectively"
  },
  {
    "id": 15543,
    "content": "Specific shapes have type restrictions :"
  },
  {
    "id": 15544,
    "content": "m8n8k4 : When"
  },
  {
    "id": 15545,
    "content": "ctype is"
  },
  {
    "id": 15546,
    "content": "f32 ,"
  },
  {
    "id": 15547,
    "content": "dtype must also be"
  },
  {
    "id": 15548,
    "content": "f32"
  },
  {
    "id": 15549,
    "content": "The qualifiers"
  },
  {
    "id": 15550,
    "content": "alayout and"
  },
  {
    "id": 15551,
    "content": "blayout indicate the row-major or column-major layouts of matrices A and B respectively"
  },
  {
    "id": 15553,
    "content": "e4m3 and"
  },
  {
    "id": 15555,
    "content": "bf16 and"
  },
  {
    "id": 15560,
    "content": "m16n8k4 ,"
  },
  {
    "id": 15561,
    "content": "m16n8k8 , and"
  },
  {
    "id": 15562,
    "content": "m16n8k16 require at least 64 registers for compilation"
  },
  {
    "id": 15563,
    "content": "f16 floating point type mma operation with"
  },
  {
    "id": 15564,
    "content": "m8n8k4 shape introduced in PTX ISA version 6"
  },
  {
    "id": 15565,
    "content": "4"
  },
  {
    "id": 15566,
    "content": "f16 floating point type mma operation with"
  },
  {
    "id": 15567,
    "content": "m16n8k8 shape introduced in PTX ISA version 6"
  },
  {
    "id": 15568,
    "content": "5"
  },
  {
    "id": 15569,
    "content": "f64 floating point type mma operation with"
  },
  {
    "id": 15570,
    "content": "m8n8k4 shape introduced in PTX ISA version 7"
  },
  {
    "id": 15571,
    "content": "0"
  },
  {
    "id": 15572,
    "content": "f16 floating point type mma operation with"
  },
  {
    "id": 15573,
    "content": "m16n8k16 shape introduced in PTX ISA version 7"
  },
  {
    "id": 15574,
    "content": "0"
  },
  {
    "id": 15575,
    "content": "bf16 alternate floating point type mma operation with"
  },
  {
    "id": 15576,
    "content": "m16n8k8 and"
  },
  {
    "id": 15577,
    "content": "m16n8k16 shapes introduced in PTX ISA version 7"
  },
  {
    "id": 15578,
    "content": "0"
  },
  {
    "id": 15579,
    "content": "tf32 alternate floating point type mma operation with"
  },
  {
    "id": 15580,
    "content": "m16n8k4 and"
  },
  {
    "id": 15581,
    "content": "m16n8k8 shapes introduced in PTX ISA version 7"
  },
  {
    "id": 15582,
    "content": "0"
  },
  {
    "id": 15583,
    "content": "u8/"
  },
  {
    "id": 15584,
    "content": "s8 integer type mma operation with"
  },
  {
    "id": 15585,
    "content": "m16n8k16 and"
  },
  {
    "id": 15586,
    "content": "m16n8k32 shapes introduced in PTX ISA version 7"
  },
  {
    "id": 15587,
    "content": "0"
  },
  {
    "id": 15588,
    "content": "u4/"
  },
  {
    "id": 15589,
    "content": "s4 integer type mma operation with"
  },
  {
    "id": 15590,
    "content": "m16n8k32 and"
  },
  {
    "id": 15591,
    "content": "m16n8k64 shapes introduced in PTX ISA version 7"
  },
  {
    "id": 15592,
    "content": "0"
  },
  {
    "id": 15593,
    "content": "b1 single-bit integer type mma operation with"
  },
  {
    "id": 15594,
    "content": "m8n8k128 ,"
  },
  {
    "id": 15595,
    "content": "m16n8k128 and"
  },
  {
    "id": 15596,
    "content": "m16n8k256 shapes introduced in PTX ISA version 7"
  },
  {
    "id": 15597,
    "content": "0"
  },
  {
    "id": 15598,
    "content": "f64 floating point type mma operation with"
  },
  {
    "id": 15599,
    "content": "m16n8k4 ,"
  },
  {
    "id": 15600,
    "content": "m16n8k8 , and"
  },
  {
    "id": 15601,
    "content": "m16n8k16 shapes introduced in PTX ISA version 7"
  },
  {
    "id": 15602,
    "content": "8"
  },
  {
    "id": 15603,
    "content": "Support for"
  },
  {
    "id": 15604,
    "content": "e4m3 and"
  },
  {
    "id": 15605,
    "content": "e5m2 alternate floating point type mma operation introduced in PTX ISA version 8"
  },
  {
    "id": 15606,
    "content": "4"
  },
  {
    "id": 15607,
    "content": "Note mma"
  },
  {
    "id": 15608,
    "content": "sync"
  },
  {
    "id": 15610,
    "content": "bf16 alternate floating point type mma operation with"
  },
  {
    "id": 15611,
    "content": "m16n8k8 and"
  },
  {
    "id": 15612,
    "content": "m16n8k16 shapes requires sm_80 or higher"
  },
  {
    "id": 15613,
    "content": "tf32 alternate floating point type mma operation with"
  },
  {
    "id": 15614,
    "content": "m16n8k4 and"
  },
  {
    "id": 15615,
    "content": "m16n8k8 shapes requires sm_80 or higher"
  },
  {
    "id": 15616,
    "content": "u8/"
  },
  {
    "id": 15617,
    "content": "s8 integer type mma operation with"
  },
  {
    "id": 15618,
    "content": "m16n8k16 and"
  },
  {
    "id": 15619,
    "content": "m16n8k32 shapes requires sm_80 or higher"
  },
  {
    "id": 15620,
    "content": "u4/"
  },
  {
    "id": 15621,
    "content": "s4 integer type mma operation with"
  },
  {
    "id": 15622,
    "content": "m16n8k32 and"
  },
  {
    "id": 15623,
    "content": "m16n8k64 shapes requires sm_80 or higher"
  },
  {
    "id": 15624,
    "content": "b1 single-bit integer type mma operation with"
  },
  {
    "id": 15625,
    "content": "m16n8k128 and"
  },
  {
    "id": 15626,
    "content": "m16n8k256 shapes requires sm_80 or higher"
  },
  {
    "id": 15627,
    "content": "f64 floating point type mma operation with"
  },
  {
    "id": 15628,
    "content": "m16n8k4 ,"
  },
  {
    "id": 15629,
    "content": "m16n8k8 , and"
  },
  {
    "id": 15630,
    "content": "m16n8k16 shapes require sm_90 or higher"
  },
  {
    "id": 15632,
    "content": "sync"
  },
  {
    "id": 15633,
    "content": "aligned"
  },
  {
    "id": 15634,
    "content": "shape"
  },
  {
    "id": 15635,
    "content": "num{"
  },
  {
    "id": 15636,
    "content": "trans}{"
  },
  {
    "id": 15637,
    "content": "ss}"
  },
  {
    "id": 15638,
    "content": "type r, [p];"
  },
  {
    "id": 15639,
    "content": "shape = {"
  },
  {
    "id": 15640,
    "content": "m8n8};"
  },
  {
    "id": 15641,
    "content": "num = {"
  },
  {
    "id": 15642,
    "content": "x1,"
  },
  {
    "id": 15643,
    "content": "x2,"
  },
  {
    "id": 15644,
    "content": "x4};"
  },
  {
    "id": 15645,
    "content": "ss = {"
  },
  {
    "id": 15646,
    "content": "shared{::cta}};"
  },
  {
    "id": 15647,
    "content": "type = {"
  },
  {
    "id": 15650,
    "content": "The mandatory"
  },
  {
    "id": 15652,
    "content": "The mandatory"
  },
  {
    "id": 15654,
    "content": "the warp has exited"
  },
  {
    "id": 15656,
    "content": "num"
  },
  {
    "id": 15658,
    "content": "num as shown in the following table"
  },
  {
    "id": 15660,
    "content": "num Threads 0–7 Threads 8–15 Threads 16–23 Threads 24–31"
  },
  {
    "id": 15662,
    "content": "target sm_75 or below, all threads must contain valid addresses"
  },
  {
    "id": 15663,
    "content": "For"
  },
  {
    "id": 15664,
    "content": "num ="
  },
  {
    "id": 15665,
    "content": "x1 and"
  },
  {
    "id": 15666,
    "content": "num ="
  },
  {
    "id": 15669,
    "content": "Figure 79 ldmatrix fragment layout  When"
  },
  {
    "id": 15670,
    "content": "num ="
  },
  {
    "id": 15672,
    "content": "Similarly, when"
  },
  {
    "id": 15673,
    "content": "num ="
  },
  {
    "id": 15675,
    "content": "The ldmatrix instruction is treated as a weak memory operation in the Memory Consistency Model"
  },
  {
    "id": 15676,
    "content": "Examples   Load a single 8x8 matrix using 64-bit addressing"
  },
  {
    "id": 15677,
    "content": "reg"
  },
  {
    "id": 15678,
    "content": "b64 addr;"
  },
  {
    "id": 15679,
    "content": "reg"
  },
  {
    "id": 15680,
    "content": "b32 d; ldmatrix"
  },
  {
    "id": 15681,
    "content": "sync"
  },
  {
    "id": 15682,
    "content": "aligned"
  },
  {
    "id": 15683,
    "content": "m8n8"
  },
  {
    "id": 15684,
    "content": "x1"
  },
  {
    "id": 15685,
    "content": "shared::cta"
  },
  {
    "id": 15686,
    "content": "b16 {d}, [addr];   Load two 8x8 matrices in column-major format"
  },
  {
    "id": 15687,
    "content": "reg"
  },
  {
    "id": 15688,
    "content": "b64 addr;"
  },
  {
    "id": 15689,
    "content": "reg"
  },
  {
    "id": 15690,
    "content": "b32 d; ldmatrix"
  },
  {
    "id": 15691,
    "content": "sync"
  },
  {
    "id": 15692,
    "content": "aligned"
  },
  {
    "id": 15693,
    "content": "m8n8"
  },
  {
    "id": 15694,
    "content": "x2"
  },
  {
    "id": 15695,
    "content": "trans"
  },
  {
    "id": 15696,
    "content": "shared"
  },
  {
    "id": 15697,
    "content": "b16 {d0, d1}, [addr];   Load four 8x8 matrices"
  },
  {
    "id": 15698,
    "content": "reg"
  },
  {
    "id": 15699,
    "content": "b64 addr;"
  },
  {
    "id": 15700,
    "content": "reg"
  },
  {
    "id": 15701,
    "content": "b32 d; ldmatrix"
  },
  {
    "id": 15702,
    "content": "sync"
  },
  {
    "id": 15703,
    "content": "aligned"
  },
  {
    "id": 15704,
    "content": "m8n8"
  },
  {
    "id": 15705,
    "content": "x4"
  },
  {
    "id": 15706,
    "content": "b16 {d0, d1, d2, d3}, [addr]; 9"
  },
  {
    "id": 15707,
    "content": "7"
  },
  {
    "id": 15708,
    "content": "13"
  },
  {
    "id": 15709,
    "content": "4"
  },
  {
    "id": 15710,
    "content": "16"
  },
  {
    "id": 15712,
    "content": "sync"
  },
  {
    "id": 15713,
    "content": "aligned"
  },
  {
    "id": 15714,
    "content": "shape"
  },
  {
    "id": 15715,
    "content": "num{"
  },
  {
    "id": 15716,
    "content": "trans}{"
  },
  {
    "id": 15717,
    "content": "ss}"
  },
  {
    "id": 15718,
    "content": "type [p], r;"
  },
  {
    "id": 15719,
    "content": "shape = {"
  },
  {
    "id": 15720,
    "content": "m8n8};"
  },
  {
    "id": 15721,
    "content": "num = {"
  },
  {
    "id": 15722,
    "content": "x1,"
  },
  {
    "id": 15723,
    "content": "x2,"
  },
  {
    "id": 15724,
    "content": "x4};"
  },
  {
    "id": 15725,
    "content": "ss = {"
  },
  {
    "id": 15726,
    "content": "shared{::cta}};"
  },
  {
    "id": 15727,
    "content": "type = {"
  },
  {
    "id": 15729,
    "content": "shared state space"
  },
  {
    "id": 15730,
    "content": "The mandatory"
  },
  {
    "id": 15732,
    "content": "The mandatory"
  },
  {
    "id": 15734,
    "content": "the warp has exited"
  },
  {
    "id": 15736,
    "content": "num num Threads 0–7 Threads 8–15 Threads 16–23 Threads 24–31"
  },
  {
    "id": 15739,
    "content": "Figure 80 stmatrix fragment layout  When"
  },
  {
    "id": 15740,
    "content": "num ="
  },
  {
    "id": 15742,
    "content": "Similarly, when"
  },
  {
    "id": 15743,
    "content": "num ="
  },
  {
    "id": 15745,
    "content": "The stmatrix instruction is treated as a weak memory operation in the Memory Consistency Model"
  },
  {
    "id": 15746,
    "content": "Examples   Store a single 8x8 matrix using 64-bit addressing"
  },
  {
    "id": 15747,
    "content": "reg"
  },
  {
    "id": 15748,
    "content": "b64 addr;"
  },
  {
    "id": 15749,
    "content": "reg"
  },
  {
    "id": 15750,
    "content": "b32 r; stmatrix"
  },
  {
    "id": 15751,
    "content": "sync"
  },
  {
    "id": 15752,
    "content": "aligned"
  },
  {
    "id": 15753,
    "content": "m8n8"
  },
  {
    "id": 15754,
    "content": "x1"
  },
  {
    "id": 15755,
    "content": "shared"
  },
  {
    "id": 15756,
    "content": "b16 [addr], {r};   Store two 8x8 matrices in column-major format"
  },
  {
    "id": 15757,
    "content": "reg"
  },
  {
    "id": 15758,
    "content": "b64 addr;"
  },
  {
    "id": 15759,
    "content": "reg"
  },
  {
    "id": 15760,
    "content": "b32 r; stmatrix"
  },
  {
    "id": 15761,
    "content": "sync"
  },
  {
    "id": 15762,
    "content": "aligned"
  },
  {
    "id": 15763,
    "content": "m8n8"
  },
  {
    "id": 15764,
    "content": "x2"
  },
  {
    "id": 15765,
    "content": "trans"
  },
  {
    "id": 15766,
    "content": "shared::cta"
  },
  {
    "id": 15767,
    "content": "b16 [addr], {r0, r1};   Store four 8x8 matrices"
  },
  {
    "id": 15768,
    "content": "reg"
  },
  {
    "id": 15769,
    "content": "b64 addr;"
  },
  {
    "id": 15770,
    "content": "reg"
  },
  {
    "id": 15771,
    "content": "b32 r; stmatrix"
  },
  {
    "id": 15772,
    "content": "sync"
  },
  {
    "id": 15773,
    "content": "aligned"
  },
  {
    "id": 15774,
    "content": "m8n8"
  },
  {
    "id": 15775,
    "content": "x4"
  },
  {
    "id": 15776,
    "content": "b16 [addr], {r0, r1, r2, r3}; 9"
  },
  {
    "id": 15777,
    "content": "7"
  },
  {
    "id": 15778,
    "content": "13"
  },
  {
    "id": 15779,
    "content": "4"
  },
  {
    "id": 15780,
    "content": "17"
  },
  {
    "id": 15782,
    "content": "sync"
  },
  {
    "id": 15783,
    "content": "aligned"
  },
  {
    "id": 15784,
    "content": "shape"
  },
  {
    "id": 15785,
    "content": "trans"
  },
  {
    "id": 15786,
    "content": "type d, a;"
  },
  {
    "id": 15787,
    "content": "shape = {"
  },
  {
    "id": 15788,
    "content": "m8n8};"
  },
  {
    "id": 15789,
    "content": "type = {"
  },
  {
    "id": 15791,
    "content": "The mandatory"
  },
  {
    "id": 15793,
    "content": "The mandatory"
  },
  {
    "id": 15796,
    "content": "The mandatory qualifier"
  },
  {
    "id": 15799,
    "content": "8"
  },
  {
    "id": 15802,
    "content": "9"
  },
  {
    "id": 15803,
    "content": "7"
  },
  {
    "id": 15804,
    "content": "13"
  },
  {
    "id": 15805,
    "content": "5"
  },
  {
    "id": 15806,
    "content": "1"
  },
  {
    "id": 15810,
    "content": "data types are described below Sparse mma"
  },
  {
    "id": 15811,
    "content": "sp{::ordered_metadata} with half-precision and"
  },
  {
    "id": 15812,
    "content": "bf16 type For the"
  },
  {
    "id": 15813,
    "content": "m16n8k16 and"
  },
  {
    "id": 15814,
    "content": "m16n8k32 mma"
  },
  {
    "id": 15815,
    "content": "sp{::ordered_metadata} operations, matrix A is structured sparse at a granularity of 2:4"
  },
  {
    "id": 15817,
    "content": "For mma"
  },
  {
    "id": 15820,
    "content": "value results in an undefined behavior"
  },
  {
    "id": 15821,
    "content": "Sparse mma"
  },
  {
    "id": 15822,
    "content": "sp{::ordered_metadata} with"
  },
  {
    "id": 15823,
    "content": "tf32 type When matrix A has tf32 elements, matrix A is structured sparse at a granularity of 1:2"
  },
  {
    "id": 15826,
    "content": "Sparse mma"
  },
  {
    "id": 15827,
    "content": "sp{::ordered_metadata} with integer type When matrices A and B have"
  },
  {
    "id": 15828,
    "content": "u8 /"
  },
  {
    "id": 15830,
    "content": " when matrices A and B have"
  },
  {
    "id": 15831,
    "content": "u4 /"
  },
  {
    "id": 15832,
    "content": "s4 elements, matrix A is pair-wise structured sparse at a granularity of 4:8"
  },
  {
    "id": 15834,
    "content": "i"
  },
  {
    "id": 15835,
    "content": "e"
  },
  {
    "id": 15838,
    "content": "u8 /"
  },
  {
    "id": 15839,
    "content": "s8 type and m16n8k64 with"
  },
  {
    "id": 15840,
    "content": "u4 /"
  },
  {
    "id": 15841,
    "content": "s4 type: A thread-pair within a group of four consecutive threads contributes the sparsity metadata"
  },
  {
    "id": 15842,
    "content": "m16n8k64 with"
  },
  {
    "id": 15843,
    "content": "u8 /"
  },
  {
    "id": 15844,
    "content": "s8 type and m16n8k128 with"
  },
  {
    "id": 15845,
    "content": "u4 /"
  },
  {
    "id": 15846,
    "content": "s4 type: All threads within a group of four consecutive threads contribute the sparsity metadata"
  },
  {
    "id": 15847,
    "content": "Sparse mma"
  },
  {
    "id": 15848,
    "content": "sp{::ordered_metadata} with"
  },
  {
    "id": 15849,
    "content": "e4m3 /"
  },
  {
    "id": 15850,
    "content": "e5m2 type When matrices A and B have"
  },
  {
    "id": 15851,
    "content": "e4m3 /"
  },
  {
    "id": 15852,
    "content": "e5m2 elements, matrix A is structured sparse at a granularity of 2:4"
  },
  {
    "id": 15855,
    "content": "9"
  },
  {
    "id": 15856,
    "content": "7"
  },
  {
    "id": 15857,
    "content": "13"
  },
  {
    "id": 15858,
    "content": "5"
  },
  {
    "id": 15859,
    "content": "2"
  },
  {
    "id": 15863,
    "content": "Tk: [m"
  },
  {
    "id": 15864,
    "content": "n] present in cell [x][y"
  },
  {
    "id": 15866,
    "content": "[x][z] of matrix A"
  },
  {
    "id": 15867,
    "content": "9"
  },
  {
    "id": 15868,
    "content": "7"
  },
  {
    "id": 15869,
    "content": "13"
  },
  {
    "id": 15870,
    "content": "5"
  },
  {
    "id": 15871,
    "content": "2"
  },
  {
    "id": 15872,
    "content": "1"
  },
  {
    "id": 15873,
    "content": "Matrix Fragments for sparse mma"
  },
  {
    "id": 15874,
    "content": "m16n8k16 with"
  },
  {
    "id": 15875,
    "content": "f16 and"
  },
  {
    "id": 15876,
    "content": "bf16 types  A warp executing sparse mma"
  },
  {
    "id": 15877,
    "content": "m16n8k16 with"
  },
  {
    "id": 15878,
    "content": "f16 /"
  },
  {
    "id": 15879,
    "content": "bf16 floating point type will compute an MMA operation of shape"
  },
  {
    "id": 15880,
    "content": "m16n8k16"
  },
  {
    "id": 15881,
    "content": "Multiplicand A:"
  },
  {
    "id": 15882,
    "content": "atype Fragment Elements"
  },
  {
    "id": 15883,
    "content": "f16 /"
  },
  {
    "id": 15884,
    "content": "bf16 A vector expression containing two b32 registers, with each register containing two non-zero"
  },
  {
    "id": 15885,
    "content": "f16 /"
  },
  {
    "id": 15886,
    "content": "bf16 elements out of 4 consecutive elements from matrix A"
  },
  {
    "id": 15888,
    "content": "D are the same as in case of Matrix Fragments for mma"
  },
  {
    "id": 15889,
    "content": "m16n8k16 with floating point type for"
  },
  {
    "id": 15890,
    "content": "f16 /"
  },
  {
    "id": 15891,
    "content": "b16 formats"
  },
  {
    "id": 15892,
    "content": "Metadata: A"
  },
  {
    "id": 15894,
    "content": "m16n8k16 metadata layout for"
  },
  {
    "id": 15895,
    "content": "f16 /"
  },
  {
    "id": 15896,
    "content": "bf16 type"
  },
  {
    "id": 15897,
    "content": " 9"
  },
  {
    "id": 15898,
    "content": "7"
  },
  {
    "id": 15899,
    "content": "13"
  },
  {
    "id": 15900,
    "content": "5"
  },
  {
    "id": 15901,
    "content": "2"
  },
  {
    "id": 15902,
    "content": "2"
  },
  {
    "id": 15903,
    "content": "Matrix Fragments for sparse mma"
  },
  {
    "id": 15904,
    "content": "m16n8k32 with"
  },
  {
    "id": 15905,
    "content": "f16 and"
  },
  {
    "id": 15906,
    "content": "bf16 types  A warp executing sparse mma"
  },
  {
    "id": 15907,
    "content": "m16n8k32 with"
  },
  {
    "id": 15908,
    "content": "f16 /"
  },
  {
    "id": 15909,
    "content": "bf16 floating point type will compute an MMA operation of shape"
  },
  {
    "id": 15910,
    "content": "m16n8k32"
  },
  {
    "id": 15911,
    "content": "Multiplicand A:"
  },
  {
    "id": 15912,
    "content": "atype Fragment Elements"
  },
  {
    "id": 15913,
    "content": "f16 /"
  },
  {
    "id": 15914,
    "content": "bf16 A vector expression containing four b32 registers, with each register containing two non-zero"
  },
  {
    "id": 15915,
    "content": "f16 /"
  },
  {
    "id": 15916,
    "content": "bf16 elements out of 4 consecutive elements from matrix A"
  },
  {
    "id": 15918,
    "content": "atype Fragment Elements (low to high)"
  },
  {
    "id": 15919,
    "content": "f16 /"
  },
  {
    "id": 15920,
    "content": "bf16 A vector expression containing four b32 registers, each containing two"
  },
  {
    "id": 15921,
    "content": "f16 /"
  },
  {
    "id": 15922,
    "content": "bf16 elements from matrix B"
  },
  {
    "id": 15924,
    "content": "m16n8k16 with floating point type for"
  },
  {
    "id": 15925,
    "content": "f16 /"
  },
  {
    "id": 15926,
    "content": "b16 formats"
  },
  {
    "id": 15927,
    "content": "Metadata: A"
  },
  {
    "id": 15929,
    "content": "m16n8k32 metadata layout for"
  },
  {
    "id": 15930,
    "content": "f16 /"
  },
  {
    "id": 15931,
    "content": "bf16 type"
  },
  {
    "id": 15932,
    "content": " 9"
  },
  {
    "id": 15933,
    "content": "7"
  },
  {
    "id": 15934,
    "content": "13"
  },
  {
    "id": 15935,
    "content": "5"
  },
  {
    "id": 15936,
    "content": "2"
  },
  {
    "id": 15937,
    "content": "3"
  },
  {
    "id": 15938,
    "content": "Matrix Fragments for sparse mma"
  },
  {
    "id": 15939,
    "content": "m16n8k16 with"
  },
  {
    "id": 15940,
    "content": "tf32 floating point type  A warp executing sparse mma"
  },
  {
    "id": 15941,
    "content": "m16n8k16 with"
  },
  {
    "id": 15942,
    "content": "tf32 floating point type will compute an MMA operation of shape"
  },
  {
    "id": 15943,
    "content": "m16n8k16"
  },
  {
    "id": 15944,
    "content": "Multiplicand A:"
  },
  {
    "id": 15945,
    "content": "atype Fragment Elements"
  },
  {
    "id": 15948,
    "content": "Multiplicand B:"
  },
  {
    "id": 15949,
    "content": "atype Fragment Elements (low to high)"
  },
  {
    "id": 15952,
    "content": "m16n8k16 with floating point type"
  },
  {
    "id": 15953,
    "content": "Metadata: A"
  },
  {
    "id": 15955,
    "content": "m16n8k16 metadata layout for"
  },
  {
    "id": 15956,
    "content": "tf32 type"
  },
  {
    "id": 15957,
    "content": " 9"
  },
  {
    "id": 15958,
    "content": "7"
  },
  {
    "id": 15959,
    "content": "13"
  },
  {
    "id": 15960,
    "content": "5"
  },
  {
    "id": 15961,
    "content": "2"
  },
  {
    "id": 15962,
    "content": "4"
  },
  {
    "id": 15963,
    "content": "Matrix Fragments for sparse mma"
  },
  {
    "id": 15964,
    "content": "m16n8k8 with"
  },
  {
    "id": 15965,
    "content": "tf32 floating point type  A warp executing sparse mma"
  },
  {
    "id": 15966,
    "content": "m16n8k8 with"
  },
  {
    "id": 15967,
    "content": "tf32 floating point type will compute an MMA operation of shape"
  },
  {
    "id": 15968,
    "content": "m16n8k8"
  },
  {
    "id": 15969,
    "content": "Multiplicand A:"
  },
  {
    "id": 15970,
    "content": "atype Fragment Elements"
  },
  {
    "id": 15973,
    "content": "as in case of Matrix Fragments for mma"
  },
  {
    "id": 15974,
    "content": "m16n8k8 for"
  },
  {
    "id": 15975,
    "content": "tf32 format"
  },
  {
    "id": 15976,
    "content": "Metadata: A"
  },
  {
    "id": 15978,
    "content": "m16n8k8 metadata layout for"
  },
  {
    "id": 15979,
    "content": "tf32 type"
  },
  {
    "id": 15980,
    "content": " 9"
  },
  {
    "id": 15981,
    "content": "7"
  },
  {
    "id": 15982,
    "content": "13"
  },
  {
    "id": 15983,
    "content": "5"
  },
  {
    "id": 15984,
    "content": "2"
  },
  {
    "id": 15985,
    "content": "5"
  },
  {
    "id": 15986,
    "content": "Matrix Fragments for sparse mma"
  },
  {
    "id": 15987,
    "content": "m16n8k32 with"
  },
  {
    "id": 15988,
    "content": "u8/"
  },
  {
    "id": 15989,
    "content": "s8 integer type  A warp executing sparse mma"
  },
  {
    "id": 15990,
    "content": "m16n8k32 with"
  },
  {
    "id": 15991,
    "content": "u8 /"
  },
  {
    "id": 15992,
    "content": "s8 integer type will compute an MMA operation of shape"
  },
  {
    "id": 15993,
    "content": "m16n8k32"
  },
  {
    "id": 15994,
    "content": "Multiplicand A:"
  },
  {
    "id": 15995,
    "content": "atype Fragment Elements"
  },
  {
    "id": 15996,
    "content": "u8 /"
  },
  {
    "id": 15997,
    "content": "s8 A vector expression containing two b32 registers, with each register containing four non-zero"
  },
  {
    "id": 15998,
    "content": "u8 /"
  },
  {
    "id": 15999,
    "content": "s8 elements out of 8 consecutive elements from matrix A"
  },
  {
    "id": 16001,
    "content": "btype Fragment Elements (low to high)"
  },
  {
    "id": 16002,
    "content": "u8 /"
  },
  {
    "id": 16003,
    "content": "s8 A vector expression containing four b32 registers, each containing four"
  },
  {
    "id": 16004,
    "content": "u8 /"
  },
  {
    "id": 16005,
    "content": "s8 elements from matrix B"
  },
  {
    "id": 16006,
    "content": "b0, b1, b2, b3, …, b15"
  },
  {
    "id": 16007,
    "content": "e4m3 /"
  },
  {
    "id": 16008,
    "content": "e5m2 A vector expression containing four b32 registers, each containing four"
  },
  {
    "id": 16009,
    "content": "e4m3 /"
  },
  {
    "id": 16010,
    "content": "e5m2 elements from matrix B"
  },
  {
    "id": 16012,
    "content": "m16n8k64 fragment layout for rows 0–15 of matrix B with"
  },
  {
    "id": 16013,
    "content": "u8 /"
  },
  {
    "id": 16014,
    "content": "s8 /"
  },
  {
    "id": 16015,
    "content": "e4m3 /"
  },
  {
    "id": 16016,
    "content": "e5m2 type"
  },
  {
    "id": 16017,
    "content": " Figure 104 Sparse MMA"
  },
  {
    "id": 16018,
    "content": "m16n8k64 fragment layout for rows 16–31 of matrix B with"
  },
  {
    "id": 16019,
    "content": "u8 /"
  },
  {
    "id": 16020,
    "content": "s8 /"
  },
  {
    "id": 16021,
    "content": "e4m3 /"
  },
  {
    "id": 16022,
    "content": "e5m2 type"
  },
  {
    "id": 16023,
    "content": " Figure 105 Sparse MMA"
  },
  {
    "id": 16024,
    "content": "m16n8k64 fragment layout for rows 32–47 of matrix B with"
  },
  {
    "id": 16025,
    "content": "u8 /"
  },
  {
    "id": 16026,
    "content": "s8 /"
  },
  {
    "id": 16027,
    "content": "e4m3 /"
  },
  {
    "id": 16028,
    "content": "e5m2 type"
  },
  {
    "id": 16029,
    "content": " Figure 106 Sparse MMA"
  },
  {
    "id": 16030,
    "content": "m16n8k64 fragment layout for rows 48–63 of matrix B with"
  },
  {
    "id": 16031,
    "content": "u8 /"
  },
  {
    "id": 16032,
    "content": "s8 /"
  },
  {
    "id": 16033,
    "content": "e4m3 /"
  },
  {
    "id": 16034,
    "content": "e5m2 type"
  },
  {
    "id": 16035,
    "content": " Matrix fragments for accumulators C and D are the same as in case of Matrix Fragments for mma"
  },
  {
    "id": 16036,
    "content": "m16n8k16 with integer type"
  },
  {
    "id": 16037,
    "content": "Metadata: A"
  },
  {
    "id": 16039,
    "content": "m16n8k64 metadata layout for columns 0–31 for"
  },
  {
    "id": 16040,
    "content": "u8 /"
  },
  {
    "id": 16041,
    "content": "s8 /"
  },
  {
    "id": 16042,
    "content": "e4m3 /"
  },
  {
    "id": 16043,
    "content": "e5m2 type"
  },
  {
    "id": 16044,
    "content": " Figure 108 Sparse MMA"
  },
  {
    "id": 16045,
    "content": "m16n8k64 metadata layout for columns 32–63 for"
  },
  {
    "id": 16046,
    "content": "u8 /"
  },
  {
    "id": 16047,
    "content": "s8 /"
  },
  {
    "id": 16048,
    "content": "e4m3 /"
  },
  {
    "id": 16049,
    "content": "e5m2 type"
  },
  {
    "id": 16050,
    "content": " 9"
  },
  {
    "id": 16051,
    "content": "7"
  },
  {
    "id": 16052,
    "content": "13"
  },
  {
    "id": 16053,
    "content": "5"
  },
  {
    "id": 16054,
    "content": "2"
  },
  {
    "id": 16055,
    "content": "7"
  },
  {
    "id": 16056,
    "content": "Matrix Fragments for sparse mma"
  },
  {
    "id": 16057,
    "content": "m16n8k64 with"
  },
  {
    "id": 16058,
    "content": "u4/"
  },
  {
    "id": 16059,
    "content": "s4 integer type  A warp executing sparse mma"
  },
  {
    "id": 16060,
    "content": "m16n8k64 with"
  },
  {
    "id": 16061,
    "content": "u4 /"
  },
  {
    "id": 16062,
    "content": "s4 integer type will compute an MMA operation of shape"
  },
  {
    "id": 16063,
    "content": "m16n8k64"
  },
  {
    "id": 16064,
    "content": "Multiplicand A:"
  },
  {
    "id": 16065,
    "content": "atype Fragment Elements"
  },
  {
    "id": 16066,
    "content": "u4 /"
  },
  {
    "id": 16067,
    "content": "s4 A vector expression containing two"
  },
  {
    "id": 16068,
    "content": "b32 registers, with each register containing eight non-zero"
  },
  {
    "id": 16069,
    "content": "u4 /"
  },
  {
    "id": 16070,
    "content": "s4 elements out of 16 consecutive elements from matrix A"
  },
  {
    "id": 16072,
    "content": "atype Fragment Elements (low to high)"
  },
  {
    "id": 16073,
    "content": "u4 /"
  },
  {
    "id": 16074,
    "content": "s4 A vector expression containing four b32 registers, each containing eight"
  },
  {
    "id": 16075,
    "content": "u4 /"
  },
  {
    "id": 16076,
    "content": "s4 elements from matrix B"
  },
  {
    "id": 16078,
    "content": "m16n8k128 fragment layout for rows 0–31 of matrix B with"
  },
  {
    "id": 16079,
    "content": "u4 /"
  },
  {
    "id": 16080,
    "content": "s4 type"
  },
  {
    "id": 16081,
    "content": " Figure 114 Sparse MMA"
  },
  {
    "id": 16082,
    "content": "m16n8k128 fragment layout for rows 31–63 of matrix B with"
  },
  {
    "id": 16083,
    "content": "u4 /"
  },
  {
    "id": 16084,
    "content": "s4 type"
  },
  {
    "id": 16085,
    "content": " Figure 115 Sparse MMA"
  },
  {
    "id": 16086,
    "content": "m16n8k128 fragment layout for rows 64–95 of matrix B with"
  },
  {
    "id": 16087,
    "content": "u4 /"
  },
  {
    "id": 16088,
    "content": "s4 type"
  },
  {
    "id": 16089,
    "content": " Figure 116 Sparse MMA"
  },
  {
    "id": 16090,
    "content": "m16n8k128 fragment layout for rows 96–127 of matrix B with"
  },
  {
    "id": 16091,
    "content": "u4 /"
  },
  {
    "id": 16092,
    "content": "s4 type"
  },
  {
    "id": 16093,
    "content": " Matrix fragments for accumulators C and D are the same as in case of Matrix Fragments for mma"
  },
  {
    "id": 16094,
    "content": "m16n8k64"
  },
  {
    "id": 16095,
    "content": "Metadata: A"
  },
  {
    "id": 16097,
    "content": "A warp executing mma"
  },
  {
    "id": 16098,
    "content": "sp"
  },
  {
    "id": 16099,
    "content": "sync/mma"
  },
  {
    "id": 16100,
    "content": "sp::ordered_metadata"
  },
  {
    "id": 16101,
    "content": "sync instruction compute a single matrix mutliply and accumulate operation"
  },
  {
    "id": 16103,
    "content": "Operand e is a 32-bit integer and operand f is a 32-bit integer constant with values in the range 0"
  },
  {
    "id": 16104,
    "content": "3 Instruction mma"
  },
  {
    "id": 16107,
    "content": "In case of shapes"
  },
  {
    "id": 16108,
    "content": "m16n8k16 and"
  },
  {
    "id": 16109,
    "content": "m16n8k32 ,"
  },
  {
    "id": 16110,
    "content": "dtype must be the same as"
  },
  {
    "id": 16111,
    "content": "ctype Precision and rounding :"
  },
  {
    "id": 16113,
    "content": "Integer operations : The integer mma sp/mma sp::ordered_metadata operation is performed with"
  },
  {
    "id": 16114,
    "content": "s32 accumulators"
  },
  {
    "id": 16115,
    "content": "The mandatory"
  },
  {
    "id": 16117,
    "content": "The mandatory"
  },
  {
    "id": 16120,
    "content": "Support for"
  },
  {
    "id": 16121,
    "content": "e4m3 and"
  },
  {
    "id": 16122,
    "content": "e5m2 alternate floating point type mma operation introduced in PTX ISA version 8"
  },
  {
    "id": 16123,
    "content": "4"
  },
  {
    "id": 16126,
    "content": "proxy async operation to make the generic proxy operations visible to the async proxy"
  },
  {
    "id": 16127,
    "content": "Issue the asynchronous matrix multiply and accumulate operations using the wgmma"
  },
  {
    "id": 16128,
    "content": "mma_async operation on the input matrices"
  },
  {
    "id": 16130,
    "content": "commit_group operation"
  },
  {
    "id": 16131,
    "content": "Once the wgmma-group completes, all the wgmma"
  },
  {
    "id": 16132,
    "content": "mma_async operations have been performed and completed"
  },
  {
    "id": 16133,
    "content": "9"
  },
  {
    "id": 16134,
    "content": "7"
  },
  {
    "id": 16135,
    "content": "14"
  },
  {
    "id": 16136,
    "content": "1"
  },
  {
    "id": 16138,
    "content": "y * %ntid"
  },
  {
    "id": 16139,
    "content": "x + %tid"
  },
  {
    "id": 16140,
    "content": "z * %ntid x * %ntid"
  },
  {
    "id": 16141,
    "content": "y) / 32 9"
  },
  {
    "id": 16142,
    "content": "7"
  },
  {
    "id": 16143,
    "content": "14"
  },
  {
    "id": 16144,
    "content": "2"
  },
  {
    "id": 16146,
    "content": "the same data-type, e"
  },
  {
    "id": 16147,
    "content": "g"
  },
  {
    "id": 16148,
    "content": "Data-type Multiplicands (A or B) Accumulator (D) Integer both u8 or both"
  },
  {
    "id": 16149,
    "content": "s8"
  },
  {
    "id": 16150,
    "content": "s32 Floating Point"
  },
  {
    "id": 16151,
    "content": "f16 f16 ,"
  },
  {
    "id": 16152,
    "content": "f32 Alternate floating Point"
  },
  {
    "id": 16153,
    "content": "bf16"
  },
  {
    "id": 16154,
    "content": "f32 Alternate floating Point"
  },
  {
    "id": 16155,
    "content": "tf32"
  },
  {
    "id": 16156,
    "content": "f32 Alternate floating Point"
  },
  {
    "id": 16157,
    "content": "e4m3 ,"
  },
  {
    "id": 16158,
    "content": "e5m2"
  },
  {
    "id": 16159,
    "content": "f16 ,"
  },
  {
    "id": 16160,
    "content": "f32 Single-bit integer"
  },
  {
    "id": 16161,
    "content": "b1"
  },
  {
    "id": 16162,
    "content": "s32 9"
  },
  {
    "id": 16163,
    "content": "7"
  },
  {
    "id": 16164,
    "content": "14"
  },
  {
    "id": 16165,
    "content": "4"
  },
  {
    "id": 16168,
    "content": "9"
  },
  {
    "id": 16169,
    "content": "7"
  },
  {
    "id": 16170,
    "content": "14"
  },
  {
    "id": 16171,
    "content": "5"
  },
  {
    "id": 16173,
    "content": "9"
  },
  {
    "id": 16174,
    "content": "7"
  },
  {
    "id": 16175,
    "content": "14"
  },
  {
    "id": 16176,
    "content": "5"
  },
  {
    "id": 16177,
    "content": "1"
  },
  {
    "id": 16179,
    "content": "9"
  },
  {
    "id": 16180,
    "content": "7"
  },
  {
    "id": 16181,
    "content": "14"
  },
  {
    "id": 16182,
    "content": "5"
  },
  {
    "id": 16183,
    "content": "1"
  },
  {
    "id": 16184,
    "content": "1"
  },
  {
    "id": 16186,
    "content": "mma_async instruction"
  },
  {
    "id": 16187,
    "content": "9"
  },
  {
    "id": 16188,
    "content": "7"
  },
  {
    "id": 16189,
    "content": "14"
  },
  {
    "id": 16190,
    "content": "5"
  },
  {
    "id": 16191,
    "content": "1"
  },
  {
    "id": 16192,
    "content": "1"
  },
  {
    "id": 16193,
    "content": "1"
  },
  {
    "id": 16194,
    "content": "Matrix Fragments for wgmma"
  },
  {
    "id": 16195,
    "content": "mma_async"
  },
  {
    "id": 16196,
    "content": "m64nNk16  A warpgroup executing wgmma"
  },
  {
    "id": 16197,
    "content": "mma_async"
  },
  {
    "id": 16200,
    "content": "Multiplicand A in registers:"
  },
  {
    "id": 16201,
    "content": "atype Fragment Elements (low to high)"
  },
  {
    "id": 16202,
    "content": "f16 /"
  },
  {
    "id": 16203,
    "content": "bf16 A vector expression containing four f16x2 registers, with each register containing two"
  },
  {
    "id": 16204,
    "content": "f16 /"
  },
  {
    "id": 16205,
    "content": "bf16 elements from matrix A"
  },
  {
    "id": 16207,
    "content": " Accumulator D:"
  },
  {
    "id": 16208,
    "content": "dtype Fragment Elements (low to high)"
  },
  {
    "id": 16211,
    "content": "Figure 120 WGMMA"
  },
  {
    "id": 16212,
    "content": "m64nNk16 register fragment layout for accumulator matrix D"
  },
  {
    "id": 16213,
    "content": " 9"
  },
  {
    "id": 16214,
    "content": "7"
  },
  {
    "id": 16215,
    "content": "14"
  },
  {
    "id": 16216,
    "content": "5"
  },
  {
    "id": 16217,
    "content": "1"
  },
  {
    "id": 16218,
    "content": "1"
  },
  {
    "id": 16219,
    "content": "2"
  },
  {
    "id": 16220,
    "content": "Matrix Fragments for wgmma"
  },
  {
    "id": 16221,
    "content": "mma_async"
  },
  {
    "id": 16222,
    "content": "m64nNk8  A warpgroup executing wgmma"
  },
  {
    "id": 16223,
    "content": "mma_async"
  },
  {
    "id": 16225,
    "content": "Multiplicand A in registers:"
  },
  {
    "id": 16226,
    "content": "atype Fragment Elements (low to high)"
  },
  {
    "id": 16227,
    "content": "tf32 A vector expression containing four b32 registers containing four tf32 elements from matrix A"
  },
  {
    "id": 16228,
    "content": "a0, a1, a2, a3 The layout of the fragments held by different threads is shown in Figure 121"
  },
  {
    "id": 16229,
    "content": " Accumulator D:"
  },
  {
    "id": 16230,
    "content": "dtype Fragment Elements (low to high)"
  },
  {
    "id": 16231,
    "content": "f32 A vector expression containing N/2 number of f32 registers"
  },
  {
    "id": 16233,
    "content": "Figure 122 WGMMA"
  },
  {
    "id": 16234,
    "content": "m64nNk8 register fragment layout for accumulator matrix D"
  },
  {
    "id": 16235,
    "content": " 9"
  },
  {
    "id": 16236,
    "content": "7"
  },
  {
    "id": 16237,
    "content": "14"
  },
  {
    "id": 16238,
    "content": "5"
  },
  {
    "id": 16239,
    "content": "1"
  },
  {
    "id": 16240,
    "content": "1"
  },
  {
    "id": 16241,
    "content": "3"
  },
  {
    "id": 16242,
    "content": "Matrix Fragments for wgmma"
  },
  {
    "id": 16243,
    "content": "mma_async"
  },
  {
    "id": 16244,
    "content": "m64nNk32  A warpgroup executing wgmma"
  },
  {
    "id": 16245,
    "content": "mma_async"
  },
  {
    "id": 16247,
    "content": "Multiplicand A in registers:"
  },
  {
    "id": 16248,
    "content": "atype Fragment Elements (low to high)"
  },
  {
    "id": 16249,
    "content": "s8 /"
  },
  {
    "id": 16250,
    "content": "u8 A vector expression containing four b32 registers, with each register containing four u8 /"
  },
  {
    "id": 16251,
    "content": "s8 elements from matrix A"
  },
  {
    "id": 16252,
    "content": "a0, a1, a2, a3, … , a14, a15"
  },
  {
    "id": 16253,
    "content": "e4m3 /"
  },
  {
    "id": 16254,
    "content": "e5m2 A vector expression containing four b32 registers, with each register containing four"
  },
  {
    "id": 16255,
    "content": "e4m3 /"
  },
  {
    "id": 16256,
    "content": "e5m2 elements from matrix A"
  },
  {
    "id": 16257,
    "content": " Accumulator D:"
  },
  {
    "id": 16258,
    "content": "dtype Fragment Elements (low to high) Miscellaneous Information"
  },
  {
    "id": 16259,
    "content": "s32 A vector expression containing N/2 number of s32 registers"
  },
  {
    "id": 16261,
    "content": "dtype, as described in the next column"
  },
  {
    "id": 16262,
    "content": "N = 8*i where i = {1, 2, 3, 4} = 16*i where i = {3, 4, , 15, 16}"
  },
  {
    "id": 16263,
    "content": "f32 A vector expression containing N/2 number of f32 registers"
  },
  {
    "id": 16264,
    "content": ", 32}"
  },
  {
    "id": 16266,
    "content": "Figure 124 WGMMA"
  },
  {
    "id": 16267,
    "content": "m64nNk32 register fragment layout for accumulator matrix D"
  },
  {
    "id": 16268,
    "content": " 9"
  },
  {
    "id": 16269,
    "content": "7"
  },
  {
    "id": 16270,
    "content": "14"
  },
  {
    "id": 16271,
    "content": "5"
  },
  {
    "id": 16272,
    "content": "1"
  },
  {
    "id": 16273,
    "content": "1"
  },
  {
    "id": 16274,
    "content": "4"
  },
  {
    "id": 16275,
    "content": "Matrix Fragments for wgmma"
  },
  {
    "id": 16276,
    "content": "mma_async"
  },
  {
    "id": 16277,
    "content": "m64nNk256  A warpgroup executing wgmma"
  },
  {
    "id": 16278,
    "content": "mma_async"
  },
  {
    "id": 16280,
    "content": "Multiplicand A in registers:"
  },
  {
    "id": 16281,
    "content": "atype Fragment Elements (low to high)"
  },
  {
    "id": 16282,
    "content": "b1 A vector expression containing four"
  },
  {
    "id": 16283,
    "content": "b32 registers, with each register containing thirty two"
  },
  {
    "id": 16284,
    "content": "b1 element from matrix A"
  },
  {
    "id": 16285,
    "content": "a0, a1, a2, …, a127 The layout of the fragments held by different threads is shown in Figure 125"
  },
  {
    "id": 16286,
    "content": " Accumulator D:"
  },
  {
    "id": 16287,
    "content": "dtype Fragment Elements (low to high)"
  },
  {
    "id": 16288,
    "content": "s32 A vector expression containing N/2 number of s32 registers"
  },
  {
    "id": 16291,
    "content": "m64nNk256 register fragment layout for accumulator matrix D"
  },
  {
    "id": 16292,
    "content": " 9"
  },
  {
    "id": 16293,
    "content": "7"
  },
  {
    "id": 16294,
    "content": "14"
  },
  {
    "id": 16295,
    "content": "5"
  },
  {
    "id": 16296,
    "content": "1"
  },
  {
    "id": 16297,
    "content": "2"
  },
  {
    "id": 16299,
    "content": "9"
  },
  {
    "id": 16300,
    "content": "7"
  },
  {
    "id": 16301,
    "content": "14"
  },
  {
    "id": 16302,
    "content": "5"
  },
  {
    "id": 16303,
    "content": "1"
  },
  {
    "id": 16304,
    "content": "2"
  },
  {
    "id": 16305,
    "content": "1"
  },
  {
    "id": 16306,
    "content": "Shared Memory Layout for wgmma"
  },
  {
    "id": 16307,
    "content": "mma_async"
  },
  {
    "id": 16309,
    "content": "f16 /"
  },
  {
    "id": 16310,
    "content": "bf16 elements"
  },
  {
    "id": 16311,
    "content": "Figure 127 WGMMA"
  },
  {
    "id": 16313,
    "content": "mma_async"
  },
  {
    "id": 16315,
    "content": "tf32 elements"
  },
  {
    "id": 16316,
    "content": "Figure 130 WGMMA"
  },
  {
    "id": 16318,
    "content": "mma_async"
  },
  {
    "id": 16319,
    "content": "m64nNk32  Core matrices of A and B are as follows:"
  },
  {
    "id": 16320,
    "content": "atype/"
  },
  {
    "id": 16321,
    "content": "btype Core matrix Matrix description Matrix size"
  },
  {
    "id": 16322,
    "content": "s8 /"
  },
  {
    "id": 16323,
    "content": "u8 A Each row is made up of sixteen"
  },
  {
    "id": 16324,
    "content": "s8 /"
  },
  {
    "id": 16325,
    "content": "u8 elements"
  },
  {
    "id": 16326,
    "content": "Figure 133 WGMMA"
  },
  {
    "id": 16328,
    "content": "mma_async"
  },
  {
    "id": 16330,
    "content": "b1 elements"
  },
  {
    "id": 16331,
    "content": "Figure 136 WGMMA"
  },
  {
    "id": 16335,
    "content": "9"
  },
  {
    "id": 16336,
    "content": "7"
  },
  {
    "id": 16337,
    "content": "14"
  },
  {
    "id": 16338,
    "content": "5"
  },
  {
    "id": 16339,
    "content": "1"
  },
  {
    "id": 16340,
    "content": "2"
  },
  {
    "id": 16341,
    "content": "6"
  },
  {
    "id": 16347,
    "content": "7"
  },
  {
    "id": 16348,
    "content": "14"
  },
  {
    "id": 16349,
    "content": "5"
  },
  {
    "id": 16350,
    "content": "2"
  },
  {
    "id": 16351,
    "content": "The operation of the form D = A*B is issued when the input predicate argument scale-d is false"
  },
  {
    "id": 16355,
    "content": "The transpose operation is only supported for the wgmma"
  },
  {
    "id": 16356,
    "content": "mma_async variants with"
  },
  {
    "id": 16357,
    "content": "f16 /"
  },
  {
    "id": 16358,
    "content": "bf16 types on matrices accessed from shared memory using matrix descriptors"
  },
  {
    "id": 16359,
    "content": "For the floating point variants of the wgmma"
  },
  {
    "id": 16361,
    "content": "The qualifiers"
  },
  {
    "id": 16362,
    "content": "dtype ,"
  },
  {
    "id": 16363,
    "content": "atype and"
  },
  {
    "id": 16364,
    "content": "btype indicate the data type of the elements in matrices D, A and B respectively"
  },
  {
    "id": 16365,
    "content": "atype and"
  },
  {
    "id": 16367,
    "content": "atype /"
  },
  {
    "id": 16368,
    "content": "btype is"
  },
  {
    "id": 16369,
    "content": "e4m3 /"
  },
  {
    "id": 16370,
    "content": "e5m2"
  },
  {
    "id": 16372,
    "content": "When"
  },
  {
    "id": 16373,
    "content": "dtype is"
  },
  {
    "id": 16374,
    "content": "f32 , accumulation of the intermediate values is performed with at least single precision"
  },
  {
    "id": 16375,
    "content": "bf16 and"
  },
  {
    "id": 16377,
    "content": "wgmma"
  },
  {
    "id": 16378,
    "content": "mma_async operation involving type"
  },
  {
    "id": 16379,
    "content": "tf32 will truncate lower 13 bits of the 32-bit input data before multiplication is issued"
  },
  {
    "id": 16380,
    "content": "Integer operations: The integer wgmma"
  },
  {
    "id": 16381,
    "content": "mma_async operation is performed with"
  },
  {
    "id": 16382,
    "content": "s32 accumulators"
  },
  {
    "id": 16383,
    "content": "The mandatory"
  },
  {
    "id": 16384,
    "content": "sync qualifier indicates that wgmma"
  },
  {
    "id": 16386,
    "content": "The mandatory"
  },
  {
    "id": 16387,
    "content": "aligned qualifier indicates that all threads in the warpgroup must execute the same wgmma"
  },
  {
    "id": 16388,
    "content": "mma_async instruction"
  },
  {
    "id": 16389,
    "content": "In conditionally executed code, a wgmma"
  },
  {
    "id": 16391,
    "content": "Asynchronous Warpgroup Level Multiply-and-Accumulate Operation using wgmma"
  },
  {
    "id": 16392,
    "content": "mma_async"
  },
  {
    "id": 16393,
    "content": "sp instruction  This section describes warp-level wgmma"
  },
  {
    "id": 16394,
    "content": "mma_async"
  },
  {
    "id": 16395,
    "content": "sp instruction with sparse matrix A"
  },
  {
    "id": 16396,
    "content": "This variant of the wgmma"
  },
  {
    "id": 16398,
    "content": "For an MxNxK sparse wgmma"
  },
  {
    "id": 16399,
    "content": "mma_async"
  },
  {
    "id": 16400,
    "content": "sp operation, the MxK matrix A is packed into MxK/2 elements"
  },
  {
    "id": 16401,
    "content": "9"
  },
  {
    "id": 16402,
    "content": "7"
  },
  {
    "id": 16403,
    "content": "14"
  },
  {
    "id": 16404,
    "content": "6"
  },
  {
    "id": 16405,
    "content": "1"
  },
  {
    "id": 16406,
    "content": "For example, in a 64x32 matrix A used in floating point wgmma"
  },
  {
    "id": 16407,
    "content": "mma_async operations, sparsity is expected to be at 2:4 granularity, i"
  },
  {
    "id": 16408,
    "content": "e"
  },
  {
    "id": 16410,
    "content": "mma_async"
  },
  {
    "id": 16411,
    "content": "sp with half-precision and"
  },
  {
    "id": 16412,
    "content": "bf16 type For"
  },
  {
    "id": 16413,
    "content": "f16 and"
  },
  {
    "id": 16414,
    "content": "bf16 types, for all supported 64xNx32 shapes, matrix A is structured sparse at a granularity of 2:4"
  },
  {
    "id": 16417,
    "content": "Sparse wgmma"
  },
  {
    "id": 16418,
    "content": "mma_async"
  },
  {
    "id": 16419,
    "content": "sp with"
  },
  {
    "id": 16422,
    "content": "Sparse wgmma"
  },
  {
    "id": 16423,
    "content": "mma_async"
  },
  {
    "id": 16424,
    "content": "sp with"
  },
  {
    "id": 16425,
    "content": "e4m3 and"
  },
  {
    "id": 16426,
    "content": "e5m2 floating point type For"
  },
  {
    "id": 16427,
    "content": "e4m3 and"
  },
  {
    "id": 16428,
    "content": "e5m2 types, for all supported 64xNx64 shapes, matrix A is structured sparse at a granularity of 2:4"
  },
  {
    "id": 16430,
    "content": "Sparse wgmma"
  },
  {
    "id": 16431,
    "content": "mma_async"
  },
  {
    "id": 16434,
    "content": "Figure 148 Sparse WGMMA metadata example for"
  },
  {
    "id": 16435,
    "content": "u8 /"
  },
  {
    "id": 16436,
    "content": "s8 type"
  },
  {
    "id": 16437,
    "content": "9"
  },
  {
    "id": 16438,
    "content": "7"
  },
  {
    "id": 16439,
    "content": "14"
  },
  {
    "id": 16440,
    "content": "6"
  },
  {
    "id": 16441,
    "content": "2"
  },
  {
    "id": 16444,
    "content": "instruction , the pictorial representations of matrix fragments are not included in this section"
  },
  {
    "id": 16445,
    "content": "9"
  },
  {
    "id": 16446,
    "content": "7"
  },
  {
    "id": 16447,
    "content": "14"
  },
  {
    "id": 16448,
    "content": "6"
  },
  {
    "id": 16449,
    "content": "2"
  },
  {
    "id": 16450,
    "content": "1"
  },
  {
    "id": 16451,
    "content": "Matrix Fragments for sparse wgmma"
  },
  {
    "id": 16452,
    "content": "mma_async"
  },
  {
    "id": 16453,
    "content": "m64nNk32  A warpgroup executing sparse wgmma"
  },
  {
    "id": 16454,
    "content": "mma_async"
  },
  {
    "id": 16456,
    "content": "Multiplicand A, from shared memory is documented in Shared Memory Layout for wgmma"
  },
  {
    "id": 16457,
    "content": "mma_async"
  },
  {
    "id": 16458,
    "content": "m64nNk32"
  },
  {
    "id": 16459,
    "content": "Multiplicand A, from registers:"
  },
  {
    "id": 16460,
    "content": "atype Fragments Elements"
  },
  {
    "id": 16461,
    "content": "f16 /"
  },
  {
    "id": 16462,
    "content": "bf16 A vector expression containing four b32 registers, with each register containing two non-zero"
  },
  {
    "id": 16463,
    "content": "f16 /"
  },
  {
    "id": 16465,
    "content": "m64nNk32 with floating point type for the same"
  },
  {
    "id": 16466,
    "content": "dtype format"
  },
  {
    "id": 16467,
    "content": "Multiplicand B: Shared memory layout for Matrix B is documented in Shared Memory Layout for wgmma"
  },
  {
    "id": 16468,
    "content": "mma_async"
  },
  {
    "id": 16469,
    "content": "m64nNk32"
  },
  {
    "id": 16470,
    "content": "Metadata operand is a"
  },
  {
    "id": 16472,
    "content": "Figure 150 Sparse WGMMA"
  },
  {
    "id": 16473,
    "content": "m64nNk32 metadata layout for"
  },
  {
    "id": 16474,
    "content": "f16 /"
  },
  {
    "id": 16475,
    "content": "bf16 type"
  },
  {
    "id": 16476,
    "content": " 9"
  },
  {
    "id": 16477,
    "content": "7"
  },
  {
    "id": 16478,
    "content": "14"
  },
  {
    "id": 16479,
    "content": "6"
  },
  {
    "id": 16480,
    "content": "2"
  },
  {
    "id": 16481,
    "content": "2"
  },
  {
    "id": 16482,
    "content": "Matrix Fragments for sparse wgmma"
  },
  {
    "id": 16483,
    "content": "mma_async"
  },
  {
    "id": 16484,
    "content": "m64nNk16  A warpgroup executing sparse wgmma"
  },
  {
    "id": 16485,
    "content": "mma_async"
  },
  {
    "id": 16487,
    "content": "Multiplicand A, from shared memory is documented in Shared Memory Layout for wgmma"
  },
  {
    "id": 16488,
    "content": "mma_async"
  },
  {
    "id": 16489,
    "content": "m64nNk16"
  },
  {
    "id": 16490,
    "content": "Multiplicand A, from registers:"
  },
  {
    "id": 16491,
    "content": "atype Fragments Elements"
  },
  {
    "id": 16493,
    "content": "case of Matrix Fragments for wgmma"
  },
  {
    "id": 16494,
    "content": "m64nNk8 with floating point type for the same"
  },
  {
    "id": 16495,
    "content": "dtype format"
  },
  {
    "id": 16496,
    "content": "Multiplicand B: Shared memory layout for Matrix B is documented in Shared Memory Layout for wgmma"
  },
  {
    "id": 16497,
    "content": "mma_async"
  },
  {
    "id": 16498,
    "content": "m64nNk16"
  },
  {
    "id": 16499,
    "content": "Metadata operand is a"
  },
  {
    "id": 16501,
    "content": "Figure 152 Sparse WGMMA"
  },
  {
    "id": 16502,
    "content": "m64nNk16 metadata layout for"
  },
  {
    "id": 16503,
    "content": "tf32 type"
  },
  {
    "id": 16504,
    "content": " 9"
  },
  {
    "id": 16505,
    "content": "7"
  },
  {
    "id": 16506,
    "content": "14"
  },
  {
    "id": 16507,
    "content": "6"
  },
  {
    "id": 16508,
    "content": "2"
  },
  {
    "id": 16509,
    "content": "3"
  },
  {
    "id": 16510,
    "content": "Matrix Fragments for sparse wgmma"
  },
  {
    "id": 16511,
    "content": "mma_async"
  },
  {
    "id": 16512,
    "content": "m64nNk64  A warpgroup executing sparse wgmma"
  },
  {
    "id": 16513,
    "content": "mma_async"
  },
  {
    "id": 16515,
    "content": "Multiplicand A, from shared memory is documented in Shared Memory Layout for wgmma"
  },
  {
    "id": 16516,
    "content": "mma_async"
  },
  {
    "id": 16517,
    "content": "m64nNk64"
  },
  {
    "id": 16518,
    "content": "Multiplicand A, from registers:"
  },
  {
    "id": 16519,
    "content": "atype Fragments Elements"
  },
  {
    "id": 16520,
    "content": "e4m3 /"
  },
  {
    "id": 16521,
    "content": "e5m2 A vector expression containing four b32 registers, with each register containing four non-zero"
  },
  {
    "id": 16522,
    "content": "e4m3 /"
  },
  {
    "id": 16524,
    "content": "s8 /"
  },
  {
    "id": 16525,
    "content": "u8 A vector expression containing four b32 registers, with each register containing four non-zero"
  },
  {
    "id": 16526,
    "content": "s8 /"
  },
  {
    "id": 16527,
    "content": "u8 elements out of eight consecutive elements from matrix A"
  },
  {
    "id": 16528,
    "content": "Figure 153 Sparse WGMMA"
  },
  {
    "id": 16529,
    "content": "m64nNk64 fragment layout for matrix A with"
  },
  {
    "id": 16530,
    "content": "e4m3 /"
  },
  {
    "id": 16531,
    "content": "e5m2 /"
  },
  {
    "id": 16532,
    "content": "s8 /"
  },
  {
    "id": 16533,
    "content": "u8 type"
  },
  {
    "id": 16534,
    "content": "Multiplicand B: Shared memory layout for Matrix B is documented in Shared Memory Layout for wgmma"
  },
  {
    "id": 16535,
    "content": "mma_async"
  },
  {
    "id": 16536,
    "content": "m64nNk64"
  },
  {
    "id": 16537,
    "content": "Metadata operand is a"
  },
  {
    "id": 16539,
    "content": "e4m3 /"
  },
  {
    "id": 16540,
    "content": "e5m2 /"
  },
  {
    "id": 16541,
    "content": "s8 /"
  },
  {
    "id": 16543,
    "content": "m64nNk64 metadata layout for"
  },
  {
    "id": 16544,
    "content": "e4m3 /"
  },
  {
    "id": 16545,
    "content": "e5m2 /"
  },
  {
    "id": 16546,
    "content": "s8 /"
  },
  {
    "id": 16547,
    "content": "u8 type for columns 32–63  9"
  },
  {
    "id": 16548,
    "content": "7"
  },
  {
    "id": 16549,
    "content": "14"
  },
  {
    "id": 16550,
    "content": "6"
  },
  {
    "id": 16551,
    "content": "3"
  },
  {
    "id": 16552,
    "content": "Matrix A is made up of 8x2 packed core matrices and Matrix B is made up of 4x (N/8) core matrices"
  },
  {
    "id": 16553,
    "content": "9"
  },
  {
    "id": 16554,
    "content": "7"
  },
  {
    "id": 16555,
    "content": "14"
  },
  {
    "id": 16556,
    "content": "6"
  },
  {
    "id": 16557,
    "content": "3"
  },
  {
    "id": 16558,
    "content": "1"
  },
  {
    "id": 16559,
    "content": "Shared Memory Layout for wgmma"
  },
  {
    "id": 16560,
    "content": "mma_async"
  },
  {
    "id": 16561,
    "content": "sp"
  },
  {
    "id": 16563,
    "content": "f16 /"
  },
  {
    "id": 16564,
    "content": "bf16 elements, with two non-zero elements out of four consecutive elements"
  },
  {
    "id": 16565,
    "content": "Figure 156 Sparse WGMMA"
  },
  {
    "id": 16567,
    "content": "mma_async"
  },
  {
    "id": 16568,
    "content": "sp"
  },
  {
    "id": 16570,
    "content": "tf32 elements with a non-zero element out of two consecutive elements"
  },
  {
    "id": 16571,
    "content": "Figure 159 Sparse WGMMA"
  },
  {
    "id": 16573,
    "content": "mma_async"
  },
  {
    "id": 16574,
    "content": "sp"
  },
  {
    "id": 16576,
    "content": "e4m3 /"
  },
  {
    "id": 16577,
    "content": "e5m2 elements, with two non-zero elements out of four consecutive elements"
  },
  {
    "id": 16578,
    "content": "Figure 162 Sparse WGMMA"
  },
  {
    "id": 16581,
    "content": "mma_async"
  },
  {
    "id": 16583,
    "content": "3"
  },
  {
    "id": 16585,
    "content": "mma_async"
  },
  {
    "id": 16587,
    "content": "m64nNk16"
  },
  {
    "id": 16588,
    "content": "tf32 0b1110 , 0b0100 0 (threads T0, T1) or 1 (threads T2, T3)"
  },
  {
    "id": 16589,
    "content": "m64nNk32"
  },
  {
    "id": 16590,
    "content": "f16 /"
  },
  {
    "id": 16591,
    "content": "bf16 0b00, 0b01, 0b10, 0b11 0 (threads T0, T1) or 1 (threads T2, T3)"
  },
  {
    "id": 16592,
    "content": "m64nNk64"
  },
  {
    "id": 16593,
    "content": "e4m3 /"
  },
  {
    "id": 16594,
    "content": "e5m2 /"
  },
  {
    "id": 16595,
    "content": "s8 /"
  },
  {
    "id": 16597,
    "content": "Examples of integer type wgmma"
  },
  {
    "id": 16598,
    "content": "fence"
  },
  {
    "id": 16599,
    "content": "sync"
  },
  {
    "id": 16600,
    "content": "aligned; wgmma"
  },
  {
    "id": 16601,
    "content": "mma_async"
  },
  {
    "id": 16602,
    "content": "sp"
  },
  {
    "id": 16603,
    "content": "sync"
  },
  {
    "id": 16604,
    "content": "aligned"
  },
  {
    "id": 16605,
    "content": "m64n8k64"
  },
  {
    "id": 16606,
    "content": "s32"
  },
  {
    "id": 16607,
    "content": "u8 u8 {s32d0, s32d1, s32d2, s32d3}, descA, descB, spMeta, 0, scaleD; wgmma"
  },
  {
    "id": 16608,
    "content": "mma_async"
  },
  {
    "id": 16609,
    "content": "sp"
  },
  {
    "id": 16610,
    "content": "sync"
  },
  {
    "id": 16611,
    "content": "aligned"
  },
  {
    "id": 16612,
    "content": "m64n8k64"
  },
  {
    "id": 16613,
    "content": "s32"
  },
  {
    "id": 16614,
    "content": "s8"
  },
  {
    "id": 16615,
    "content": "u8 {s32d0, s32d1, s32d2, s32d3}, descA, descB, spMeta, 0, scaleD; wgmma"
  },
  {
    "id": 16616,
    "content": "commit_group"
  },
  {
    "id": 16617,
    "content": "sync"
  },
  {
    "id": 16618,
    "content": "aligned; wgmma"
  },
  {
    "id": 16619,
    "content": "wait_group"
  },
  {
    "id": 16620,
    "content": "sync"
  },
  {
    "id": 16621,
    "content": "aligned 0; 9"
  },
  {
    "id": 16622,
    "content": "7"
  },
  {
    "id": 16623,
    "content": "14"
  },
  {
    "id": 16624,
    "content": "7"
  },
  {
    "id": 16626,
    "content": "wait_group instructions"
  },
  {
    "id": 16627,
    "content": "9"
  },
  {
    "id": 16628,
    "content": "7"
  },
  {
    "id": 16629,
    "content": "14"
  },
  {
    "id": 16630,
    "content": "7"
  },
  {
    "id": 16631,
    "content": "1"
  },
  {
    "id": 16633,
    "content": "mma_async and other operations"
  },
  {
    "id": 16634,
    "content": "Syntax wgmma"
  },
  {
    "id": 16635,
    "content": "fence"
  },
  {
    "id": 16636,
    "content": "sync"
  },
  {
    "id": 16637,
    "content": "aligned; Description wgmma"
  },
  {
    "id": 16639,
    "content": "mma_async instruction"
  },
  {
    "id": 16643,
    "content": "The mandatory"
  },
  {
    "id": 16644,
    "content": "sync qualifier indicates that wgmma"
  },
  {
    "id": 16646,
    "content": "The mandatory"
  },
  {
    "id": 16647,
    "content": "aligned qualifier indicates that all threads in the warpgroup must execute the same wgmma"
  },
  {
    "id": 16648,
    "content": "fence instruction"
  },
  {
    "id": 16649,
    "content": "In conditionally executed code, an wgmma"
  },
  {
    "id": 16651,
    "content": "Examples   Example 1, first use example: wgmma"
  },
  {
    "id": 16652,
    "content": "fence"
  },
  {
    "id": 16653,
    "content": "sync"
  },
  {
    "id": 16654,
    "content": "aligned;   Establishes an ordering w"
  },
  {
    "id": 16655,
    "content": "r"
  },
  {
    "id": 16656,
    "content": "t"
  },
  {
    "id": 16657,
    "content": "prior accesses to the registers s32d wgmma"
  },
  {
    "id": 16658,
    "content": "mma_async"
  },
  {
    "id": 16659,
    "content": "sync"
  },
  {
    "id": 16660,
    "content": "aligned"
  },
  {
    "id": 16661,
    "content": "m64n8k32"
  },
  {
    "id": 16662,
    "content": "s32"
  },
  {
    "id": 16663,
    "content": "u8 u8 {s32d0, s32d1, s32d2, s32d3}, descA, descB, scaleD; wgmma"
  },
  {
    "id": 16664,
    "content": "commit_group"
  },
  {
    "id": 16665,
    "content": "sync"
  },
  {
    "id": 16666,
    "content": "aligned; wgmma"
  },
  {
    "id": 16667,
    "content": "wait_group"
  },
  {
    "id": 16668,
    "content": "sync"
  },
  {
    "id": 16669,
    "content": "aligned 0;   Example 2, use-case with the input value updated in between: wgmma"
  },
  {
    "id": 16670,
    "content": "fence"
  },
  {
    "id": 16671,
    "content": "sync"
  },
  {
    "id": 16672,
    "content": "aligned; wgmma"
  },
  {
    "id": 16673,
    "content": "mma_async"
  },
  {
    "id": 16674,
    "content": "sync"
  },
  {
    "id": 16675,
    "content": "aligned"
  },
  {
    "id": 16676,
    "content": "m64n8k32"
  },
  {
    "id": 16677,
    "content": "s32"
  },
  {
    "id": 16678,
    "content": "u8 u8 {s32d0, s32d1, s32d2, s32d3}, descA, descB, scaleD;"
  },
  {
    "id": 16679,
    "content": "mov"
  },
  {
    "id": 16680,
    "content": "b32 s32d0, new_val; wgmma"
  },
  {
    "id": 16681,
    "content": "fence"
  },
  {
    "id": 16682,
    "content": "sync"
  },
  {
    "id": 16683,
    "content": "aligned; wgmma"
  },
  {
    "id": 16684,
    "content": "mma_async"
  },
  {
    "id": 16685,
    "content": "sync"
  },
  {
    "id": 16686,
    "content": "aligned"
  },
  {
    "id": 16687,
    "content": "m64n8k32"
  },
  {
    "id": 16688,
    "content": "s32"
  },
  {
    "id": 16689,
    "content": "u8 u8 {s32d4, s32d5, s32d6, s32d7}, {s32d0, s32d1, s32d2, s32d3}, descB, scaleD; wgmma"
  },
  {
    "id": 16690,
    "content": "commit_group"
  },
  {
    "id": 16691,
    "content": "sync"
  },
  {
    "id": 16692,
    "content": "aligned; wgmma"
  },
  {
    "id": 16693,
    "content": "wait_group"
  },
  {
    "id": 16694,
    "content": "sync"
  },
  {
    "id": 16695,
    "content": "aligned 0; 9"
  },
  {
    "id": 16696,
    "content": "7"
  },
  {
    "id": 16697,
    "content": "14"
  },
  {
    "id": 16698,
    "content": "7"
  },
  {
    "id": 16699,
    "content": "2"
  },
  {
    "id": 16701,
    "content": "sync"
  },
  {
    "id": 16703,
    "content": "of all wgmma mma_async operations in a wgmma-group by using wgmma"
  },
  {
    "id": 16704,
    "content": "wait_group"
  },
  {
    "id": 16705,
    "content": "The mandatory"
  },
  {
    "id": 16706,
    "content": "sync qualifier indicates that wgmma"
  },
  {
    "id": 16708,
    "content": "The mandatory"
  },
  {
    "id": 16709,
    "content": "aligned qualifier indicates that all threads in the warpgroup must execute the same wgmma"
  },
  {
    "id": 16710,
    "content": "commit_group instruction"
  },
  {
    "id": 16711,
    "content": "In conditionally executed code, an wgmma"
  },
  {
    "id": 16714,
    "content": "sync"
  },
  {
    "id": 16717,
    "content": "The mandatory"
  },
  {
    "id": 16718,
    "content": "sync qualifier indicates that wgmma"
  },
  {
    "id": 16720,
    "content": "The mandatory"
  },
  {
    "id": 16721,
    "content": "aligned qualifier indicates that all threads in the warpgroup must execute the same wgmma"
  },
  {
    "id": 16722,
    "content": "wait_group instruction"
  },
  {
    "id": 16723,
    "content": "In conditionally executed code, an wgmma"
  },
  {
    "id": 16725,
    "content": "Examples wgmma"
  },
  {
    "id": 16726,
    "content": "fence"
  },
  {
    "id": 16727,
    "content": "sync"
  },
  {
    "id": 16728,
    "content": "aligned; wgmma"
  },
  {
    "id": 16729,
    "content": "mma_async"
  },
  {
    "id": 16730,
    "content": "sync"
  },
  {
    "id": 16731,
    "content": "aligned"
  },
  {
    "id": 16732,
    "content": "m64n8k32"
  },
  {
    "id": 16733,
    "content": "s32"
  },
  {
    "id": 16734,
    "content": "u8 u8 {s32d0, s32d1, s32d2, s32d3}, descA, descB, scaleD; wgmma"
  },
  {
    "id": 16735,
    "content": "commit_group"
  },
  {
    "id": 16736,
    "content": "sync"
  },
  {
    "id": 16737,
    "content": "aligned; wgmma"
  },
  {
    "id": 16738,
    "content": "mma_async"
  },
  {
    "id": 16739,
    "content": "sync"
  },
  {
    "id": 16740,
    "content": "aligned"
  },
  {
    "id": 16741,
    "content": "m64n8k16"
  },
  {
    "id": 16742,
    "content": "f32"
  },
  {
    "id": 16743,
    "content": "f16 f16 {f32d0, f32d1, f32d2, f32d3}, {f16a0, f16a1, f16a2, f16a3}, descB, 1, -1, -1, 1; wgmma"
  },
  {
    "id": 16744,
    "content": "commit_group"
  },
  {
    "id": 16745,
    "content": "sync"
  },
  {
    "id": 16746,
    "content": "aligned; wgmma"
  },
  {
    "id": 16747,
    "content": "wait_group"
  },
  {
    "id": 16748,
    "content": "sync"
  },
  {
    "id": 16749,
    "content": "aligned 0; 9"
  },
  {
    "id": 16750,
    "content": "7"
  },
  {
    "id": 16751,
    "content": "15"
  },
  {
    "id": 16753,
    "content": "type d; type = {"
  },
  {
    "id": 16754,
    "content": "u32,"
  },
  {
    "id": 16756,
    "content": "Syntax stackrestore"
  },
  {
    "id": 16757,
    "content": "type a; type = {"
  },
  {
    "id": 16758,
    "content": "u32,"
  },
  {
    "id": 16759,
    "content": "u64 }; Description Sets the current stack pointer to source register a"
  },
  {
    "id": 16761,
    "content": "type a without redefining the value of a between them"
  },
  {
    "id": 16762,
    "content": "Syntax alloca"
  },
  {
    "id": 16763,
    "content": "type ptr, size{, immAlign}; type = {"
  },
  {
    "id": 16764,
    "content": "u32,"
  },
  {
    "id": 16772,
    "content": "Examples"
  },
  {
    "id": 16773,
    "content": "reg"
  },
  {
    "id": 16775,
    "content": "local"
  },
  {
    "id": 16777,
    "content": "7"
  },
  {
    "id": 16778,
    "content": "16"
  },
  {
    "id": 16781,
    "content": "7"
  },
  {
    "id": 16782,
    "content": "16"
  },
  {
    "id": 16783,
    "content": "1"
  },
  {
    "id": 16786,
    "content": "dtype"
  },
  {
    "id": 16787,
    "content": "atype"
  },
  {
    "id": 16788,
    "content": "btype{"
  },
  {
    "id": 16789,
    "content": "sat} d, a{"
  },
  {
    "id": 16790,
    "content": "asel}, b{"
  },
  {
    "id": 16791,
    "content": "bsel}; vop"
  },
  {
    "id": 16792,
    "content": "dtype"
  },
  {
    "id": 16793,
    "content": "atype"
  },
  {
    "id": 16794,
    "content": "btype{"
  },
  {
    "id": 16795,
    "content": "sat}"
  },
  {
    "id": 16796,
    "content": "secop d, a{"
  },
  {
    "id": 16797,
    "content": "asel}, b{"
  },
  {
    "id": 16798,
    "content": "bsel}, c;   32-bit scalar operation, with optional data merge vop"
  },
  {
    "id": 16799,
    "content": "dtype"
  },
  {
    "id": 16800,
    "content": "atype"
  },
  {
    "id": 16801,
    "content": "btype{"
  },
  {
    "id": 16802,
    "content": "sat} d"
  },
  {
    "id": 16803,
    "content": "dsel, a{"
  },
  {
    "id": 16804,
    "content": "asel}, b{"
  },
  {
    "id": 16805,
    "content": "bsel}, c;"
  },
  {
    "id": 16806,
    "content": "dtype ="
  },
  {
    "id": 16807,
    "content": "atype ="
  },
  {
    "id": 16808,
    "content": "btype = {"
  },
  {
    "id": 16809,
    "content": "u32,"
  },
  {
    "id": 16810,
    "content": "s32 };"
  },
  {
    "id": 16811,
    "content": "dsel ="
  },
  {
    "id": 16812,
    "content": "asel ="
  },
  {
    "id": 16813,
    "content": "bsel = {"
  },
  {
    "id": 16814,
    "content": "b0,"
  },
  {
    "id": 16815,
    "content": "b1,"
  },
  {
    "id": 16816,
    "content": "b2,"
  },
  {
    "id": 16817,
    "content": "b3,"
  },
  {
    "id": 16818,
    "content": "h0,"
  },
  {
    "id": 16819,
    "content": "h1 };"
  },
  {
    "id": 16820,
    "content": "secop = {"
  },
  {
    "id": 16821,
    "content": "add,"
  },
  {
    "id": 16822,
    "content": "min,"
  },
  {
    "id": 16823,
    "content": "max }; The source and destination operands are all 32-bit registers"
  },
  {
    "id": 16824,
    "content": "The type of each operand ("
  },
  {
    "id": 16825,
    "content": "u32 or"
  },
  {
    "id": 16827,
    "content": "s33 values"
  },
  {
    "id": 16829,
    "content": "s33 optSaturate("
  },
  {
    "id": 16830,
    "content": "s34 tmp, Bool sat, Bool sign, Modifier dsel ) { if ( sat ) return tmp; switch ( dsel ) { case"
  },
  {
    "id": 16831,
    "content": "b0,"
  },
  {
    "id": 16832,
    "content": "b1,"
  },
  {
    "id": 16833,
    "content": "b2,"
  },
  {
    "id": 16834,
    "content": "b3: if ( sign ) return CLAMP( tmp, S8_MAX, S8_MIN ); else return CLAMP( tmp, U8_MAX, U8_MIN ); case"
  },
  {
    "id": 16835,
    "content": "h0,"
  },
  {
    "id": 16839,
    "content": "0"
  },
  {
    "id": 16840,
    "content": "Examples vshl"
  },
  {
    "id": 16841,
    "content": "s32"
  },
  {
    "id": 16842,
    "content": "u32 u32"
  },
  {
    "id": 16843,
    "content": "clamp r1, r2, r3; vshr"
  },
  {
    "id": 16844,
    "content": "u32 u32 u32"
  },
  {
    "id": 16845,
    "content": "wrap r1, r2, r3"
  },
  {
    "id": 16846,
    "content": "h1; 9"
  },
  {
    "id": 16847,
    "content": "7"
  },
  {
    "id": 16848,
    "content": "16"
  },
  {
    "id": 16849,
    "content": "1"
  },
  {
    "id": 16850,
    "content": "3"
  },
  {
    "id": 16851,
    "content": "Syntax   32-bit scalar operation vmad"
  },
  {
    "id": 16852,
    "content": "dtype"
  },
  {
    "id": 16853,
    "content": "atype"
  },
  {
    "id": 16854,
    "content": "btype{"
  },
  {
    "id": 16855,
    "content": "sat}{"
  },
  {
    "id": 16856,
    "content": "scale} d, {-}a{"
  },
  {
    "id": 16857,
    "content": "asel}, {-}b{"
  },
  {
    "id": 16858,
    "content": "bsel}, {-}c; vmad"
  },
  {
    "id": 16859,
    "content": "dtype"
  },
  {
    "id": 16860,
    "content": "atype"
  },
  {
    "id": 16861,
    "content": "btype"
  },
  {
    "id": 16862,
    "content": "po{"
  },
  {
    "id": 16863,
    "content": "sat}{"
  },
  {
    "id": 16864,
    "content": "scale} d, a{"
  },
  {
    "id": 16865,
    "content": "asel}, b{"
  },
  {
    "id": 16866,
    "content": "bsel}, c;"
  },
  {
    "id": 16867,
    "content": "dtype ="
  },
  {
    "id": 16868,
    "content": "atype ="
  },
  {
    "id": 16869,
    "content": "btype = {"
  },
  {
    "id": 16870,
    "content": "u32,"
  },
  {
    "id": 16871,
    "content": "s32 };"
  },
  {
    "id": 16872,
    "content": "asel ="
  },
  {
    "id": 16873,
    "content": "bsel = {"
  },
  {
    "id": 16874,
    "content": "b0,"
  },
  {
    "id": 16875,
    "content": "b1,"
  },
  {
    "id": 16876,
    "content": "b2,"
  },
  {
    "id": 16877,
    "content": "b3,"
  },
  {
    "id": 16878,
    "content": "h0,"
  },
  {
    "id": 16879,
    "content": "h1 };"
  },
  {
    "id": 16880,
    "content": "scale = {"
  },
  {
    "id": 16881,
    "content": "shr7,"
  },
  {
    "id": 16888,
    "content": "0"
  },
  {
    "id": 16889,
    "content": "Examples vmad"
  },
  {
    "id": 16890,
    "content": "s32 s32"
  },
  {
    "id": 16891,
    "content": "u32"
  },
  {
    "id": 16892,
    "content": "sat r0, r1, r2, -r3; vmad"
  },
  {
    "id": 16893,
    "content": "u32 u32 u32"
  },
  {
    "id": 16894,
    "content": "shr15 r0, r1"
  },
  {
    "id": 16895,
    "content": "h0, r2 h0, r3; 9"
  },
  {
    "id": 16896,
    "content": "7"
  },
  {
    "id": 16897,
    "content": "16"
  },
  {
    "id": 16898,
    "content": "1"
  },
  {
    "id": 16899,
    "content": "4"
  },
  {
    "id": 16900,
    "content": "Syntax   32-bit scalar operation, with optional secondary operation vset"
  },
  {
    "id": 16901,
    "content": "atype"
  },
  {
    "id": 16902,
    "content": "btype"
  },
  {
    "id": 16903,
    "content": "cmp d, a{"
  },
  {
    "id": 16904,
    "content": "asel}, b{"
  },
  {
    "id": 16905,
    "content": "bsel}; vset"
  },
  {
    "id": 16906,
    "content": "atype"
  },
  {
    "id": 16907,
    "content": "btype"
  },
  {
    "id": 16908,
    "content": "cmp"
  },
  {
    "id": 16909,
    "content": "op2 d, a{"
  },
  {
    "id": 16910,
    "content": "asel}, b{"
  },
  {
    "id": 16911,
    "content": "bsel}, c;   32-bit scalar operation, with optional data merge vset"
  },
  {
    "id": 16912,
    "content": "atype"
  },
  {
    "id": 16913,
    "content": "btype"
  },
  {
    "id": 16914,
    "content": "cmp d"
  },
  {
    "id": 16915,
    "content": "dsel, a{"
  },
  {
    "id": 16916,
    "content": "asel}, b{"
  },
  {
    "id": 16917,
    "content": "bsel}, c;"
  },
  {
    "id": 16918,
    "content": "atype ="
  },
  {
    "id": 16919,
    "content": "btype = {"
  },
  {
    "id": 16920,
    "content": "u32,"
  },
  {
    "id": 16921,
    "content": "s32 };"
  },
  {
    "id": 16922,
    "content": "cmp = {"
  },
  {
    "id": 16923,
    "content": "eq,"
  },
  {
    "id": 16924,
    "content": "ne,"
  },
  {
    "id": 16925,
    "content": "lt,"
  },
  {
    "id": 16926,
    "content": "le,"
  },
  {
    "id": 16927,
    "content": "gt,"
  },
  {
    "id": 16928,
    "content": "ge };"
  },
  {
    "id": 16929,
    "content": "dsel ="
  },
  {
    "id": 16930,
    "content": "asel ="
  },
  {
    "id": 16931,
    "content": "bsel = {"
  },
  {
    "id": 16932,
    "content": "b0,"
  },
  {
    "id": 16933,
    "content": "b1,"
  },
  {
    "id": 16934,
    "content": "b2,"
  },
  {
    "id": 16935,
    "content": "b3,"
  },
  {
    "id": 16936,
    "content": "h0,"
  },
  {
    "id": 16937,
    "content": "h1 };"
  },
  {
    "id": 16938,
    "content": "op2 = {"
  },
  {
    "id": 16939,
    "content": "add,"
  },
  {
    "id": 16940,
    "content": "min,"
  },
  {
    "id": 16945,
    "content": "0"
  },
  {
    "id": 16950,
    "content": "dtype"
  },
  {
    "id": 16951,
    "content": "atype"
  },
  {
    "id": 16952,
    "content": "btype{"
  },
  {
    "id": 16953,
    "content": "sat}{"
  },
  {
    "id": 16954,
    "content": "add} d{"
  },
  {
    "id": 16955,
    "content": "mask}, a{"
  },
  {
    "id": 16956,
    "content": "asel}, b{"
  },
  {
    "id": 16957,
    "content": "bsel}, c;"
  },
  {
    "id": 16958,
    "content": "dtype ="
  },
  {
    "id": 16959,
    "content": "atype ="
  },
  {
    "id": 16960,
    "content": "btype = {"
  },
  {
    "id": 16961,
    "content": "u32,"
  },
  {
    "id": 16962,
    "content": "s32 };"
  },
  {
    "id": 16963,
    "content": "mask = {"
  },
  {
    "id": 16964,
    "content": "h0,"
  },
  {
    "id": 16965,
    "content": "h1,"
  },
  {
    "id": 16966,
    "content": "h10 };"
  },
  {
    "id": 16967,
    "content": "asel ="
  },
  {
    "id": 16968,
    "content": "bsel = {"
  },
  {
    "id": 16970,
    "content": "dtype"
  },
  {
    "id": 16971,
    "content": "atype"
  },
  {
    "id": 16972,
    "content": "btype{"
  },
  {
    "id": 16973,
    "content": "sat}{"
  },
  {
    "id": 16974,
    "content": "add} d{"
  },
  {
    "id": 16975,
    "content": "mask}, a{"
  },
  {
    "id": 16976,
    "content": "asel}, b{"
  },
  {
    "id": 16977,
    "content": "bsel}, c;"
  },
  {
    "id": 16978,
    "content": "dtype ="
  },
  {
    "id": 16979,
    "content": "atype ="
  },
  {
    "id": 16980,
    "content": "btype = {"
  },
  {
    "id": 16981,
    "content": "u32,"
  },
  {
    "id": 16982,
    "content": "s32 };"
  },
  {
    "id": 16983,
    "content": "mask = {"
  },
  {
    "id": 16984,
    "content": "b0,"
  },
  {
    "id": 16985,
    "content": "b1,"
  },
  {
    "id": 16986,
    "content": "b10"
  },
  {
    "id": 16987,
    "content": "b2,"
  },
  {
    "id": 16988,
    "content": "b20,"
  },
  {
    "id": 16989,
    "content": "b21,"
  },
  {
    "id": 16990,
    "content": "b210,"
  },
  {
    "id": 16991,
    "content": "b3,"
  },
  {
    "id": 16992,
    "content": "b30,"
  },
  {
    "id": 16993,
    "content": "b31,"
  },
  {
    "id": 16994,
    "content": "b310,"
  },
  {
    "id": 16995,
    "content": "b32,"
  },
  {
    "id": 16996,
    "content": "b320,"
  },
  {
    "id": 16997,
    "content": "b321,"
  },
  {
    "id": 16998,
    "content": "b3210 };"
  },
  {
    "id": 16999,
    "content": "asel ="
  },
  {
    "id": 17000,
    "content": "bsel ="
  },
  {
    "id": 17001,
    "content": "bxyzw, where x,y,z,w are from { 0,"
  },
  {
    "id": 17002,
    "content": ", 7 }; The source and destination operands are all 32-bit registers"
  },
  {
    "id": 17003,
    "content": "The sign of the intermediate result depends on dtype"
  },
  {
    "id": 17004,
    "content": "9"
  },
  {
    "id": 17005,
    "content": "7"
  },
  {
    "id": 17006,
    "content": "16"
  },
  {
    "id": 17007,
    "content": "2"
  },
  {
    "id": 17008,
    "content": "1"
  },
  {
    "id": 17010,
    "content": "dtype"
  },
  {
    "id": 17011,
    "content": "atype"
  },
  {
    "id": 17012,
    "content": "btype{"
  },
  {
    "id": 17013,
    "content": "sat} d{"
  },
  {
    "id": 17014,
    "content": "mask}, a{"
  },
  {
    "id": 17015,
    "content": "asel}, b{"
  },
  {
    "id": 17016,
    "content": "bsel}, c;   SIMD instruction with secondary accumulate operation vop2"
  },
  {
    "id": 17017,
    "content": "dtype"
  },
  {
    "id": 17018,
    "content": "atype"
  },
  {
    "id": 17019,
    "content": "btype"
  },
  {
    "id": 17020,
    "content": "add d{"
  },
  {
    "id": 17021,
    "content": "mask}, a{"
  },
  {
    "id": 17022,
    "content": "asel}, b{"
  },
  {
    "id": 17023,
    "content": "bsel}, c; vop2 = { vadd2, vsub2, vavrg2, vabsdiff2, vmin2, vmax2 };"
  },
  {
    "id": 17024,
    "content": "dtype ="
  },
  {
    "id": 17025,
    "content": "atype ="
  },
  {
    "id": 17026,
    "content": "btype = {"
  },
  {
    "id": 17027,
    "content": "u32,"
  },
  {
    "id": 17028,
    "content": "s32 };"
  },
  {
    "id": 17029,
    "content": "mask = {"
  },
  {
    "id": 17030,
    "content": "h0,"
  },
  {
    "id": 17031,
    "content": "h1,"
  },
  {
    "id": 17032,
    "content": "h10 };   defaults to h10"
  },
  {
    "id": 17033,
    "content": "asel ="
  },
  {
    "id": 17034,
    "content": "bsel = {"
  },
  {
    "id": 17035,
    "content": "hxy, where x,y are from { 0, 1, 2, 3 } };"
  },
  {
    "id": 17036,
    "content": "asel defaults to"
  },
  {
    "id": 17037,
    "content": "h10"
  },
  {
    "id": 17038,
    "content": "bsel defaults to"
  },
  {
    "id": 17039,
    "content": "h32 Description Two-way SIMD parallel arithmetic operation with secondary operation"
  },
  {
    "id": 17043,
    "content": "operand c , producing a result in d"
  },
  {
    "id": 17044,
    "content": "Syntax (predefined)"
  },
  {
    "id": 17045,
    "content": "sreg"
  },
  {
    "id": 17046,
    "content": "v4"
  },
  {
    "id": 17047,
    "content": "u32 %tid;   thread id vector"
  },
  {
    "id": 17048,
    "content": "sreg"
  },
  {
    "id": 17049,
    "content": "u32 %tid x, %tid y, %tid"
  },
  {
    "id": 17051,
    "content": "It is guaranteed that: 0 ;"
  },
  {
    "id": 17052,
    "content": "reg"
  },
  {
    "id": 17053,
    "content": "v4"
  },
  {
    "id": 17054,
    "content": "b32 %rx; mov"
  },
  {
    "id": 17055,
    "content": "u32 %r0, %clusterid"
  },
  {
    "id": 17056,
    "content": "x; mov"
  },
  {
    "id": 17057,
    "content": "u32 %r1, %clusterid"
  },
  {
    "id": 17058,
    "content": "z; mov"
  },
  {
    "id": 17059,
    "content": "v4"
  },
  {
    "id": 17060,
    "content": "u32 %rx, %clusterid; 10"
  },
  {
    "id": 17061,
    "content": "13"
  },
  {
    "id": 17062,
    "content": "Syntax (predefined)"
  },
  {
    "id": 17063,
    "content": "sreg"
  },
  {
    "id": 17064,
    "content": "v4"
  },
  {
    "id": 17065,
    "content": "u32 %nclusterid;"
  },
  {
    "id": 17066,
    "content": "sreg"
  },
  {
    "id": 17067,
    "content": "u32 %nclusterid x, %nclusterid y, %nclusterid"
  },
  {
    "id": 17069,
    "content": "Examples"
  },
  {
    "id": 17070,
    "content": "reg"
  },
  {
    "id": 17071,
    "content": "b32 %r;"
  },
  {
    "id": 17072,
    "content": "reg"
  },
  {
    "id": 17073,
    "content": "v4"
  },
  {
    "id": 17074,
    "content": "b32 %rx; mov"
  },
  {
    "id": 17075,
    "content": "u32 %r0, %nclusterid"
  },
  {
    "id": 17076,
    "content": "x; mov"
  },
  {
    "id": 17077,
    "content": "u32 %r1, %nclusterid"
  },
  {
    "id": 17078,
    "content": "z; mov"
  },
  {
    "id": 17079,
    "content": "v4"
  },
  {
    "id": 17080,
    "content": "u32 %rx, %nclusterid; 10"
  },
  {
    "id": 17081,
    "content": "14"
  },
  {
    "id": 17082,
    "content": "Syntax (predefined)"
  },
  {
    "id": 17083,
    "content": "sreg"
  },
  {
    "id": 17084,
    "content": "v4"
  },
  {
    "id": 17085,
    "content": "u32 %cluster_ctaid;"
  },
  {
    "id": 17086,
    "content": "sreg"
  },
  {
    "id": 17087,
    "content": "u32 %cluster_ctaid x, %cluster_ctaid y, %cluster_ctaid"
  },
  {
    "id": 17089,
    "content": "It is guaranteed that: 0 ;"
  },
  {
    "id": 17090,
    "content": "reg"
  },
  {
    "id": 17091,
    "content": "v4"
  },
  {
    "id": 17092,
    "content": "b32 %rx; mov"
  },
  {
    "id": 17093,
    "content": "u32 %r0, %cluster_ctaid"
  },
  {
    "id": 17094,
    "content": "x; mov"
  },
  {
    "id": 17095,
    "content": "u32 %r1, %cluster_ctaid"
  },
  {
    "id": 17096,
    "content": "z; mov"
  },
  {
    "id": 17097,
    "content": "v4"
  },
  {
    "id": 17098,
    "content": "u32 %rx, %cluster_ctaid; 10"
  },
  {
    "id": 17099,
    "content": "15"
  },
  {
    "id": 17100,
    "content": "Special Registers: %cluster_nctaid  %cluster_nctaid Number of CTA identifiers per cluster"
  },
  {
    "id": 17101,
    "content": "Syntax (predefined)"
  },
  {
    "id": 17102,
    "content": "sreg"
  },
  {
    "id": 17103,
    "content": "v4"
  },
  {
    "id": 17104,
    "content": "u32 %cluster_nctaid;"
  },
  {
    "id": 17105,
    "content": "sreg"
  },
  {
    "id": 17106,
    "content": "u32 %cluster_nctaid x, %cluster_nctaid y, %cluster_nctaid"
  },
  {
    "id": 17108,
    "content": "Examples"
  },
  {
    "id": 17109,
    "content": "reg"
  },
  {
    "id": 17110,
    "content": "b32 %r;"
  },
  {
    "id": 17111,
    "content": "reg"
  },
  {
    "id": 17112,
    "content": "v4"
  },
  {
    "id": 17113,
    "content": "b32 %rx; mov"
  },
  {
    "id": 17114,
    "content": "u32 %r0, %cluster_nctaid"
  },
  {
    "id": 17115,
    "content": "x; mov"
  },
  {
    "id": 17116,
    "content": "u32 %r1, %cluster_nctaid"
  },
  {
    "id": 17117,
    "content": "z; mov"
  },
  {
    "id": 17118,
    "content": "v4"
  },
  {
    "id": 17119,
    "content": "u32 %rx, %cluster_nctaid; 10"
  },
  {
    "id": 17120,
    "content": "16"
  },
  {
    "id": 17122,
    "content": "Syntax (predefined)"
  },
  {
    "id": 17123,
    "content": "sreg"
  },
  {
    "id": 17125,
    "content": "%pm7 are unsigned 32-bit read-only performance monitor counters"
  },
  {
    "id": 17126,
    "content": "Special Registers: %pm0_64 %pm7_64  %pm0_64 %pm7_64 64 bit Performance monitoring counters"
  },
  {
    "id": 17127,
    "content": "Syntax (predefined)"
  },
  {
    "id": 17128,
    "content": "sreg"
  },
  {
    "id": 17129,
    "content": "u64 %pm0_64;"
  },
  {
    "id": 17130,
    "content": "sreg"
  },
  {
    "id": 17131,
    "content": "u64 %pm1_64;"
  },
  {
    "id": 17132,
    "content": "sreg"
  },
  {
    "id": 17133,
    "content": "u64 %pm2_64;"
  },
  {
    "id": 17134,
    "content": "sreg"
  },
  {
    "id": 17135,
    "content": "u64 %pm3_64;"
  },
  {
    "id": 17136,
    "content": "sreg"
  },
  {
    "id": 17137,
    "content": "u64 %pm4_64;"
  },
  {
    "id": 17138,
    "content": "sreg"
  },
  {
    "id": 17139,
    "content": "u64 %pm5_64;"
  },
  {
    "id": 17140,
    "content": "sreg"
  },
  {
    "id": 17141,
    "content": "u64 %pm6_64;"
  },
  {
    "id": 17142,
    "content": "sreg"
  },
  {
    "id": 17144,
    "content": "Syntax (predefined)"
  },
  {
    "id": 17145,
    "content": "sreg"
  },
  {
    "id": 17149,
    "content": "Syntax (predefined)"
  },
  {
    "id": 17150,
    "content": "sreg"
  },
  {
    "id": 17151,
    "content": "u64 %globaltimer;"
  },
  {
    "id": 17152,
    "content": "sreg"
  },
  {
    "id": 17155,
    "content": "Syntax (predefined)"
  },
  {
    "id": 17156,
    "content": "sreg"
  },
  {
    "id": 17157,
    "content": "b32 %reserved_smem_offset_begin;"
  },
  {
    "id": 17158,
    "content": "sreg"
  },
  {
    "id": 17159,
    "content": "b32 %reserved_smem_offset_end;"
  },
  {
    "id": 17160,
    "content": "sreg"
  },
  {
    "id": 17161,
    "content": "b32 %reserved_smem_offset_cap;"
  },
  {
    "id": 17162,
    "content": "sreg"
  },
  {
    "id": 17164,
    "content": "Examples"
  },
  {
    "id": 17165,
    "content": "reg"
  },
  {
    "id": 17167,
    "content": "30"
  },
  {
    "id": 17169,
    "content": "Syntax (predefined)"
  },
  {
    "id": 17170,
    "content": "sreg"
  },
  {
    "id": 17173,
    "content": "1"
  },
  {
    "id": 17175,
    "content": "Syntax (predefined)"
  },
  {
    "id": 17176,
    "content": "sreg"
  },
  {
    "id": 17178,
    "content": "allocated dynamically at kernel launch"
  },
  {
    "id": 17179,
    "content": "Syntax (predefined)"
  },
  {
    "id": 17180,
    "content": "sreg"
  },
  {
    "id": 17183,
    "content": "Syntax (predefined)"
  },
  {
    "id": 17184,
    "content": "sreg"
  },
  {
    "id": 17187,
    "content": "Syntax"
  },
  {
    "id": 17190,
    "content": "version directive, and no other version directive is allowed anywhere else within the module"
  },
  {
    "id": 17191,
    "content": "Syntax"
  },
  {
    "id": 17196,
    "content": "Semantics Each PTX module must begin with a"
  },
  {
    "id": 17198,
    "content": "A"
  },
  {
    "id": 17200,
    "content": "A program with multiple"
  },
  {
    "id": 17203,
    "content": "f16 and"
  },
  {
    "id": 17204,
    "content": "f16x2 types"
  },
  {
    "id": 17205,
    "content": "The texturing mode is specified for an entire module and cannot be changed within the module The"
  },
  {
    "id": 17208,
    "content": "Note that"
  },
  {
    "id": 17209,
    "content": "f64 storage remains as 64-bits, with only half being used by instructions converted from f64 to"
  },
  {
    "id": 17210,
    "content": "f32"
  },
  {
    "id": 17211,
    "content": "Examples"
  },
  {
    "id": 17213,
    "content": "1"
  },
  {
    "id": 17214,
    "content": "3"
  },
  {
    "id": 17215,
    "content": "PTX Module Directives:"
  },
  {
    "id": 17216,
    "content": "address_size  address_size Address size used throughout PTX module"
  },
  {
    "id": 17217,
    "content": "Syntax"
  },
  {
    "id": 17220,
    "content": "Examples   example directives"
  },
  {
    "id": 17222,
    "content": "version 2"
  },
  {
    "id": 17223,
    "content": "3"
  },
  {
    "id": 17224,
    "content": "target sm_20"
  },
  {
    "id": 17225,
    "content": "address_size 64"
  },
  {
    "id": 17226,
    "content": "entry foo () {"
  },
  {
    "id": 17227,
    "content": "} 11"
  },
  {
    "id": 17228,
    "content": "2"
  },
  {
    "id": 17230,
    "content": "Syntax"
  },
  {
    "id": 17232,
    "content": "Parameters are passed via"
  },
  {
    "id": 17233,
    "content": "param space memory and are listed within an optional parenthesized parameter list"
  },
  {
    "id": 17234,
    "content": "Parameters may be referenced by name within the kernel body and loaded into registers using ld"
  },
  {
    "id": 17235,
    "content": "param{::entry} instructions"
  },
  {
    "id": 17236,
    "content": "In addition to normal parameters, opaque"
  },
  {
    "id": 17237,
    "content": "texref ,"
  },
  {
    "id": 17238,
    "content": "samplerref , and"
  },
  {
    "id": 17239,
    "content": "surfref variables may be passed as parameters"
  },
  {
    "id": 17241,
    "content": "param instructions"
  },
  {
    "id": 17243,
    "content": "g"
  },
  {
    "id": 17244,
    "content": ", %ntid , %nctaid , etc"
  },
  {
    "id": 17245,
    "content": "PTX ISA Notes For PTX ISA version 1"
  },
  {
    "id": 17246,
    "content": "4 and later, parameter variables are declared in the kernel parameter list"
  },
  {
    "id": 17247,
    "content": "For PTX ISA versions 1"
  },
  {
    "id": 17248,
    "content": "0 through 1"
  },
  {
    "id": 17249,
    "content": "3, parameter variables are declared in the kernel body"
  },
  {
    "id": 17252,
    "content": "Examples"
  },
  {
    "id": 17253,
    "content": "entry cta_fft entry filter ("
  },
  {
    "id": 17254,
    "content": "param"
  },
  {
    "id": 17255,
    "content": "b32 x,"
  },
  {
    "id": 17256,
    "content": "param"
  },
  {
    "id": 17257,
    "content": "b32 y,"
  },
  {
    "id": 17258,
    "content": "param"
  },
  {
    "id": 17259,
    "content": "b32 z ) {"
  },
  {
    "id": 17260,
    "content": "reg"
  },
  {
    "id": 17261,
    "content": "b32 %r; ld"
  },
  {
    "id": 17262,
    "content": "param"
  },
  {
    "id": 17263,
    "content": "b32 %r1, [x]; ld"
  },
  {
    "id": 17264,
    "content": "param"
  },
  {
    "id": 17265,
    "content": "b32 %r2, [y]; ld"
  },
  {
    "id": 17266,
    "content": "param"
  },
  {
    "id": 17267,
    "content": "b32 %r3, [z];"
  },
  {
    "id": 17268,
    "content": "}"
  },
  {
    "id": 17269,
    "content": "entry prefix_sum ("
  },
  {
    "id": 17270,
    "content": "param"
  },
  {
    "id": 17271,
    "content": "align 4"
  },
  {
    "id": 17272,
    "content": "s32 pitch[8000] ) {"
  },
  {
    "id": 17273,
    "content": "reg"
  },
  {
    "id": 17274,
    "content": "s32 %t; ld"
  },
  {
    "id": 17275,
    "content": "param::entry"
  },
  {
    "id": 17276,
    "content": "s32 %t, [pitch];"
  },
  {
    "id": 17277,
    "content": "} 11"
  },
  {
    "id": 17278,
    "content": "2"
  },
  {
    "id": 17279,
    "content": "2"
  },
  {
    "id": 17280,
    "content": "Kernel and Function Directives:"
  },
  {
    "id": 17281,
    "content": "func  func Function definition"
  },
  {
    "id": 17282,
    "content": "Syntax"
  },
  {
    "id": 17283,
    "content": "func {"
  },
  {
    "id": 17284,
    "content": "attribute(attr-list)} fname {"
  },
  {
    "id": 17285,
    "content": "noreturn} function-body"
  },
  {
    "id": 17286,
    "content": "func {"
  },
  {
    "id": 17287,
    "content": "attribute(attr-list)} fname (param-list) {"
  },
  {
    "id": 17288,
    "content": "noreturn} function-body"
  },
  {
    "id": 17289,
    "content": "func {"
  },
  {
    "id": 17292,
    "content": "b8 with no size specified"
  },
  {
    "id": 17296,
    "content": "Release Notes For PTX ISA version 1"
  },
  {
    "id": 17297,
    "content": "x code, parameters must be in the register state space, there is no stack, and recursion is illegal"
  },
  {
    "id": 17298,
    "content": "PTX ISA versions 2"
  },
  {
    "id": 17299,
    "content": "0 and later with target sm_20 or higher allow parameters in the"
  },
  {
    "id": 17300,
    "content": "param state space, implements an ABI with stack, and supports recursion"
  },
  {
    "id": 17301,
    "content": "PTX ISA versions 2"
  },
  {
    "id": 17303,
    "content": "Examples"
  },
  {
    "id": 17304,
    "content": "func ("
  },
  {
    "id": 17305,
    "content": "reg"
  },
  {
    "id": 17306,
    "content": "b32 rval) foo ("
  },
  {
    "id": 17307,
    "content": "reg"
  },
  {
    "id": 17308,
    "content": "b32 N,"
  },
  {
    "id": 17309,
    "content": "reg"
  },
  {
    "id": 17310,
    "content": "f64 dbl) {"
  },
  {
    "id": 17311,
    "content": "reg"
  },
  {
    "id": 17312,
    "content": "b32 localVar;"
  },
  {
    "id": 17313,
    "content": "func ("
  },
  {
    "id": 17314,
    "content": "param"
  },
  {
    "id": 17315,
    "content": "u32 rval) bar("
  },
  {
    "id": 17316,
    "content": "param"
  },
  {
    "id": 17317,
    "content": "u32 N,"
  },
  {
    "id": 17318,
    "content": "param"
  },
  {
    "id": 17319,
    "content": "align 4"
  },
  {
    "id": 17320,
    "content": "b8 numbers[]) {"
  },
  {
    "id": 17321,
    "content": "reg"
  },
  {
    "id": 17322,
    "content": "b32 input0, input1; ld"
  },
  {
    "id": 17323,
    "content": "param"
  },
  {
    "id": 17324,
    "content": "b32 input0, [numbers + 0]; ld"
  },
  {
    "id": 17325,
    "content": "param"
  },
  {
    "id": 17326,
    "content": "b32 input1, [numbers + 4];"
  },
  {
    "id": 17327,
    "content": "param"
  },
  {
    "id": 17328,
    "content": "u32 N;"
  },
  {
    "id": 17329,
    "content": "param"
  },
  {
    "id": 17330,
    "content": "align 4"
  },
  {
    "id": 17331,
    "content": "b8 numbers[8]; st"
  },
  {
    "id": 17332,
    "content": "param"
  },
  {
    "id": 17333,
    "content": "u32 [N], 2; st"
  },
  {
    "id": 17334,
    "content": "param"
  },
  {
    "id": 17335,
    "content": "b32 [numbers + 0], 5; st"
  },
  {
    "id": 17336,
    "content": "param"
  },
  {
    "id": 17337,
    "content": "b32 [numbers + 4], 10; call (rval), bar, (N, numbers);"
  },
  {
    "id": 17338,
    "content": "11"
  },
  {
    "id": 17339,
    "content": "2"
  },
  {
    "id": 17340,
    "content": "3"
  },
  {
    "id": 17341,
    "content": "Kernel and Function Directives:"
  },
  {
    "id": 17342,
    "content": "alias  alias Define an alias to existing function symbol"
  },
  {
    "id": 17343,
    "content": "Syntax"
  },
  {
    "id": 17345,
    "content": "param"
  },
  {
    "id": 17346,
    "content": "u32 p; call bar, (p);   call foo through alias }"
  },
  {
    "id": 17347,
    "content": "entry filter ("
  },
  {
    "id": 17348,
    "content": "param"
  },
  {
    "id": 17349,
    "content": "b32 x,"
  },
  {
    "id": 17350,
    "content": "param"
  },
  {
    "id": 17351,
    "content": "b32 y,"
  },
  {
    "id": 17352,
    "content": "param"
  },
  {
    "id": 17353,
    "content": "b32 z ) {"
  },
  {
    "id": 17354,
    "content": "reg"
  },
  {
    "id": 17355,
    "content": "b32 %r1, %r2, %r3; ld"
  },
  {
    "id": 17356,
    "content": "param"
  },
  {
    "id": 17357,
    "content": "b32 %r1, [x]; ld"
  },
  {
    "id": 17358,
    "content": "param"
  },
  {
    "id": 17359,
    "content": "b32 %r2, [y]; ld"
  },
  {
    "id": 17360,
    "content": "param"
  },
  {
    "id": 17361,
    "content": "b32 %r3, [z];"
  },
  {
    "id": 17362,
    "content": "} 11"
  },
  {
    "id": 17363,
    "content": "3"
  },
  {
    "id": 17364,
    "content": "Control Flow Directives  PTX provides directives for specifying potential targets for brx"
  },
  {
    "id": 17365,
    "content": "idx and call instructions"
  },
  {
    "id": 17366,
    "content": "Control Flow Directives:"
  },
  {
    "id": 17367,
    "content": "branchtargets  branchtargets Declare a list of potential branch targets"
  },
  {
    "id": 17368,
    "content": "Syntax Label:"
  },
  {
    "id": 17370,
    "content": "syntax described in Parameterized Variable Names"
  },
  {
    "id": 17371,
    "content": "ts:"
  },
  {
    "id": 17372,
    "content": "branchtargets N; @p brx"
  },
  {
    "id": 17373,
    "content": "idx %r0, ts;"
  },
  {
    "id": 17374,
    "content": "11"
  },
  {
    "id": 17375,
    "content": "3"
  },
  {
    "id": 17376,
    "content": "2"
  },
  {
    "id": 17377,
    "content": "Control Flow Directives:"
  },
  {
    "id": 17378,
    "content": "calltargets  calltargets Declare a list of potential call targets"
  },
  {
    "id": 17380,
    "content": "@p call (%f1), %r0, (%x), calltgt;"
  },
  {
    "id": 17381,
    "content": "11"
  },
  {
    "id": 17382,
    "content": "3"
  },
  {
    "id": 17383,
    "content": "3"
  },
  {
    "id": 17384,
    "content": "Control Flow Directives:"
  },
  {
    "id": 17385,
    "content": "callprototype  callprototype Declare a prototype for use in an indirect call"
  },
  {
    "id": 17386,
    "content": "Syntax   no input or return parameters label:"
  },
  {
    "id": 17387,
    "content": "callprototype _"
  },
  {
    "id": 17388,
    "content": "noreturn;   input params, no return params label:"
  },
  {
    "id": 17389,
    "content": "callprototype _ (param-list)"
  },
  {
    "id": 17392,
    "content": "Examples Fproto1:"
  },
  {
    "id": 17393,
    "content": "callprototype _ ; Fproto2: callprototype _ ("
  },
  {
    "id": 17394,
    "content": "param"
  },
  {
    "id": 17395,
    "content": "f32 _); Fproto3:"
  },
  {
    "id": 17396,
    "content": "callprototype ("
  },
  {
    "id": 17397,
    "content": "param"
  },
  {
    "id": 17398,
    "content": "u32 _) _ ; Fproto4:"
  },
  {
    "id": 17399,
    "content": "callprototype ("
  },
  {
    "id": 17400,
    "content": "param"
  },
  {
    "id": 17401,
    "content": "u32 _) _ ("
  },
  {
    "id": 17402,
    "content": "param"
  },
  {
    "id": 17403,
    "content": "f32 _);"
  },
  {
    "id": 17404,
    "content": "example of array parameter Fproto5:"
  },
  {
    "id": 17405,
    "content": "callprototype _ ("
  },
  {
    "id": 17406,
    "content": "param"
  },
  {
    "id": 17407,
    "content": "b8 _[12]); Fproto6:"
  },
  {
    "id": 17408,
    "content": "callprototype _ ("
  },
  {
    "id": 17409,
    "content": "param"
  },
  {
    "id": 17410,
    "content": "f32 _)"
  },
  {
    "id": 17411,
    "content": "noreturn;"
  },
  {
    "id": 17412,
    "content": "@p call %r0, (%f1), Fproto6;"
  },
  {
    "id": 17413,
    "content": "11"
  },
  {
    "id": 17414,
    "content": "4"
  },
  {
    "id": 17416,
    "content": "maxnreg"
  },
  {
    "id": 17417,
    "content": "maxntid"
  },
  {
    "id": 17418,
    "content": "reqntid"
  },
  {
    "id": 17419,
    "content": "minnctapersm"
  },
  {
    "id": 17420,
    "content": "maxnctapersm (deprecated)"
  },
  {
    "id": 17421,
    "content": "pragma The"
  },
  {
    "id": 17423,
    "content": "These can be used, for example, to throttle the resource requirements (e"
  },
  {
    "id": 17424,
    "content": "g"
  },
  {
    "id": 17426,
    "content": "The"
  },
  {
    "id": 17427,
    "content": "minnctapersm directive can be used together with either the"
  },
  {
    "id": 17428,
    "content": "maxntid or"
  },
  {
    "id": 17430,
    "content": "Currently, the"
  },
  {
    "id": 17431,
    "content": "maxnreg ,"
  },
  {
    "id": 17432,
    "content": "maxntid ,"
  },
  {
    "id": 17433,
    "content": "reqntid , and"
  },
  {
    "id": 17437,
    "content": "The interpretation of"
  },
  {
    "id": 17438,
    "content": "pragma values is determined by the backend implementation and is beyond the scope of the PTX ISA"
  },
  {
    "id": 17439,
    "content": "Note that"
  },
  {
    "id": 17441,
    "content": "11"
  },
  {
    "id": 17442,
    "content": "4"
  },
  {
    "id": 17443,
    "content": "1"
  },
  {
    "id": 17444,
    "content": "Performance-Tuning Directives:"
  },
  {
    "id": 17445,
    "content": "maxnreg  maxnreg Maximum number of registers that can be allocated per thread"
  },
  {
    "id": 17446,
    "content": "Syntax"
  },
  {
    "id": 17448,
    "content": "maxntid and"
  },
  {
    "id": 17449,
    "content": "maxctapersm"
  },
  {
    "id": 17450,
    "content": "Performance-Tuning Directives:"
  },
  {
    "id": 17451,
    "content": "maxntid  maxntid Maximum number of threads in the thread block (CTA)"
  },
  {
    "id": 17452,
    "content": "Syntax"
  },
  {
    "id": 17455,
    "content": "Performance-Tuning Directives:"
  },
  {
    "id": 17456,
    "content": "reqntid  reqntid Number of threads in the thread block (CTA)"
  },
  {
    "id": 17457,
    "content": "Syntax"
  },
  {
    "id": 17459,
    "content": "error or kernel launch failure"
  },
  {
    "id": 17460,
    "content": "Performance-Tuning Directives:"
  },
  {
    "id": 17461,
    "content": "minnctapersm  minnctapersm Minimum number of CTAs per SM"
  },
  {
    "id": 17462,
    "content": "Syntax"
  },
  {
    "id": 17464,
    "content": "Notes Optimizations based on"
  },
  {
    "id": 17465,
    "content": "minnctapersm need either"
  },
  {
    "id": 17466,
    "content": "maxntid or"
  },
  {
    "id": 17467,
    "content": "reqntid to be specified as well"
  },
  {
    "id": 17468,
    "content": "If the total number of threads on a single SM resulting from"
  },
  {
    "id": 17469,
    "content": "minnctapersm and"
  },
  {
    "id": 17470,
    "content": "maxntid /"
  },
  {
    "id": 17471,
    "content": "reqntid exceed maximum number of threads supported by an SM then directive"
  },
  {
    "id": 17472,
    "content": "minnctapersm will be ignored"
  },
  {
    "id": 17473,
    "content": "In PTX ISA version 2"
  },
  {
    "id": 17474,
    "content": "1 or higher, a warning is generated if"
  },
  {
    "id": 17475,
    "content": "minnctapersm is specified without specifying either"
  },
  {
    "id": 17476,
    "content": "maxntid or"
  },
  {
    "id": 17477,
    "content": "reqntid"
  },
  {
    "id": 17478,
    "content": "Examples"
  },
  {
    "id": 17479,
    "content": "entry foo"
  },
  {
    "id": 17480,
    "content": "maxntid 256"
  },
  {
    "id": 17481,
    "content": "minnctapersm 4 {"
  },
  {
    "id": 17482,
    "content": "} 11"
  },
  {
    "id": 17483,
    "content": "4"
  },
  {
    "id": 17484,
    "content": "5"
  },
  {
    "id": 17485,
    "content": "Performance-Tuning Directives:"
  },
  {
    "id": 17486,
    "content": "maxnctapersm (deprecated)  maxnctapersm Maximum number of CTAs per SM"
  },
  {
    "id": 17487,
    "content": "Syntax"
  },
  {
    "id": 17489,
    "content": "Notes Optimizations based on"
  },
  {
    "id": 17490,
    "content": "maxnctapersm generally need"
  },
  {
    "id": 17491,
    "content": "maxntid to be specified as well"
  },
  {
    "id": 17492,
    "content": "The optimizing backend compiler uses"
  },
  {
    "id": 17493,
    "content": "maxntid and"
  },
  {
    "id": 17495,
    "content": "Examples"
  },
  {
    "id": 17496,
    "content": "entry foo"
  },
  {
    "id": 17497,
    "content": "maxntid 256"
  },
  {
    "id": 17498,
    "content": "maxnctapersm 4 {"
  },
  {
    "id": 17499,
    "content": "} 11"
  },
  {
    "id": 17500,
    "content": "4"
  },
  {
    "id": 17501,
    "content": "6"
  },
  {
    "id": 17502,
    "content": "Performance-Tuning Directives:"
  },
  {
    "id": 17503,
    "content": "noreturn  noreturn Indicate that the function does not return to its caller function"
  },
  {
    "id": 17504,
    "content": "Syntax"
  },
  {
    "id": 17505,
    "content": "noreturn Description Indicate that the function does not return to its caller function"
  },
  {
    "id": 17506,
    "content": "Semantics An optional"
  },
  {
    "id": 17508,
    "content": "Examples"
  },
  {
    "id": 17509,
    "content": "func foo"
  },
  {
    "id": 17510,
    "content": "noreturn {"
  },
  {
    "id": 17511,
    "content": "} 11"
  },
  {
    "id": 17512,
    "content": "4"
  },
  {
    "id": 17513,
    "content": "7"
  },
  {
    "id": 17514,
    "content": "Performance-Tuning Directives:"
  },
  {
    "id": 17515,
    "content": "pragma  pragma Pass directives to PTX backend compiler"
  },
  {
    "id": 17516,
    "content": "Syntax"
  },
  {
    "id": 17519,
    "content": "See Descriptions of pragma Strings for descriptions of the pragma strings defined in ptxas"
  },
  {
    "id": 17520,
    "content": "Examples"
  },
  {
    "id": 17521,
    "content": "pragma \"nounroll\";   disable unrolling in backend   disable unrolling for current kernel"
  },
  {
    "id": 17522,
    "content": "entry foo"
  },
  {
    "id": 17523,
    "content": "pragma \"nounroll\"; {"
  },
  {
    "id": 17524,
    "content": "} 11"
  },
  {
    "id": 17525,
    "content": "5"
  },
  {
    "id": 17527,
    "content": "section"
  },
  {
    "id": 17528,
    "content": "file"
  },
  {
    "id": 17529,
    "content": "loc The"
  },
  {
    "id": 17530,
    "content": "section directive was introduced in PTX ISA version 2"
  },
  {
    "id": 17532,
    "content": "x code"
  },
  {
    "id": 17533,
    "content": "Beginning with PTX ISA version 3"
  },
  {
    "id": 17534,
    "content": "0, PTX files containing DWARF debug information should include the target debug platform option"
  },
  {
    "id": 17535,
    "content": "This forward declaration directs PTX compilation to retain mappings for source-level debugging"
  },
  {
    "id": 17536,
    "content": "11"
  },
  {
    "id": 17537,
    "content": "5"
  },
  {
    "id": 17538,
    "content": "1"
  },
  {
    "id": 17541,
    "content": "2^32-1]"
  },
  {
    "id": 17542,
    "content": "quad int64-list   comma-separated hexadecimal integers in range [0"
  },
  {
    "id": 17543,
    "content": "2^64-1]"
  },
  {
    "id": 17544,
    "content": "4byte label quad label PTX ISA Notes Introduced in PTX ISA version 1"
  },
  {
    "id": 17545,
    "content": "2"
  },
  {
    "id": 17546,
    "content": "Examples @@DWARF"
  },
  {
    "id": 17547,
    "content": "section"
  },
  {
    "id": 17548,
    "content": "debug_pubnames, \"\", @progbits @@DWARF"
  },
  {
    "id": 17549,
    "content": "byte 0x2b, 0x00, 0x00, 0x00, 0x02, 0x00 @@DWARF"
  },
  {
    "id": 17550,
    "content": "4byte"
  },
  {
    "id": 17552,
    "content": "byte 0x00, 0x00, 0x00, 0x00, 0x00 11"
  },
  {
    "id": 17553,
    "content": "5"
  },
  {
    "id": 17554,
    "content": "2"
  },
  {
    "id": 17555,
    "content": "Examples"
  },
  {
    "id": 17556,
    "content": "section"
  },
  {
    "id": 17557,
    "content": "debug_pubnames {"
  },
  {
    "id": 17558,
    "content": "b32 LpubNames_end0-LpubNames_begin0 LpubNames_begin0:"
  },
  {
    "id": 17559,
    "content": "b8 0x2b, 0x00, 0x00, 0x00, 0x02, 0x00"
  },
  {
    "id": 17560,
    "content": "b32"
  },
  {
    "id": 17561,
    "content": "debug_info info_label1:"
  },
  {
    "id": 17562,
    "content": "b32 0x000006b5, 0x00000364, 0x61395a5f, 0x5f736f63"
  },
  {
    "id": 17563,
    "content": "b32 0x6e69616d, 0x63613031, 0x6150736f, 0x736d6172"
  },
  {
    "id": 17564,
    "content": "b8 0x00, 0x00, 0x00, 0x00, 0x00 LpubNames_end0: }"
  },
  {
    "id": 17565,
    "content": "section"
  },
  {
    "id": 17566,
    "content": "debug_info {"
  },
  {
    "id": 17567,
    "content": "b32 11430"
  },
  {
    "id": 17568,
    "content": "b8 2, 0"
  },
  {
    "id": 17569,
    "content": "b32"
  },
  {
    "id": 17570,
    "content": "debug_abbrev"
  },
  {
    "id": 17571,
    "content": "b8 8, 1, 108, 103, 101, 110, 102, 101, 58, 32, 69, 68, 71, 32, 52, 46, 49 b8 0"
  },
  {
    "id": 17572,
    "content": "b32 3, 37, 176, -99 b32 info_label1 b32"
  },
  {
    "id": 17573,
    "content": "debug_loc+0x4"
  },
  {
    "id": 17574,
    "content": "b8 -11, 11, 112, 97"
  },
  {
    "id": 17575,
    "content": "b32 info_label1+12"
  },
  {
    "id": 17576,
    "content": "b64 -1"
  },
  {
    "id": 17577,
    "content": "b16 -5, -65535 } 11"
  },
  {
    "id": 17578,
    "content": "5"
  },
  {
    "id": 17579,
    "content": "3"
  },
  {
    "id": 17580,
    "content": "Syntax"
  },
  {
    "id": 17582,
    "content": "The"
  },
  {
    "id": 17583,
    "content": "file directive is allowed only in the outermost scope, i"
  },
  {
    "id": 17584,
    "content": "e"
  },
  {
    "id": 17585,
    "content": ", at the same level as kernel and device function declarations"
  },
  {
    "id": 17586,
    "content": "Examples"
  },
  {
    "id": 17587,
    "content": "file 1 \"example"
  },
  {
    "id": 17588,
    "content": "cu\""
  },
  {
    "id": 17589,
    "content": "file 2 \"kernel"
  },
  {
    "id": 17590,
    "content": "cu\""
  },
  {
    "id": 17591,
    "content": "file 1 “kernel"
  },
  {
    "id": 17592,
    "content": "cu”, 1339013327, 64118 11"
  },
  {
    "id": 17593,
    "content": "5"
  },
  {
    "id": 17594,
    "content": "4"
  },
  {
    "id": 17595,
    "content": "Syntax"
  },
  {
    "id": 17598,
    "content": "inlined_at can be specified as part of the"
  },
  {
    "id": 17599,
    "content": "loc directive"
  },
  {
    "id": 17601,
    "content": "Offset is specified as label expression or label + immediate expression where label is defined in"
  },
  {
    "id": 17604,
    "content": "Examples"
  },
  {
    "id": 17606,
    "content": "global"
  },
  {
    "id": 17607,
    "content": "u32 %r1, [gg];   Function at line 9 setp"
  },
  {
    "id": 17608,
    "content": "lt"
  },
  {
    "id": 17609,
    "content": "s32 %p1, %r1, 8;   inlined at line 21"
  },
  {
    "id": 17611,
    "content": "ne"
  },
  {
    "id": 17612,
    "content": "s32 %p2, %r1, 18; @%p2 bra BB2_3;"
  },
  {
    "id": 17613,
    "content": "section"
  },
  {
    "id": 17614,
    "content": "debug_str { info_string0:"
  },
  {
    "id": 17616,
    "content": "6"
  },
  {
    "id": 17617,
    "content": "Syntax"
  },
  {
    "id": 17619,
    "content": "weak or"
  },
  {
    "id": 17620,
    "content": "visible only once in a single object file"
  },
  {
    "id": 17624,
    "content": "Syntax"
  },
  {
    "id": 17626,
    "content": "that common symbol from different object files"
  },
  {
    "id": 17627,
    "content": "Cluster Dimension Directives  The following directives specify information about clusters:"
  },
  {
    "id": 17628,
    "content": "reqnctapercluster"
  },
  {
    "id": 17629,
    "content": "explicitcluster"
  },
  {
    "id": 17630,
    "content": "maxclusterrank The"
  },
  {
    "id": 17632,
    "content": "11"
  },
  {
    "id": 17633,
    "content": "7"
  },
  {
    "id": 17634,
    "content": "1"
  },
  {
    "id": 17635,
    "content": "Cluster Dimension Directives:"
  },
  {
    "id": 17636,
    "content": "reqnctapercluster  reqnctapercluster Declare the number of CTAs in the cluster"
  },
  {
    "id": 17637,
    "content": "Syntax"
  },
  {
    "id": 17639,
    "content": "For kernels with"
  },
  {
    "id": 17641,
    "content": "Examples"
  },
  {
    "id": 17642,
    "content": "entry foo"
  },
  {
    "id": 17643,
    "content": "reqnctapercluster 2 {"
  },
  {
    "id": 17644,
    "content": "}"
  },
  {
    "id": 17645,
    "content": "entry bar"
  },
  {
    "id": 17646,
    "content": "reqnctapercluster 2, 2, 1 {"
  },
  {
    "id": 17647,
    "content": "entry ker"
  },
  {
    "id": 17648,
    "content": "reqnctapercluster 3, 2 {"
  },
  {
    "id": 17649,
    "content": "11"
  },
  {
    "id": 17650,
    "content": "7"
  },
  {
    "id": 17651,
    "content": "2"
  },
  {
    "id": 17652,
    "content": "Cluster Dimension Directives:"
  },
  {
    "id": 17654,
    "content": "Syntax"
  },
  {
    "id": 17656,
    "content": "Semantics Kernels with"
  },
  {
    "id": 17658,
    "content": "reqnctapercluster ), otherwise program will fail with runtime error or kernel launch failure"
  },
  {
    "id": 17659,
    "content": "Examples"
  },
  {
    "id": 17660,
    "content": "entry foo"
  },
  {
    "id": 17661,
    "content": "explicitcluster {"
  },
  {
    "id": 17662,
    "content": "11"
  },
  {
    "id": 17663,
    "content": "7"
  },
  {
    "id": 17664,
    "content": "3"
  },
  {
    "id": 17665,
    "content": "Cluster Dimension Directives:"
  },
  {
    "id": 17666,
    "content": "maxclusterrank  maxclusterrank Declare the maximum number of CTAs that can be part of the cluster"
  },
  {
    "id": 17667,
    "content": "Syntax"
  },
  {
    "id": 17669,
    "content": "Examples"
  },
  {
    "id": 17670,
    "content": "entry foo"
  },
  {
    "id": 17671,
    "content": "maxclusterrank 8 {"
  },
  {
    "id": 17672,
    "content": "12"
  },
  {
    "id": 17674,
    "content": "0"
  },
  {
    "id": 17676,
    "content": "sp::ordered_metadata instruction"
  },
  {
    "id": 17678,
    "content": "sp are invalid and their usage results in undefined behavior"
  },
  {
    "id": 17679,
    "content": "12"
  },
  {
    "id": 17680,
    "content": "2"
  },
  {
    "id": 17682,
    "content": "b128 type to support"
  },
  {
    "id": 17683,
    "content": "sys scope"
  },
  {
    "id": 17684,
    "content": "Extends integer wgmma"
  },
  {
    "id": 17685,
    "content": "mma_async instruction to support"
  },
  {
    "id": 17686,
    "content": "u8"
  },
  {
    "id": 17687,
    "content": "s8 and s8"
  },
  {
    "id": 17688,
    "content": "u8 as"
  },
  {
    "id": 17689,
    "content": "atype and"
  },
  {
    "id": 17690,
    "content": "btype respectively"
  },
  {
    "id": 17691,
    "content": "Semantic Changes and Clarifications None"
  },
  {
    "id": 17692,
    "content": "12"
  },
  {
    "id": 17693,
    "content": "3"
  },
  {
    "id": 17695,
    "content": "Extends isspacep , cvta"
  },
  {
    "id": 17696,
    "content": "to , ld and st instructions to accept ::entry and ::func sub-qualifiers with"
  },
  {
    "id": 17697,
    "content": "param state space qualifier"
  },
  {
    "id": 17698,
    "content": "Add support for instructions tensormap replace , tensormap cp_fenceproxy and support for qualifier"
  },
  {
    "id": 17699,
    "content": "to_proxykind::from_proxykind on instruction fence"
  },
  {
    "id": 17700,
    "content": "proxy to support modifying tensor-map"
  },
  {
    "id": 17701,
    "content": "12"
  },
  {
    "id": 17702,
    "content": "4"
  },
  {
    "id": 17704,
    "content": "mmio qualifier on ld and st instructions"
  },
  {
    "id": 17705,
    "content": "Extends multimem"
  },
  {
    "id": 17706,
    "content": "ld_reduce instruction to support"
  },
  {
    "id": 17707,
    "content": "acc::f32 qualifer to allow"
  },
  {
    "id": 17708,
    "content": "f32 precision of the intermediate accumulation"
  },
  {
    "id": 17709,
    "content": "Extends the asynchronous warpgroup-level matrix multiply-and-accumulate operation wgmma"
  },
  {
    "id": 17710,
    "content": "mma_async to support"
  },
  {
    "id": 17711,
    "content": "sp modifier that allows matrix multiply-accumulate operation when input matrix A is sparse"
  },
  {
    "id": 17712,
    "content": "Semantic Changes and Clarifications The"
  },
  {
    "id": 17713,
    "content": "multicast::cluster qualifier on cp"
  },
  {
    "id": 17714,
    "content": "async"
  },
  {
    "id": 17715,
    "content": "bulk and cp"
  },
  {
    "id": 17716,
    "content": "async"
  },
  {
    "id": 17717,
    "content": "bulk"
  },
  {
    "id": 17719,
    "content": "12"
  },
  {
    "id": 17720,
    "content": "5"
  },
  {
    "id": 17723,
    "content": "Adds support for"
  },
  {
    "id": 17724,
    "content": "satfinite saturation modifer on cvt instruction for"
  },
  {
    "id": 17725,
    "content": "f16 ,"
  },
  {
    "id": 17726,
    "content": "bf16 and"
  },
  {
    "id": 17727,
    "content": "tf32 formats"
  },
  {
    "id": 17729,
    "content": "12"
  },
  {
    "id": 17730,
    "content": "6"
  },
  {
    "id": 17733,
    "content": "Extends integer arithmetic instruction add to allow packed integer types"
  },
  {
    "id": 17734,
    "content": "u16x2 and"
  },
  {
    "id": 17735,
    "content": "s16x2"
  },
  {
    "id": 17736,
    "content": "Extends integer arithmetic instructions min and max to allow packed integer types"
  },
  {
    "id": 17737,
    "content": "u16x2 and"
  },
  {
    "id": 17738,
    "content": "s16x2 , as well as saturation modifier"
  },
  {
    "id": 17739,
    "content": "relu on"
  },
  {
    "id": 17740,
    "content": "s16x2 and"
  },
  {
    "id": 17741,
    "content": "s32 types"
  },
  {
    "id": 17743,
    "content": "Extends the fence instruction to allow opcode-specific synchronizaion using op_restrict qualifier"
  },
  {
    "id": 17744,
    "content": "Adds support for"
  },
  {
    "id": 17745,
    "content": "cluster scope on mbarrier arrive , mbarrier arrive_drop , mbarrier test_wait and mbarrier"
  },
  {
    "id": 17747,
    "content": "expect_tx and"
  },
  {
    "id": 17748,
    "content": "complete_tx qualifiers"
  },
  {
    "id": 17749,
    "content": "12"
  },
  {
    "id": 17750,
    "content": "7"
  },
  {
    "id": 17752,
    "content": "Extends the"
  },
  {
    "id": 17753,
    "content": "f64 floating point type mma operation with shapes"
  },
  {
    "id": 17754,
    "content": "m16n8k4 ,"
  },
  {
    "id": 17755,
    "content": "m16n8k8 , and"
  },
  {
    "id": 17756,
    "content": "m16n8k16"
  },
  {
    "id": 17759,
    "content": "cluster which is a set of Cooperative Thread Arrays (CTAs)"
  },
  {
    "id": 17760,
    "content": "Adds support for extended visibility of shared state space to all threads within a cluster"
  },
  {
    "id": 17761,
    "content": "Extends"
  },
  {
    "id": 17764,
    "content": "reqnctapercluster ,"
  },
  {
    "id": 17765,
    "content": "explicitcluster , and"
  },
  {
    "id": 17766,
    "content": "maxclusterrank"
  },
  {
    "id": 17767,
    "content": "12"
  },
  {
    "id": 17768,
    "content": "8"
  },
  {
    "id": 17770,
    "content": "param state space for kernel function parameters"
  },
  {
    "id": 17771,
    "content": "12"
  },
  {
    "id": 17772,
    "content": "9"
  },
  {
    "id": 17775,
    "content": "12"
  },
  {
    "id": 17776,
    "content": "10"
  },
  {
    "id": 17778,
    "content": "section debugging directive"
  },
  {
    "id": 17780,
    "content": "Support for new fence"
  },
  {
    "id": 17782,
    "content": "12"
  },
  {
    "id": 17783,
    "content": "11"
  },
  {
    "id": 17785,
    "content": "level::eviction_priority qualifier which allows specifying cache eviction priority hints on ld , ld"
  },
  {
    "id": 17786,
    "content": "global"
  },
  {
    "id": 17787,
    "content": "nc , st , and prefetch instructions"
  },
  {
    "id": 17788,
    "content": "Support for"
  },
  {
    "id": 17789,
    "content": "level::prefetch_size qualifier which allows specifying data prefetch hints on ld and cp"
  },
  {
    "id": 17790,
    "content": "async instructions"
  },
  {
    "id": 17792,
    "content": "global"
  },
  {
    "id": 17793,
    "content": "nc , st , atom , red and cp"
  },
  {
    "id": 17794,
    "content": "async instructions"
  },
  {
    "id": 17795,
    "content": "Support for applypriority and discard operations on cached data"
  },
  {
    "id": 17796,
    "content": "12 12"
  },
  {
    "id": 17799,
    "content": "3"
  },
  {
    "id": 17800,
    "content": "12"
  },
  {
    "id": 17801,
    "content": "13"
  },
  {
    "id": 17803,
    "content": "loc directive to represent inline function information"
  },
  {
    "id": 17804,
    "content": "Extends min and max instructions to support"
  },
  {
    "id": 17805,
    "content": "xorsign and"
  },
  {
    "id": 17806,
    "content": "abs modifiers"
  },
  {
    "id": 17807,
    "content": "12"
  },
  {
    "id": 17808,
    "content": "14"
  },
  {
    "id": 17812,
    "content": "sp modifier that allows matrix multiply-accumulate operation when input matrix A is sparse"
  },
  {
    "id": 17813,
    "content": "Extends mbarrier"
  },
  {
    "id": 17814,
    "content": "test_wait instruction to test the completion of specific phase parity"
  },
  {
    "id": 17815,
    "content": "12"
  },
  {
    "id": 17816,
    "content": "15"
  },
  {
    "id": 17819,
    "content": "sync instruction which allows reduction operation across threads in a warp"
  },
  {
    "id": 17820,
    "content": "Extends mma instruction to support new shapes"
  },
  {
    "id": 17821,
    "content": "m8n8k128 ,"
  },
  {
    "id": 17822,
    "content": "m16n8k4 ,"
  },
  {
    "id": 17823,
    "content": "m16n8k16 ,"
  },
  {
    "id": 17824,
    "content": "m16n8k32 ,"
  },
  {
    "id": 17825,
    "content": "m16n8k64 ,"
  },
  {
    "id": 17826,
    "content": "m16n8k128 and"
  },
  {
    "id": 17827,
    "content": "m16n8k256"
  },
  {
    "id": 17828,
    "content": "Extends min and max instructions to support"
  },
  {
    "id": 17829,
    "content": "NaN modifier and"
  },
  {
    "id": 17830,
    "content": "f16 ,"
  },
  {
    "id": 17831,
    "content": "f16x2 ,"
  },
  {
    "id": 17832,
    "content": "bf16 and"
  },
  {
    "id": 17833,
    "content": "bf16x2 data formats"
  },
  {
    "id": 17834,
    "content": "Extends fma instruction to support"
  },
  {
    "id": 17835,
    "content": "relu saturation mode and"
  },
  {
    "id": 17836,
    "content": "bf16 and"
  },
  {
    "id": 17837,
    "content": "bf16x2 data formats"
  },
  {
    "id": 17838,
    "content": "Extends cvt instruction to support"
  },
  {
    "id": 17839,
    "content": "relu saturation mode and"
  },
  {
    "id": 17840,
    "content": "f16 ,"
  },
  {
    "id": 17841,
    "content": "f16x2 ,"
  },
  {
    "id": 17842,
    "content": "bf16 ,"
  },
  {
    "id": 17843,
    "content": "bf16x2 and"
  },
  {
    "id": 17844,
    "content": "tf32 destination formats"
  },
  {
    "id": 17845,
    "content": "Extends ex2 instruction to support"
  },
  {
    "id": 17846,
    "content": "f16 and"
  },
  {
    "id": 17847,
    "content": "f16x2 types"
  },
  {
    "id": 17848,
    "content": "12"
  },
  {
    "id": 17849,
    "content": "16"
  },
  {
    "id": 17851,
    "content": "pack instruction which allows converting two integer values and packing the results together"
  },
  {
    "id": 17853,
    "content": "Removed Features PTX ISA version 6 5 removes the following features: Support for"
  },
  {
    "id": 17854,
    "content": "satfinite qualifier on floating point wmma"
  },
  {
    "id": 17855,
    "content": "mma instruction has been removed"
  },
  {
    "id": 17856,
    "content": "This support was deprecated since PTX ISA version 6"
  },
  {
    "id": 17857,
    "content": "4"
  },
  {
    "id": 17858,
    "content": "12"
  },
  {
    "id": 17859,
    "content": "17"
  },
  {
    "id": 17861,
    "content": "noreturn directive which can be used to indicate a function does not return to it’s caller function"
  },
  {
    "id": 17862,
    "content": "Adds support for mma instruction which allows performing matrix multiply-and-accumulate operation"
  },
  {
    "id": 17863,
    "content": "Deprecated Features PTX ISA version 6 4 deprecates the following features: Support for"
  },
  {
    "id": 17864,
    "content": "satfinite qualifier on floating point wmma"
  },
  {
    "id": 17865,
    "content": "mma instruction"
  },
  {
    "id": 17866,
    "content": "Removed Features PTX ISA version 6"
  },
  {
    "id": 17867,
    "content": "4 removes the following features: Support for shfl and vote instructions without the"
  },
  {
    "id": 17868,
    "content": "sync qualifier has been removed for"
  },
  {
    "id": 17869,
    "content": "target sm_70 and higher"
  },
  {
    "id": 17870,
    "content": "This support was deprecated since PTX ISA version 6 0 as documented in PTX ISA version 6"
  },
  {
    "id": 17871,
    "content": "2"
  },
  {
    "id": 17872,
    "content": "Semantic Changes and Clarifications Clarified that resolving references of a"
  },
  {
    "id": 17873,
    "content": "weak symbol considers only weak or"
  },
  {
    "id": 17874,
    "content": "visible symbols with the same name and does not consider local symbols with the same name"
  },
  {
    "id": 17875,
    "content": "Clarified that in cvt instruction, modifier"
  },
  {
    "id": 17876,
    "content": "ftz can only be specified when either"
  },
  {
    "id": 17877,
    "content": "atype or"
  },
  {
    "id": 17878,
    "content": "dtype is"
  },
  {
    "id": 17879,
    "content": "f32"
  },
  {
    "id": 17880,
    "content": "12"
  },
  {
    "id": 17881,
    "content": "18"
  },
  {
    "id": 17883,
    "content": "The wmma instructions are extended to support multiplicand matrices of type"
  },
  {
    "id": 17884,
    "content": "s8 ,"
  },
  {
    "id": 17885,
    "content": "u8 ,"
  },
  {
    "id": 17886,
    "content": "s4 ,"
  },
  {
    "id": 17887,
    "content": "u4 ,"
  },
  {
    "id": 17888,
    "content": "b1 and accumulator matrices of type"
  },
  {
    "id": 17889,
    "content": "s32"
  },
  {
    "id": 17890,
    "content": "Semantic Changes and Clarifications Introduced the mandatory"
  },
  {
    "id": 17892,
    "content": "store"
  },
  {
    "id": 17895,
    "content": "12"
  },
  {
    "id": 17896,
    "content": "19"
  },
  {
    "id": 17898,
    "content": "Extends atomic and reduction instructions to perform"
  },
  {
    "id": 17899,
    "content": "f16x2 addition operation with mandatory"
  },
  {
    "id": 17900,
    "content": "noftz qualifier"
  },
  {
    "id": 17901,
    "content": "Deprecated Features PTX ISA version 6"
  },
  {
    "id": 17902,
    "content": "2 deprecates the following features: The use of shfl and vote instructions without the"
  },
  {
    "id": 17903,
    "content": "sync is deprecated retrospectively from PTX ISA version 6"
  },
  {
    "id": 17904,
    "content": "0, which introduced the sm_70 architecture that implements Independent Thread Scheduling"
  },
  {
    "id": 17907,
    "content": "12"
  },
  {
    "id": 17908,
    "content": "20"
  },
  {
    "id": 17910,
    "content": "12"
  },
  {
    "id": 17911,
    "content": "21"
  },
  {
    "id": 17916,
    "content": "A new instruction match"
  },
  {
    "id": 17917,
    "content": "sync which allows broadcasting and comparing a value across threads in warp"
  },
  {
    "id": 17918,
    "content": "A new instruction brx"
  },
  {
    "id": 17919,
    "content": "idx which allows branching to a label indexed from list of potential targets"
  },
  {
    "id": 17920,
    "content": "Support for unsized array parameter for"
  },
  {
    "id": 17921,
    "content": "func which can be used to implement variadic functions"
  },
  {
    "id": 17923,
    "content": "Support for indirect branch introduced in PTX 2"
  },
  {
    "id": 17925,
    "content": "12"
  },
  {
    "id": 17926,
    "content": "22"
  },
  {
    "id": 17930,
    "content": "12"
  },
  {
    "id": 17931,
    "content": "23"
  },
  {
    "id": 17934,
    "content": "12"
  },
  {
    "id": 17935,
    "content": "24"
  },
  {
    "id": 17938,
    "content": "param and st param instructions used for argument passing cannot be predicated"
  },
  {
    "id": 17939,
    "content": "Semantics of {atom/red}"
  },
  {
    "id": 17940,
    "content": "add"
  },
  {
    "id": 17942,
    "content": "12"
  },
  {
    "id": 17943,
    "content": "25"
  },
  {
    "id": 17945,
    "content": "Support for special registers %total_smem_size and %dynamic_smem_size"
  },
  {
    "id": 17946,
    "content": "12"
  },
  {
    "id": 17947,
    "content": "26"
  },
  {
    "id": 17949,
    "content": "approx"
  },
  {
    "id": 17950,
    "content": "ftz"
  },
  {
    "id": 17951,
    "content": "f64 has been added to compute a fast approximation of the square root reciprocal of a value"
  },
  {
    "id": 17953,
    "content": "ballot"
  },
  {
    "id": 17954,
    "content": "b32"
  },
  {
    "id": 17955,
    "content": "12"
  },
  {
    "id": 17956,
    "content": "27"
  },
  {
    "id": 17959,
    "content": "12"
  },
  {
    "id": 17960,
    "content": "28"
  },
  {
    "id": 17964,
    "content": "global or"
  },
  {
    "id": 17965,
    "content": "const variables used in initializers"
  },
  {
    "id": 17966,
    "content": "A new"
  },
  {
    "id": 17967,
    "content": "weak directive to permit linking multiple object files containing declarations of the same symbol"
  },
  {
    "id": 17968,
    "content": "Semantic Changes and Clarifications PTX 3"
  },
  {
    "id": 17970,
    "content": "Instruction mad"
  },
  {
    "id": 17971,
    "content": "f32 requires a rounding modifier for sm_20 and higher targets"
  },
  {
    "id": 17972,
    "content": "12"
  },
  {
    "id": 17973,
    "content": "29"
  },
  {
    "id": 17975,
    "content": "Platform option"
  },
  {
    "id": 17976,
    "content": "target debug to declare that a PTX module contains DWARF debug information"
  },
  {
    "id": 17978,
    "content": "PTX ISA version 3"
  },
  {
    "id": 17979,
    "content": "0 deprecates module-scoped"
  },
  {
    "id": 17980,
    "content": "reg and"
  },
  {
    "id": 17981,
    "content": "local variables when compiling to the Application Binary Interface (ABI)"
  },
  {
    "id": 17983,
    "content": "{u32,s32,f32} have been removed"
  },
  {
    "id": 17984,
    "content": "12"
  },
  {
    "id": 17985,
    "content": "30"
  },
  {
    "id": 17986,
    "content": "Changes in PTX ISA Version 2 3  New Features PTX 2"
  },
  {
    "id": 17987,
    "content": "3 adds support for texture arrays"
  },
  {
    "id": 17989,
    "content": "Semantic Changes and Clarifications The semantics of the"
  },
  {
    "id": 17990,
    "content": "maxntid directive have been updated to match the current implementation"
  },
  {
    "id": 17991,
    "content": "Specifically,"
  },
  {
    "id": 17994,
    "content": "255"
  },
  {
    "id": 17995,
    "content": "{min,max}"
  },
  {
    "id": 17996,
    "content": "f32 have been removed"
  },
  {
    "id": 17997,
    "content": "12"
  },
  {
    "id": 17998,
    "content": "31"
  },
  {
    "id": 17999,
    "content": "Changes in PTX ISA Version 2 2  New Features PTX 2"
  },
  {
    "id": 18002,
    "content": "PTX 2"
  },
  {
    "id": 18003,
    "content": "2 deprecates explicit constant banks and supports a large, flat address space for the"
  },
  {
    "id": 18004,
    "content": "const state space"
  },
  {
    "id": 18005,
    "content": "PTX 2"
  },
  {
    "id": 18008,
    "content": "12"
  },
  {
    "id": 18009,
    "content": "32"
  },
  {
    "id": 18011,
    "content": "1 for sm_2x targets"
  },
  {
    "id": 18012,
    "content": "New directives,"
  },
  {
    "id": 18013,
    "content": "branchtargets and"
  },
  {
    "id": 18015,
    "content": "A"
  },
  {
    "id": 18017,
    "content": "The names of"
  },
  {
    "id": 18018,
    "content": "global and"
  },
  {
    "id": 18019,
    "content": "const variables can now be specified in variable initializers to represent their addresses"
  },
  {
    "id": 18020,
    "content": "A set of thirty-two driver-specific execution environment special registers has been added"
  },
  {
    "id": 18022,
    "content": "A new instruction, rcp"
  },
  {
    "id": 18023,
    "content": "approx"
  },
  {
    "id": 18024,
    "content": "ftz"
  },
  {
    "id": 18025,
    "content": "f64 , has been added to compute a fast, gross approximate reciprocal"
  },
  {
    "id": 18026,
    "content": "Semantic Changes and Clarifications A warning is emitted if"
  },
  {
    "id": 18027,
    "content": "minnctapersm is specified without also specifying"
  },
  {
    "id": 18028,
    "content": "maxntid"
  },
  {
    "id": 18029,
    "content": "12"
  },
  {
    "id": 18030,
    "content": "33"
  },
  {
    "id": 18032,
    "content": "0 for sm_20 targets"
  },
  {
    "id": 18034,
    "content": "x code and sm_1x targets"
  },
  {
    "id": 18035,
    "content": "The changes from PTX ISA version 1"
  },
  {
    "id": 18037,
    "content": "rm and"
  },
  {
    "id": 18039,
    "content": "The mad"
  },
  {
    "id": 18040,
    "content": "f32 instruction has been extended with rounding modifiers so that it’s synonymous with fma"
  },
  {
    "id": 18041,
    "content": "f32 for sm_20 targets"
  },
  {
    "id": 18042,
    "content": "The mad"
  },
  {
    "id": 18043,
    "content": "f32 instruction without rounding is retained so that compilers can generate code for sm_1x targets"
  },
  {
    "id": 18044,
    "content": "Single- and double-precision div , rcp , and sqrt with IEEE 754 compliant rounding have been added"
  },
  {
    "id": 18045,
    "content": "Instructions {atom,red}"
  },
  {
    "id": 18048,
    "content": "g"
  },
  {
    "id": 18049,
    "content": ", for prefetching to specified level of memory hierarchy"
  },
  {
    "id": 18050,
    "content": "The"
  },
  {
    "id": 18051,
    "content": "maxnctapersm directive was deprecated and replaced with"
  },
  {
    "id": 18052,
    "content": "minnctapersm to better match its behavior and usage"
  },
  {
    "id": 18053,
    "content": "A new directive,"
  },
  {
    "id": 18055,
    "content": "A new directive,"
  },
  {
    "id": 18056,
    "content": "pragma nounroll , has been added to allow users to disable loop unrolling"
  },
  {
    "id": 18057,
    "content": "Semantic Changes and Clarifications The errata in cvt"
  },
  {
    "id": 18058,
    "content": "ftz for PTX ISA versions 1"
  },
  {
    "id": 18060,
    "content": "In PTX ISA version 1"
  },
  {
    "id": 18061,
    "content": "5 and later, cvt ftz (and cvt for"
  },
  {
    "id": 18062,
    "content": "target sm_1x , where"
  },
  {
    "id": 18064,
    "content": "To maintain compatibility with legacy PTX code, if"
  },
  {
    "id": 18065,
    "content": "version is 1"
  },
  {
    "id": 18069,
    "content": "5; the correct number is sixteen"
  },
  {
    "id": 18070,
    "content": "14"
  },
  {
    "id": 18071,
    "content": "Descriptions of"
  },
  {
    "id": 18072,
    "content": "pragma Strings  This section describes the pragma strings defined by ptxas"
  },
  {
    "id": 18073,
    "content": "14"
  },
  {
    "id": 18074,
    "content": "1"
  },
  {
    "id": 18075,
    "content": "Pragma Strings: “nounroll”  “nounroll” Disable loop unrolling in optimizing the backend compiler"
  },
  {
    "id": 18076,
    "content": "Syntax"
  },
  {
    "id": 18079,
    "content": "appearing outside of loop header blocks are silently ignored"
  },
  {
    "id": 18080,
    "content": "Examples"
  },
  {
    "id": 18081,
    "content": "entry foo ("
  },
  {
    "id": 18082,
    "content": ")"
  },
  {
    "id": 18083,
    "content": "pragma \"nounroll\";   do not unroll any loop in this function {"
  },
  {
    "id": 18084,
    "content": "L1_continue: bra L1_head; L1_end:"
  },
  {
    "id": 18085,
    "content": "} 14"
  },
  {
    "id": 18086,
    "content": "2"
  },
  {
    "id": 18088,
    "content": "Syntax"
  },
  {
    "id": 18091,
    "content": "global"
  },
  {
    "id": 18093,
    "content": "pragma \"used_bytes_mask 0xfff\"; ld"
  },
  {
    "id": 18094,
    "content": "global"
  },
  {
    "id": 18095,
    "content": "v4"
  },
  {
    "id": 18096,
    "content": "u32 {%r0, %r1, %r2, %r3}, [gbl];   %r3 unused PTX ISA Notes Introduced in PTX ISA version 8"
  },
  {
    "id": 18097,
    "content": "3"
  },
  {
    "id": 18098,
    "content": "Examples"
  },
  {
    "id": 18099,
    "content": "pragma \"used_bytes_mask 0xfff\"; ld"
  },
  {
    "id": 18100,
    "content": "global"
  },
  {
    "id": 18101,
    "content": "v4"
  },
  {
    "id": 18102,
    "content": "u32 {%r0, %r1, %r2, %r3}, [gbl];   Only lower 12 bytes used 15"
  },
  {
    "id": 18105,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 18117,
    "content": "15"
  },
  {
    "id": 18118,
    "content": "2"
  },
  {
    "id": 18119,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 18120,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 18121,
    "content": "15"
  },
  {
    "id": 18122,
    "content": "3"
  },
  {
    "id": 18124,
    "content": "S"
  },
  {
    "id": 18127,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 18128,
    "content": "Navigation"
  },
  {
    "id": 18129,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 18130,
    "content": "pageBottom();}\n1"
  },
  {
    "id": 18131,
    "content": "Introduction v12"
  },
  {
    "id": 18133,
    "content": "PTX is a low-level parallel-thread-execution virtual machine and ISA (Instruction Set Architecture)"
  },
  {
    "id": 18135,
    "content": "For more information on PTX, refer to the latest version of the PTX ISA reference document"
  },
  {
    "id": 18137,
    "content": "2"
  },
  {
    "id": 18138,
    "content": "Data Representation  2"
  },
  {
    "id": 18139,
    "content": "1"
  },
  {
    "id": 18141,
    "content": "address_size directive that specifies the address size used throughout the PTX code"
  },
  {
    "id": 18142,
    "content": "PTX Type Size (bytes) Align (bytes) Hardware Representation"
  },
  {
    "id": 18144,
    "content": "f16 2 2 IEEE half precision f32 4 4 IEEE single precision f64 8 8 IEEE double precision 2"
  },
  {
    "id": 18145,
    "content": "2"
  },
  {
    "id": 18149,
    "content": "This may require tail padding, depending on the last member"
  },
  {
    "id": 18150,
    "content": "2"
  },
  {
    "id": 18151,
    "content": "3"
  },
  {
    "id": 18154,
    "content": "assumes little-endian layout"
  },
  {
    "id": 18160,
    "content": "4"
  },
  {
    "id": 18163,
    "content": "texref or"
  },
  {
    "id": 18164,
    "content": "samplerref type and surfaces are expressed by the"
  },
  {
    "id": 18165,
    "content": "surfref type"
  },
  {
    "id": 18166,
    "content": "The data of opaque objects can be accessed by specific instructions (TEX for"
  },
  {
    "id": 18167,
    "content": "texref/"
  },
  {
    "id": 18168,
    "content": "samplerref and SULD/SUST for"
  },
  {
    "id": 18169,
    "content": "surfref)"
  },
  {
    "id": 18171,
    "content": "known during compile time all information required to read data and attributes is contained in a"
  },
  {
    "id": 18172,
    "content": "b64 value called the handle"
  },
  {
    "id": 18174,
    "content": "3"
  },
  {
    "id": 18177,
    "content": "0 or greater must be used"
  },
  {
    "id": 18178,
    "content": "3"
  },
  {
    "id": 18179,
    "content": "1"
  },
  {
    "id": 18181,
    "content": "3"
  },
  {
    "id": 18182,
    "content": "2"
  },
  {
    "id": 18184,
    "content": "3"
  },
  {
    "id": 18185,
    "content": "3"
  },
  {
    "id": 18187,
    "content": "param)"
  },
  {
    "id": 18189,
    "content": "u32 (if unsigned) or"
  },
  {
    "id": 18190,
    "content": "s32 (if signed) Integral types 64"
  },
  {
    "id": 18191,
    "content": "u64 (if unsigned) or"
  },
  {
    "id": 18193,
    "content": "f64 Aggregates or unions Any size"
  },
  {
    "id": 18195,
    "content": "Handles (E) 64"
  },
  {
    "id": 18196,
    "content": "b64 (assigned from"
  },
  {
    "id": 18197,
    "content": "texref,"
  },
  {
    "id": 18198,
    "content": "sampleref,"
  },
  {
    "id": 18202,
    "content": "more information on handles"
  },
  {
    "id": 18203,
    "content": "4"
  },
  {
    "id": 18204,
    "content": "System Calls  System calls are calls into the driver operating system code"
  },
  {
    "id": 18207,
    "content": "malloc and free functions defined in “malloc"
  },
  {
    "id": 18208,
    "content": "h”"
  },
  {
    "id": 18210,
    "content": "h”"
  },
  {
    "id": 18211,
    "content": "5"
  },
  {
    "id": 18212,
    "content": "Debug Information  Debug information is encoded in DWARF (Debug With Arbitrary Record Format)"
  },
  {
    "id": 18213,
    "content": "5"
  },
  {
    "id": 18214,
    "content": "1"
  },
  {
    "id": 18216,
    "content": "section and"
  },
  {
    "id": 18217,
    "content": "b8-"
  },
  {
    "id": 18218,
    "content": "b16-"
  },
  {
    "id": 18219,
    "content": "b32-and-"
  },
  {
    "id": 18220,
    "content": "b64 directives in PTX"
  },
  {
    "id": 18221,
    "content": "This should contain the"
  },
  {
    "id": 18222,
    "content": "debug_info and"
  },
  {
    "id": 18223,
    "content": "debug_abbrev sections, and possibly optional sections"
  },
  {
    "id": 18224,
    "content": "debug_pubnames and"
  },
  {
    "id": 18225,
    "content": "debug_aranges"
  },
  {
    "id": 18226,
    "content": "These sections are standard DWARF2 sections that refer to labels and registers in the PTX"
  },
  {
    "id": 18227,
    "content": "The PTX-to-SASS backend is responsible for generating the"
  },
  {
    "id": 18228,
    "content": "debug_line section from the"
  },
  {
    "id": 18229,
    "content": "file and loc directives in the PTX file"
  },
  {
    "id": 18230,
    "content": "The backend also generates the"
  },
  {
    "id": 18231,
    "content": "debug_frame section"
  },
  {
    "id": 18232,
    "content": "5"
  },
  {
    "id": 18233,
    "content": "2"
  },
  {
    "id": 18236,
    "content": "11 Texture sampler storage ADDR_generic_space 12 Generic-address storage 6"
  },
  {
    "id": 18238,
    "content": "b8 8 , 1 , 108 , 103 , 101 , 110 , 102 , 101 , 58 , 32 , 69 , 68 , 71 , 32 , 52 , 46 , 57"
  },
  {
    "id": 18241,
    "content": "e"
  },
  {
    "id": 18245,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 18257,
    "content": "8"
  },
  {
    "id": 18258,
    "content": "2"
  },
  {
    "id": 18259,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 18260,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 18261,
    "content": "8"
  },
  {
    "id": 18262,
    "content": "3"
  },
  {
    "id": 18264,
    "content": "S"
  },
  {
    "id": 18267,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 18268,
    "content": "Navigation"
  },
  {
    "id": 18269,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 18270,
    "content": "pageBottom();}\n1"
  },
  {
    "id": 18273,
    "content": "1"
  },
  {
    "id": 18274,
    "content": "1"
  },
  {
    "id": 18276,
    "content": "1"
  },
  {
    "id": 18277,
    "content": "1"
  },
  {
    "id": 18278,
    "content": "1"
  },
  {
    "id": 18282,
    "content": "g"
  },
  {
    "id": 18283,
    "content": ": asm ( \"mov"
  },
  {
    "id": 18284,
    "content": "s32 %0, 2;\" : \"=r\" ( i )); If there is no output operand, the colon separators are adjacent, e"
  },
  {
    "id": 18285,
    "content": "g"
  },
  {
    "id": 18286,
    "content": ": asm ( \"mov"
  },
  {
    "id": 18288,
    "content": "g"
  },
  {
    "id": 18289,
    "content": ": asm ( \"mov"
  },
  {
    "id": 18292,
    "content": "So the earlier example asm() statement: asm ( \"add"
  },
  {
    "id": 18294,
    "content": "There is also available a “+” modifier that specifies the register is both read and written, e"
  },
  {
    "id": 18295,
    "content": "g"
  },
  {
    "id": 18299,
    "content": "For example, a cube routine could be written as: __device__ int cube ( int x ) { int y ; asm ( \""
  },
  {
    "id": 18300,
    "content": "reg u32 t1;  \\t \"   temp reg t1 \" mul"
  },
  {
    "id": 18301,
    "content": "lo"
  },
  {
    "id": 18302,
    "content": "u32 t1, %1, %1;  \\t \"   t1 = x * x \" mul"
  },
  {
    "id": 18303,
    "content": "lo"
  },
  {
    "id": 18305,
    "content": "For example, __device__ int cond ( int x ) { int y = 0 ; asm ( \"{  \\t \" \""
  },
  {
    "id": 18306,
    "content": "reg"
  },
  {
    "id": 18307,
    "content": "pred %p;  \\t \" \" setp"
  },
  {
    "id": 18308,
    "content": "eq"
  },
  {
    "id": 18309,
    "content": "s32 %p, %1, 34;  \\t \"   x == 34"
  },
  {
    "id": 18310,
    "content": "\" @%p mov"
  },
  {
    "id": 18311,
    "content": "s32 %0, 1;  \\t \"   set y to 1 if true \"}\"   conceptually y = (x==34)"
  },
  {
    "id": 18312,
    "content": "1:y : \"+r\" ( y ) : \"r\" ( x )); return y ; } 1"
  },
  {
    "id": 18313,
    "content": "1"
  },
  {
    "id": 18314,
    "content": "2"
  },
  {
    "id": 18320,
    "content": "(terms in italics are C++ standard terms and/or terms from the GNU inline asm specification)"
  },
  {
    "id": 18324,
    "content": "1"
  },
  {
    "id": 18325,
    "content": "2"
  },
  {
    "id": 18327,
    "content": "1"
  },
  {
    "id": 18328,
    "content": "2"
  },
  {
    "id": 18329,
    "content": "1"
  },
  {
    "id": 18331,
    "content": "g"
  },
  {
    "id": 18332,
    "content": ": __device__ int cube ( int x ) { int y ; asm ( \"{  \\t \"   use braces for local scope \" reg"
  },
  {
    "id": 18333,
    "content": "u32 t1;  \\t \"   temp reg t1, \" mul"
  },
  {
    "id": 18334,
    "content": "lo"
  },
  {
    "id": 18335,
    "content": "u32 t1, %1, %1;  \\t \"   t1 = x * x \" mul"
  },
  {
    "id": 18336,
    "content": "lo"
  },
  {
    "id": 18338,
    "content": "1"
  },
  {
    "id": 18339,
    "content": "2"
  },
  {
    "id": 18340,
    "content": "2"
  },
  {
    "id": 18342,
    "content": "For sm_20 and greater, any pointer argument to an asm() statement is passed as a generic address"
  },
  {
    "id": 18343,
    "content": "1"
  },
  {
    "id": 18344,
    "content": "2"
  },
  {
    "id": 18345,
    "content": "3"
  },
  {
    "id": 18348,
    "content": "g"
  },
  {
    "id": 18349,
    "content": ": asm volatile ( \"mov"
  },
  {
    "id": 18351,
    "content": "colon, e"
  },
  {
    "id": 18352,
    "content": "g"
  },
  {
    "id": 18354,
    "content": "2"
  },
  {
    "id": 18355,
    "content": "4"
  },
  {
    "id": 18357,
    "content": "For example, if you pass a value with an “r” constraint but use it in an add"
  },
  {
    "id": 18358,
    "content": "f64 you will get a parse error from ptxas"
  },
  {
    "id": 18359,
    "content": "For example, in asm ( \"mov"
  },
  {
    "id": 18361,
    "content": "Refer to the document nvcc"
  },
  {
    "id": 18362,
    "content": "pdf for further compiler related details"
  },
  {
    "id": 18363,
    "content": "1"
  },
  {
    "id": 18364,
    "content": "3"
  },
  {
    "id": 18366,
    "content": "g"
  },
  {
    "id": 18372,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 18384,
    "content": "2"
  },
  {
    "id": 18385,
    "content": "2"
  },
  {
    "id": 18386,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 18387,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 18388,
    "content": "2"
  },
  {
    "id": 18389,
    "content": "3"
  },
  {
    "id": 18391,
    "content": "S"
  },
  {
    "id": 18394,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 18395,
    "content": "Navigation"
  },
  {
    "id": 18396,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 18398,
    "content": "5"
  },
  {
    "id": 18399,
    "content": "1 CUDA Runtime API 1 Deprecated List Search Results CUDA Runtime API ( PDF ) - v12"
  },
  {
    "id": 18400,
    "content": "5"
  },
  {
    "id": 18401,
    "content": "1 ( older ) - Last updated July 1, 2024 - Send Feedback Table of Contents 1"
  },
  {
    "id": 18405,
    "content": "5"
  },
  {
    "id": 18406,
    "content": "1 CUDA Driver API 1 Deprecated List Search Results CUDA Driver API ( PDF ) - v12"
  },
  {
    "id": 18407,
    "content": "5"
  },
  {
    "id": 18408,
    "content": "1 ( older ) - Last updated July 1, 2024 - Send Feedback Table of Contents 1"
  },
  {
    "id": 18411,
    "content": "pageBottom();\n1"
  },
  {
    "id": 18413,
    "content": "functions, not available with the host compilers, are implemented in crt/math_functions"
  },
  {
    "id": 18414,
    "content": "hpp header file"
  },
  {
    "id": 18415,
    "content": "Other, less common functions, like rhypot() , cyl_bessel_i0() are only available in device code"
  },
  {
    "id": 18420,
    "content": "Introduction v12"
  },
  {
    "id": 18422,
    "content": "It allows the user to access the computational resources of NVIDIA Graphics Processing Unit (GPU)"
  },
  {
    "id": 18429,
    "content": "1"
  },
  {
    "id": 18430,
    "content": "1"
  },
  {
    "id": 18437,
    "content": "2"
  },
  {
    "id": 18442,
    "content": "This change removes these unnecessary wrappers around cudaMalloc() and cudaFree() , respectively"
  },
  {
    "id": 18445,
    "content": "h"
  },
  {
    "id": 18447,
    "content": "h and cublas_v2"
  },
  {
    "id": 18448,
    "content": "h header files will lead to compilation errors due to incompatible symbol redeclarations"
  },
  {
    "id": 18450,
    "content": "interfaces to the legacy and the cuBLAS library APIs are the header file cublas"
  },
  {
    "id": 18451,
    "content": "h and cublas_v2"
  },
  {
    "id": 18452,
    "content": "h , respectively"
  },
  {
    "id": 18454,
    "content": "dylib for Mac OS X"
  },
  {
    "id": 18455,
    "content": "Note The same dynamic library implements both the new and legacy cuBLAS APIs"
  },
  {
    "id": 18456,
    "content": "1"
  },
  {
    "id": 18457,
    "content": "3"
  },
  {
    "id": 18458,
    "content": "Example Code  For sample code references please see the two examples below"
  },
  {
    "id": 18461,
    "content": "2"
  },
  {
    "id": 18462,
    "content": "1"
  },
  {
    "id": 18463,
    "content": "5"
  },
  {
    "id": 18470,
    "content": "2"
  },
  {
    "id": 18471,
    "content": "1"
  },
  {
    "id": 18472,
    "content": "6"
  },
  {
    "id": 18476,
    "content": "2"
  },
  {
    "id": 18477,
    "content": "1"
  },
  {
    "id": 18478,
    "content": "7"
  },
  {
    "id": 18483,
    "content": "This will ensure that when possible the different computations will be executed concurrently"
  },
  {
    "id": 18485,
    "content": "2"
  },
  {
    "id": 18486,
    "content": "1"
  },
  {
    "id": 18487,
    "content": "8"
  },
  {
    "id": 18490,
    "content": "2"
  },
  {
    "id": 18491,
    "content": "1"
  },
  {
    "id": 18492,
    "content": "9"
  },
  {
    "id": 18493,
    "content": "Static Library Support  The cuBLAS Library is also delivered in a static form as libcublas_static"
  },
  {
    "id": 18494,
    "content": "a on Linux"
  },
  {
    "id": 18496,
    "content": "a"
  },
  {
    "id": 18501,
    "content": "Starting with release 11"
  },
  {
    "id": 18503,
    "content": "2"
  },
  {
    "id": 18504,
    "content": "1"
  },
  {
    "id": 18505,
    "content": "10"
  },
  {
    "id": 18508,
    "content": "type"
  },
  {
    "id": 18511,
    "content": "1"
  },
  {
    "id": 18512,
    "content": "11"
  },
  {
    "id": 18513,
    "content": "Tensor Core Usage  Tensor cores were first introduced with Volta GPUs (compute capability 7"
  },
  {
    "id": 18514,
    "content": "0 and above) and significantly accelerate matrix multiplications"
  },
  {
    "id": 18515,
    "content": "Starting with cuBLAS version 11"
  },
  {
    "id": 18516,
    "content": "0"
  },
  {
    "id": 18520,
    "content": "dimensions and pointers meet the optimal requirements listed above"
  },
  {
    "id": 18522,
    "content": "0"
  },
  {
    "id": 18523,
    "content": "0)"
  },
  {
    "id": 18524,
    "content": "2"
  },
  {
    "id": 18525,
    "content": "1"
  },
  {
    "id": 18526,
    "content": "12"
  },
  {
    "id": 18531,
    "content": "To avoid this issue, use the cublasSetWorkspace() function to provide user-owned workspace memory"
  },
  {
    "id": 18532,
    "content": "2"
  },
  {
    "id": 18533,
    "content": "1"
  },
  {
    "id": 18534,
    "content": "13"
  },
  {
    "id": 18536,
    "content": "For instance, cublasSetMathMode() doesn’t have any arguments that could meaningfully be int64_t"
  },
  {
    "id": 18538,
    "content": "2"
  },
  {
    "id": 18539,
    "content": "2"
  },
  {
    "id": 18540,
    "content": "cuBLAS Datatypes Reference  2"
  },
  {
    "id": 18541,
    "content": "2"
  },
  {
    "id": 18542,
    "content": "1"
  },
  {
    "id": 18544,
    "content": "2"
  },
  {
    "id": 18545,
    "content": "2"
  },
  {
    "id": 18546,
    "content": "2"
  },
  {
    "id": 18547,
    "content": "cublasStatus_t  The type is used for function status returns"
  },
  {
    "id": 18549,
    "content": "allocated memory as much as possible"
  },
  {
    "id": 18552,
    "content": "0"
  },
  {
    "id": 18553,
    "content": "To correct: compile and run the application on a device with appropriate compute capability"
  },
  {
    "id": 18557,
    "content": "2"
  },
  {
    "id": 18558,
    "content": "2"
  },
  {
    "id": 18559,
    "content": "3"
  },
  {
    "id": 18562,
    "content": "2"
  },
  {
    "id": 18563,
    "content": "2"
  },
  {
    "id": 18564,
    "content": "4"
  },
  {
    "id": 18566,
    "content": "2"
  },
  {
    "id": 18567,
    "content": "2"
  },
  {
    "id": 18568,
    "content": "5"
  },
  {
    "id": 18571,
    "content": "2"
  },
  {
    "id": 18572,
    "content": "2"
  },
  {
    "id": 18573,
    "content": "6"
  },
  {
    "id": 18576,
    "content": "CUBLAS_SIDE_RIGHT The matrix is on the right side in the equation"
  },
  {
    "id": 18577,
    "content": "2"
  },
  {
    "id": 18578,
    "content": "2"
  },
  {
    "id": 18579,
    "content": "7"
  },
  {
    "id": 18583,
    "content": "CUBLAS_POINTER_MODE_DEVICE The scalars are passed by reference on the device"
  },
  {
    "id": 18584,
    "content": "2"
  },
  {
    "id": 18585,
    "content": "2"
  },
  {
    "id": 18586,
    "content": "8"
  },
  {
    "id": 18588,
    "content": "2"
  },
  {
    "id": 18589,
    "content": "2"
  },
  {
    "id": 18590,
    "content": "9"
  },
  {
    "id": 18595,
    "content": "Allows use of reduced precision CUBLAS_COMPUTE_32F_FAST_16F kernels (for backward compatibility)"
  },
  {
    "id": 18596,
    "content": "2"
  },
  {
    "id": 18597,
    "content": "2"
  },
  {
    "id": 18598,
    "content": "10"
  },
  {
    "id": 18603,
    "content": "CUBLAS_TF32_TENSOR_OP_MATH Enable acceleration of single-precision routines using TF32 tensor cores"
  },
  {
    "id": 18605,
    "content": "This is a flag that can be set (using a bitwise or operation) alongside any of the other values"
  },
  {
    "id": 18606,
    "content": "CUBLAS_TENSOR_OP_MATH [DEPRECATED] This mode is deprecated and will be removed in a future release"
  },
  {
    "id": 18607,
    "content": "For single precision GEMM routines cuBLAS will use the CUBLAS_COMPUTE_32F_FAST_16F compute type"
  },
  {
    "id": 18608,
    "content": "2"
  },
  {
    "id": 18609,
    "content": "2"
  },
  {
    "id": 18610,
    "content": "11"
  },
  {
    "id": 18613,
    "content": "studies, testing, and debugging"
  },
  {
    "id": 18614,
    "content": "This mode might not be as performant as the other modes since it disables use of tensor cores"
  },
  {
    "id": 18619,
    "content": "cores"
  },
  {
    "id": 18620,
    "content": "2"
  },
  {
    "id": 18621,
    "content": "3"
  },
  {
    "id": 18623,
    "content": "h"
  },
  {
    "id": 18624,
    "content": "2"
  },
  {
    "id": 18625,
    "content": "3"
  },
  {
    "id": 18626,
    "content": "1"
  },
  {
    "id": 18627,
    "content": "cudaDataType_t  The cudaDataType_t type is an enumerant to specify the data precision"
  },
  {
    "id": 18632,
    "content": "in E5M2 format 2"
  },
  {
    "id": 18633,
    "content": "3"
  },
  {
    "id": 18634,
    "content": "2"
  },
  {
    "id": 18636,
    "content": "4"
  },
  {
    "id": 18641,
    "content": "4"
  },
  {
    "id": 18642,
    "content": "2"
  },
  {
    "id": 18645,
    "content": "4"
  },
  {
    "id": 18646,
    "content": "3"
  },
  {
    "id": 18648,
    "content": "to NULL"
  },
  {
    "id": 18649,
    "content": "Another way to do this is with cublasGetProperty()"
  },
  {
    "id": 18650,
    "content": "2"
  },
  {
    "id": 18651,
    "content": "4"
  },
  {
    "id": 18652,
    "content": "4"
  },
  {
    "id": 18654,
    "content": "4"
  },
  {
    "id": 18655,
    "content": "5"
  },
  {
    "id": 18657,
    "content": "4"
  },
  {
    "id": 18658,
    "content": "6"
  },
  {
    "id": 18662,
    "content": "4"
  },
  {
    "id": 18663,
    "content": "8"
  },
  {
    "id": 18666,
    "content": "library from utilizing the default workspace"
  },
  {
    "id": 18670,
    "content": "workspace pointer wasn’t aligned to at least 256 bytes 2"
  },
  {
    "id": 18671,
    "content": "4"
  },
  {
    "id": 18672,
    "content": "9"
  },
  {
    "id": 18674,
    "content": "streamId == NULL 2"
  },
  {
    "id": 18675,
    "content": "4"
  },
  {
    "id": 18676,
    "content": "10"
  },
  {
    "id": 18678,
    "content": "4"
  },
  {
    "id": 18679,
    "content": "11"
  },
  {
    "id": 18681,
    "content": "CUBLAS_POINTER_MODE_DEVICE 2"
  },
  {
    "id": 18682,
    "content": "4"
  },
  {
    "id": 18683,
    "content": "12"
  },
  {
    "id": 18690,
    "content": "4"
  },
  {
    "id": 18691,
    "content": "21"
  },
  {
    "id": 18694,
    "content": "4"
  },
  {
    "id": 18695,
    "content": "22"
  },
  {
    "id": 18700,
    "content": "CUBLAS_STATUS_NOT_INITIALIZED the library was not initialized"
  },
  {
    "id": 18701,
    "content": "2"
  },
  {
    "id": 18702,
    "content": "4"
  },
  {
    "id": 18703,
    "content": "23"
  },
  {
    "id": 18705,
    "content": "CUBLAS_STATUS_INVALID_VALUE if mode is NULL"
  },
  {
    "id": 18706,
    "content": "2"
  },
  {
    "id": 18707,
    "content": "4"
  },
  {
    "id": 18708,
    "content": "24"
  },
  {
    "id": 18714,
    "content": "CUBLAS_STATUS_INVALID_VALUE the value of smCountTarget outside of the allowed range"
  },
  {
    "id": 18715,
    "content": "2"
  },
  {
    "id": 18716,
    "content": "4"
  },
  {
    "id": 18717,
    "content": "25"
  },
  {
    "id": 18719,
    "content": "2"
  },
  {
    "id": 18720,
    "content": "4"
  },
  {
    "id": 18721,
    "content": "26"
  },
  {
    "id": 18725,
    "content": "Returns CUBLAS_STATUS_SUCCESS Success"
  },
  {
    "id": 18726,
    "content": "2"
  },
  {
    "id": 18727,
    "content": "4"
  },
  {
    "id": 18728,
    "content": "27"
  },
  {
    "id": 18731,
    "content": "4"
  },
  {
    "id": 18732,
    "content": "28"
  },
  {
    "id": 18734,
    "content": "2"
  },
  {
    "id": 18735,
    "content": "5"
  },
  {
    "id": 18739,
    "content": "Cs , Dz and Zd"
  },
  {
    "id": 18742,
    "content": "2"
  },
  {
    "id": 18743,
    "content": "5"
  },
  {
    "id": 18744,
    "content": "1"
  },
  {
    "id": 18748,
    "content": "Notice that the last equation reflects 1-based indexing used for compatibility with Fortran"
  },
  {
    "id": 18755,
    "content": "result host or device output the resulting index, which is 0"
  },
  {
    "id": 18760,
    "content": "Notice that the last two equations reflect 1-based indexing used for compatibility with Fortran"
  },
  {
    "id": 18762,
    "content": "5"
  },
  {
    "id": 18763,
    "content": "5"
  },
  {
    "id": 18768,
    "content": "5"
  },
  {
    "id": 18769,
    "content": "6"
  },
  {
    "id": 18772,
    "content": "result host or device output the resulting dot product, which is 0"
  },
  {
    "id": 18776,
    "content": "This function applies Givens rotation matrix (i"
  },
  {
    "id": 18777,
    "content": "e"
  },
  {
    "id": 18781,
    "content": "5"
  },
  {
    "id": 18782,
    "content": "9"
  },
  {
    "id": 18789,
    "content": "5"
  },
  {
    "id": 18790,
    "content": "10"
  },
  {
    "id": 18796,
    "content": "0} \\\\ {- 1"
  },
  {
    "id": 18797,
    "content": "0} & h_{22} \\\\ \\end{pmatrix}\\) \\(\\begin{pmatrix} {1"
  },
  {
    "id": 18798,
    "content": "0} & {0"
  },
  {
    "id": 18799,
    "content": "0} \\\\ {0"
  },
  {
    "id": 18800,
    "content": "0} & {1"
  },
  {
    "id": 18801,
    "content": "0} \\\\ \\end{pmatrix}\\) Notice that the values -1"
  },
  {
    "id": 18802,
    "content": "0, 0"
  },
  {
    "id": 18803,
    "content": "0 and 1"
  },
  {
    "id": 18806,
    "content": "5"
  },
  {
    "id": 18807,
    "content": "11"
  },
  {
    "id": 18812,
    "content": "5"
  },
  {
    "id": 18813,
    "content": "12"
  },
  {
    "id": 18816,
    "content": "This function scales the vector x by the scalar \\(\\alpha\\) and overwrites it with the result"
  },
  {
    "id": 18819,
    "content": "5"
  },
  {
    "id": 18820,
    "content": "13"
  },
  {
    "id": 18823,
    "content": "\\mathbf{y}\\lbrack j brack\\Leftrightarrow\\mathbf{x}\\lbrack k brack  ight"
  },
  {
    "id": 18826,
    "content": "6"
  },
  {
    "id": 18832,
    "content": "Before entry, the leading m by n part of the array A must contain the matrix of coefficients"
  },
  {
    "id": 18855,
    "content": "mode, \\(\\mathbf{x}\\) and \\(\\mathbf{y}\\) are vectors, and \\(\\alpha\\) and \\(\\beta\\) are scalars"
  },
  {
    "id": 18859,
    "content": "triangular banded matrix, and \\(\\mathbf{x}\\) is a vector"
  },
  {
    "id": 18865,
    "content": "\\) The solution \\(\\mathbf{x}\\) overwrites the right-hand-sides \\(\\mathbf{b}\\) on exit"
  },
  {
    "id": 18867,
    "content": "where \\(A\\) is a triangular matrix stored in packed format, and \\(\\mathbf{x}\\) is a vector"
  },
  {
    "id": 18875,
    "content": "\\) Param"
  },
  {
    "id": 18876,
    "content": "trans input operation op( A ) (that is, non- or conj"
  },
  {
    "id": 18877,
    "content": ") A device input array of dimensions lda x n , with lda>=max(1,n)"
  },
  {
    "id": 18893,
    "content": "location AP[i+(j*(j+1))/2] for \\(j = 1,\\ldots,n\\) and \\(i \\leq j\\)"
  },
  {
    "id": 18909,
    "content": "e"
  },
  {
    "id": 18912,
    "content": "trans input operation op( A[i] ) that is non- or (conj"
  },
  {
    "id": 18913,
    "content": ") m input number of rows of matrix A[i]"
  },
  {
    "id": 18921,
    "content": "e"
  },
  {
    "id": 18927,
    "content": ") m input number of rows of matrix op( A ) and C"
  },
  {
    "id": 18931,
    "content": "64-bit Integer Interface"
  },
  {
    "id": 18935,
    "content": "0 Param"
  },
  {
    "id": 18950,
    "content": "brack)\\) \\(k \\times n\\) and \\(C\\lbrack i brack\\) \\(m \\times n\\) , respectively"
  },
  {
    "id": 18962,
    "content": "transa_array host input array containing the operations, op( A[idx] ), that is non- or (conj"
  },
  {
    "id": 18963,
    "content": ") transpose for each group"
  },
  {
    "id": 18973,
    "content": "and \\(\\alpha\\) and \\(\\beta\\) are scalars"
  },
  {
    "id": 18977,
    "content": "\\) Param"
  },
  {
    "id": 18983,
    "content": "\\) Param"
  },
  {
    "id": 18999,
    "content": "0"
  },
  {
    "id": 19001,
    "content": "lda x m with lda>=max(1,m) if side == CUBLAS_SIDE_LEFT and lda x n with lda>=max(1,n) otherwise"
  },
  {
    "id": 19005,
    "content": "and \\(\\alpha\\) and \\(\\beta\\) are scalars"
  },
  {
    "id": 19007,
    "content": "beta input scalar used for multiplication, if beta==0 then C does not have to be a valid input"
  },
  {
    "id": 19012,
    "content": "\\) Param"
  },
  {
    "id": 19018,
    "content": "\\) Param"
  },
  {
    "id": 19033,
    "content": "represents partial pivoting with row interchanges"
  },
  {
    "id": 19034,
    "content": "Formally P is written by a product of permutation matrices Pj , for j = 1,2,"
  },
  {
    "id": 19035,
    "content": ",n , say P = P1 * P2 * P3 *"
  },
  {
    "id": 19044,
    "content": "ldb input leading dimension of two-dimensional array used to store each solution matrix Barray[i]"
  },
  {
    "id": 19049,
    "content": "If cublasgetrfBatched is performed by non-pivoting, PivotArray of cublasgetriBatched should be NULL"
  },
  {
    "id": 19052,
    "content": "If the matrix A[i] is singular, then info[i] reports singularity, the same as cublasgetrfBatched"
  },
  {
    "id": 19055,
    "content": "8"
  },
  {
    "id": 19056,
    "content": "7"
  },
  {
    "id": 19057,
    "content": "This function performs the QR factorization of each Aarray[i] for i = 0,"
  },
  {
    "id": 19058,
    "content": ",batchSize-1 using Householder reflections"
  },
  {
    "id": 19060,
    "content": "H[j](k), where k = min(m,n)"
  },
  {
    "id": 19073,
    "content": "that corresponds to the computeType and Ctype, see the table below for details"
  },
  {
    "id": 19077,
    "content": "0"
  },
  {
    "id": 19079,
    "content": "run"
  },
  {
    "id": 19087,
    "content": "0"
  },
  {
    "id": 19098,
    "content": "0"
  },
  {
    "id": 19100,
    "content": "group"
  },
  {
    "id": 19105,
    "content": "used for multiplication, if beta==0 then C does not have to be a valid input"
  },
  {
    "id": 19108,
    "content": "CUDA_C_32F The possible error values returned by this function and their meanings are listed below"
  },
  {
    "id": 19110,
    "content": "result host or device output the resulting norm, which is 0"
  },
  {
    "id": 19111,
    "content": "0 if n,incxaxpy where input data, output data and compute type can be specified independently"
  },
  {
    "id": 19112,
    "content": "executionType input Enumerant specifying the datatype in which the computation is executed"
  },
  {
    "id": 19114,
    "content": "error values returned by this function and their meanings are listed below"
  },
  {
    "id": 19118,
    "content": "result host or device output The resulting dot product, which is 0"
  },
  {
    "id": 19120,
    "content": "executionType input enumerant specifying the datatype in which the computation is executed"
  },
  {
    "id": 19122,
    "content": "their meanings are listed below"
  },
  {
    "id": 19124,
    "content": "8"
  },
  {
    "id": 19125,
    "content": "24"
  },
  {
    "id": 19129,
    "content": "For references please refer to: sscal , dscal , csscal , cscal , zdscal , zscal 3"
  },
  {
    "id": 19135,
    "content": "3"
  },
  {
    "id": 19136,
    "content": "1"
  },
  {
    "id": 19137,
    "content": "1"
  },
  {
    "id": 19143,
    "content": "3"
  },
  {
    "id": 19144,
    "content": "1"
  },
  {
    "id": 19145,
    "content": "2"
  },
  {
    "id": 19147,
    "content": "This requires performing some computations on the host CPU, which could take tens of microseconds"
  },
  {
    "id": 19153,
    "content": "5x-2"
  },
  {
    "id": 19154,
    "content": "x over the anticipated number of unique matmul problems to achieve a nearly perfect hit rate"
  },
  {
    "id": 19156,
    "content": "1"
  },
  {
    "id": 19157,
    "content": "4"
  },
  {
    "id": 19159,
    "content": "9 and above) and is designed to further accelerate matrix multiplications"
  },
  {
    "id": 19163,
    "content": "The scaleA, scaleB, and scaleC are used for de-quantization, and scaleD is used for quantization"
  },
  {
    "id": 19168,
    "content": "3"
  },
  {
    "id": 19169,
    "content": "1"
  },
  {
    "id": 19170,
    "content": "5"
  },
  {
    "id": 19173,
    "content": "3"
  },
  {
    "id": 19174,
    "content": "1"
  },
  {
    "id": 19175,
    "content": "6"
  },
  {
    "id": 19180,
    "content": "the matrixes, but not both"
  },
  {
    "id": 19183,
    "content": "Matmul will return an error if both input and output counter pointers to a non-NULL value"
  },
  {
    "id": 19185,
    "content": "Both of these attributes must be set to a value greater than zero for the feature to be enabled"
  },
  {
    "id": 19196,
    "content": "3"
  },
  {
    "id": 19197,
    "content": "3"
  },
  {
    "id": 19198,
    "content": "9"
  },
  {
    "id": 19209,
    "content": "pass when CUBLASLT_EPILOGUE_DGELU or CUBLASLT_EPILOGUE_DGELU_BGRAD epilogue is used"
  },
  {
    "id": 19213,
    "content": "int64_t CUBLASLT_MATMUL_DESC_EPILOGUE_AUX_BATCH_STRIDE Batch stride for epilogue auxiliary buffer"
  },
  {
    "id": 19233,
    "content": "A wavesCount value of 1"
  },
  {
    "id": 19234,
    "content": "0f suggests that when the kernel is launched it will fully occupy the GPU"
  },
  {
    "id": 19235,
    "content": "int reserved[4]; Reserved"
  },
  {
    "id": 19236,
    "content": "3"
  },
  {
    "id": 19237,
    "content": "3"
  },
  {
    "id": 19238,
    "content": "11"
  },
  {
    "id": 19240,
    "content": "CUBLASLT_MATMUL_INNER_SHAPE_MMA16816 Inner shape is MMA16816"
  },
  {
    "id": 19241,
    "content": "3"
  },
  {
    "id": 19242,
    "content": "3"
  },
  {
    "id": 19243,
    "content": "12"
  },
  {
    "id": 19246,
    "content": "3"
  },
  {
    "id": 19247,
    "content": "3"
  },
  {
    "id": 19248,
    "content": "13"
  },
  {
    "id": 19252,
    "content": "For example, a mask value of 0x03 will allow only INPLACE and COMPUTE_TYPE reduction schemes"
  },
  {
    "id": 19262,
    "content": "3"
  },
  {
    "id": 19263,
    "content": "3"
  },
  {
    "id": 19264,
    "content": "15"
  },
  {
    "id": 19266,
    "content": "3"
  },
  {
    "id": 19267,
    "content": "3"
  },
  {
    "id": 19268,
    "content": "16"
  },
  {
    "id": 19271,
    "content": "Stage size is 128, number of stages is selected automatically"
  },
  {
    "id": 19272,
    "content": "3"
  },
  {
    "id": 19273,
    "content": "3"
  },
  {
    "id": 19274,
    "content": "17"
  },
  {
    "id": 19285,
    "content": "3"
  },
  {
    "id": 19286,
    "content": "18"
  },
  {
    "id": 19289,
    "content": "3"
  },
  {
    "id": 19290,
    "content": "3"
  },
  {
    "id": 19291,
    "content": "19"
  },
  {
    "id": 19295,
    "content": "Must be large enough so that matrix memory locations are not overlapping (e"
  },
  {
    "id": 19296,
    "content": "g"
  },
  {
    "id": 19297,
    "content": ", greater or equal to CUBLASLT_MATRIX_LAYOUT_ROWS in case of CUBLASLT_ORDER_COL)"
  },
  {
    "id": 19298,
    "content": "int64_t CUBLASLT_MATRIX_LAYOUT_BATCH_COUNT Number of matmul operations to perform in the batch"
  },
  {
    "id": 19300,
    "content": "When matrix type is planar-complex (CUBLASLT_MATRIX_LAYOUT_PLANE_OFFSET"
  },
  {
    "id": 19303,
    "content": "complex numbers are interleaved in memory for each element)"
  },
  {
    "id": 19306,
    "content": "3"
  },
  {
    "id": 19307,
    "content": "3"
  },
  {
    "id": 19308,
    "content": "21"
  },
  {
    "id": 19316,
    "content": "3"
  },
  {
    "id": 19317,
    "content": "3"
  },
  {
    "id": 19318,
    "content": "23"
  },
  {
    "id": 19322,
    "content": "of length equal to the number of rows of matrix D, and beta is a single value in host memory"
  },
  {
    "id": 19323,
    "content": "3"
  },
  {
    "id": 19324,
    "content": "3"
  },
  {
    "id": 19325,
    "content": "24"
  },
  {
    "id": 19329,
    "content": "3"
  },
  {
    "id": 19330,
    "content": "25"
  },
  {
    "id": 19332,
    "content": "e"
  },
  {
    "id": 19333,
    "content": ", “split - K”)"
  },
  {
    "id": 19336,
    "content": "CUBLASLT_REDUCTION_SCHEME_MASK Allows all reduction schemes"
  },
  {
    "id": 19337,
    "content": "3"
  },
  {
    "id": 19338,
    "content": "4"
  },
  {
    "id": 19339,
    "content": "cuBLASLt API Reference  3"
  },
  {
    "id": 19340,
    "content": "4"
  },
  {
    "id": 19341,
    "content": "1"
  },
  {
    "id": 19344,
    "content": "Returns: Return Value Description CUBLAS_STATUS_SUCCESS The allocation completed successfully"
  },
  {
    "id": 19348,
    "content": "3"
  },
  {
    "id": 19349,
    "content": "4"
  },
  {
    "id": 19350,
    "content": "2"
  },
  {
    "id": 19353,
    "content": "3"
  },
  {
    "id": 19354,
    "content": "4"
  },
  {
    "id": 19355,
    "content": "3"
  },
  {
    "id": 19357,
    "content": "The function takes precedence over the CUBLASLT_DISABLE_CPU_INSTRUCTIONS_MASK environment variable"
  },
  {
    "id": 19359,
    "content": "3"
  },
  {
    "id": 19360,
    "content": "4"
  },
  {
    "id": 19361,
    "content": "4"
  },
  {
    "id": 19363,
    "content": "3"
  },
  {
    "id": 19364,
    "content": "4"
  },
  {
    "id": 19365,
    "content": "5"
  },
  {
    "id": 19368,
    "content": "3"
  },
  {
    "id": 19369,
    "content": "4"
  },
  {
    "id": 19370,
    "content": "6"
  },
  {
    "id": 19372,
    "content": "3"
  },
  {
    "id": 19373,
    "content": "4"
  },
  {
    "id": 19374,
    "content": "7"
  },
  {
    "id": 19376,
    "content": "3"
  },
  {
    "id": 19377,
    "content": "4"
  },
  {
    "id": 19378,
    "content": "8"
  },
  {
    "id": 19380,
    "content": "3"
  },
  {
    "id": 19381,
    "content": "4"
  },
  {
    "id": 19382,
    "content": "9"
  },
  {
    "id": 19384,
    "content": "This function takes precedence over CUBLASLT_HEURISTICS_CACHE_CAPACITY environment variable"
  },
  {
    "id": 19385,
    "content": "Returns: Return Value Description CUBLAS_STATUS_SUCCESS The capacity was successfully set"
  },
  {
    "id": 19386,
    "content": "3"
  },
  {
    "id": 19387,
    "content": "4"
  },
  {
    "id": 19388,
    "content": "10"
  },
  {
    "id": 19390,
    "content": "3"
  },
  {
    "id": 19391,
    "content": "4"
  },
  {
    "id": 19392,
    "content": "11"
  },
  {
    "id": 19394,
    "content": "See cublasStatus_t for a complete list of valid return codes"
  },
  {
    "id": 19395,
    "content": "3"
  },
  {
    "id": 19396,
    "content": "4"
  },
  {
    "id": 19397,
    "content": "12"
  },
  {
    "id": 19399,
    "content": "Returns : Return Value Description CUBLAS_STATUS_SUCCESS If logging file was successfully set"
  },
  {
    "id": 19400,
    "content": "3"
  },
  {
    "id": 19401,
    "content": "4"
  },
  {
    "id": 19402,
    "content": "13"
  },
  {
    "id": 19404,
    "content": "3"
  },
  {
    "id": 19405,
    "content": "4"
  },
  {
    "id": 19406,
    "content": "14"
  },
  {
    "id": 19408,
    "content": "successfully set"
  },
  {
    "id": 19409,
    "content": "3"
  },
  {
    "id": 19410,
    "content": "4"
  },
  {
    "id": 19411,
    "content": "15"
  },
  {
    "id": 19413,
    "content": "3"
  },
  {
    "id": 19414,
    "content": "4"
  },
  {
    "id": 19415,
    "content": "16"
  },
  {
    "id": 19417,
    "content": "Returns : Return Value Description CUBLAS_STATUS_SUCCESS If logging was successfully disabled"
  },
  {
    "id": 19418,
    "content": "3"
  },
  {
    "id": 19419,
    "content": "4"
  },
  {
    "id": 19420,
    "content": "17"
  },
  {
    "id": 19423,
    "content": "out-of-place matrix multiplication ( C"
  },
  {
    "id": 19435,
    "content": "Matmul descriptor must specify CUBLAS_OP_T on matrix B and CUBLAS_OP_N (default) on matrix A and C"
  },
  {
    "id": 19436,
    "content": "If scaleType CUDA_R_32I is used, the only supported values for alpha and beta are 0 or 1"
  },
  {
    "id": 19440,
    "content": "e"
  },
  {
    "id": 19448,
    "content": "Ddesc Input Handle to the previous created descriptor of the type cublasLtMatrixLayout_t"
  },
  {
    "id": 19453,
    "content": "3"
  },
  {
    "id": 19454,
    "content": "4"
  },
  {
    "id": 19455,
    "content": "18"
  },
  {
    "id": 19463,
    "content": "CUBLAS_STATUS_SUCCESS If the check was successful"
  },
  {
    "id": 19464,
    "content": "3"
  },
  {
    "id": 19465,
    "content": "4"
  },
  {
    "id": 19466,
    "content": "20"
  },
  {
    "id": 19468,
    "content": "retrieved from the enumerated type cublasLtMatmulAlgoConfigAttributes_t"
  },
  {
    "id": 19470,
    "content": "See cublasLtMatmulAlgoConfigAttributes_t"
  },
  {
    "id": 19471,
    "content": "3"
  },
  {
    "id": 19472,
    "content": "4"
  },
  {
    "id": 19473,
    "content": "21"
  },
  {
    "id": 19476,
    "content": "3"
  },
  {
    "id": 19477,
    "content": "4"
  },
  {
    "id": 19478,
    "content": "22"
  },
  {
    "id": 19481,
    "content": "The output is placed in heuristicResultsArray[] in the order of increasing estimated compute time"
  },
  {
    "id": 19482,
    "content": "preference Input Pointer to the structure holding the heuristic search preferences descriptor"
  },
  {
    "id": 19485,
    "content": "Inspect heuristicResultsArray[0 to (returnAlgoCount -1)]"
  },
  {
    "id": 19486,
    "content": "state for the status of the results"
  },
  {
    "id": 19488,
    "content": "Do not allocate the entire VRAM before running cublasLtMatmulAlgoGetHeuristic()"
  },
  {
    "id": 19489,
    "content": "3"
  },
  {
    "id": 19490,
    "content": "4"
  },
  {
    "id": 19491,
    "content": "23"
  },
  {
    "id": 19495,
    "content": "Inspect returnAlgoCount to get actual number of IDs available"
  },
  {
    "id": 19496,
    "content": "3"
  },
  {
    "id": 19497,
    "content": "4"
  },
  {
    "id": 19498,
    "content": "24"
  },
  {
    "id": 19500,
    "content": "specified matrix multiply algorithm and input matrices A, B and C, and the output matrix D"
  },
  {
    "id": 19503,
    "content": "CUBLAS_STATUS_SUCCESS If the structure was successfully initialized"
  },
  {
    "id": 19504,
    "content": "3"
  },
  {
    "id": 19505,
    "content": "4"
  },
  {
    "id": 19506,
    "content": "25"
  },
  {
    "id": 19509,
    "content": "Returns : Return Value Description CUBLAS_STATUS_ALLOC_FAILED If memory could not be allocated"
  },
  {
    "id": 19510,
    "content": "CUBLAS_STATUS_SUCCESS If the descriptor was created successfully"
  },
  {
    "id": 19511,
    "content": "3"
  },
  {
    "id": 19512,
    "content": "4"
  },
  {
    "id": 19513,
    "content": "26"
  },
  {
    "id": 19516,
    "content": "3"
  },
  {
    "id": 19517,
    "content": "4"
  },
  {
    "id": 19518,
    "content": "27"
  },
  {
    "id": 19520,
    "content": "Returns : Return Value Description CUBLAS_STATUS_SUCCESS If operation was successful"
  },
  {
    "id": 19521,
    "content": "3"
  },
  {
    "id": 19522,
    "content": "4"
  },
  {
    "id": 19523,
    "content": "28"
  },
  {
    "id": 19526,
    "content": "3"
  },
  {
    "id": 19527,
    "content": "4"
  },
  {
    "id": 19528,
    "content": "29"
  },
  {
    "id": 19530,
    "content": "3"
  },
  {
    "id": 19531,
    "content": "4"
  },
  {
    "id": 19532,
    "content": "30"
  },
  {
    "id": 19534,
    "content": "descriptor created by this function"
  },
  {
    "id": 19535,
    "content": "See cublasLtMatrixLayout_t"
  },
  {
    "id": 19536,
    "content": "3"
  },
  {
    "id": 19537,
    "content": "4"
  },
  {
    "id": 19538,
    "content": "31"
  },
  {
    "id": 19540,
    "content": "3"
  },
  {
    "id": 19541,
    "content": "4"
  },
  {
    "id": 19542,
    "content": "32"
  },
  {
    "id": 19544,
    "content": "Returns : Return Value Description CUBLAS_STATUS_SUCCESS If the operation was successful"
  },
  {
    "id": 19545,
    "content": "3"
  },
  {
    "id": 19546,
    "content": "4"
  },
  {
    "id": 19547,
    "content": "33"
  },
  {
    "id": 19550,
    "content": "3"
  },
  {
    "id": 19551,
    "content": "4"
  },
  {
    "id": 19552,
    "content": "34"
  },
  {
    "id": 19555,
    "content": "3"
  },
  {
    "id": 19556,
    "content": "4"
  },
  {
    "id": 19557,
    "content": "35"
  },
  {
    "id": 19560,
    "content": "Returns : Return Value Description CUBLAS_STATUS_ALLOC_FAILED If the memory could not be allocated"
  },
  {
    "id": 19561,
    "content": "3"
  },
  {
    "id": 19562,
    "content": "4"
  },
  {
    "id": 19563,
    "content": "36"
  },
  {
    "id": 19566,
    "content": "3"
  },
  {
    "id": 19567,
    "content": "4"
  },
  {
    "id": 19568,
    "content": "37"
  },
  {
    "id": 19570,
    "content": "3"
  },
  {
    "id": 19571,
    "content": "4"
  },
  {
    "id": 19572,
    "content": "38"
  },
  {
    "id": 19575,
    "content": "3"
  },
  {
    "id": 19576,
    "content": "4"
  },
  {
    "id": 19577,
    "content": "39"
  },
  {
    "id": 19579,
    "content": "sizeInBytes doesn’t match size of internal storage for the selected attribute"
  },
  {
    "id": 19580,
    "content": "CUBLAS_STATUS_SUCCESS If attribute was set successfully"
  },
  {
    "id": 19581,
    "content": "3"
  },
  {
    "id": 19582,
    "content": "4"
  },
  {
    "id": 19583,
    "content": "40"
  },
  {
    "id": 19586,
    "content": "This function can be used to change the memory order of data or to scale and shift the values"
  },
  {
    "id": 19587,
    "content": "transformDesc Input Pointer to the opaque descriptor holding the matrix transformation operation"
  },
  {
    "id": 19590,
    "content": "CUBLAS_STATUS_INVALID_VALUE If the parameters are in conflict or in an impossible configuration"
  },
  {
    "id": 19592,
    "content": "3"
  },
  {
    "id": 19593,
    "content": "4"
  },
  {
    "id": 19594,
    "content": "41"
  },
  {
    "id": 19596,
    "content": "transform descriptor created by this function"
  },
  {
    "id": 19597,
    "content": "3"
  },
  {
    "id": 19598,
    "content": "4"
  },
  {
    "id": 19599,
    "content": "42"
  },
  {
    "id": 19601,
    "content": "by this function"
  },
  {
    "id": 19602,
    "content": "3"
  },
  {
    "id": 19603,
    "content": "4"
  },
  {
    "id": 19604,
    "content": "43"
  },
  {
    "id": 19606,
    "content": "3"
  },
  {
    "id": 19607,
    "content": "4"
  },
  {
    "id": 19608,
    "content": "44"
  },
  {
    "id": 19611,
    "content": "3"
  },
  {
    "id": 19612,
    "content": "4"
  },
  {
    "id": 19613,
    "content": "45"
  },
  {
    "id": 19616,
    "content": "4"
  },
  {
    "id": 19617,
    "content": "Using the cuBLASXt API  4"
  },
  {
    "id": 19618,
    "content": "1"
  },
  {
    "id": 19623,
    "content": "g matrix-matrix operations) where the PCI transfers back and forth from the GPU can be amortized"
  },
  {
    "id": 19624,
    "content": "Starting with release 8"
  },
  {
    "id": 19626,
    "content": "4"
  },
  {
    "id": 19627,
    "content": "1"
  },
  {
    "id": 19628,
    "content": "1"
  },
  {
    "id": 19635,
    "content": "synchronization is required"
  },
  {
    "id": 19636,
    "content": "4"
  },
  {
    "id": 19637,
    "content": "1"
  },
  {
    "id": 19638,
    "content": "2"
  },
  {
    "id": 19641,
    "content": "4"
  },
  {
    "id": 19642,
    "content": "1"
  },
  {
    "id": 19643,
    "content": "3"
  },
  {
    "id": 19646,
    "content": "4"
  },
  {
    "id": 19647,
    "content": "2"
  },
  {
    "id": 19648,
    "content": "cuBLASXt API Datatypes Reference  4"
  },
  {
    "id": 19649,
    "content": "2"
  },
  {
    "id": 19650,
    "content": "1"
  },
  {
    "id": 19652,
    "content": "4"
  },
  {
    "id": 19653,
    "content": "2"
  },
  {
    "id": 19654,
    "content": "2"
  },
  {
    "id": 19655,
    "content": "cublasXtOpType_t  The cublasOpType_t enumerates the four possible types supported by BLAS routines"
  },
  {
    "id": 19658,
    "content": "2"
  },
  {
    "id": 19659,
    "content": "3"
  },
  {
    "id": 19661,
    "content": "routine CUBLASXT_HERKX HERKX routine 4"
  },
  {
    "id": 19662,
    "content": "2"
  },
  {
    "id": 19663,
    "content": "4"
  },
  {
    "id": 19665,
    "content": "3"
  },
  {
    "id": 19668,
    "content": "3"
  },
  {
    "id": 19669,
    "content": "2"
  },
  {
    "id": 19672,
    "content": "3"
  },
  {
    "id": 19673,
    "content": "3"
  },
  {
    "id": 19675,
    "content": "To be able to run multiple configurations, multiple cuBLASXt API contexts should be created"
  },
  {
    "id": 19677,
    "content": "4"
  },
  {
    "id": 19678,
    "content": "3"
  },
  {
    "id": 19679,
    "content": "4"
  },
  {
    "id": 19681,
    "content": "make sure that the PCI transfers are well overlapped with the computation"
  },
  {
    "id": 19684,
    "content": "otherwise"
  },
  {
    "id": 19685,
    "content": "beta host input scalar used for multiplication, if beta==0 then C does not have to be a valid input"
  },
  {
    "id": 19689,
    "content": "beta host input scalar used for multiplication, if beta==0 then C does not have to be a valid input"
  },
  {
    "id": 19699,
    "content": "API by passing the address of the matrix B in place of the matrix C"
  },
  {
    "id": 19701,
    "content": "cuBLAS Fortran Bindings  The cuBLAS library is implemented using the C-based CUDA toolchain"
  },
  {
    "id": 19706,
    "content": "2"
  },
  {
    "id": 19707,
    "content": "3 and g95 0"
  },
  {
    "id": 19708,
    "content": "91 on 32-bit Linux, g77 3"
  },
  {
    "id": 19709,
    "content": "4"
  },
  {
    "id": 19710,
    "content": "5 and g95 0"
  },
  {
    "id": 19712,
    "content": "4"
  },
  {
    "id": 19713,
    "content": "0 and g95 0"
  },
  {
    "id": 19714,
    "content": "92 on Mac OS X"
  },
  {
    "id": 19720,
    "content": "To use the thunking wrappers, the application needs to be compiled with the file fortran_thunking"
  },
  {
    "id": 19721,
    "content": "c"
  },
  {
    "id": 19724,
    "content": "The sample wrappers provided in fortran"
  },
  {
    "id": 19728,
    "content": "On Windows platforms with Microsoft Visual C/C++, using ’cl -EP’ achieves similar results"
  },
  {
    "id": 19734,
    "content": "0 , 12"
  },
  {
    "id": 19735,
    "content": "0 ) stat = cublas_get_matrix ( M , N , sizeof_real , devPtrA , M , a , M ) if ( stat"
  },
  {
    "id": 19736,
    "content": "NE"
  },
  {
    "id": 19738,
    "content": "0$)\" ) a ( i , j ) enddo write ( * , * ) \"\" enddo stop end 8"
  },
  {
    "id": 19740,
    "content": "8"
  },
  {
    "id": 19741,
    "content": "1"
  },
  {
    "id": 19743,
    "content": "between different minor revision versions"
  },
  {
    "id": 19745,
    "content": "For example, the following call prunes libcublas_static"
  },
  {
    "id": 19751,
    "content": "This product includes {fmt} - A modern formatting library https: fmt"
  },
  {
    "id": 19752,
    "content": "dev Copyright (c) 2012 - present, Victor Zverovich"
  },
  {
    "id": 19754,
    "content": "org Boost Software License - Version 1"
  },
  {
    "id": 19755,
    "content": "0 - August 17th, 2003"
  },
  {
    "id": 19756,
    "content": "This product includes Frozen - a header-only, constexpr alternative to gperf for C++14 users"
  },
  {
    "id": 19758,
    "content": "0 - August 17th, 2003"
  },
  {
    "id": 19762,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 19774,
    "content": "10"
  },
  {
    "id": 19775,
    "content": "2"
  },
  {
    "id": 19776,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 19777,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 19778,
    "content": "10"
  },
  {
    "id": 19779,
    "content": "3"
  },
  {
    "id": 19781,
    "content": "S"
  },
  {
    "id": 19784,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 19785,
    "content": "Navigation"
  },
  {
    "id": 19786,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 19788,
    "content": "5"
  },
  {
    "id": 19789,
    "content": "1 cuDLA API 1 Data Fields Search Results cuDLA API ( PDF ) - v12"
  },
  {
    "id": 19790,
    "content": "5"
  },
  {
    "id": 19791,
    "content": "1 ( older ) - Last updated July 1, 2024 - Send Feedback 1"
  },
  {
    "id": 19800,
    "content": "2"
  },
  {
    "id": 19802,
    "content": "1"
  },
  {
    "id": 19804,
    "content": "2"
  },
  {
    "id": 19805,
    "content": "2"
  },
  {
    "id": 19807,
    "content": "memory allocation 2"
  },
  {
    "id": 19808,
    "content": "3"
  },
  {
    "id": 19810,
    "content": "2"
  },
  {
    "id": 19811,
    "content": "4"
  },
  {
    "id": 19813,
    "content": "2"
  },
  {
    "id": 19814,
    "content": "5"
  },
  {
    "id": 19815,
    "content": "cudlaModuleAttribute Union Reference [ Data types used by cuDLA driver ] Module attribute"
  },
  {
    "id": 19818,
    "content": "2"
  },
  {
    "id": 19819,
    "content": "6"
  },
  {
    "id": 19820,
    "content": "cudlaModuleTensorDescriptor Struct Reference [ Data types used by cuDLA driver ] Tensor descriptor"
  },
  {
    "id": 19821,
    "content": "2"
  },
  {
    "id": 19822,
    "content": "7"
  },
  {
    "id": 19825,
    "content": "2"
  },
  {
    "id": 19826,
    "content": "8"
  },
  {
    "id": 19827,
    "content": "cudlaTask Struct Reference [ Data types used by cuDLA driver ] Structure of Task"
  },
  {
    "id": 19829,
    "content": "2"
  },
  {
    "id": 19830,
    "content": "9"
  },
  {
    "id": 19845,
    "content": "S"
  },
  {
    "id": 19849,
    "content": "pageBottom();\n1"
  },
  {
    "id": 19850,
    "content": "Introduction v12"
  },
  {
    "id": 19852,
    "content": "up on a GPU"
  },
  {
    "id": 19853,
    "content": "2"
  },
  {
    "id": 19856,
    "content": "3"
  },
  {
    "id": 19859,
    "content": "Symmetric matrix-matrix multiplication hemm C,Z Hermitian matrix-matrix multiplication 4"
  },
  {
    "id": 19861,
    "content": "original BLAS routine will be executed for those cases"
  },
  {
    "id": 19862,
    "content": "5"
  },
  {
    "id": 19863,
    "content": "Device Memory Support  Starting with Release 8"
  },
  {
    "id": 19866,
    "content": "6"
  },
  {
    "id": 19869,
    "content": "7"
  },
  {
    "id": 19872,
    "content": "Blank lines or lines beginning with the character # are ignored"
  },
  {
    "id": 19873,
    "content": "7"
  },
  {
    "id": 19874,
    "content": "1"
  },
  {
    "id": 19876,
    "content": "conf in the current directory"
  },
  {
    "id": 19877,
    "content": "For a safe use of NVBLAS, the configuration file should have have restricted write permissions"
  },
  {
    "id": 19878,
    "content": "7"
  },
  {
    "id": 19879,
    "content": "2"
  },
  {
    "id": 19881,
    "content": "7"
  },
  {
    "id": 19882,
    "content": "2"
  },
  {
    "id": 19883,
    "content": "1"
  },
  {
    "id": 19885,
    "content": "7"
  },
  {
    "id": 19886,
    "content": "2"
  },
  {
    "id": 19887,
    "content": "2"
  },
  {
    "id": 19889,
    "content": "This feature, even though intrusive, can be useful for debugging purposes"
  },
  {
    "id": 19890,
    "content": "7"
  },
  {
    "id": 19891,
    "content": "2"
  },
  {
    "id": 19892,
    "content": "3"
  },
  {
    "id": 19893,
    "content": "NVBLAS_CPU_BLAS_LIB  This keyword defines the CPU BLAS dynamic library file (for example,"
  },
  {
    "id": 19894,
    "content": "so file on Linux or"
  },
  {
    "id": 19897,
    "content": "7"
  },
  {
    "id": 19898,
    "content": "2"
  },
  {
    "id": 19899,
    "content": "4"
  },
  {
    "id": 19903,
    "content": "7"
  },
  {
    "id": 19904,
    "content": "2"
  },
  {
    "id": 19905,
    "content": "5"
  },
  {
    "id": 19908,
    "content": "7"
  },
  {
    "id": 19909,
    "content": "2"
  },
  {
    "id": 19910,
    "content": "6"
  },
  {
    "id": 19912,
    "content": "By default, all supported BLAS routines are enabled"
  },
  {
    "id": 19913,
    "content": "7"
  },
  {
    "id": 19914,
    "content": "2"
  },
  {
    "id": 19915,
    "content": "7"
  },
  {
    "id": 19918,
    "content": "7"
  },
  {
    "id": 19919,
    "content": "2"
  },
  {
    "id": 19920,
    "content": "8"
  },
  {
    "id": 19921,
    "content": "NVBLAS_AUTOPIN_MEM_ENABLED  This keyword enables the Pinning Memory mode"
  },
  {
    "id": 19922,
    "content": "This functionality is directly mapped to the cublasXt API routine cublasXtSetPinningMemMode"
  },
  {
    "id": 19926,
    "content": "Please refer to the cuBLAS Documentation of the routine `cublasXtSetPinningMemMode `__ for details"
  },
  {
    "id": 19927,
    "content": "7"
  },
  {
    "id": 19928,
    "content": "2"
  },
  {
    "id": 19929,
    "content": "9"
  },
  {
    "id": 19931,
    "content": "cuBLAS, so the cuBLAS library needs to be accessible by NVBLAS"
  },
  {
    "id": 19932,
    "content": "9"
  },
  {
    "id": 19937,
    "content": "10 Notices  10"
  },
  {
    "id": 19938,
    "content": "1"
  },
  {
    "id": 19941,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 19953,
    "content": "10"
  },
  {
    "id": 19954,
    "content": "2"
  },
  {
    "id": 19955,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 19956,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 19957,
    "content": "10"
  },
  {
    "id": 19958,
    "content": "3"
  },
  {
    "id": 19960,
    "content": "S"
  },
  {
    "id": 19963,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 19964,
    "content": "Navigation"
  },
  {
    "id": 19965,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 19966,
    "content": "pageBottom();}\n1"
  },
  {
    "id": 19967,
    "content": "Introduction v12"
  },
  {
    "id": 19970,
    "content": "Illegal, not supported: The specified semantics is not supported, such as a fence instruction"
  },
  {
    "id": 19973,
    "content": "org/7"
  },
  {
    "id": 19974,
    "content": "0"
  },
  {
    "id": 19975,
    "content": "1/docs/LangRef"
  },
  {
    "id": 19976,
    "content": "html )"
  },
  {
    "id": 19977,
    "content": "2"
  },
  {
    "id": 19980,
    "content": "3"
  },
  {
    "id": 19981,
    "content": "2"
  },
  {
    "id": 19983,
    "content": "3"
  },
  {
    "id": 19984,
    "content": "2"
  },
  {
    "id": 19985,
    "content": "1"
  },
  {
    "id": 19987,
    "content": "case below)"
  },
  {
    "id": 19992,
    "content": "S % arg2 ),"
  },
  {
    "id": 19993,
    "content": "callalign"
  },
  {
    "id": 19994,
    "content": "10 10 ="
  },
  {
    "id": 19997,
    "content": "3"
  },
  {
    "id": 19998,
    "content": "3"
  },
  {
    "id": 19999,
    "content": "Visibility Styles  All styles—default, hidden, and protected—are accepted and ignored"
  },
  {
    "id": 20000,
    "content": "3"
  },
  {
    "id": 20001,
    "content": "11"
  },
  {
    "id": 20003,
    "content": "Use undef initialization"
  },
  {
    "id": 20004,
    "content": "3"
  },
  {
    "id": 20005,
    "content": "12"
  },
  {
    "id": 20007,
    "content": "13"
  },
  {
    "id": 20008,
    "content": "Aliases  Supported only as aliases of non-kernel functions"
  },
  {
    "id": 20009,
    "content": "3"
  },
  {
    "id": 20010,
    "content": "14"
  },
  {
    "id": 20011,
    "content": "Ifuncs  Not supported"
  },
  {
    "id": 20012,
    "content": "3"
  },
  {
    "id": 20013,
    "content": "15"
  },
  {
    "id": 20014,
    "content": "Named Metadata  Accepted and ignored, except for the following:"
  },
  {
    "id": 20015,
    "content": "nvvm"
  },
  {
    "id": 20016,
    "content": "annotations : see Global Property Annotation"
  },
  {
    "id": 20017,
    "content": "nvvmir"
  },
  {
    "id": 20018,
    "content": "version"
  },
  {
    "id": 20019,
    "content": "llvm"
  },
  {
    "id": 20020,
    "content": "dbg"
  },
  {
    "id": 20021,
    "content": "cu"
  },
  {
    "id": 20022,
    "content": "llvm"
  },
  {
    "id": 20023,
    "content": "module"
  },
  {
    "id": 20024,
    "content": "flags The NVVM IR version is specified using a named metadata called"
  },
  {
    "id": 20025,
    "content": "nvvmir"
  },
  {
    "id": 20026,
    "content": "version"
  },
  {
    "id": 20027,
    "content": "The"
  },
  {
    "id": 20028,
    "content": "nvvmir"
  },
  {
    "id": 20031,
    "content": "0, which can be specified as:"
  },
  {
    "id": 20032,
    "content": "nvvmir"
  },
  {
    "id": 20033,
    "content": "version ="
  },
  {
    "id": 20034,
    "content": "{"
  },
  {
    "id": 20035,
    "content": "0}"
  },
  {
    "id": 20036,
    "content": "0 ="
  },
  {
    "id": 20038,
    "content": "1"
  },
  {
    "id": 20039,
    "content": "3"
  },
  {
    "id": 20040,
    "content": "16"
  },
  {
    "id": 20042,
    "content": "3"
  },
  {
    "id": 20043,
    "content": "21"
  },
  {
    "id": 20046,
    "content": "22"
  },
  {
    "id": 20047,
    "content": "3"
  },
  {
    "id": 20048,
    "content": "25"
  },
  {
    "id": 20052,
    "content": "26"
  },
  {
    "id": 20054,
    "content": "27"
  },
  {
    "id": 20055,
    "content": "Note that for code generation: ld"
  },
  {
    "id": 20056,
    "content": "volatile and st volatile will be generated"
  },
  {
    "id": 20057,
    "content": "3"
  },
  {
    "id": 20058,
    "content": "29"
  },
  {
    "id": 20059,
    "content": "Memory Model for Concurrent Operations  Not applicable"
  },
  {
    "id": 20060,
    "content": "Threads in an NVVM IR program must use atomic operations or barrier synchronization to communicate"
  },
  {
    "id": 20061,
    "content": "3"
  },
  {
    "id": 20062,
    "content": "30"
  },
  {
    "id": 20064,
    "content": "3"
  },
  {
    "id": 20065,
    "content": "31"
  },
  {
    "id": 20066,
    "content": "Fast-Math Flags  Supported"
  },
  {
    "id": 20067,
    "content": "4"
  },
  {
    "id": 20069,
    "content": "5"
  },
  {
    "id": 20070,
    "content": "Constants  Fully supported, except for the following: Token constants is not supported"
  },
  {
    "id": 20073,
    "content": "srcloc is accepted and ignored"
  },
  {
    "id": 20074,
    "content": "The following metadata are understood by the NVVM compiler: Specialized Metadata Nodes llvm"
  },
  {
    "id": 20075,
    "content": "loop"
  },
  {
    "id": 20076,
    "content": "unroll"
  },
  {
    "id": 20077,
    "content": "count llvm"
  },
  {
    "id": 20078,
    "content": "loop"
  },
  {
    "id": 20079,
    "content": "unroll"
  },
  {
    "id": 20080,
    "content": "disable llvm"
  },
  {
    "id": 20081,
    "content": "loop"
  },
  {
    "id": 20082,
    "content": "unroll"
  },
  {
    "id": 20084,
    "content": "compiler"
  },
  {
    "id": 20087,
    "content": "2"
  },
  {
    "id": 20088,
    "content": "Binary Operations  Supported: add fadd sub fsub mul fmul udiv sdiv fdiv urem srem frem 10"
  },
  {
    "id": 20089,
    "content": "3"
  },
  {
    "id": 20090,
    "content": "alloca Instruction  The alloca instruction returns a generic pointer to the local address space"
  },
  {
    "id": 20091,
    "content": "The addrspace() specifier is supported only if num is 0"
  },
  {
    "id": 20092,
    "content": "10"
  },
  {
    "id": 20093,
    "content": "6"
  },
  {
    "id": 20094,
    "content": "2"
  },
  {
    "id": 20095,
    "content": "load Instruction  load atomic is not supported"
  },
  {
    "id": 20096,
    "content": "Use NVVM intrinsic functions instead"
  },
  {
    "id": 20097,
    "content": "10"
  },
  {
    "id": 20098,
    "content": "6"
  },
  {
    "id": 20099,
    "content": "5"
  },
  {
    "id": 20101,
    "content": "10"
  },
  {
    "id": 20102,
    "content": "6"
  },
  {
    "id": 20103,
    "content": "6"
  },
  {
    "id": 20104,
    "content": "atomicrmw Instruction  nand is not supported"
  },
  {
    "id": 20105,
    "content": "The other keywords are supported for i32 , i64 , and i128 types, with the following restrictions"
  },
  {
    "id": 20107,
    "content": "For i128 , only xchg is supported, and only on compute_90 and above"
  },
  {
    "id": 20108,
    "content": "10"
  },
  {
    "id": 20109,
    "content": "6"
  },
  {
    "id": 20110,
    "content": "7"
  },
  {
    "id": 20111,
    "content": "getelementptr Instruction  Fully supported"
  },
  {
    "id": 20112,
    "content": "to See Conversion for a special use case of bitcast"
  },
  {
    "id": 20113,
    "content": "10"
  },
  {
    "id": 20114,
    "content": "8"
  },
  {
    "id": 20116,
    "content": ") Unsupported: landingpad catchpad cleanuppad 11"
  },
  {
    "id": 20117,
    "content": "Note that the constant address space cannot be used as the destination since it is read-only"
  },
  {
    "id": 20118,
    "content": "llvm"
  },
  {
    "id": 20119,
    "content": "maxnum Not supported"
  },
  {
    "id": 20120,
    "content": "11"
  },
  {
    "id": 20121,
    "content": "5"
  },
  {
    "id": 20122,
    "content": "Bit Manipulations Intrinsics  llvm"
  },
  {
    "id": 20123,
    "content": "bitreverse Supported for i8 , i16 , i32 , and i64"
  },
  {
    "id": 20124,
    "content": "llvm"
  },
  {
    "id": 20125,
    "content": "fshr Supported for i8 , i16 , i32 , and i64"
  },
  {
    "id": 20126,
    "content": "11"
  },
  {
    "id": 20127,
    "content": "6"
  },
  {
    "id": 20128,
    "content": "Specialised Arithmetic Intrinsics  llvm"
  },
  {
    "id": 20129,
    "content": "fmuladd Supported"
  },
  {
    "id": 20130,
    "content": "llvm"
  },
  {
    "id": 20131,
    "content": "canonicalize Not supported"
  },
  {
    "id": 20132,
    "content": "11"
  },
  {
    "id": 20133,
    "content": "7"
  },
  {
    "id": 20134,
    "content": "Arithmetic with Overflow Intrinsics  Supported for i16 , i32 , and i64"
  },
  {
    "id": 20135,
    "content": "11"
  },
  {
    "id": 20136,
    "content": "8"
  },
  {
    "id": 20137,
    "content": "Half Precision Floating Point Intrinsics  Supported: llvm"
  },
  {
    "id": 20138,
    "content": "convert"
  },
  {
    "id": 20139,
    "content": "to"
  },
  {
    "id": 20140,
    "content": "fp16 , llvm"
  },
  {
    "id": 20141,
    "content": "convert"
  },
  {
    "id": 20142,
    "content": "from"
  },
  {
    "id": 20143,
    "content": "fp16 11"
  },
  {
    "id": 20144,
    "content": "9"
  },
  {
    "id": 20145,
    "content": "11"
  },
  {
    "id": 20146,
    "content": "18"
  },
  {
    "id": 20147,
    "content": "Memory Use Markers  Supported: llvm"
  },
  {
    "id": 20148,
    "content": "lifetime"
  },
  {
    "id": 20149,
    "content": "start , llvm"
  },
  {
    "id": 20150,
    "content": "lifetime"
  },
  {
    "id": 20151,
    "content": "end , llvm"
  },
  {
    "id": 20152,
    "content": "invariant"
  },
  {
    "id": 20153,
    "content": "start , and llvm"
  },
  {
    "id": 20154,
    "content": "invariant"
  },
  {
    "id": 20155,
    "content": "end"
  },
  {
    "id": 20156,
    "content": "Not supported: llvm"
  },
  {
    "id": 20157,
    "content": "launder"
  },
  {
    "id": 20158,
    "content": "invariant"
  },
  {
    "id": 20159,
    "content": "group , llvm"
  },
  {
    "id": 20160,
    "content": "strip"
  },
  {
    "id": 20161,
    "content": "invariant"
  },
  {
    "id": 20162,
    "content": "group"
  },
  {
    "id": 20163,
    "content": "11"
  },
  {
    "id": 20164,
    "content": "19"
  },
  {
    "id": 20165,
    "content": "General Intrinsics  llvm"
  },
  {
    "id": 20166,
    "content": "var"
  },
  {
    "id": 20167,
    "content": "annotation Accepted and ignored"
  },
  {
    "id": 20172,
    "content": "12"
  },
  {
    "id": 20173,
    "content": "2"
  },
  {
    "id": 20174,
    "content": "Generic Pointers and Non-Generic Pointers  12"
  },
  {
    "id": 20175,
    "content": "2"
  },
  {
    "id": 20176,
    "content": "1"
  },
  {
    "id": 20180,
    "content": "inttoptr and ptrtoint are value preserving instructions when the two operands are of the same size"
  },
  {
    "id": 20182,
    "content": "nvvm"
  },
  {
    "id": 20183,
    "content": "isspacep"
  },
  {
    "id": 20185,
    "content": "i1 @llvm"
  },
  {
    "id": 20186,
    "content": "nvvm"
  },
  {
    "id": 20187,
    "content": "isspacep"
  },
  {
    "id": 20189,
    "content": "nvvm"
  },
  {
    "id": 20190,
    "content": "isspacep"
  },
  {
    "id": 20191,
    "content": "const(i8*) i1 @llvm"
  },
  {
    "id": 20192,
    "content": "nvvm"
  },
  {
    "id": 20193,
    "content": "isspacep"
  },
  {
    "id": 20194,
    "content": "global(i8*) i1 @llvm"
  },
  {
    "id": 20195,
    "content": "nvvm"
  },
  {
    "id": 20196,
    "content": "isspacep"
  },
  {
    "id": 20197,
    "content": "local(i8*) i1 @llvm"
  },
  {
    "id": 20198,
    "content": "nvvm"
  },
  {
    "id": 20199,
    "content": "isspacep"
  },
  {
    "id": 20201,
    "content": "12"
  },
  {
    "id": 20202,
    "content": "2"
  },
  {
    "id": 20203,
    "content": "3"
  },
  {
    "id": 20205,
    "content": "12"
  },
  {
    "id": 20206,
    "content": "3"
  },
  {
    "id": 20209,
    "content": "13"
  },
  {
    "id": 20210,
    "content": "2"
  },
  {
    "id": 20212,
    "content": "annotations"
  },
  {
    "id": 20214,
    "content": "nvvm"
  },
  {
    "id": 20215,
    "content": "annotations ="
  },
  {
    "id": 20216,
    "content": "{"
  },
  {
    "id": 20217,
    "content": "12,"
  },
  {
    "id": 20218,
    "content": "13}"
  },
  {
    "id": 20219,
    "content": "12 ="
  },
  {
    "id": 20220,
    "content": "{void (i32, i32)* @_Z6kernelii, \"kernel\", i32 1}"
  },
  {
    "id": 20221,
    "content": "13 ="
  },
  {
    "id": 20222,
    "content": "{void ()* @_Z7kernel2v,"
  },
  {
    "id": 20224,
    "content": "13"
  },
  {
    "id": 20225,
    "content": "3"
  },
  {
    "id": 20230,
    "content": "managed global variable Signifies that variable is a UVM managed variable"
  },
  {
    "id": 20231,
    "content": "14 Texture and Surface  14"
  },
  {
    "id": 20232,
    "content": "1"
  },
  {
    "id": 20234,
    "content": "argument as shown below In llvm used Global Variable 14"
  },
  {
    "id": 20235,
    "content": "2"
  },
  {
    "id": 20238,
    "content": "15 NVVM Specific Intrinsic Functions  15"
  },
  {
    "id": 20239,
    "content": "1"
  },
  {
    "id": 20241,
    "content": "declare float @llvm"
  },
  {
    "id": 20242,
    "content": "nvvm"
  },
  {
    "id": 20243,
    "content": "atomic"
  },
  {
    "id": 20244,
    "content": "load"
  },
  {
    "id": 20245,
    "content": "add"
  },
  {
    "id": 20246,
    "content": "f32"
  },
  {
    "id": 20247,
    "content": "p0f32(float* address, float val) declare float @llvm"
  },
  {
    "id": 20248,
    "content": "nvvm"
  },
  {
    "id": 20249,
    "content": "atomic"
  },
  {
    "id": 20250,
    "content": "load"
  },
  {
    "id": 20251,
    "content": "add"
  },
  {
    "id": 20252,
    "content": "f32"
  },
  {
    "id": 20253,
    "content": "p1f32(float addrspace(1)* address, float val) declare float @llvm"
  },
  {
    "id": 20254,
    "content": "nvvm"
  },
  {
    "id": 20255,
    "content": "atomic"
  },
  {
    "id": 20256,
    "content": "load"
  },
  {
    "id": 20257,
    "content": "add"
  },
  {
    "id": 20258,
    "content": "f32"
  },
  {
    "id": 20259,
    "content": "p3f32(float addrspace(3)* address, float val) declare double @llvm"
  },
  {
    "id": 20260,
    "content": "nvvm"
  },
  {
    "id": 20261,
    "content": "atomic"
  },
  {
    "id": 20262,
    "content": "load"
  },
  {
    "id": 20263,
    "content": "add"
  },
  {
    "id": 20264,
    "content": "f64"
  },
  {
    "id": 20265,
    "content": "p0f64(double* address, double val) declare double @llvm"
  },
  {
    "id": 20266,
    "content": "nvvm"
  },
  {
    "id": 20267,
    "content": "atomic"
  },
  {
    "id": 20268,
    "content": "load"
  },
  {
    "id": 20269,
    "content": "add"
  },
  {
    "id": 20270,
    "content": "f64"
  },
  {
    "id": 20271,
    "content": "p1f64(double addrspace(1)* address, double val) declare double @llvm"
  },
  {
    "id": 20272,
    "content": "nvvm"
  },
  {
    "id": 20273,
    "content": "atomic"
  },
  {
    "id": 20274,
    "content": "load"
  },
  {
    "id": 20275,
    "content": "add"
  },
  {
    "id": 20276,
    "content": "f64"
  },
  {
    "id": 20278,
    "content": "declare i32 @llvm"
  },
  {
    "id": 20279,
    "content": "nvvm"
  },
  {
    "id": 20280,
    "content": "atomic"
  },
  {
    "id": 20281,
    "content": "load"
  },
  {
    "id": 20282,
    "content": "inc"
  },
  {
    "id": 20283,
    "content": "32"
  },
  {
    "id": 20284,
    "content": "p0i32(i32* address, i32 val) declare i32 @llvm"
  },
  {
    "id": 20285,
    "content": "nvvm"
  },
  {
    "id": 20286,
    "content": "atomic"
  },
  {
    "id": 20287,
    "content": "load"
  },
  {
    "id": 20288,
    "content": "inc"
  },
  {
    "id": 20289,
    "content": "32"
  },
  {
    "id": 20290,
    "content": "p1i32(i32 addrspace(1)* address, i32 val) declare i32 @llvm"
  },
  {
    "id": 20291,
    "content": "nvvm"
  },
  {
    "id": 20292,
    "content": "atomic"
  },
  {
    "id": 20293,
    "content": "load"
  },
  {
    "id": 20294,
    "content": "inc"
  },
  {
    "id": 20295,
    "content": "32"
  },
  {
    "id": 20297,
    "content": "nvvm"
  },
  {
    "id": 20298,
    "content": "atomic"
  },
  {
    "id": 20299,
    "content": "load"
  },
  {
    "id": 20300,
    "content": "dec"
  },
  {
    "id": 20301,
    "content": "32"
  },
  {
    "id": 20302,
    "content": "p0i32(i32* address, i32 val) declare i32 @llvm"
  },
  {
    "id": 20303,
    "content": "nvvm"
  },
  {
    "id": 20304,
    "content": "atomic"
  },
  {
    "id": 20305,
    "content": "load"
  },
  {
    "id": 20306,
    "content": "dec"
  },
  {
    "id": 20307,
    "content": "32"
  },
  {
    "id": 20308,
    "content": "p1i32(i32 addrspace(1)* address, i32 val) declare i32 @llvm"
  },
  {
    "id": 20309,
    "content": "nvvm"
  },
  {
    "id": 20310,
    "content": "atomic"
  },
  {
    "id": 20311,
    "content": "load"
  },
  {
    "id": 20312,
    "content": "dec"
  },
  {
    "id": 20313,
    "content": "32"
  },
  {
    "id": 20315,
    "content": "15"
  },
  {
    "id": 20316,
    "content": "2"
  },
  {
    "id": 20317,
    "content": "Barrier and Memory Fence  declare void @llvm"
  },
  {
    "id": 20318,
    "content": "nvvm"
  },
  {
    "id": 20320,
    "content": "nvvm"
  },
  {
    "id": 20321,
    "content": "barrier0() are visible to all threads in the block"
  },
  {
    "id": 20322,
    "content": "declare i32 @llvm"
  },
  {
    "id": 20323,
    "content": "nvvm"
  },
  {
    "id": 20324,
    "content": "barrier0"
  },
  {
    "id": 20325,
    "content": "popc(i32) is identical to llvm"
  },
  {
    "id": 20326,
    "content": "nvvm"
  },
  {
    "id": 20328,
    "content": "declare i32 @llvm"
  },
  {
    "id": 20329,
    "content": "nvvm"
  },
  {
    "id": 20330,
    "content": "barrier0"
  },
  {
    "id": 20331,
    "content": "and(i32) is identical to llvm"
  },
  {
    "id": 20332,
    "content": "nvvm"
  },
  {
    "id": 20334,
    "content": "declare i32 @llvm"
  },
  {
    "id": 20335,
    "content": "nvvm"
  },
  {
    "id": 20336,
    "content": "barrier0"
  },
  {
    "id": 20337,
    "content": "or(i32) is identical to llvm"
  },
  {
    "id": 20338,
    "content": "nvvm"
  },
  {
    "id": 20340,
    "content": "declare void @llvm"
  },
  {
    "id": 20341,
    "content": "nvvm"
  },
  {
    "id": 20345,
    "content": "nvvm"
  },
  {
    "id": 20346,
    "content": "membar"
  },
  {
    "id": 20347,
    "content": "cta() is a memory fence at the thread block level"
  },
  {
    "id": 20348,
    "content": "declare void @llvm"
  },
  {
    "id": 20349,
    "content": "nvvm"
  },
  {
    "id": 20352,
    "content": "3"
  },
  {
    "id": 20354,
    "content": "15"
  },
  {
    "id": 20355,
    "content": "4"
  },
  {
    "id": 20357,
    "content": "nvvm"
  },
  {
    "id": 20358,
    "content": "read"
  },
  {
    "id": 20359,
    "content": "ptx"
  },
  {
    "id": 20360,
    "content": "sreg"
  },
  {
    "id": 20361,
    "content": "tid"
  },
  {
    "id": 20362,
    "content": "x() declare i32 @llvm"
  },
  {
    "id": 20363,
    "content": "nvvm"
  },
  {
    "id": 20364,
    "content": "read"
  },
  {
    "id": 20365,
    "content": "ptx"
  },
  {
    "id": 20366,
    "content": "sreg"
  },
  {
    "id": 20367,
    "content": "tid"
  },
  {
    "id": 20368,
    "content": "y() declare i32 @llvm"
  },
  {
    "id": 20369,
    "content": "nvvm"
  },
  {
    "id": 20370,
    "content": "read"
  },
  {
    "id": 20371,
    "content": "ptx"
  },
  {
    "id": 20372,
    "content": "sreg"
  },
  {
    "id": 20373,
    "content": "tid"
  },
  {
    "id": 20374,
    "content": "z() declare i32 @llvm"
  },
  {
    "id": 20375,
    "content": "nvvm"
  },
  {
    "id": 20376,
    "content": "read"
  },
  {
    "id": 20377,
    "content": "ptx"
  },
  {
    "id": 20378,
    "content": "sreg"
  },
  {
    "id": 20379,
    "content": "ntid"
  },
  {
    "id": 20380,
    "content": "x() declare i32 @llvm"
  },
  {
    "id": 20381,
    "content": "nvvm"
  },
  {
    "id": 20382,
    "content": "read"
  },
  {
    "id": 20383,
    "content": "ptx"
  },
  {
    "id": 20384,
    "content": "sreg"
  },
  {
    "id": 20385,
    "content": "ntid"
  },
  {
    "id": 20386,
    "content": "y() declare i32 @llvm"
  },
  {
    "id": 20387,
    "content": "nvvm"
  },
  {
    "id": 20388,
    "content": "read"
  },
  {
    "id": 20389,
    "content": "ptx"
  },
  {
    "id": 20390,
    "content": "sreg"
  },
  {
    "id": 20391,
    "content": "ntid"
  },
  {
    "id": 20392,
    "content": "z() declare i32 @llvm"
  },
  {
    "id": 20393,
    "content": "nvvm"
  },
  {
    "id": 20394,
    "content": "read"
  },
  {
    "id": 20395,
    "content": "ptx"
  },
  {
    "id": 20396,
    "content": "sreg"
  },
  {
    "id": 20397,
    "content": "ctaid"
  },
  {
    "id": 20398,
    "content": "x() declare i32 @llvm"
  },
  {
    "id": 20399,
    "content": "nvvm"
  },
  {
    "id": 20400,
    "content": "read"
  },
  {
    "id": 20401,
    "content": "ptx"
  },
  {
    "id": 20402,
    "content": "sreg"
  },
  {
    "id": 20403,
    "content": "ctaid"
  },
  {
    "id": 20404,
    "content": "y() declare i32 @llvm"
  },
  {
    "id": 20405,
    "content": "nvvm"
  },
  {
    "id": 20406,
    "content": "read"
  },
  {
    "id": 20407,
    "content": "ptx"
  },
  {
    "id": 20408,
    "content": "sreg"
  },
  {
    "id": 20409,
    "content": "ctaid"
  },
  {
    "id": 20410,
    "content": "z() declare i32 @llvm"
  },
  {
    "id": 20411,
    "content": "nvvm"
  },
  {
    "id": 20412,
    "content": "read"
  },
  {
    "id": 20413,
    "content": "ptx"
  },
  {
    "id": 20414,
    "content": "sreg"
  },
  {
    "id": 20415,
    "content": "nctaid"
  },
  {
    "id": 20416,
    "content": "x() declare i32 @llvm"
  },
  {
    "id": 20417,
    "content": "nvvm"
  },
  {
    "id": 20418,
    "content": "read"
  },
  {
    "id": 20419,
    "content": "ptx"
  },
  {
    "id": 20420,
    "content": "sreg"
  },
  {
    "id": 20421,
    "content": "nctaid"
  },
  {
    "id": 20422,
    "content": "y() declare i32 @llvm"
  },
  {
    "id": 20423,
    "content": "nvvm"
  },
  {
    "id": 20424,
    "content": "read"
  },
  {
    "id": 20425,
    "content": "ptx"
  },
  {
    "id": 20426,
    "content": "sreg"
  },
  {
    "id": 20427,
    "content": "nctaid"
  },
  {
    "id": 20428,
    "content": "z() declare i32 @llvm"
  },
  {
    "id": 20429,
    "content": "nvvm"
  },
  {
    "id": 20430,
    "content": "read"
  },
  {
    "id": 20431,
    "content": "ptx"
  },
  {
    "id": 20432,
    "content": "sreg"
  },
  {
    "id": 20433,
    "content": "warpsize() 15"
  },
  {
    "id": 20434,
    "content": "5"
  },
  {
    "id": 20436,
    "content": "declare i64 %llvm"
  },
  {
    "id": 20437,
    "content": "nvvm"
  },
  {
    "id": 20438,
    "content": "texsurf"
  },
  {
    "id": 20439,
    "content": "handle"
  },
  {
    "id": 20440,
    "content": "p1i64(metadata, i64 addrspace(1)*) See Accessing Texture Memory or Surface Memory for details"
  },
  {
    "id": 20442,
    "content": "5"
  },
  {
    "id": 20443,
    "content": "1"
  },
  {
    "id": 20445,
    "content": "on 8-bit data channels, the input operands are of type i16"
  },
  {
    "id": 20446,
    "content": "(i64 %tex, i32 %x, i32 %r, i32 %g, i32 %b, i32 %a) ;; Formatted void @llvm"
  },
  {
    "id": 20447,
    "content": "nvvm"
  },
  {
    "id": 20448,
    "content": "sust"
  },
  {
    "id": 20449,
    "content": "p"
  },
  {
    "id": 20450,
    "content": "1d"
  },
  {
    "id": 20452,
    "content": "nvvm"
  },
  {
    "id": 20453,
    "content": "sust"
  },
  {
    "id": 20454,
    "content": "b"
  },
  {
    "id": 20455,
    "content": "1d"
  },
  {
    "id": 20456,
    "content": "array"
  },
  {
    "id": 20457,
    "content": "i8"
  },
  {
    "id": 20458,
    "content": "(i64 %tex, i32 %idx, i32 %x, i16 %r, i16 %g, i16 %b, i16 %a) void @llvm"
  },
  {
    "id": 20459,
    "content": "nvvm"
  },
  {
    "id": 20460,
    "content": "sust"
  },
  {
    "id": 20461,
    "content": "b"
  },
  {
    "id": 20462,
    "content": "1d"
  },
  {
    "id": 20463,
    "content": "array"
  },
  {
    "id": 20464,
    "content": "v4i16"
  },
  {
    "id": 20465,
    "content": "(i64 %tex, i32 %idx, i32 %x, i16 %r, i16 %g, i16 %b, i16 %a) void @llvm"
  },
  {
    "id": 20466,
    "content": "nvvm"
  },
  {
    "id": 20467,
    "content": "sust"
  },
  {
    "id": 20468,
    "content": "b"
  },
  {
    "id": 20469,
    "content": "1d"
  },
  {
    "id": 20470,
    "content": "array"
  },
  {
    "id": 20471,
    "content": "v4i32"
  },
  {
    "id": 20472,
    "content": "(i64 %tex, i32 %idx, i32 %x, i32 %r, i32 %g, i32 %b, i32 %a) ;; Formatted void @llvm"
  },
  {
    "id": 20473,
    "content": "nvvm"
  },
  {
    "id": 20474,
    "content": "sust"
  },
  {
    "id": 20475,
    "content": "p"
  },
  {
    "id": 20476,
    "content": "1d"
  },
  {
    "id": 20477,
    "content": "array"
  },
  {
    "id": 20479,
    "content": "nvvm"
  },
  {
    "id": 20480,
    "content": "sust"
  },
  {
    "id": 20481,
    "content": "b"
  },
  {
    "id": 20482,
    "content": "2d"
  },
  {
    "id": 20483,
    "content": "i8"
  },
  {
    "id": 20484,
    "content": "(i64 %tex, i32 %x, i32 %y, i16 %r, i16 %g, i16 %b, i16 %a) void @llvm"
  },
  {
    "id": 20485,
    "content": "nvvm"
  },
  {
    "id": 20486,
    "content": "sust"
  },
  {
    "id": 20487,
    "content": "b"
  },
  {
    "id": 20488,
    "content": "2d"
  },
  {
    "id": 20489,
    "content": "v4i16"
  },
  {
    "id": 20490,
    "content": "(i64 %tex, i32 %x, i32 %y, i16 %r, i16 %g, i16 %b, i16 %a) void @llvm"
  },
  {
    "id": 20491,
    "content": "nvvm"
  },
  {
    "id": 20492,
    "content": "sust"
  },
  {
    "id": 20493,
    "content": "b"
  },
  {
    "id": 20494,
    "content": "2d"
  },
  {
    "id": 20495,
    "content": "v4i32"
  },
  {
    "id": 20496,
    "content": "(i64 %tex, i32 %x, i32 %y, i32 %r, i32 %g, i32 %b, i32 %a) ;; Formatted void @llvm"
  },
  {
    "id": 20497,
    "content": "nvvm"
  },
  {
    "id": 20498,
    "content": "sust"
  },
  {
    "id": 20499,
    "content": "p"
  },
  {
    "id": 20500,
    "content": "2d"
  },
  {
    "id": 20502,
    "content": "nvvm"
  },
  {
    "id": 20503,
    "content": "sust"
  },
  {
    "id": 20504,
    "content": "b"
  },
  {
    "id": 20505,
    "content": "2d"
  },
  {
    "id": 20506,
    "content": "array"
  },
  {
    "id": 20507,
    "content": "i8"
  },
  {
    "id": 20508,
    "content": "(i64 %tex, i32 %idx, i32 %x, i32 %y, i16 %r, i16 %g) void @llvm"
  },
  {
    "id": 20509,
    "content": "nvvm"
  },
  {
    "id": 20510,
    "content": "sust"
  },
  {
    "id": 20511,
    "content": "b"
  },
  {
    "id": 20512,
    "content": "2d"
  },
  {
    "id": 20513,
    "content": "array"
  },
  {
    "id": 20514,
    "content": "v2i16"
  },
  {
    "id": 20515,
    "content": "(i64 %tex, i32 %idx, i32 %x, i32 %y, i16 %r, i16 %g) void @llvm"
  },
  {
    "id": 20516,
    "content": "nvvm"
  },
  {
    "id": 20517,
    "content": "sust"
  },
  {
    "id": 20518,
    "content": "b"
  },
  {
    "id": 20519,
    "content": "2d"
  },
  {
    "id": 20520,
    "content": "array"
  },
  {
    "id": 20521,
    "content": "v2i32"
  },
  {
    "id": 20522,
    "content": "(i64 %tex, i32 %idx, i32 %x, i32 %y, i32 %r, i32 %g) void @llvm"
  },
  {
    "id": 20523,
    "content": "nvvm"
  },
  {
    "id": 20524,
    "content": "sust"
  },
  {
    "id": 20525,
    "content": "b"
  },
  {
    "id": 20526,
    "content": "2d"
  },
  {
    "id": 20527,
    "content": "array"
  },
  {
    "id": 20528,
    "content": "v2i64"
  },
  {
    "id": 20529,
    "content": "(i64 %tex, i32 %idx, i32 %x, i32 %y, i64 %r, i64 %g) void @llvm"
  },
  {
    "id": 20530,
    "content": "nvvm"
  },
  {
    "id": 20531,
    "content": "sust"
  },
  {
    "id": 20532,
    "content": "b"
  },
  {
    "id": 20533,
    "content": "2d"
  },
  {
    "id": 20534,
    "content": "array"
  },
  {
    "id": 20535,
    "content": "v4i8"
  },
  {
    "id": 20536,
    "content": "(i64 %tex, i32 %idx, i32 %x, i32 %y, i16 %r, i16 %g, i16 %b, i16 %a) void @llvm"
  },
  {
    "id": 20537,
    "content": "nvvm"
  },
  {
    "id": 20538,
    "content": "sust"
  },
  {
    "id": 20539,
    "content": "b"
  },
  {
    "id": 20540,
    "content": "2d"
  },
  {
    "id": 20541,
    "content": "array"
  },
  {
    "id": 20542,
    "content": "v4i16"
  },
  {
    "id": 20543,
    "content": "(i64 %tex, i32 %idx, i32 %x, i32 %y, i16 %r, i16 %g, i16 %b, i16 %a) void @llvm"
  },
  {
    "id": 20544,
    "content": "nvvm"
  },
  {
    "id": 20545,
    "content": "sust"
  },
  {
    "id": 20546,
    "content": "b"
  },
  {
    "id": 20547,
    "content": "2d"
  },
  {
    "id": 20548,
    "content": "array"
  },
  {
    "id": 20549,
    "content": "v4i32"
  },
  {
    "id": 20550,
    "content": "(i64 %tex, i32 %idx, i32 %x, i32 %y, i32 %r, i32 %g, i32 %b, i32 %a) ;; Formatted void @llvm"
  },
  {
    "id": 20551,
    "content": "nvvm"
  },
  {
    "id": 20552,
    "content": "sust"
  },
  {
    "id": 20553,
    "content": "p"
  },
  {
    "id": 20554,
    "content": "2d"
  },
  {
    "id": 20555,
    "content": "array"
  },
  {
    "id": 20556,
    "content": "i32 (i64 %tex, i32 %idx, i32 %x, i32 %y, i32 %r, i32 %g) void @llvm"
  },
  {
    "id": 20557,
    "content": "nvvm"
  },
  {
    "id": 20558,
    "content": "sust"
  },
  {
    "id": 20559,
    "content": "p"
  },
  {
    "id": 20560,
    "content": "2d"
  },
  {
    "id": 20561,
    "content": "array"
  },
  {
    "id": 20562,
    "content": "v4i32"
  },
  {
    "id": 20564,
    "content": "nvvm"
  },
  {
    "id": 20565,
    "content": "sust"
  },
  {
    "id": 20566,
    "content": "b"
  },
  {
    "id": 20567,
    "content": "3d"
  },
  {
    "id": 20568,
    "content": "i8"
  },
  {
    "id": 20569,
    "content": "(i64 %tex, i32 %x, i32 %y, i32 %z, i16 %r, i16 %g, i16 %b, i16 %a) void @llvm"
  },
  {
    "id": 20570,
    "content": "nvvm"
  },
  {
    "id": 20571,
    "content": "sust"
  },
  {
    "id": 20572,
    "content": "b"
  },
  {
    "id": 20573,
    "content": "3d"
  },
  {
    "id": 20574,
    "content": "v4i16"
  },
  {
    "id": 20575,
    "content": "(i64 %tex, i32 %x, i32 %y, i32 %z, i16 %r, i16 %g, i16 %b, i16 %a) void @llvm"
  },
  {
    "id": 20576,
    "content": "nvvm"
  },
  {
    "id": 20577,
    "content": "sust"
  },
  {
    "id": 20578,
    "content": "b"
  },
  {
    "id": 20579,
    "content": "3d"
  },
  {
    "id": 20580,
    "content": "v4i32"
  },
  {
    "id": 20581,
    "content": "(i64 %tex, i32 %x, i32 %y, i32 %z, i32 %r, i32 %g, i32 %b, i32 %a) ;; Formatted void @llvm"
  },
  {
    "id": 20582,
    "content": "nvvm"
  },
  {
    "id": 20583,
    "content": "sust"
  },
  {
    "id": 20584,
    "content": "p"
  },
  {
    "id": 20585,
    "content": "3d"
  },
  {
    "id": 20586,
    "content": "i32"
  },
  {
    "id": 20588,
    "content": "declare void @llvm"
  },
  {
    "id": 20589,
    "content": "nvvm"
  },
  {
    "id": 20590,
    "content": "bar"
  },
  {
    "id": 20591,
    "content": "warp"
  },
  {
    "id": 20593,
    "content": "The argument %membership is a 32bit mask, with each bit corresponding to a lane in the warp"
  },
  {
    "id": 20595,
    "content": "nvvm"
  },
  {
    "id": 20596,
    "content": "bar"
  },
  {
    "id": 20597,
    "content": "warp"
  },
  {
    "id": 20599,
    "content": "Otherwise, the behavior is undefined"
  },
  {
    "id": 20600,
    "content": "15"
  },
  {
    "id": 20601,
    "content": "6"
  },
  {
    "id": 20602,
    "content": "2"
  },
  {
    "id": 20604,
    "content": "declare {i32, i1} @llvm"
  },
  {
    "id": 20605,
    "content": "nvvm"
  },
  {
    "id": 20606,
    "content": "shfl"
  },
  {
    "id": 20607,
    "content": "sync"
  },
  {
    "id": 20610,
    "content": "returned i1 value is set to 1 if the source lane j is in range, and otherwise set to 0"
  },
  {
    "id": 20613,
    "content": "These intrinsics are only available on compute_70 or higher"
  },
  {
    "id": 20614,
    "content": "15"
  },
  {
    "id": 20615,
    "content": "6"
  },
  {
    "id": 20616,
    "content": "5"
  },
  {
    "id": 20617,
    "content": "2"
  },
  {
    "id": 20620,
    "content": "16"
  },
  {
    "id": 20622,
    "content": "org/7"
  },
  {
    "id": 20623,
    "content": "0"
  },
  {
    "id": 20624,
    "content": "1/docs/LangRef"
  },
  {
    "id": 20626,
    "content": "org/7"
  },
  {
    "id": 20627,
    "content": "0"
  },
  {
    "id": 20628,
    "content": "1/docs/SourceLevelDebugging"
  },
  {
    "id": 20629,
    "content": "html )"
  },
  {
    "id": 20631,
    "content": "llvm"
  },
  {
    "id": 20632,
    "content": "dbg"
  },
  {
    "id": 20634,
    "content": "nvvmir"
  },
  {
    "id": 20636,
    "content": "The debug resolution (e"
  },
  {
    "id": 20637,
    "content": "g"
  },
  {
    "id": 20640,
    "content": "17 NVVM ABI for PTX  17"
  },
  {
    "id": 20641,
    "content": "1"
  },
  {
    "id": 20645,
    "content": "17"
  },
  {
    "id": 20646,
    "content": "2"
  },
  {
    "id": 20648,
    "content": "u32 or"
  },
  {
    "id": 20649,
    "content": "b32 (zero-extended if unsigned)"
  },
  {
    "id": 20650,
    "content": "s32 or"
  },
  {
    "id": 20651,
    "content": "b32 (sign-extended if signed) 64"
  },
  {
    "id": 20652,
    "content": "u64 or"
  },
  {
    "id": 20653,
    "content": "b64 (if unsigned)"
  },
  {
    "id": 20654,
    "content": "s64 or"
  },
  {
    "id": 20655,
    "content": "b64 (if signed) Pointer types (without byval attribute) 32"
  },
  {
    "id": 20656,
    "content": "u32 or"
  },
  {
    "id": 20657,
    "content": "b32 64"
  },
  {
    "id": 20658,
    "content": "u64 or"
  },
  {
    "id": 20659,
    "content": "b64 Floating-point types 32"
  },
  {
    "id": 20660,
    "content": "f32 or"
  },
  {
    "id": 20661,
    "content": "b32 64"
  },
  {
    "id": 20662,
    "content": "f64 or"
  },
  {
    "id": 20663,
    "content": "b64 Aggregate types Any size"
  },
  {
    "id": 20665,
    "content": "Version 1"
  },
  {
    "id": 20667,
    "content": "8"
  },
  {
    "id": 20668,
    "content": "Version 2 0 Updated the NVVM IR to version 2 0 which is incompatible with NVVM IR version 1"
  },
  {
    "id": 20669,
    "content": "x Removed address space conversion intrinsics"
  },
  {
    "id": 20672,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 20684,
    "content": "19"
  },
  {
    "id": 20685,
    "content": "2"
  },
  {
    "id": 20686,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 20687,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 20688,
    "content": "19"
  },
  {
    "id": 20689,
    "content": "3"
  },
  {
    "id": 20691,
    "content": "S"
  },
  {
    "id": 20694,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 20695,
    "content": "Navigation"
  },
  {
    "id": 20696,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 20698,
    "content": "5"
  },
  {
    "id": 20699,
    "content": "1 libdevice User's Guide 1 __nv_ynf Search Results libdevice User's Guide ( PDF ) - v12"
  },
  {
    "id": 20700,
    "content": "5"
  },
  {
    "id": 20704,
    "content": "pageBottom();\n1"
  },
  {
    "id": 20706,
    "content": "Compatible input can be generated by tools and libraries that produce LLVM 7"
  },
  {
    "id": 20708,
    "content": "1"
  },
  {
    "id": 20709,
    "content": "2"
  },
  {
    "id": 20710,
    "content": "Thread Safety  libNVVM API provides a thread-safe interface to libNVVM"
  },
  {
    "id": 20712,
    "content": "1"
  },
  {
    "id": 20713,
    "content": "3"
  },
  {
    "id": 20714,
    "content": "Module  This chapter presents the API of the libNVVM library"
  },
  {
    "id": 20716,
    "content": "2"
  },
  {
    "id": 20717,
    "content": "1"
  },
  {
    "id": 20718,
    "content": "Enumerations  enum nvvmResult  NVVM API call result code"
  },
  {
    "id": 20720,
    "content": "2"
  },
  {
    "id": 20722,
    "content": "3"
  },
  {
    "id": 20724,
    "content": "3"
  },
  {
    "id": 20725,
    "content": "1"
  },
  {
    "id": 20730,
    "content": "4"
  },
  {
    "id": 20731,
    "content": "1"
  },
  {
    "id": 20733,
    "content": "0"
  },
  {
    "id": 20734,
    "content": "1 bitcode representation or in the LLVM 7"
  },
  {
    "id": 20735,
    "content": "0"
  },
  {
    "id": 20744,
    "content": "* name )  Add a module level NVVM IR to a program"
  },
  {
    "id": 20746,
    "content": "possible"
  },
  {
    "id": 20748,
    "content": "4"
  },
  {
    "id": 20749,
    "content": "2"
  },
  {
    "id": 20752,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 20764,
    "content": "5"
  },
  {
    "id": 20765,
    "content": "2"
  },
  {
    "id": 20766,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 20767,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 20768,
    "content": "5"
  },
  {
    "id": 20769,
    "content": "3"
  },
  {
    "id": 20771,
    "content": "S"
  },
  {
    "id": 20774,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 20775,
    "content": "Navigation"
  },
  {
    "id": 20776,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 20777,
    "content": "pageBottom();}\n1"
  },
  {
    "id": 20779,
    "content": "It also discusses EGL interoperability"
  },
  {
    "id": 20780,
    "content": "2"
  },
  {
    "id": 20784,
    "content": "nvidia"
  },
  {
    "id": 20785,
    "content": "com/cuda/cuda-c-programming-guide/index html CUDA C++ Best Practices Guide: https: docs"
  },
  {
    "id": 20786,
    "content": "nvidia"
  },
  {
    "id": 20787,
    "content": "com/cuda/cuda-c-best-practices-guide/index"
  },
  {
    "id": 20788,
    "content": "html 3"
  },
  {
    "id": 20791,
    "content": "capability is less than 7"
  },
  {
    "id": 20792,
    "content": "2"
  },
  {
    "id": 20794,
    "content": "3"
  },
  {
    "id": 20795,
    "content": "1"
  },
  {
    "id": 20802,
    "content": "3"
  },
  {
    "id": 20803,
    "content": "2"
  },
  {
    "id": 20809,
    "content": "of allocatable device memory as there is no swap space to move memory pages to swap area"
  },
  {
    "id": 20810,
    "content": "4"
  },
  {
    "id": 20812,
    "content": "efficient performance for the application"
  },
  {
    "id": 20813,
    "content": "4"
  },
  {
    "id": 20814,
    "content": "1"
  },
  {
    "id": 20819,
    "content": "Pageable Host Memory Use pageable host memory for buffers whose accessibility is limited to the CPU"
  },
  {
    "id": 20821,
    "content": "2 are I/O coherent and others are not I/O coherent"
  },
  {
    "id": 20828,
    "content": "applications to determine the correct memory selection"
  },
  {
    "id": 20829,
    "content": "4"
  },
  {
    "id": 20830,
    "content": "2"
  },
  {
    "id": 20833,
    "content": "nvidia"
  },
  {
    "id": 20834,
    "content": "com/cuda/cuda-c-best-practices-guide/index"
  },
  {
    "id": 20836,
    "content": "nvidia"
  },
  {
    "id": 20837,
    "content": "com/cuda/cuda-c-best-practices-guide/index"
  },
  {
    "id": 20846,
    "content": "2, because those devices do not have I/O coherency"
  },
  {
    "id": 20848,
    "content": "memory"
  },
  {
    "id": 20849,
    "content": "4"
  },
  {
    "id": 20850,
    "content": "3"
  },
  {
    "id": 20853,
    "content": "The performance of unified memory on Tegra® can be improved by providing data prefetching hints"
  },
  {
    "id": 20855,
    "content": "nvidia"
  },
  {
    "id": 20856,
    "content": "com/cuda/cuda-c-programming-guide/index"
  },
  {
    "id": 20857,
    "content": "html#um-coherency-hd to prefetch the data"
  },
  {
    "id": 20860,
    "content": "Programming Guide at the following web site: https: docs"
  },
  {
    "id": 20861,
    "content": "nvidia"
  },
  {
    "id": 20862,
    "content": "com/cuda/cuda-c-programming-guide/index"
  },
  {
    "id": 20867,
    "content": "5"
  },
  {
    "id": 20868,
    "content": "1"
  },
  {
    "id": 20869,
    "content": "3"
  },
  {
    "id": 20872,
    "content": "height;"
  },
  {
    "id": 20876,
    "content": "5"
  },
  {
    "id": 20877,
    "content": "1"
  },
  {
    "id": 20878,
    "content": "4"
  },
  {
    "id": 20879,
    "content": "Implicit Synchronization  EGLStream provides implicit synchronization in an application"
  },
  {
    "id": 20882,
    "content": "The EGLStreams_CUDA_Interop CUDA sample code shows the usage of EGLStream in detail"
  },
  {
    "id": 20883,
    "content": "5"
  },
  {
    "id": 20884,
    "content": "1"
  },
  {
    "id": 20885,
    "content": "5"
  },
  {
    "id": 20888,
    "content": "5"
  },
  {
    "id": 20889,
    "content": "1"
  },
  {
    "id": 20890,
    "content": "6"
  },
  {
    "id": 20895,
    "content": "5"
  },
  {
    "id": 20896,
    "content": "2"
  },
  {
    "id": 20898,
    "content": "following web site: https: www"
  },
  {
    "id": 20899,
    "content": "khronos"
  },
  {
    "id": 20900,
    "content": "org/registry/EGL/extensions/KHR/EGL_KHR_image_base"
  },
  {
    "id": 20901,
    "content": "txt 5"
  },
  {
    "id": 20902,
    "content": "2"
  },
  {
    "id": 20903,
    "content": "1"
  },
  {
    "id": 20905,
    "content": "operating systems"
  },
  {
    "id": 20912,
    "content": "6"
  },
  {
    "id": 20913,
    "content": "CUDA Upgradable Package for Jetson  CUDA introduced an upgrade path starting with JetPack SDK 5"
  },
  {
    "id": 20914,
    "content": "0 which provides an option to update the CUDA driver and the CUDA toolkit to the latest version"
  },
  {
    "id": 20915,
    "content": "Prerequisite  The Jetson device must be installed with a compatible NVIDIA JetPack version"
  },
  {
    "id": 20916,
    "content": "Refer to Use the Right Upgrade Package for more info"
  },
  {
    "id": 20917,
    "content": "6"
  },
  {
    "id": 20918,
    "content": "1"
  },
  {
    "id": 20919,
    "content": "2"
  },
  {
    "id": 20922,
    "content": "Taking 11"
  },
  {
    "id": 20924,
    "content": "* - Just In Time - Link Time Optimization (CUDA 11"
  },
  {
    "id": 20925,
    "content": "8 and later only) libnvidia-ptxjitcompiler"
  },
  {
    "id": 20926,
    "content": "so"
  },
  {
    "id": 20928,
    "content": "8 driver interfaces"
  },
  {
    "id": 20930,
    "content": "Get:1 https: developer"
  },
  {
    "id": 20931,
    "content": "download"
  },
  {
    "id": 20932,
    "content": "nvidia"
  },
  {
    "id": 20933,
    "content": "com/compute/cuda/repos/ubuntu2004/arm64 cuda-compat-11-8 11"
  },
  {
    "id": 20934,
    "content": "8"
  },
  {
    "id": 20936,
    "content": "148682 files and directories currently installed"
  },
  {
    "id": 20937,
    "content": ") Preparing to unpack"
  },
  {
    "id": 20938,
    "content": "/00-cuda-compat-11-8_11"
  },
  {
    "id": 20939,
    "content": "8"
  },
  {
    "id": 20940,
    "content": "30682616-1_arm64"
  },
  {
    "id": 20941,
    "content": "deb"
  },
  {
    "id": 20942,
    "content": "deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 11 8, CUDA Runtime Version = 11"
  },
  {
    "id": 20946,
    "content": "6"
  },
  {
    "id": 20947,
    "content": "2"
  },
  {
    "id": 20948,
    "content": "Deployment Considerations for CUDA Upgrade Package  6"
  },
  {
    "id": 20949,
    "content": "2"
  },
  {
    "id": 20950,
    "content": "1"
  },
  {
    "id": 20952,
    "content": "For example, if you are on the NVIDIA JetPack SDK 5"
  },
  {
    "id": 20953,
    "content": "0 (11 4) driver but require 11 8 application support, install the CUDA upgrade package for 11"
  },
  {
    "id": 20954,
    "content": "8"
  },
  {
    "id": 20956,
    "content": "6"
  },
  {
    "id": 20957,
    "content": "2"
  },
  {
    "id": 20958,
    "content": "3"
  },
  {
    "id": 20962,
    "content": "7"
  },
  {
    "id": 20968,
    "content": "7"
  },
  {
    "id": 20969,
    "content": "1"
  },
  {
    "id": 20973,
    "content": "7"
  },
  {
    "id": 20974,
    "content": "1"
  },
  {
    "id": 20975,
    "content": "1"
  },
  {
    "id": 20980,
    "content": "7"
  },
  {
    "id": 20981,
    "content": "1"
  },
  {
    "id": 20982,
    "content": "2"
  },
  {
    "id": 20986,
    "content": "= cudlaSuccess ) {   handle error }   Get tensor attributes"
  },
  {
    "id": 20991,
    "content": "section under cudlaModuleGetAttributes()"
  },
  {
    "id": 20992,
    "content": "7"
  },
  {
    "id": 20993,
    "content": "1"
  },
  {
    "id": 20994,
    "content": "3"
  },
  {
    "id": 20999,
    "content": "void * buffer ; uint32_t size = 100 ; result = cudaMalloc ( & inputBufferGPU , size ); if ( result"
  },
  {
    "id": 21000,
    "content": "= cudaSuccess ) {   handle error }   Register the CUDA-allocated buffers"
  },
  {
    "id": 21007,
    "content": "= cudlaSuccess ) {   handle error } 7"
  },
  {
    "id": 21008,
    "content": "1"
  },
  {
    "id": 21009,
    "content": "4"
  },
  {
    "id": 21014,
    "content": "size , cudaMemcpyHostToDevice , stream ); if ( result"
  },
  {
    "id": 21016,
    "content": "signalEvents = NULL ; err = cudlaSubmitTask ( devHandle , & task , 1 , stream , 0 ); if ( err"
  },
  {
    "id": 21017,
    "content": "= cudlaSuccess ) {   handle error } DPRINTF ( \"SUBMIT IS DONE"
  },
  {
    "id": 21018,
    "content": "\" ); result = cudaMemcpyAsync ( outputBuffer , outputBufferGPU , outputTensorDesc [ 0 ]"
  },
  {
    "id": 21019,
    "content": "size , cudaMemcpyDeviceToHost , stream ); if ( result"
  },
  {
    "id": 21021,
    "content": "In this case, the tasks submitted to the DLA are executed in FIFO order"
  },
  {
    "id": 21022,
    "content": "7"
  },
  {
    "id": 21023,
    "content": "1"
  },
  {
    "id": 21024,
    "content": "4"
  },
  {
    "id": 21025,
    "content": "1"
  },
  {
    "id": 21026,
    "content": "1"
  },
  {
    "id": 21029,
    "content": "7"
  },
  {
    "id": 21030,
    "content": "1"
  },
  {
    "id": 21031,
    "content": "4"
  },
  {
    "id": 21032,
    "content": "2"
  },
  {
    "id": 21033,
    "content": "Synchronization  Synchronization of tasks in hybrid mode does not need a different API"
  },
  {
    "id": 21038,
    "content": "task submission"
  },
  {
    "id": 21040,
    "content": "DPRINTF ( \"ALL EXTERNAL SEMAPHORES REGISTERED SUCCESSFULLY \" ); 7"
  },
  {
    "id": 21041,
    "content": "1"
  },
  {
    "id": 21042,
    "content": "4"
  },
  {
    "id": 21043,
    "content": "2"
  },
  {
    "id": 21044,
    "content": "2"
  },
  {
    "id": 21049,
    "content": "task , 1 , NULL , 0 ); if ( err"
  },
  {
    "id": 21050,
    "content": "= cudlaSuccess ) {   handle error } DPRINTF ( \"SUBMIT IS DONE"
  },
  {
    "id": 21051,
    "content": "\" ); 7"
  },
  {
    "id": 21052,
    "content": "1"
  },
  {
    "id": 21053,
    "content": "4"
  },
  {
    "id": 21054,
    "content": "2"
  },
  {
    "id": 21055,
    "content": "3"
  },
  {
    "id": 21057,
    "content": "fence ), nvSciCtx , -1 ); if ( sciError"
  },
  {
    "id": 21058,
    "content": "= NvSciError_Success ) {   handle error } 7"
  },
  {
    "id": 21059,
    "content": "1"
  },
  {
    "id": 21060,
    "content": "4"
  },
  {
    "id": 21061,
    "content": "2"
  },
  {
    "id": 21062,
    "content": "4"
  },
  {
    "id": 21065,
    "content": "object and insert waits accordingly"
  },
  {
    "id": 21066,
    "content": "7"
  },
  {
    "id": 21067,
    "content": "1"
  },
  {
    "id": 21068,
    "content": "4"
  },
  {
    "id": 21069,
    "content": "2"
  },
  {
    "id": 21070,
    "content": "5"
  },
  {
    "id": 21072,
    "content": "len = sizeof ( detFenceReq ); return NvSciSyncAttrListSetAttrs ( list , keyValue , 2 ); 7"
  },
  {
    "id": 21073,
    "content": "1"
  },
  {
    "id": 21074,
    "content": "4"
  },
  {
    "id": 21075,
    "content": "2"
  },
  {
    "id": 21076,
    "content": "6"
  },
  {
    "id": 21079,
    "content": "7"
  },
  {
    "id": 21080,
    "content": "1"
  },
  {
    "id": 21081,
    "content": "4"
  },
  {
    "id": 21082,
    "content": "2"
  },
  {
    "id": 21083,
    "content": "7"
  },
  {
    "id": 21087,
    "content": "1"
  },
  {
    "id": 21088,
    "content": "4"
  },
  {
    "id": 21089,
    "content": "3"
  },
  {
    "id": 21093,
    "content": "7"
  },
  {
    "id": 21094,
    "content": "1"
  },
  {
    "id": 21095,
    "content": "4"
  },
  {
    "id": 21096,
    "content": "4"
  },
  {
    "id": 21097,
    "content": "NOOP Submission  Users can mark certain tasks as noop tasks while calling cudlaSubmitTask()"
  },
  {
    "id": 21099,
    "content": "This is supported in both hybrid and standalone modes"
  },
  {
    "id": 21100,
    "content": "7"
  },
  {
    "id": 21101,
    "content": "1"
  },
  {
    "id": 21102,
    "content": "5"
  },
  {
    "id": 21104,
    "content": "execution"
  },
  {
    "id": 21108,
    "content": "and then use cudlaGetLastError() on the relevant handle to report the exact error"
  },
  {
    "id": 21112,
    "content": "7"
  },
  {
    "id": 21113,
    "content": "2"
  },
  {
    "id": 21121,
    "content": "7"
  },
  {
    "id": 21122,
    "content": "3"
  },
  {
    "id": 21124,
    "content": "2"
  },
  {
    "id": 21127,
    "content": "NvSciBuf buffer allocations made by the application must adhere to DLA alignment constraints"
  },
  {
    "id": 21131,
    "content": "Applications are expected to detect these scenarios and respond accordingly"
  },
  {
    "id": 21132,
    "content": "8"
  },
  {
    "id": 21133,
    "content": "Notices  8"
  },
  {
    "id": 21134,
    "content": "1"
  },
  {
    "id": 21137,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 21149,
    "content": "8"
  },
  {
    "id": 21150,
    "content": "2"
  },
  {
    "id": 21151,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 21152,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 21153,
    "content": "8"
  },
  {
    "id": 21154,
    "content": "3"
  },
  {
    "id": 21156,
    "content": "S"
  },
  {
    "id": 21159,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 21160,
    "content": "Navigation"
  },
  {
    "id": 21161,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 21162,
    "content": "pageBottom();}\n1"
  },
  {
    "id": 21163,
    "content": "Introduction v12"
  },
  {
    "id": 21166,
    "content": "In general, these linear systems can be solved using direct or preconditioned iterative methods"
  },
  {
    "id": 21170,
    "content": "p"
  },
  {
    "id": 21171,
    "content": "d"
  },
  {
    "id": 21172,
    "content": ") linear systems, respectively [2] , [11]"
  },
  {
    "id": 21180,
    "content": "2"
  },
  {
    "id": 21186,
    "content": "p"
  },
  {
    "id": 21187,
    "content": "d"
  },
  {
    "id": 21189,
    "content": "The appropriate memory has been allocated and set to zero"
  },
  {
    "id": 21190,
    "content": "3"
  },
  {
    "id": 21193,
    "content": ", 0"
  },
  {
    "id": 21194,
    "content": "0 , r ); cublasDscal ( n , -1"
  },
  {
    "id": 21195,
    "content": "0 , r , 1 ); cublasDaxpy ( n , 1"
  },
  {
    "id": 21196,
    "content": "0 , f , 1 , r , 1 ); nrmr0 = cublasDnrm2 ( n , r , 1 );  2: repeat until convergence (based on max"
  },
  {
    "id": 21206,
    "content": "Symmetric Positive Definite (s"
  },
  {
    "id": 21207,
    "content": "p"
  },
  {
    "id": 21208,
    "content": "d"
  },
  {
    "id": 21209,
    "content": ") and Nonsymmetric Test Matrices  # Matrix m,n nnz s"
  },
  {
    "id": 21210,
    "content": "p"
  },
  {
    "id": 21211,
    "content": "d"
  },
  {
    "id": 21214,
    "content": "07GHz, using the 64-bit Linux operating system Ubuntu 10"
  },
  {
    "id": 21215,
    "content": "04 LTS, cuSPARSE library 4"
  },
  {
    "id": 21216,
    "content": "0 and MKL 10"
  },
  {
    "id": 21217,
    "content": "2"
  },
  {
    "id": 21218,
    "content": "3"
  },
  {
    "id": 21219,
    "content": "029"
  },
  {
    "id": 21223,
    "content": "triangular factors and the i -th row of the coefficient matrix \\(A\\) , respectively"
  },
  {
    "id": 21227,
    "content": "ilu0 1 0"
  },
  {
    "id": 21228,
    "content": "38 0"
  },
  {
    "id": 21229,
    "content": "02 0"
  },
  {
    "id": 21230,
    "content": "72 8"
  },
  {
    "id": 21231,
    "content": "83E-08 25 1"
  },
  {
    "id": 21232,
    "content": "52 8"
  },
  {
    "id": 21233,
    "content": "83E-08 25 0"
  },
  {
    "id": 21234,
    "content": "57 2 1"
  },
  {
    "id": 21235,
    "content": "62 0"
  },
  {
    "id": 21236,
    "content": "04 38"
  },
  {
    "id": 21237,
    "content": "5 1"
  },
  {
    "id": 21238,
    "content": "00E-07 569 33"
  },
  {
    "id": 21239,
    "content": "9 9"
  },
  {
    "id": 21240,
    "content": "69E-08 571 1"
  },
  {
    "id": 21241,
    "content": "13 3 0 13 0"
  },
  {
    "id": 21242,
    "content": "01 39"
  },
  {
    "id": 21243,
    "content": "2 9"
  },
  {
    "id": 21244,
    "content": "84E-08 1044 6"
  },
  {
    "id": 21245,
    "content": "91 9"
  },
  {
    "id": 21246,
    "content": "84E-08 1044 5"
  },
  {
    "id": 21247,
    "content": "59 4 0"
  },
  {
    "id": 21248,
    "content": "12 0"
  },
  {
    "id": 21249,
    "content": "01 35"
  },
  {
    "id": 21250,
    "content": "0 9"
  },
  {
    "id": 21251,
    "content": "97E-08 713 12"
  },
  {
    "id": 21252,
    "content": "8 9"
  },
  {
    "id": 21253,
    "content": "97E-08 713 2"
  },
  {
    "id": 21254,
    "content": "72 5 0"
  },
  {
    "id": 21255,
    "content": "09 0"
  },
  {
    "id": 21256,
    "content": "01 107 9"
  },
  {
    "id": 21257,
    "content": "98E-08 1746 55"
  },
  {
    "id": 21258,
    "content": "3 9"
  },
  {
    "id": 21259,
    "content": "98E-08 1746 1"
  },
  {
    "id": 21260,
    "content": "92 6 0"
  },
  {
    "id": 21261,
    "content": "40 0"
  },
  {
    "id": 21262,
    "content": "02 155 9"
  },
  {
    "id": 21263,
    "content": "96E-08 1656 54"
  },
  {
    "id": 21264,
    "content": "4 9"
  },
  {
    "id": 21265,
    "content": "79E-08 1656 2"
  },
  {
    "id": 21266,
    "content": "83 7 0"
  },
  {
    "id": 21267,
    "content": "16 0"
  },
  {
    "id": 21268,
    "content": "02 20"
  },
  {
    "id": 21269,
    "content": "2 8"
  },
  {
    "id": 21270,
    "content": "70E-08 183 8"
  },
  {
    "id": 21271,
    "content": "61 8"
  },
  {
    "id": 21272,
    "content": "22E-08 183 2"
  },
  {
    "id": 21273,
    "content": "32 8 0 32 0"
  },
  {
    "id": 21274,
    "content": "02 0"
  },
  {
    "id": 21275,
    "content": "13 5"
  },
  {
    "id": 21276,
    "content": "25E-08 4 0"
  },
  {
    "id": 21277,
    "content": "52 5"
  },
  {
    "id": 21278,
    "content": "25E-08 4 0"
  },
  {
    "id": 21279,
    "content": "53 9 0"
  },
  {
    "id": 21280,
    "content": "20 0"
  },
  {
    "id": 21281,
    "content": "01 72"
  },
  {
    "id": 21282,
    "content": "7 1"
  },
  {
    "id": 21283,
    "content": "96E-04 2000 40"
  },
  {
    "id": 21284,
    "content": "0 2"
  },
  {
    "id": 21285,
    "content": "08E-04 2000 1"
  },
  {
    "id": 21286,
    "content": "80 10 0"
  },
  {
    "id": 21287,
    "content": "11 0"
  },
  {
    "id": 21288,
    "content": "01 0"
  },
  {
    "id": 21289,
    "content": "27 6"
  },
  {
    "id": 21290,
    "content": "33E-08 6 0"
  },
  {
    "id": 21291,
    "content": "12 6"
  },
  {
    "id": 21292,
    "content": "33E-08 6 1"
  },
  {
    "id": 21293,
    "content": "59 11 0"
  },
  {
    "id": 21294,
    "content": "70 0"
  },
  {
    "id": 21295,
    "content": "03 0"
  },
  {
    "id": 21296,
    "content": "28 2"
  },
  {
    "id": 21297,
    "content": "52E-08 2"
  },
  {
    "id": 21298,
    "content": "5 0"
  },
  {
    "id": 21299,
    "content": "15 2"
  },
  {
    "id": 21300,
    "content": "52E-08 2"
  },
  {
    "id": 21301,
    "content": "5 1"
  },
  {
    "id": 21302,
    "content": "10 12 0"
  },
  {
    "id": 21303,
    "content": "25 0"
  },
  {
    "id": 21304,
    "content": "04 12"
  },
  {
    "id": 21305,
    "content": "5 7"
  },
  {
    "id": 21306,
    "content": "33E-08 76"
  },
  {
    "id": 21307,
    "content": "5 4"
  },
  {
    "id": 21308,
    "content": "30 9"
  },
  {
    "id": 21309,
    "content": "69E-08 74"
  },
  {
    "id": 21310,
    "content": "5 2"
  },
  {
    "id": 21311,
    "content": "79 Table 3"
  },
  {
    "id": 21312,
    "content": "csrilut (5,10 -3 ) Preconditioned CG and BiCGStab Methods  ilut(5,10 -3 ) CPU GPU Speedup # fact"
  },
  {
    "id": 21315,
    "content": "csrilut (10,10 -5 ) Preconditioned CG and BiCGStab Methods  ilut(10,10 -5 ) CPU GPU Speedup # fact"
  },
  {
    "id": 21316,
    "content": "ilu0 1 0"
  },
  {
    "id": 21317,
    "content": "15 0"
  },
  {
    "id": 21318,
    "content": "01 1"
  },
  {
    "id": 21319,
    "content": "06 8"
  },
  {
    "id": 21320,
    "content": "79E-08 34 1"
  },
  {
    "id": 21321,
    "content": "96 8"
  },
  {
    "id": 21322,
    "content": "79E-08 34 0"
  },
  {
    "id": 21323,
    "content": "57 0"
  },
  {
    "id": 21324,
    "content": "63 2 0"
  },
  {
    "id": 21325,
    "content": "52 0"
  },
  {
    "id": 21326,
    "content": "03 60"
  },
  {
    "id": 21327,
    "content": "0 9"
  },
  {
    "id": 21328,
    "content": "86E-08 748 38"
  },
  {
    "id": 21329,
    "content": "7 9"
  },
  {
    "id": 21330,
    "content": "86E-08 748 1"
  },
  {
    "id": 21331,
    "content": "54 1"
  },
  {
    "id": 21332,
    "content": "70 3 3"
  },
  {
    "id": 21333,
    "content": "89 0"
  },
  {
    "id": 21334,
    "content": "03 9"
  },
  {
    "id": 21335,
    "content": "02 9"
  },
  {
    "id": 21336,
    "content": "79E-08 147 5"
  },
  {
    "id": 21337,
    "content": "42 9"
  },
  {
    "id": 21338,
    "content": "78E-08 147 1"
  },
  {
    "id": 21339,
    "content": "38 1"
  },
  {
    "id": 21340,
    "content": "83 4 1"
  },
  {
    "id": 21341,
    "content": "09 0"
  },
  {
    "id": 21342,
    "content": "03 34"
  },
  {
    "id": 21343,
    "content": "5 9"
  },
  {
    "id": 21344,
    "content": "83E-08 454 38"
  },
  {
    "id": 21345,
    "content": "2 9"
  },
  {
    "id": 21346,
    "content": "83E-08 454 0"
  },
  {
    "id": 21347,
    "content": "91 2"
  },
  {
    "id": 21348,
    "content": "76 5 3"
  },
  {
    "id": 21349,
    "content": "25 0"
  },
  {
    "id": 21350,
    "content": "06 26"
  },
  {
    "id": 21351,
    "content": "3 9"
  },
  {
    "id": 21352,
    "content": "71E-08 272 55"
  },
  {
    "id": 21353,
    "content": "2 9"
  },
  {
    "id": 21354,
    "content": "71E-08 272 0"
  },
  {
    "id": 21355,
    "content": "51 0"
  },
  {
    "id": 21356,
    "content": "53 6 11"
  },
  {
    "id": 21357,
    "content": "0 0"
  },
  {
    "id": 21358,
    "content": "07 44"
  },
  {
    "id": 21359,
    "content": "7 9"
  },
  {
    "id": 21360,
    "content": "42E-08 263 84"
  },
  {
    "id": 21361,
    "content": "0 9"
  },
  {
    "id": 21362,
    "content": "44E-08 263 0"
  },
  {
    "id": 21363,
    "content": "59 1"
  },
  {
    "id": 21364,
    "content": "02 7 5"
  },
  {
    "id": 21365,
    "content": "95 0"
  },
  {
    "id": 21366,
    "content": "09 8"
  },
  {
    "id": 21367,
    "content": "84 8"
  },
  {
    "id": 21368,
    "content": "53E-08 43 17"
  },
  {
    "id": 21369,
    "content": "0 8"
  },
  {
    "id": 21370,
    "content": "53E-08 43 0"
  },
  {
    "id": 21371,
    "content": "64 1"
  },
  {
    "id": 21372,
    "content": "68 8 2"
  },
  {
    "id": 21373,
    "content": "94 0"
  },
  {
    "id": 21374,
    "content": "04 0"
  },
  {
    "id": 21375,
    "content": "09 2"
  },
  {
    "id": 21376,
    "content": "10E-08 1"
  },
  {
    "id": 21377,
    "content": "5 1"
  },
  {
    "id": 21378,
    "content": "75 2"
  },
  {
    "id": 21379,
    "content": "10E-08 1"
  },
  {
    "id": 21380,
    "content": "5 0"
  },
  {
    "id": 21381,
    "content": "64 3"
  },
  {
    "id": 21382,
    "content": "54 9 0"
  },
  {
    "id": 21383,
    "content": "11 0"
  },
  {
    "id": 21384,
    "content": "01 53"
  },
  {
    "id": 21385,
    "content": "2 4"
  },
  {
    "id": 21386,
    "content": "24E-03 2000 24"
  },
  {
    "id": 21387,
    "content": "4 4"
  },
  {
    "id": 21388,
    "content": "92E-03 2000 2"
  },
  {
    "id": 21389,
    "content": "18 1"
  },
  {
    "id": 21390,
    "content": "31 10 0"
  },
  {
    "id": 21391,
    "content": "12 0"
  },
  {
    "id": 21392,
    "content": "01 0"
  },
  {
    "id": 21393,
    "content": "16 4"
  },
  {
    "id": 21394,
    "content": "89E-11 4 0"
  },
  {
    "id": 21395,
    "content": "08 6"
  },
  {
    "id": 21396,
    "content": "45E-11 4 1"
  },
  {
    "id": 21397,
    "content": "36 1"
  },
  {
    "id": 21398,
    "content": "18 11 2"
  },
  {
    "id": 21399,
    "content": "89 0"
  },
  {
    "id": 21400,
    "content": "09 0"
  },
  {
    "id": 21401,
    "content": "44 6"
  },
  {
    "id": 21402,
    "content": "10E-09 2"
  },
  {
    "id": 21403,
    "content": "5 0"
  },
  {
    "id": 21404,
    "content": "48 6"
  },
  {
    "id": 21405,
    "content": "10E-09 2"
  },
  {
    "id": 21406,
    "content": "5 1"
  },
  {
    "id": 21407,
    "content": "00 33"
  },
  {
    "id": 21408,
    "content": "2 12 0"
  },
  {
    "id": 21409,
    "content": "36 0 03 36"
  },
  {
    "id": 21410,
    "content": "6 7"
  },
  {
    "id": 21411,
    "content": "05E-08 278"
  },
  {
    "id": 21412,
    "content": "5 10"
  },
  {
    "id": 21413,
    "content": "6 8"
  },
  {
    "id": 21414,
    "content": "82E-08 270"
  },
  {
    "id": 21415,
    "content": "5 3"
  },
  {
    "id": 21416,
    "content": "35 8"
  },
  {
    "id": 21417,
    "content": "04 Table 5"
  },
  {
    "id": 21418,
    "content": "csrilut (20,10 -7 ) Preconditioned CG and BiCGStab Methods  ilut(20,10 -7 ) CPU GPU Speedup # fact"
  },
  {
    "id": 21427,
    "content": "5"
  },
  {
    "id": 21428,
    "content": "Acknowledgements  This white paper was authored by Maxim Naumov for NVIDIA Corporation"
  },
  {
    "id": 21430,
    "content": "6"
  },
  {
    "id": 21431,
    "content": "References  [1] E"
  },
  {
    "id": 21433,
    "content": "Garland, Implementing Sparse Matrix-Vector Multiplication on Throughput-Oriented Processors, Proc"
  },
  {
    "id": 21435,
    "content": "291-312 (86), 2009"
  },
  {
    "id": 21436,
    "content": "[7] R"
  },
  {
    "id": 21437,
    "content": "Baxter, Run-Time Parallelization and Scheduling of Loops, IEEE Transactions on Computers, pp"
  },
  {
    "id": 21438,
    "content": "(40), 1991"
  },
  {
    "id": 21439,
    "content": "[8] M"
  },
  {
    "id": 21442,
    "content": ", pp"
  },
  {
    "id": 21443,
    "content": "719-741 (18), 1992"
  },
  {
    "id": 21444,
    "content": "[11] Y"
  },
  {
    "id": 21445,
    "content": "Saltz, Aggregation Methods for Solving Sparse Triangular Systems on Multiprocessors, SIAM J"
  },
  {
    "id": 21446,
    "content": "Kandrot, CUDA by Example: An Introduction to General-Purpose GPU Programming, Addison-Wesley, 2010"
  },
  {
    "id": 21448,
    "content": ", pp"
  },
  {
    "id": 21449,
    "content": "178-194 (35-3), 2009"
  },
  {
    "id": 21450,
    "content": "[16] NVIDIA cuSPARSE and cuBLAS Libraries, http: www nvidia"
  },
  {
    "id": 21451,
    "content": "com/object/cuda_develop"
  },
  {
    "id": 21453,
    "content": "cise"
  },
  {
    "id": 21454,
    "content": "ufl"
  },
  {
    "id": 21455,
    "content": "edu/research/sparse/matrices/"
  },
  {
    "id": 21458,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 21470,
    "content": "7"
  },
  {
    "id": 21471,
    "content": "2"
  },
  {
    "id": 21472,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 21473,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 21474,
    "content": "7"
  },
  {
    "id": 21475,
    "content": "3"
  },
  {
    "id": 21477,
    "content": "S"
  },
  {
    "id": 21480,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 21481,
    "content": "Navigation"
  },
  {
    "id": 21482,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 21483,
    "content": "pageBottom();}\n1"
  },
  {
    "id": 21484,
    "content": "Introduction v12"
  },
  {
    "id": 21492,
    "content": "numeric issues relating to floating point on the GPU"
  },
  {
    "id": 21493,
    "content": "2"
  },
  {
    "id": 21494,
    "content": "Floating Point  2"
  },
  {
    "id": 21495,
    "content": "1"
  },
  {
    "id": 21497,
    "content": "Goldberg [5] gives a good introduction to floating point and many of the issues that arise"
  },
  {
    "id": 21501,
    "content": "For example, the value -192 equals (-1) 1 x 2 7 x 1"
  },
  {
    "id": 21502,
    "content": "5, and can be represented as having a negative sign, an exponent of 7, and a fractional part"
  },
  {
    "id": 21503,
    "content": "5"
  },
  {
    "id": 21505,
    "content": "Hence the exponent 7 is represented by bit strings with values 134 for float and 1030 for double"
  },
  {
    "id": 21507,
    "content": "The most frequently used is the round-to-nearest-or-even mode (abbreviated as round-to-nearest)"
  },
  {
    "id": 21509,
    "content": "2"
  },
  {
    "id": 21510,
    "content": "2"
  },
  {
    "id": 21512,
    "content": "and rounding mode"
  },
  {
    "id": 21516,
    "content": "1000000000000000000000110000"
  },
  {
    "id": 21518,
    "content": "0010000000000000000000100100"
  },
  {
    "id": 21520,
    "content": "0110000000000000000000101100"
  },
  {
    "id": 21525,
    "content": "2"
  },
  {
    "id": 21526,
    "content": "3"
  },
  {
    "id": 21529,
    "content": "0008\\) , the correct mathematical result is \\(x^{2} - 1 = 1"
  },
  {
    "id": 21530,
    "content": "60064 \\times 10^{- 4}\\)"
  },
  {
    "id": 21531,
    "content": "The closest number using only four digits after the decimal point is \\(1"
  },
  {
    "id": 21532,
    "content": "6006 \\times 10^{- 4}\\)"
  },
  {
    "id": 21534,
    "content": "The corresponding FMA computation is wrong by only 0"
  },
  {
    "id": 21539,
    "content": "0"
  },
  {
    "id": 21541,
    "content": "NVIDIA GPUs with compute capability 2"
  },
  {
    "id": 21546,
    "content": "3"
  },
  {
    "id": 21549,
    "content": "implementation in software involves several choices"
  },
  {
    "id": 21550,
    "content": "All of the strategies we will discuss use purely IEEE 754 compliant operations"
  },
  {
    "id": 21551,
    "content": "3"
  },
  {
    "id": 21552,
    "content": "1"
  },
  {
    "id": 21554,
    "content": "Individual operation are shown as a circle with arrows pointing from arguments to operations"
  },
  {
    "id": 21556,
    "content": "The final result can be represented as (a 1 x b 1 ) + (a 2 x b 2 )) + (a 3 x b 3 )) + (a 4 x b 4 ))"
  },
  {
    "id": 21558,
    "content": "The final result can be represented as a 4 x b 4 = (a 3 x b 3 + (a 2 x b 2 + (a 1 x b 1 + 0)))"
  },
  {
    "id": 21561,
    "content": "3"
  },
  {
    "id": 21562,
    "content": "2"
  },
  {
    "id": 21566,
    "content": "4"
  },
  {
    "id": 21570,
    "content": "4"
  },
  {
    "id": 21571,
    "content": "1"
  },
  {
    "id": 21573,
    "content": "4"
  },
  {
    "id": 21574,
    "content": "2"
  },
  {
    "id": 21578,
    "content": "3"
  },
  {
    "id": 21582,
    "content": "It is also possible to disable FMA merging via a compiler flag"
  },
  {
    "id": 21583,
    "content": "4"
  },
  {
    "id": 21584,
    "content": "4"
  },
  {
    "id": 21586,
    "content": "0 or later"
  },
  {
    "id": 21589,
    "content": "The flags have no effect on double precision or on devices of compute capability below 2"
  },
  {
    "id": 21590,
    "content": "0"
  },
  {
    "id": 21591,
    "content": "4"
  },
  {
    "id": 21592,
    "content": "5"
  },
  {
    "id": 21596,
    "content": "5"
  },
  {
    "id": 21597,
    "content": "Considerations for a Heterogeneous World  5"
  },
  {
    "id": 21598,
    "content": "1"
  },
  {
    "id": 21600,
    "content": "These operations are simple enough that computing the best floating point result (e"
  },
  {
    "id": 21601,
    "content": "g"
  },
  {
    "id": 21602,
    "content": ", the closest in round-to-nearest) is reasonable"
  },
  {
    "id": 21606,
    "content": "We compiled the code sequence on a 64-bit x86 platform using gcc version 4"
  },
  {
    "id": 21607,
    "content": "4"
  },
  {
    "id": 21608,
    "content": "3 (Ubuntu 4"
  },
  {
    "id": 21609,
    "content": "3"
  },
  {
    "id": 21610,
    "content": "3-4ubuntu5)"
  },
  {
    "id": 21611,
    "content": "This shows that the result of computing cos(5992555"
  },
  {
    "id": 21614,
    "content": "g"
  },
  {
    "id": 21615,
    "content": ", glibc on Linux)"
  },
  {
    "id": 21617,
    "content": "5"
  },
  {
    "id": 21618,
    "content": "2"
  },
  {
    "id": 21621,
    "content": "g"
  },
  {
    "id": 21622,
    "content": ", single precision for float and double precision for double )"
  },
  {
    "id": 21624,
    "content": "Because of these issues, guaranteeing a specific precision level on the CPU can sometimes be tricky"
  },
  {
    "id": 21628,
    "content": "5"
  },
  {
    "id": 21629,
    "content": "3"
  },
  {
    "id": 21634,
    "content": "5"
  },
  {
    "id": 21635,
    "content": "4"
  },
  {
    "id": 21639,
    "content": "6"
  },
  {
    "id": 21642,
    "content": "Devices of compute capability 2"
  },
  {
    "id": 21647,
    "content": "7"
  },
  {
    "id": 21651,
    "content": "8"
  },
  {
    "id": 21652,
    "content": "References  [1] ANSI/IEEE 754-1985"
  },
  {
    "id": 21654,
    "content": "CR-LIBM: A library of correctly rounded elementary functions in double-precision, February 2005"
  },
  {
    "id": 21655,
    "content": "Edited reprint available at: http: download"
  },
  {
    "id": 21656,
    "content": "oracle"
  },
  {
    "id": 21657,
    "content": "com/docs/cd/E19957-01/806-3568/ncg_goldberg"
  },
  {
    "id": 21658,
    "content": "html"
  },
  {
    "id": 21661,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 21673,
    "content": "9"
  },
  {
    "id": 21674,
    "content": "2"
  },
  {
    "id": 21675,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 21676,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 21677,
    "content": "9"
  },
  {
    "id": 21678,
    "content": "3"
  },
  {
    "id": 21680,
    "content": "S"
  },
  {
    "id": 21682,
    "content": "1 https: forums"
  },
  {
    "id": 21683,
    "content": "nvidia"
  },
  {
    "id": 21684,
    "content": "com/index"
  },
  {
    "id": 21685,
    "content": "php"
  },
  {
    "id": 21686,
    "content": "showforum=62 2 https: developer"
  },
  {
    "id": 21688,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 21689,
    "content": "Navigation"
  },
  {
    "id": 21690,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 21691,
    "content": "pageBottom();}\n1"
  },
  {
    "id": 21692,
    "content": "Overview v12"
  },
  {
    "id": 21694,
    "content": "1"
  },
  {
    "id": 21695,
    "content": "1"
  },
  {
    "id": 21697,
    "content": "NVCC"
  },
  {
    "id": 21700,
    "content": "3"
  },
  {
    "id": 21702,
    "content": "e"
  },
  {
    "id": 21703,
    "content": "long names must be preceded by two hyphens and short names must be preceded by a single hyphen"
  },
  {
    "id": 21708,
    "content": "In the below example, test"
  },
  {
    "id": 21709,
    "content": "bin binary will be disassembled assuming SM75 as the architecture"
  },
  {
    "id": 21710,
    "content": "nvdisasm"
  },
  {
    "id": 21711,
    "content": "exe -b SM70 -b SM75 test"
  },
  {
    "id": 21714,
    "content": "Instruction Set Reference"
  },
  {
    "id": 21715,
    "content": "2"
  },
  {
    "id": 21716,
    "content": "1"
  },
  {
    "id": 21717,
    "content": "Usage  cuobjdump accepts a single input file each time it’s run"
  },
  {
    "id": 21719,
    "content": "cu"
  },
  {
    "id": 21720,
    "content": "version 7"
  },
  {
    "id": 21721,
    "content": "0"
  },
  {
    "id": 21722,
    "content": "target sm_70"
  },
  {
    "id": 21723,
    "content": "address_size 64"
  },
  {
    "id": 21724,
    "content": "visible"
  },
  {
    "id": 21725,
    "content": "entry _Z3addPiS_S_("
  },
  {
    "id": 21726,
    "content": "param"
  },
  {
    "id": 21727,
    "content": "u64 _Z3addPiS_S__param_0,"
  },
  {
    "id": 21728,
    "content": "param"
  },
  {
    "id": 21729,
    "content": "u64 _Z3addPiS_S__param_1,"
  },
  {
    "id": 21730,
    "content": "param"
  },
  {
    "id": 21731,
    "content": "u64 _Z3addPiS_S__param_2 ) {"
  },
  {
    "id": 21732,
    "content": "reg"
  },
  {
    "id": 21733,
    "content": "s32 %r;"
  },
  {
    "id": 21734,
    "content": "reg"
  },
  {
    "id": 21735,
    "content": "s64 %rd; ld"
  },
  {
    "id": 21736,
    "content": "param"
  },
  {
    "id": 21737,
    "content": "u64 %rd1, [_Z3addPiS_S__param_0]; ld"
  },
  {
    "id": 21738,
    "content": "param"
  },
  {
    "id": 21739,
    "content": "u64 %rd2, [_Z3addPiS_S__param_1]; ld"
  },
  {
    "id": 21740,
    "content": "param"
  },
  {
    "id": 21741,
    "content": "u64 %rd3, [_Z3addPiS_S__param_2]; cvta"
  },
  {
    "id": 21742,
    "content": "to"
  },
  {
    "id": 21743,
    "content": "global"
  },
  {
    "id": 21744,
    "content": "u64 %rd4, %rd3; cvta"
  },
  {
    "id": 21745,
    "content": "to"
  },
  {
    "id": 21746,
    "content": "global"
  },
  {
    "id": 21747,
    "content": "u64 %rd5, %rd2; cvta"
  },
  {
    "id": 21748,
    "content": "to"
  },
  {
    "id": 21749,
    "content": "global"
  },
  {
    "id": 21750,
    "content": "u64 %rd6, %rd1; ld"
  },
  {
    "id": 21751,
    "content": "global"
  },
  {
    "id": 21752,
    "content": "u32 %r1, [%rd6]; ld"
  },
  {
    "id": 21753,
    "content": "global"
  },
  {
    "id": 21754,
    "content": "u32 %r2, [%rd5]; add s32 %r3, %r2, %r1; st"
  },
  {
    "id": 21755,
    "content": "global"
  },
  {
    "id": 21756,
    "content": "u32 [%rd4], %r3; ret; } As shown in the output, the a"
  },
  {
    "id": 21757,
    "content": "out host binary contains cubin and ptx code for sm_70"
  },
  {
    "id": 21758,
    "content": "To dump common and per function resource usage information: $ cuobjdump test"
  },
  {
    "id": 21760,
    "content": "value for REG, TEXTURE, SURFACE and SAMPLER denotes the count and for other resources it denotes no"
  },
  {
    "id": 21761,
    "content": "of byte(s) used"
  },
  {
    "id": 21762,
    "content": "2"
  },
  {
    "id": 21763,
    "content": "2"
  },
  {
    "id": 21765,
    "content": "assembly for a single cubin file or all cubin files embedded in the binary"
  },
  {
    "id": 21766,
    "content": "-findex Specify symbol table index of the function whose fat binary structures must be dumped"
  },
  {
    "id": 21768,
    "content": "--version -V Print version information on this tool"
  },
  {
    "id": 21769,
    "content": "3"
  },
  {
    "id": 21772,
    "content": "3"
  },
  {
    "id": 21773,
    "content": "1"
  },
  {
    "id": 21776,
    "content": "elftype @\"ET_EXEC\"  -"
  },
  {
    "id": 21777,
    "content": "nv"
  },
  {
    "id": 21778,
    "content": "info -"
  },
  {
    "id": 21779,
    "content": "section"
  },
  {
    "id": 21780,
    "content": "nv"
  },
  {
    "id": 21781,
    "content": "info,\"\",@\"SHT_CUDA_INFO\""
  },
  {
    "id": 21782,
    "content": "align 4"
  },
  {
    "id": 21785,
    "content": "cubin | dot -ocfg"
  },
  {
    "id": 21787,
    "content": "cubin ) with nvdisasm and Graphviz: nvdisasm -bbcfg a"
  },
  {
    "id": 21788,
    "content": "cubin | dot -obbcfg"
  },
  {
    "id": 21795,
    "content": "-fun Restrict the output to the CUDA functions represented by symbols with the given indices"
  },
  {
    "id": 21799,
    "content": "However, it may occasionally fail when certain restrictions on the input nvelf/cubin are not met"
  },
  {
    "id": 21803,
    "content": "--print-line-info -g Annotate disassembly with source line information obtained from"
  },
  {
    "id": 21804,
    "content": "debug_line section, if present"
  },
  {
    "id": 21805,
    "content": "--print-line-info-inline -gi Annotate disassembly with source line information obtained from"
  },
  {
    "id": 21806,
    "content": "debug_line section along with function inlining info, if present"
  },
  {
    "id": 21807,
    "content": "--print-line-info-ptx -gp Annotate disassembly with source line information obtained from"
  },
  {
    "id": 21808,
    "content": "nv_debug_line_sass section, if present"
  },
  {
    "id": 21810,
    "content": "4"
  },
  {
    "id": 21812,
    "content": "4"
  },
  {
    "id": 21813,
    "content": "1"
  },
  {
    "id": 21821,
    "content": "5"
  },
  {
    "id": 21822,
    "content": "1"
  },
  {
    "id": 21826,
    "content": "sm_70"
  },
  {
    "id": 21828,
    "content": "2"
  },
  {
    "id": 21830,
    "content": "-p When demangling the name of a function, do not display the types of the function’s parameters"
  },
  {
    "id": 21831,
    "content": "-v Print the version information of this tool"
  },
  {
    "id": 21832,
    "content": "5"
  },
  {
    "id": 21833,
    "content": "3"
  },
  {
    "id": 21836,
    "content": "h” located in the SDK"
  },
  {
    "id": 21839,
    "content": "Example Usage #include #include #include \"nv_decode"
  },
  {
    "id": 21843,
    "content": "6"
  },
  {
    "id": 21844,
    "content": "1"
  },
  {
    "id": 21847,
    "content": "a -o libcublas_static70 a Note that this means that libcublas_static70"
  },
  {
    "id": 21849,
    "content": "6"
  },
  {
    "id": 21850,
    "content": "2"
  },
  {
    "id": 21855,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 21867,
    "content": "7"
  },
  {
    "id": 21868,
    "content": "2"
  },
  {
    "id": 21869,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 21870,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 21871,
    "content": "7"
  },
  {
    "id": 21872,
    "content": "3"
  },
  {
    "id": 21874,
    "content": "S"
  },
  {
    "id": 21877,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 21878,
    "content": "Navigation"
  },
  {
    "id": 21879,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 21880,
    "content": "pageBottom();}\n1"
  },
  {
    "id": 21881,
    "content": "Preparing An Application For Profiling v12"
  },
  {
    "id": 21884,
    "content": "The NVIDIA Volta platform is the last architecture on which these tools are fully supported"
  },
  {
    "id": 21886,
    "content": "It corresponds to a single hardware counter value which is collected during kernel execution"
  },
  {
    "id": 21887,
    "content": "To see a list of all available events on a particular NVIDIA GPU, type nvprof --query-events"
  },
  {
    "id": 21888,
    "content": "A metric is a characteristic of an application that is calculated from one or more event values"
  },
  {
    "id": 21889,
    "content": "To see a list of all available metrics on a particular NVIDIA GPU, type nvprof --query-metrics"
  },
  {
    "id": 21891,
    "content": "1"
  },
  {
    "id": 21892,
    "content": "1"
  },
  {
    "id": 21899,
    "content": "To use these functions you must include cuda_profiler_api"
  },
  {
    "id": 21900,
    "content": "h (or cudaProfiler"
  },
  {
    "id": 21901,
    "content": "h for the driver API)"
  },
  {
    "id": 21903,
    "content": "1"
  },
  {
    "id": 21904,
    "content": "2"
  },
  {
    "id": 21907,
    "content": "In summary mode, each range is shown with CUDA activities associated with that range"
  },
  {
    "id": 21908,
    "content": "1"
  },
  {
    "id": 21909,
    "content": "3"
  },
  {
    "id": 21911,
    "content": "CPU and GPU resources"
  },
  {
    "id": 21912,
    "content": "Thread names are displayed in summary mode"
  },
  {
    "id": 21913,
    "content": "1"
  },
  {
    "id": 21914,
    "content": "4"
  },
  {
    "id": 21921,
    "content": "1"
  },
  {
    "id": 21922,
    "content": "5"
  },
  {
    "id": 21925,
    "content": "This option is supported on Linux 64-bit targets in PGI 2019 version 19"
  },
  {
    "id": 21926,
    "content": "1 or later"
  },
  {
    "id": 21927,
    "content": "2"
  },
  {
    "id": 21930,
    "content": "Starting with the CUDA 11"
  },
  {
    "id": 21932,
    "content": "2"
  },
  {
    "id": 21933,
    "content": "1"
  },
  {
    "id": 21934,
    "content": "Getting Started  This section describes steps you might take as you begin profiling"
  },
  {
    "id": 21935,
    "content": "2"
  },
  {
    "id": 21936,
    "content": "1"
  },
  {
    "id": 21937,
    "content": "1"
  },
  {
    "id": 21938,
    "content": "Setting up Java Runtime Environment  Visual Profiler requires Java Runtime Environment (JRE) 1"
  },
  {
    "id": 21939,
    "content": "8 to be available on the local system"
  },
  {
    "id": 21940,
    "content": "However, starting with CUDA Toolkit version 10"
  },
  {
    "id": 21943,
    "content": "8"
  },
  {
    "id": 21944,
    "content": "0/bin/java Note The -vm option is only required when JRE 1"
  },
  {
    "id": 21945,
    "content": "8 is not in the default path"
  },
  {
    "id": 21946,
    "content": "To run Visual Profiler on Ubuntu 18 04 or Ubuntu 18"
  },
  {
    "id": 21948,
    "content": "8 is not in the default path"
  },
  {
    "id": 21949,
    "content": "On Ubuntu 18"
  },
  {
    "id": 21950,
    "content": "10, if you get error “ no swt-pi-gtk in java"
  },
  {
    "id": 21951,
    "content": "library"
  },
  {
    "id": 21952,
    "content": "path ” when running Visual Profiler, then you need to install GTK2"
  },
  {
    "id": 21953,
    "content": "apt-get install libgtk2"
  },
  {
    "id": 21955,
    "content": "8 is not in the default path"
  },
  {
    "id": 21956,
    "content": "To run Visual Profiler on macOS: Visual Profiler requires Java Runtime Environment (JRE) 1"
  },
  {
    "id": 21957,
    "content": "8 update 151"
  },
  {
    "id": 21959,
    "content": "8 update 151 is not in the default path"
  },
  {
    "id": 21961,
    "content": "8"
  },
  {
    "id": 21962,
    "content": "0_77\\jre\\bin\\java\" Note The -vm option is only required when JRE 1"
  },
  {
    "id": 21963,
    "content": "8 is not in the default path"
  },
  {
    "id": 21964,
    "content": "2"
  },
  {
    "id": 21965,
    "content": "1"
  },
  {
    "id": 21966,
    "content": "2"
  },
  {
    "id": 21967,
    "content": "Installing JRE  Visual Profiler require Java Runtime Environment (JRE) 1"
  },
  {
    "id": 21968,
    "content": "8 to be available on the local system"
  },
  {
    "id": 21969,
    "content": "However, as of CUDA Toolkit version 10"
  },
  {
    "id": 21971,
    "content": "8u152 or later is not supported for Visual Profiler"
  },
  {
    "id": 21972,
    "content": "You can find the JRE update 151 on the Oracle Download Archive site here: https: www oracle"
  },
  {
    "id": 21973,
    "content": "com/technetwork/java/javase/downloads/java-archive-javase8-2177648"
  },
  {
    "id": 21974,
    "content": "html"
  },
  {
    "id": 21975,
    "content": "printOnly=1"
  },
  {
    "id": 21976,
    "content": "2"
  },
  {
    "id": 21977,
    "content": "1"
  },
  {
    "id": 21978,
    "content": "3"
  },
  {
    "id": 21980,
    "content": "profiling experience"
  },
  {
    "id": 21981,
    "content": "2"
  },
  {
    "id": 21982,
    "content": "1"
  },
  {
    "id": 21983,
    "content": "4"
  },
  {
    "id": 21996,
    "content": "Press Finish"
  },
  {
    "id": 21997,
    "content": "2"
  },
  {
    "id": 21998,
    "content": "1"
  },
  {
    "id": 21999,
    "content": "5"
  },
  {
    "id": 22001,
    "content": "2"
  },
  {
    "id": 22002,
    "content": "1"
  },
  {
    "id": 22003,
    "content": "6"
  },
  {
    "id": 22005,
    "content": "specific areas of your application"
  },
  {
    "id": 22006,
    "content": "2"
  },
  {
    "id": 22007,
    "content": "1"
  },
  {
    "id": 22008,
    "content": "7"
  },
  {
    "id": 22010,
    "content": "2"
  },
  {
    "id": 22011,
    "content": "1"
  },
  {
    "id": 22012,
    "content": "8"
  },
  {
    "id": 22017,
    "content": "eclipse"
  },
  {
    "id": 22018,
    "content": "equinox"
  },
  {
    "id": 22019,
    "content": "launcher_1"
  },
  {
    "id": 22020,
    "content": "3"
  },
  {
    "id": 22021,
    "content": "0"
  },
  {
    "id": 22022,
    "content": "v20140415-2008"
  },
  {
    "id": 22023,
    "content": "jar --launcher"
  },
  {
    "id": 22024,
    "content": "library plugins/org"
  },
  {
    "id": 22025,
    "content": "eclipse"
  },
  {
    "id": 22026,
    "content": "equinox"
  },
  {
    "id": 22027,
    "content": "launcher"
  },
  {
    "id": 22028,
    "content": "gtk"
  },
  {
    "id": 22029,
    "content": "linux"
  },
  {
    "id": 22030,
    "content": "x86_64_1"
  },
  {
    "id": 22031,
    "content": "1"
  },
  {
    "id": 22032,
    "content": "200"
  },
  {
    "id": 22033,
    "content": "v20140603-1326 -data @user"
  },
  {
    "id": 22034,
    "content": "home/nvvp_workspace -vm"
  },
  {
    "id": 22035,
    "content": "/jre/bin/java -vmargs -Dorg"
  },
  {
    "id": 22036,
    "content": "eclipse"
  },
  {
    "id": 22037,
    "content": "swt"
  },
  {
    "id": 22038,
    "content": "browser"
  },
  {
    "id": 22042,
    "content": "Some other nvvp"
  },
  {
    "id": 22046,
    "content": "The modified nvvp"
  },
  {
    "id": 22047,
    "content": "ini file as per examples given above is as follows: -data @user"
  },
  {
    "id": 22048,
    "content": "home/nvvp_workspace -vm"
  },
  {
    "id": 22049,
    "content": "/jre/bin/java -d64 -vmargs -Xms2g -Xmx22g -XX:+UseConcMarkSweepGC -XX:+CMSIncrementalMode -Dorg"
  },
  {
    "id": 22050,
    "content": "eclipse"
  },
  {
    "id": 22051,
    "content": "swt"
  },
  {
    "id": 22052,
    "content": "browser"
  },
  {
    "id": 22053,
    "content": "DefaultType=Mozilla For more details on JVM settings, consult the Java virtual machine manual"
  },
  {
    "id": 22055,
    "content": "2"
  },
  {
    "id": 22056,
    "content": "2"
  },
  {
    "id": 22058,
    "content": "the Visual Profiler, and an import session that is created by importing data generated by nvprof"
  },
  {
    "id": 22059,
    "content": "2"
  },
  {
    "id": 22060,
    "content": "2"
  },
  {
    "id": 22061,
    "content": "1"
  },
  {
    "id": 22064,
    "content": "2"
  },
  {
    "id": 22065,
    "content": "2"
  },
  {
    "id": 22066,
    "content": "2"
  },
  {
    "id": 22069,
    "content": "2"
  },
  {
    "id": 22070,
    "content": "2"
  },
  {
    "id": 22071,
    "content": "2"
  },
  {
    "id": 22072,
    "content": "1"
  },
  {
    "id": 22076,
    "content": "2"
  },
  {
    "id": 22077,
    "content": "2"
  },
  {
    "id": 22078,
    "content": "2"
  },
  {
    "id": 22079,
    "content": "2"
  },
  {
    "id": 22081,
    "content": "only supported for timeline data"
  },
  {
    "id": 22082,
    "content": "2"
  },
  {
    "id": 22083,
    "content": "2"
  },
  {
    "id": 22084,
    "content": "2"
  },
  {
    "id": 22085,
    "content": "3"
  },
  {
    "id": 22088,
    "content": "2"
  },
  {
    "id": 22089,
    "content": "3"
  },
  {
    "id": 22094,
    "content": "kernel and memcpy invocations must be the same each time the application executes"
  },
  {
    "id": 22095,
    "content": "2"
  },
  {
    "id": 22096,
    "content": "4"
  },
  {
    "id": 22098,
    "content": "2"
  },
  {
    "id": 22099,
    "content": "4"
  },
  {
    "id": 22100,
    "content": "1"
  },
  {
    "id": 22102,
    "content": "Multiple timelines can be opened in the Visual Profiler at the same time in different tabs"
  },
  {
    "id": 22108,
    "content": "application spends in a given OpenMP region or state"
  },
  {
    "id": 22122,
    "content": "2"
  },
  {
    "id": 22123,
    "content": "4"
  },
  {
    "id": 22124,
    "content": "1"
  },
  {
    "id": 22125,
    "content": "1"
  },
  {
    "id": 22128,
    "content": "When the double arrow pointer appears, click and hold the left mouse button while dragging"
  },
  {
    "id": 22143,
    "content": "2"
  },
  {
    "id": 22144,
    "content": "4"
  },
  {
    "id": 22145,
    "content": "1"
  },
  {
    "id": 22146,
    "content": "3"
  },
  {
    "id": 22147,
    "content": "Timeline Refreshing  The profiler loads the timeline gradually as it reads the data"
  },
  {
    "id": 22150,
    "content": "2"
  },
  {
    "id": 22151,
    "content": "4"
  },
  {
    "id": 22152,
    "content": "1"
  },
  {
    "id": 22153,
    "content": "4"
  },
  {
    "id": 22159,
    "content": "2"
  },
  {
    "id": 22160,
    "content": "4"
  },
  {
    "id": 22161,
    "content": "2"
  },
  {
    "id": 22164,
    "content": "2"
  },
  {
    "id": 22165,
    "content": "4"
  },
  {
    "id": 22166,
    "content": "2"
  },
  {
    "id": 22167,
    "content": "1"
  },
  {
    "id": 22169,
    "content": "2"
  },
  {
    "id": 22170,
    "content": "4"
  },
  {
    "id": 22171,
    "content": "2"
  },
  {
    "id": 22172,
    "content": "2"
  },
  {
    "id": 22176,
    "content": "with that entry will open"
  },
  {
    "id": 22177,
    "content": "2"
  },
  {
    "id": 22178,
    "content": "4"
  },
  {
    "id": 22179,
    "content": "2"
  },
  {
    "id": 22180,
    "content": "3"
  },
  {
    "id": 22185,
    "content": "For devices with compute capability 6"
  },
  {
    "id": 22189,
    "content": "2"
  },
  {
    "id": 22190,
    "content": "4"
  },
  {
    "id": 22191,
    "content": "2"
  },
  {
    "id": 22192,
    "content": "4"
  },
  {
    "id": 22193,
    "content": "Memory Statistics  Devices with compute capability 5"
  },
  {
    "id": 22194,
    "content": "0 and higher have a feature to show usage of the memory sub-system during kernel execution"
  },
  {
    "id": 22198,
    "content": "reports the total amount of memory requests made"
  },
  {
    "id": 22200,
    "content": "2"
  },
  {
    "id": 22201,
    "content": "4"
  },
  {
    "id": 22202,
    "content": "2"
  },
  {
    "id": 22203,
    "content": "5"
  },
  {
    "id": 22206,
    "content": "‘Logical NVLink Throughput’ table"
  },
  {
    "id": 22207,
    "content": "2"
  },
  {
    "id": 22208,
    "content": "4"
  },
  {
    "id": 22209,
    "content": "3"
  },
  {
    "id": 22215,
    "content": "2"
  },
  {
    "id": 22216,
    "content": "4"
  },
  {
    "id": 22217,
    "content": "4"
  },
  {
    "id": 22224,
    "content": "can be exported in CSV format using the toolbar icon in the upper right corner of the view"
  },
  {
    "id": 22225,
    "content": "2"
  },
  {
    "id": 22226,
    "content": "4"
  },
  {
    "id": 22227,
    "content": "5"
  },
  {
    "id": 22238,
    "content": "Tip The CPU profile is gathered by periodically sampling the state of the running application"
  },
  {
    "id": 22243,
    "content": "2"
  },
  {
    "id": 22244,
    "content": "4"
  },
  {
    "id": 22245,
    "content": "6"
  },
  {
    "id": 22250,
    "content": "solely to each activity occurring at this source location"
  },
  {
    "id": 22251,
    "content": "2"
  },
  {
    "id": 22252,
    "content": "4"
  },
  {
    "id": 22253,
    "content": "7"
  },
  {
    "id": 22256,
    "content": "multiple states at the same time"
  },
  {
    "id": 22257,
    "content": "2"
  },
  {
    "id": 22258,
    "content": "4"
  },
  {
    "id": 22259,
    "content": "8"
  },
  {
    "id": 22262,
    "content": "2"
  },
  {
    "id": 22263,
    "content": "4"
  },
  {
    "id": 22264,
    "content": "9"
  },
  {
    "id": 22266,
    "content": "2"
  },
  {
    "id": 22267,
    "content": "4"
  },
  {
    "id": 22268,
    "content": "10"
  },
  {
    "id": 22273,
    "content": "2"
  },
  {
    "id": 22274,
    "content": "4"
  },
  {
    "id": 22275,
    "content": "11"
  },
  {
    "id": 22281,
    "content": "2"
  },
  {
    "id": 22282,
    "content": "5"
  },
  {
    "id": 22284,
    "content": "2"
  },
  {
    "id": 22285,
    "content": "5"
  },
  {
    "id": 22286,
    "content": "1"
  },
  {
    "id": 22288,
    "content": "2"
  },
  {
    "id": 22289,
    "content": "5"
  },
  {
    "id": 22290,
    "content": "2"
  },
  {
    "id": 22292,
    "content": "2"
  },
  {
    "id": 22293,
    "content": "5"
  },
  {
    "id": 22294,
    "content": "3"
  },
  {
    "id": 22296,
    "content": "2"
  },
  {
    "id": 22297,
    "content": "5"
  },
  {
    "id": 22298,
    "content": "4"
  },
  {
    "id": 22300,
    "content": "2"
  },
  {
    "id": 22301,
    "content": "5"
  },
  {
    "id": 22302,
    "content": "5"
  },
  {
    "id": 22304,
    "content": "2"
  },
  {
    "id": 22305,
    "content": "6"
  },
  {
    "id": 22308,
    "content": "3"
  },
  {
    "id": 22311,
    "content": "3"
  },
  {
    "id": 22312,
    "content": "1"
  },
  {
    "id": 22313,
    "content": "Command Line Options  3"
  },
  {
    "id": 22314,
    "content": "1"
  },
  {
    "id": 22315,
    "content": "1"
  },
  {
    "id": 22317,
    "content": "Those event/metric values will be collected for each domain instance, instead of the whole device"
  },
  {
    "id": 22319,
    "content": "If concurrent kernel execution is off, all kernels running on one device will be serialized"
  },
  {
    "id": 22338,
    "content": "3"
  },
  {
    "id": 22339,
    "content": "1"
  },
  {
    "id": 22340,
    "content": "2"
  },
  {
    "id": 22343,
    "content": "e"
  },
  {
    "id": 22347,
    "content": "3"
  },
  {
    "id": 22348,
    "content": "1"
  },
  {
    "id": 22349,
    "content": "3"
  },
  {
    "id": 22355,
    "content": "3"
  },
  {
    "id": 22356,
    "content": "1"
  },
  {
    "id": 22357,
    "content": "4"
  },
  {
    "id": 22363,
    "content": "3"
  },
  {
    "id": 22364,
    "content": "2"
  },
  {
    "id": 22365,
    "content": "Profiling Modes  nvprof operates in one of the modes listed below"
  },
  {
    "id": 22369,
    "content": "0 MatrixA ( 320 , 320 ), MatrixB ( 640 , 320 ) Computing result using CUDA Kernel"
  },
  {
    "id": 22370,
    "content": "done Performance = 35 35 GFlop / s , Time = 3"
  },
  {
    "id": 22375,
    "content": "27325 == Profiling result : Time ( % ) Time Calls ( host ) Calls ( device ) Avg Min Max Name 99"
  },
  {
    "id": 22376,
    "content": "71 % 1"
  },
  {
    "id": 22377,
    "content": "2114 ms 1 14 80"
  },
  {
    "id": 22378,
    "content": "761 us 5 1200 us 145 66 us cdp_simple_quicksort ( unsigned int * , int , int , int ) 0"
  },
  {
    "id": 22379,
    "content": "18 % 2"
  },
  {
    "id": 22380,
    "content": "2080 us 1 - 2 2080 us 2 2080 us 2 2080 us [ CUDA memcpy DtoH ] 0"
  },
  {
    "id": 22381,
    "content": "11 % 1"
  },
  {
    "id": 22382,
    "content": "2800 us 1 - 1 2800 us 1 2800 us 1 2800 us [ CUDA memcpy HtoD ] 3"
  },
  {
    "id": 22383,
    "content": "2"
  },
  {
    "id": 22384,
    "content": "2"
  },
  {
    "id": 22388,
    "content": "GPU Device 0 : \"GeForce GT 640M LE\" with compute capability 3"
  },
  {
    "id": 22389,
    "content": "0 MatrixA ( 320 , 320 ), MatrixB ( 640 , 320 ) Computing result using CUDA Kernel"
  },
  {
    "id": 22390,
    "content": "done Performance = 35"
  },
  {
    "id": 22391,
    "content": "36 GFlop / s , Time = 3"
  },
  {
    "id": 22395,
    "content": "GPU Device 0 : \"GeForce GT 640M LE\" with compute capability 3"
  },
  {
    "id": 22396,
    "content": "0 MatrixA ( 320 , 320 ), MatrixB ( 640 , 320 ) Computing result using CUDA Kernel"
  },
  {
    "id": 22397,
    "content": "done Performance = 35 35 GFlop / s , Time = 3"
  },
  {
    "id": 22399,
    "content": "== 27722 == Profiling result : Start Duration Name 108"
  },
  {
    "id": 22400,
    "content": "38 ms 6"
  },
  {
    "id": 22402,
    "content": "737 us cudaLaunch ( void matrixMulCUDA ( float * , float * , float * , int , int ) [ 2198 ]) 149"
  },
  {
    "id": 22403,
    "content": "39 ms 6"
  },
  {
    "id": 22404,
    "content": "6290 us cudaEventRecord 149"
  },
  {
    "id": 22405,
    "content": "40 ms 1"
  },
  {
    "id": 22406,
    "content": "10156 s cudaEventSynchronize 1"
  },
  {
    "id": 22407,
    "content": "25096 s 21"
  },
  {
    "id": 22408,
    "content": "543 us cudaEventElapsedTime 1"
  },
  {
    "id": 22409,
    "content": "25103 s 1"
  },
  {
    "id": 22410,
    "content": "5462 ms cudaMemcpy 1"
  },
  {
    "id": 22411,
    "content": "25467 s 153"
  },
  {
    "id": 22412,
    "content": "93 us cudaFree 1"
  },
  {
    "id": 22413,
    "content": "25483 s 75"
  },
  {
    "id": 22414,
    "content": "373 us cudaFree 1"
  },
  {
    "id": 22415,
    "content": "25491 s 75"
  },
  {
    "id": 22416,
    "content": "564 us cudaFree 1"
  },
  {
    "id": 22417,
    "content": "25693 s 10"
  },
  {
    "id": 22419,
    "content": "3"
  },
  {
    "id": 22420,
    "content": "2"
  },
  {
    "id": 22421,
    "content": "3"
  },
  {
    "id": 22423,
    "content": ", command : matrixMul GPU Device 0 : \"GeForce GTX TITAN\" with compute capability 3"
  },
  {
    "id": 22424,
    "content": "5 MatrixA ( 320 , 320 ), MatrixB ( 640 , 320 ) Computing result using CUDA Kernel"
  },
  {
    "id": 22426,
    "content": "done Performance = 6"
  },
  {
    "id": 22427,
    "content": "39 GFlop / s , Time = 20"
  },
  {
    "id": 22431,
    "content": "282576 1"
  },
  {
    "id": 22432,
    "content": "299736 1"
  },
  {
    "id": 22435,
    "content": "which replay mode is chosen, the overall application execution time may increase significantly"
  },
  {
    "id": 22436,
    "content": "3"
  },
  {
    "id": 22437,
    "content": "2"
  },
  {
    "id": 22438,
    "content": "4"
  },
  {
    "id": 22441,
    "content": "matrixMul GPU Device 0 : \"GeForce GTX TITAN\" with compute capability 3"
  },
  {
    "id": 22442,
    "content": "5 MatrixA ( 320 , 320 ), MatrixB ( 640 , 320 ) Computing result using CUDA Kernel"
  },
  {
    "id": 22443,
    "content": "done Performance = 16"
  },
  {
    "id": 22444,
    "content": "76 GFlop / s , Time = 7"
  },
  {
    "id": 22448,
    "content": "3"
  },
  {
    "id": 22449,
    "content": "3"
  },
  {
    "id": 22450,
    "content": "Profiling Controls  3"
  },
  {
    "id": 22451,
    "content": "3"
  },
  {
    "id": 22452,
    "content": "1"
  },
  {
    "id": 22453,
    "content": "Note Timeout starts counting from the moment the CUDA driver is initialized"
  },
  {
    "id": 22454,
    "content": "3"
  },
  {
    "id": 22455,
    "content": "3"
  },
  {
    "id": 22456,
    "content": "2"
  },
  {
    "id": 22458,
    "content": "3"
  },
  {
    "id": 22459,
    "content": "3"
  },
  {
    "id": 22460,
    "content": "3"
  },
  {
    "id": 22466,
    "content": "3"
  },
  {
    "id": 22467,
    "content": "3"
  },
  {
    "id": 22468,
    "content": "4"
  },
  {
    "id": 22471,
    "content": "Note CPU profiling is not supported in multi-process mode"
  },
  {
    "id": 22472,
    "content": "3"
  },
  {
    "id": 22473,
    "content": "3"
  },
  {
    "id": 22474,
    "content": "5"
  },
  {
    "id": 22476,
    "content": "To see the detail of each sample point, combine the above option with --print-gpu-trace"
  },
  {
    "id": 22477,
    "content": "3"
  },
  {
    "id": 22478,
    "content": "3"
  },
  {
    "id": 22479,
    "content": "6"
  },
  {
    "id": 22481,
    "content": "To see the detail of each memory transfer while this feature is enabled, use --print-gpu-trace"
  },
  {
    "id": 22483,
    "content": "CUDA_VISIBLE_DEVICES is recommended to restrict CUDA to only use those GPUs that have P2P support"
  },
  {
    "id": 22485,
    "content": "3"
  },
  {
    "id": 22486,
    "content": "3"
  },
  {
    "id": 22487,
    "content": "7"
  },
  {
    "id": 22490,
    "content": "nvprof tries to detect which calls are necessary to model the execution behavior and filters others"
  },
  {
    "id": 22493,
    "content": "3"
  },
  {
    "id": 22494,
    "content": "4"
  },
  {
    "id": 22495,
    "content": "Output  3"
  },
  {
    "id": 22496,
    "content": "4"
  },
  {
    "id": 22497,
    "content": "1"
  },
  {
    "id": 22499,
    "content": "3"
  },
  {
    "id": 22500,
    "content": "4"
  },
  {
    "id": 22501,
    "content": "2"
  },
  {
    "id": 22503,
    "content": "The result can be directly imported to spreadsheet software such as Excel"
  },
  {
    "id": 22504,
    "content": "3"
  },
  {
    "id": 22505,
    "content": "4"
  },
  {
    "id": 22506,
    "content": "3"
  },
  {
    "id": 22509,
    "content": "3"
  },
  {
    "id": 22510,
    "content": "4"
  },
  {
    "id": 22511,
    "content": "4"
  },
  {
    "id": 22513,
    "content": "3"
  },
  {
    "id": 22514,
    "content": "4"
  },
  {
    "id": 22515,
    "content": "5"
  },
  {
    "id": 22516,
    "content": "Redirecting Output  By default, nvprof sends most of its output to stderr"
  },
  {
    "id": 22518,
    "content": "3"
  },
  {
    "id": 22519,
    "content": "4"
  },
  {
    "id": 22520,
    "content": "6"
  },
  {
    "id": 22522,
    "content": "For applications using CUDA from multiple CPU threads, CPU Thread Tracing should be enabled, too"
  },
  {
    "id": 22524,
    "content": "to all CPU activity that is not tracked by nvprof (e"
  },
  {
    "id": 22525,
    "content": "g"
  },
  {
    "id": 22527,
    "content": "06 4"
  },
  {
    "id": 22528,
    "content": "061817 0"
  },
  {
    "id": 22529,
    "content": "000000 clock_block ( long * , long ) 4"
  },
  {
    "id": 22530,
    "content": "54 0"
  },
  {
    "id": 22531,
    "content": "200511 0"
  },
  {
    "id": 22532,
    "content": "000000 cudaMalloc 3"
  },
  {
    "id": 22533,
    "content": "25 0"
  },
  {
    "id": 22534,
    "content": "143326 0"
  },
  {
    "id": 22535,
    "content": "000000 cudaDeviceReset 0"
  },
  {
    "id": 22536,
    "content": "13 5"
  },
  {
    "id": 22537,
    "content": "7273280e-03 0"
  },
  {
    "id": 22538,
    "content": "000000 0"
  },
  {
    "id": 22539,
    "content": "01 2"
  },
  {
    "id": 22540,
    "content": "7200900e-04 0"
  },
  {
    "id": 22541,
    "content": "000000 cudaFree 0"
  },
  {
    "id": 22542,
    "content": "00 0"
  },
  {
    "id": 22543,
    "content": "000000 4"
  },
  {
    "id": 22544,
    "content": "062506 pthread_join 0"
  },
  {
    "id": 22545,
    "content": "00 0"
  },
  {
    "id": 22546,
    "content": "000000 4"
  },
  {
    "id": 22547,
    "content": "061790 cudaStreamSynchronize 0"
  },
  {
    "id": 22548,
    "content": "00 0"
  },
  {
    "id": 22549,
    "content": "000000 1"
  },
  {
    "id": 22550,
    "content": "015485 pthread_mutex_lock 0"
  },
  {
    "id": 22551,
    "content": "00 0"
  },
  {
    "id": 22552,
    "content": "000000 1"
  },
  {
    "id": 22553,
    "content": "013711 pthread_cond_wait 0"
  },
  {
    "id": 22554,
    "content": "00 0"
  },
  {
    "id": 22555,
    "content": "000000 0 000000 pthread_mutex_unlock 0"
  },
  {
    "id": 22556,
    "content": "00 0"
  },
  {
    "id": 22557,
    "content": "000000 0 000000 pthread_exit 0"
  },
  {
    "id": 22558,
    "content": "00 0"
  },
  {
    "id": 22559,
    "content": "000000 0 000000 pthread_enter 0"
  },
  {
    "id": 22560,
    "content": "00 0"
  },
  {
    "id": 22561,
    "content": "000000 0 000000 pthread_create 0"
  },
  {
    "id": 22562,
    "content": "00 0"
  },
  {
    "id": 22563,
    "content": "000000 0 000000 pthread_cond_signal 0"
  },
  {
    "id": 22564,
    "content": "00 0"
  },
  {
    "id": 22565,
    "content": "000000 0 000000 cudaLaunch 3"
  },
  {
    "id": 22566,
    "content": "5"
  },
  {
    "id": 22569,
    "content": "Applications should therefore ensure that system calls are handled appropriately when interrupted"
  },
  {
    "id": 22570,
    "content": "Note On Windows, nvprof requires Visual Studio installation (2010 or later) and compiler-generated"
  },
  {
    "id": 22571,
    "content": "PDB (program database) files to resolve symbol information"
  },
  {
    "id": 22572,
    "content": "When building your application, ensure that"
  },
  {
    "id": 22573,
    "content": "PDB files are created and placed next to the profiled executable and libraries"
  },
  {
    "id": 22574,
    "content": "3"
  },
  {
    "id": 22575,
    "content": "5"
  },
  {
    "id": 22576,
    "content": "1"
  },
  {
    "id": 22577,
    "content": "CPU Sampling Limitations  The following are known issues with the current release"
  },
  {
    "id": 22579,
    "content": "The CPU sampling result does not support CSV mode"
  },
  {
    "id": 22580,
    "content": "3"
  },
  {
    "id": 22581,
    "content": "6"
  },
  {
    "id": 22583,
    "content": "1 or later"
  },
  {
    "id": 22586,
    "content": "applications using PGI OpenACC runtime before 19"
  },
  {
    "id": 22587,
    "content": "1, this value will always be unknown"
  },
  {
    "id": 22588,
    "content": "--openacc-summary-mode Specify how activity durations are presented in the OpenACC summary"
  },
  {
    "id": 22589,
    "content": "“inclusive” - inclusive durations"
  },
  {
    "id": 22590,
    "content": "3"
  },
  {
    "id": 22591,
    "content": "6"
  },
  {
    "id": 22592,
    "content": "2"
  },
  {
    "id": 22597,
    "content": "3"
  },
  {
    "id": 22598,
    "content": "7"
  },
  {
    "id": 22601,
    "content": "97 % 277"
  },
  {
    "id": 22602,
    "content": "10 ms 20 13 855 ms 13 131 ms 18 151 ms omp_parallel 0"
  },
  {
    "id": 22603,
    "content": "03 % 72"
  },
  {
    "id": 22604,
    "content": "728 us 19 3 8270 us 2 9840 us 9 5610 us omp_idle 0"
  },
  {
    "id": 22605,
    "content": "00 % 7"
  },
  {
    "id": 22606,
    "content": "9170 us 7 1 1310 us 1 0360 us 1 5330 us omp_wait_barrier 3"
  },
  {
    "id": 22607,
    "content": "7"
  },
  {
    "id": 22608,
    "content": "1"
  },
  {
    "id": 22610,
    "content": "4"
  },
  {
    "id": 22612,
    "content": "4"
  },
  {
    "id": 22613,
    "content": "1"
  },
  {
    "id": 22618,
    "content": "architectures The remote system must be accessible via SSH"
  },
  {
    "id": 22619,
    "content": "4"
  },
  {
    "id": 22620,
    "content": "1"
  },
  {
    "id": 22621,
    "content": "1"
  },
  {
    "id": 22625,
    "content": "Once this setup is complete, you can profile the application as you would on any remote machine"
  },
  {
    "id": 22626,
    "content": "Copying all data to and from the login and compute nodes happens transparently and automatically"
  },
  {
    "id": 22627,
    "content": "4"
  },
  {
    "id": 22628,
    "content": "2"
  },
  {
    "id": 22630,
    "content": "4"
  },
  {
    "id": 22631,
    "content": "2"
  },
  {
    "id": 22632,
    "content": "1"
  },
  {
    "id": 22638,
    "content": "4"
  },
  {
    "id": 22639,
    "content": "2"
  },
  {
    "id": 22640,
    "content": "2"
  },
  {
    "id": 22644,
    "content": "5"
  },
  {
    "id": 22647,
    "content": "1"
  },
  {
    "id": 22649,
    "content": "h and nvToolsExtCudaRt"
  },
  {
    "id": 22650,
    "content": "h"
  },
  {
    "id": 22652,
    "content": "dylib"
  },
  {
    "id": 22653,
    "content": "On Windows the library ("
  },
  {
    "id": 22654,
    "content": "lib) and runtime components ("
  },
  {
    "id": 22655,
    "content": "dll) are named nvToolsExt[bitness=32|64]_[version]"
  },
  {
    "id": 22660,
    "content": "5"
  },
  {
    "id": 22661,
    "content": "2"
  },
  {
    "id": 22665,
    "content": "5"
  },
  {
    "id": 22666,
    "content": "2"
  },
  {
    "id": 22667,
    "content": "1"
  },
  {
    "id": 22670,
    "content": "Code Example nvtxMarkA ( \"My mark\" ); nvtxEventAttributes_t eventAttrib = { 0 }; eventAttrib"
  },
  {
    "id": 22676,
    "content": "nvtxRangeEnd ( r1 ); nvtxRangeEnd ( r2 ); 5"
  },
  {
    "id": 22677,
    "content": "2"
  },
  {
    "id": 22678,
    "content": "3"
  },
  {
    "id": 22681,
    "content": "If the pop does not have a matching push, a negative value is returned to indicate an error"
  },
  {
    "id": 22687,
    "content": "atomic operations and spinlocks"
  },
  {
    "id": 22690,
    "content": "3"
  },
  {
    "id": 22693,
    "content": "4"
  },
  {
    "id": 22700,
    "content": "5"
  },
  {
    "id": 22707,
    "content": "00 % 16 652 us 1 16 652 us 16 652 us 16 652 us MPI_Reduce"
  },
  {
    "id": 22708,
    "content": "Range \"MPI_Scatter\" Type Time ( % ) Time Calls Avg Min Max Name Range : 100"
  },
  {
    "id": 22709,
    "content": "00 % 3"
  },
  {
    "id": 22710,
    "content": "0320 ms 1 3 0320 ms 3 0320 ms 3 0320 ms MPI_Scatter"
  },
  {
    "id": 22712,
    "content": "00 % 21 062 us 1 21 062 us 21 062 us 21 062 us MPI_Reduce"
  },
  {
    "id": 22713,
    "content": "Range \"MPI_Scatter\" Type Time ( % ) Time Calls Avg Min Max Name Range : 100"
  },
  {
    "id": 22714,
    "content": "00 % 85 296 ms 1 85 296 ms 85 296 ms 85 296 ms MPI_Scatter"
  },
  {
    "id": 22716,
    "content": "documentation and open-source scripts located here"
  },
  {
    "id": 22717,
    "content": "6"
  },
  {
    "id": 22718,
    "content": "2"
  },
  {
    "id": 22721,
    "content": "Starting CUDA 7"
  },
  {
    "id": 22727,
    "content": "7"
  },
  {
    "id": 22729,
    "content": "7"
  },
  {
    "id": 22730,
    "content": "1"
  },
  {
    "id": 22733,
    "content": "7"
  },
  {
    "id": 22734,
    "content": "2"
  },
  {
    "id": 22736,
    "content": "7"
  },
  {
    "id": 22737,
    "content": "3"
  },
  {
    "id": 22739,
    "content": "Note that the Compute and kernel timeline row shows three kernels overlapping"
  },
  {
    "id": 22740,
    "content": "8"
  },
  {
    "id": 22743,
    "content": "8"
  },
  {
    "id": 22744,
    "content": "1"
  },
  {
    "id": 22750,
    "content": "e"
  },
  {
    "id": 22751,
    "content": "optimizing activities on this path can directly improve the execution time"
  },
  {
    "id": 22752,
    "content": "8"
  },
  {
    "id": 22753,
    "content": "2"
  },
  {
    "id": 22756,
    "content": "e"
  },
  {
    "id": 22759,
    "content": "8"
  },
  {
    "id": 22760,
    "content": "3"
  },
  {
    "id": 22762,
    "content": "section Dependency Analysis on how to use this feature in nvprof"
  },
  {
    "id": 22763,
    "content": "8"
  },
  {
    "id": 22764,
    "content": "4"
  },
  {
    "id": 22770,
    "content": "9"
  },
  {
    "id": 22774,
    "content": "9"
  },
  {
    "id": 22775,
    "content": "1"
  },
  {
    "id": 22803,
    "content": "0"
  },
  {
    "id": 22811,
    "content": "3"
  },
  {
    "id": 22824,
    "content": ")"
  },
  {
    "id": 22830,
    "content": "g"
  },
  {
    "id": 22831,
    "content": ", use 64-bit memory requests instead of two 32-bit requests)"
  },
  {
    "id": 22834,
    "content": "g"
  },
  {
    "id": 22835,
    "content": ", packing data in texture and unpacking in SM or using vector loads)"
  },
  {
    "id": 22838,
    "content": "This may be high the first time each constant is accessed (e"
  },
  {
    "id": 22839,
    "content": "g"
  },
  {
    "id": 22840,
    "content": ", at the beginning of a kernel)"
  },
  {
    "id": 22843,
    "content": "Look for arithmetic improvements (e"
  },
  {
    "id": 22844,
    "content": "g"
  },
  {
    "id": 22848,
    "content": "Stalled for other - Warp is blocked for an uncommon reason like compiler or hardware reasons"
  },
  {
    "id": 22849,
    "content": "Developers do not have control over these stalls"
  },
  {
    "id": 22850,
    "content": "11"
  },
  {
    "id": 22854,
    "content": "Compute is an interactive kernel profiler for CUDA applications"
  },
  {
    "id": 22861,
    "content": "Starting with the CUDA 11"
  },
  {
    "id": 22864,
    "content": "17 or Linux 418"
  },
  {
    "id": 22865,
    "content": "43 or later driver"
  },
  {
    "id": 22866,
    "content": "By default, NVIDIA drivers require elevated permissions to access GPU performance counters"
  },
  {
    "id": 22868,
    "content": "More details about the issue and the solutions can be found on the ERR_NVGPUCTRPERM web page"
  },
  {
    "id": 22874,
    "content": "0 and higher"
  },
  {
    "id": 22882,
    "content": "compute capability 6 0 and 6"
  },
  {
    "id": 22883,
    "content": "1"
  },
  {
    "id": 22887,
    "content": "For devices with compute capability 6"
  },
  {
    "id": 22890,
    "content": "CUDA profiling might not work on systems that contain a mixture of supported and unsupported GPUs"
  },
  {
    "id": 22896,
    "content": "Visual Profiler and nvprof versions shipped in the CUDA Toolkit 11 7 and CUDA Toolkit 11"
  },
  {
    "id": 22897,
    "content": "8 don’t support Kepler (sm_35 and sm_37) devices"
  },
  {
    "id": 22915,
    "content": "so on Linux and cuinj64_*"
  },
  {
    "id": 22916,
    "content": "dll on Windows, before launching the application"
  },
  {
    "id": 22918,
    "content": "5 and higher are supported in the NVIDIA Nsight Compute"
  },
  {
    "id": 22920,
    "content": "5 and higher"
  },
  {
    "id": 22921,
    "content": "One can launch the NVIDIA Nsight Compute UI for devices with compute capability 7"
  },
  {
    "id": 22922,
    "content": "5 and higher from Visual Profiler"
  },
  {
    "id": 22924,
    "content": "5 and higher"
  },
  {
    "id": 22928,
    "content": "g"
  },
  {
    "id": 22932,
    "content": "Here are a couple of reasons why Visual Profiler may fail to gather metric or event information"
  },
  {
    "id": 22935,
    "content": "if the application is using multiple contexts within the same application"
  },
  {
    "id": 22938,
    "content": "Linux, setting the X Config option Interactive to false is recommended"
  },
  {
    "id": 22940,
    "content": "microsoft"
  },
  {
    "id": 22942,
    "content": "Profiling results might be incorrect for CUDA applications compiled with nvcc version older than 9"
  },
  {
    "id": 22943,
    "content": "0 for devices with compute capability 6"
  },
  {
    "id": 22944,
    "content": "0 and 6"
  },
  {
    "id": 22945,
    "content": "1"
  },
  {
    "id": 22947,
    "content": "13"
  },
  {
    "id": 22948,
    "content": "Changelog  Profiler changes in CUDA 12 5 List of changes done as part of the CUDA Toolkit 12"
  },
  {
    "id": 22949,
    "content": "5 release"
  },
  {
    "id": 22950,
    "content": "Profiler changes in CUDA 12 4 List of changes done as part of the CUDA Toolkit 12"
  },
  {
    "id": 22951,
    "content": "4 release"
  },
  {
    "id": 22952,
    "content": "Profiler changes in CUDA 12 3 List of changes done as part of the CUDA Toolkit 12"
  },
  {
    "id": 22953,
    "content": "3 release"
  },
  {
    "id": 22954,
    "content": "Profiler changes in CUDA 12 2 List of changes done as part of the CUDA Toolkit 12"
  },
  {
    "id": 22955,
    "content": "2 release"
  },
  {
    "id": 22956,
    "content": "Profiler changes in CUDA 12 1 List of changes done as part of the CUDA Toolkit 12"
  },
  {
    "id": 22957,
    "content": "1 release"
  },
  {
    "id": 22958,
    "content": "Profiler changes in CUDA 12 0 List of changes done as part of the CUDA Toolkit 12"
  },
  {
    "id": 22959,
    "content": "0 release"
  },
  {
    "id": 22960,
    "content": "Profiler changes in CUDA 11 8 List of changes done as part of the CUDA Toolkit 11"
  },
  {
    "id": 22961,
    "content": "8 release"
  },
  {
    "id": 22962,
    "content": "Profiler changes in CUDA 11 7 List of changes done as part of the CUDA Toolkit 11"
  },
  {
    "id": 22963,
    "content": "7 release"
  },
  {
    "id": 22964,
    "content": "Profiler changes in CUDA 11 6 List of changes done as part of the CUDA Toolkit 11"
  },
  {
    "id": 22965,
    "content": "6 release"
  },
  {
    "id": 22966,
    "content": "Profiler changes in CUDA 11 5 List of changes done as part of the CUDA Toolkit 11"
  },
  {
    "id": 22967,
    "content": "5 release"
  },
  {
    "id": 22968,
    "content": "Profiler changes in CUDA 11 4 List of changes done as part of the CUDA Toolkit 11"
  },
  {
    "id": 22969,
    "content": "4 release"
  },
  {
    "id": 22970,
    "content": "Profiler changes in CUDA 11 3 List of changes done as part of the CUDA Toolkit 11"
  },
  {
    "id": 22971,
    "content": "3 release"
  },
  {
    "id": 22973,
    "content": "2 release"
  },
  {
    "id": 22974,
    "content": "Profiler changes in CUDA 11 1 List of changes done as part of the CUDA Toolkit 11"
  },
  {
    "id": 22975,
    "content": "1 release"
  },
  {
    "id": 22976,
    "content": "Profiler changes in CUDA 11 0 List of changes done as part of the CUDA Toolkit 11"
  },
  {
    "id": 22977,
    "content": "0 release"
  },
  {
    "id": 22978,
    "content": "Starting with the CUDA 11"
  },
  {
    "id": 22980,
    "content": "2 release"
  },
  {
    "id": 22982,
    "content": "platforms and \"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\\\extras\\CUPTI\\lib64\" for Windows"
  },
  {
    "id": 22986,
    "content": "As a result, Visual Profiler and nvprof cannot profile the application when using a Windows 419"
  },
  {
    "id": 22987,
    "content": "17 or Linux 418"
  },
  {
    "id": 22988,
    "content": "43 or later driver"
  },
  {
    "id": 22989,
    "content": "Visual Profiler requires Java Runtime Environment (JRE) 1"
  },
  {
    "id": 22990,
    "content": "8 to be available on the local system"
  },
  {
    "id": 22991,
    "content": "Profiler changes in CUDA 10 1 List of changes done as part of the CUDA Toolkit 10"
  },
  {
    "id": 22992,
    "content": "1 release"
  },
  {
    "id": 22993,
    "content": "Profiler changes in CUDA 10 0 List of changes done as part of the CUDA Toolkit 10"
  },
  {
    "id": 22994,
    "content": "0 release"
  },
  {
    "id": 22995,
    "content": "Profiling features for devices with compute capability 7"
  },
  {
    "id": 22996,
    "content": "5 and higher are supported in the NVIDIA Nsight Compute"
  },
  {
    "id": 22997,
    "content": "Profiler changes in CUDA 9 2 List of changes done as part of the CUDA Toolkit 9"
  },
  {
    "id": 22998,
    "content": "2 release"
  },
  {
    "id": 23005,
    "content": "Profiler changes in CUDA 9 1 List of changes done as part of the CUDA Toolkit 9"
  },
  {
    "id": 23006,
    "content": "1 release"
  },
  {
    "id": 23008,
    "content": "0 release"
  },
  {
    "id": 23009,
    "content": "Tools and extensions for profiling are hosted on Github at https: github"
  },
  {
    "id": 23013,
    "content": "0 release"
  },
  {
    "id": 23014,
    "content": "Visual Profiler and nvprof now support NVLink analysis for devices with compute capability 6"
  },
  {
    "id": 23015,
    "content": "0"
  },
  {
    "id": 23022,
    "content": "0 and higher"
  },
  {
    "id": 23024,
    "content": "changes in CUDA 7 5 List of changes done as part of the CUDA Toolkit 7"
  },
  {
    "id": 23025,
    "content": "5 release"
  },
  {
    "id": 23027,
    "content": "All events and metrics for devices with compute capability 5"
  },
  {
    "id": 23028,
    "content": "2 can now be collected accurately in presence of multiple contexts on the GPU"
  },
  {
    "id": 23030,
    "content": "0 release"
  },
  {
    "id": 23034,
    "content": "x and 5"
  },
  {
    "id": 23035,
    "content": "0 can now be collected accurately in presence of multiple contexts on the GPU"
  },
  {
    "id": 23036,
    "content": "Profiler changes in CUDA 6 5 List of changes done as part of the CUDA Toolkit 6"
  },
  {
    "id": 23037,
    "content": "5 release"
  },
  {
    "id": 23044,
    "content": "Profiler changes in CUDA 6 0 List of changes done as part of the CUDA Toolkit 6"
  },
  {
    "id": 23045,
    "content": "0 release"
  },
  {
    "id": 23047,
    "content": "This multi-process import capability also includes support for CUDA applications using MPS"
  },
  {
    "id": 23049,
    "content": "predicated instruction counts"
  },
  {
    "id": 23052,
    "content": "Profiling overheads for both nvvp and nvprof have been significantly reduced"
  },
  {
    "id": 23053,
    "content": "14 Notices  14"
  },
  {
    "id": 23054,
    "content": "1"
  },
  {
    "id": 23057,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 23069,
    "content": "14"
  },
  {
    "id": 23070,
    "content": "2"
  },
  {
    "id": 23071,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 23072,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 23073,
    "content": "14"
  },
  {
    "id": 23074,
    "content": "3"
  },
  {
    "id": 23076,
    "content": "S"
  },
  {
    "id": 23079,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 23080,
    "content": "Navigation"
  },
  {
    "id": 23081,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 23083,
    "content": "2"
  },
  {
    "id": 23091,
    "content": "2"
  },
  {
    "id": 23097,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 23098,
    "content": "Navigation"
  },
  {
    "id": 23100,
    "content": "Documentation for previous versions of the NVIDIA Nsight Systems"
  },
  {
    "id": 23101,
    "content": "Introduction v12"
  },
  {
    "id": 23103,
    "content": "(through Help->Help Contents menu)"
  },
  {
    "id": 23104,
    "content": "1"
  },
  {
    "id": 23105,
    "content": "1"
  },
  {
    "id": 23108,
    "content": "eclipse"
  },
  {
    "id": 23109,
    "content": "org 2"
  },
  {
    "id": 23111,
    "content": "1"
  },
  {
    "id": 23112,
    "content": "1"
  },
  {
    "id": 23114,
    "content": "nvidia"
  },
  {
    "id": 23115,
    "content": "com/cuda-downloads Select appropriate operating system"
  },
  {
    "id": 23116,
    "content": "Follow instructions to configure CUDA Driver and Toolkit on your system"
  },
  {
    "id": 23117,
    "content": "2"
  },
  {
    "id": 23118,
    "content": "1"
  },
  {
    "id": 23119,
    "content": "2"
  },
  {
    "id": 23122,
    "content": "target-related components: 2"
  },
  {
    "id": 23123,
    "content": "2"
  },
  {
    "id": 23126,
    "content": "from the running application"
  },
  {
    "id": 23127,
    "content": "2"
  },
  {
    "id": 23128,
    "content": "3"
  },
  {
    "id": 23132,
    "content": "2"
  },
  {
    "id": 23133,
    "content": "4"
  },
  {
    "id": 23134,
    "content": "1"
  },
  {
    "id": 23135,
    "content": "cuHook Sample  cuHook sample builds both the library and the executable"
  },
  {
    "id": 23138,
    "content": "/libcuhook"
  },
  {
    "id": 23139,
    "content": "so"
  },
  {
    "id": 23140,
    "content": "1 > Run will execute the sample 2"
  },
  {
    "id": 23141,
    "content": "5"
  },
  {
    "id": 23146,
    "content": "2"
  },
  {
    "id": 23147,
    "content": "6"
  },
  {
    "id": 23149,
    "content": "You can now explore your CUDA device state, step through your GPU code or resume the application"
  },
  {
    "id": 23152,
    "content": "0"
  },
  {
    "id": 23155,
    "content": "8"
  },
  {
    "id": 23156,
    "content": "Debugging Remote CUDA Applications  Remote debugging is available starting with CUDA Toolkit 5"
  },
  {
    "id": 23157,
    "content": "5"
  },
  {
    "id": 23158,
    "content": "Debug host and target may run different operating systems or have different CPU architectures"
  },
  {
    "id": 23160,
    "content": "Select the project and right click then go to Debug As…>NVIDIA CUDA GDB Debugger(Remote) menu item"
  },
  {
    "id": 23164,
    "content": "Starting with CUDA 11"
  },
  {
    "id": 23165,
    "content": "5, this feature is available on the Debugger Configurations -> Debugger tab"
  },
  {
    "id": 23167,
    "content": "2"
  },
  {
    "id": 23168,
    "content": "9"
  },
  {
    "id": 23174,
    "content": "2"
  },
  {
    "id": 23175,
    "content": "11"
  },
  {
    "id": 23181,
    "content": "exported from Nsight Eclipse Edition"
  },
  {
    "id": 23182,
    "content": "2"
  },
  {
    "id": 23183,
    "content": "13"
  },
  {
    "id": 23186,
    "content": "nvidia"
  },
  {
    "id": 23187,
    "content": "com/cuda 3"
  },
  {
    "id": 23189,
    "content": "Source editors may show error markers on a valid code for the files in newly created projects"
  },
  {
    "id": 23192,
    "content": "4"
  },
  {
    "id": 23193,
    "content": "0/default as below CONF = gcc_ntoaarch64le 4"
  },
  {
    "id": 23196,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 23208,
    "content": "4"
  },
  {
    "id": 23209,
    "content": "2"
  },
  {
    "id": 23210,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 23211,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 23212,
    "content": "4"
  },
  {
    "id": 23213,
    "content": "3"
  },
  {
    "id": 23215,
    "content": "S"
  },
  {
    "id": 23218,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 23219,
    "content": "Navigation"
  },
  {
    "id": 23220,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 23221,
    "content": "pageBottom();}\n1"
  },
  {
    "id": 23222,
    "content": "Introduction v12"
  },
  {
    "id": 23224,
    "content": "1"
  },
  {
    "id": 23225,
    "content": "1"
  },
  {
    "id": 23227,
    "content": "Choose the the zip file(com"
  },
  {
    "id": 23228,
    "content": "nvidia"
  },
  {
    "id": 23229,
    "content": "cuda"
  },
  {
    "id": 23230,
    "content": "repo"
  },
  {
    "id": 23232,
    "content": "8/nsightee_plugins directory"
  },
  {
    "id": 23234,
    "content": "org)"
  },
  {
    "id": 23235,
    "content": "Menu to verify the “Cuda Developer Tools” and “Cuda Remote Launch” plugins are installed 1"
  },
  {
    "id": 23236,
    "content": "2"
  },
  {
    "id": 23238,
    "content": "1"
  },
  {
    "id": 23239,
    "content": "3"
  },
  {
    "id": 23241,
    "content": "By default, it is located in /usr/local/cuda-11"
  },
  {
    "id": 23242,
    "content": "8/bin : The usage of the script is as follows: Usage:"
  },
  {
    "id": 23243,
    "content": "/nsight_ee_plugins_manage"
  },
  {
    "id": 23245,
    "content": "8/bin/nsight_ee_plugins_manage"
  },
  {
    "id": 23246,
    "content": "sh install To uninstall the Nsight Eclipse Plugins, run the following command: $ /usr/local/cuda-11"
  },
  {
    "id": 23247,
    "content": "8/bin/nsight_ee_plugins_manage"
  },
  {
    "id": 23248,
    "content": "sh uninstall 2"
  },
  {
    "id": 23251,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 23263,
    "content": "2"
  },
  {
    "id": 23264,
    "content": "2"
  },
  {
    "id": 23265,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 23266,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 23267,
    "content": "2"
  },
  {
    "id": 23268,
    "content": "3"
  },
  {
    "id": 23270,
    "content": "S"
  },
  {
    "id": 23273,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 23274,
    "content": "Navigation"
  },
  {
    "id": 23275,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 23279,
    "content": "pageBottom(); var switchTo5x=true; stLight"
  },
  {
    "id": 23281,
    "content": "Introduction v12"
  },
  {
    "id": 23283,
    "content": "1"
  },
  {
    "id": 23284,
    "content": "1"
  },
  {
    "id": 23290,
    "content": "1"
  },
  {
    "id": 23291,
    "content": "3"
  },
  {
    "id": 23293,
    "content": "2"
  },
  {
    "id": 23294,
    "content": "Release Notes  12"
  },
  {
    "id": 23295,
    "content": "5 Release Updated GDB version Moved from GDB 13 1 to 13"
  },
  {
    "id": 23296,
    "content": "2"
  },
  {
    "id": 23299,
    "content": "Fixed issues resulting in crashes/errors when reading/writing from/to CUDA generic memory"
  },
  {
    "id": 23302,
    "content": "Python 3"
  },
  {
    "id": 23303,
    "content": "6 and 3"
  },
  {
    "id": 23304,
    "content": "7 deprecation notice Support for end-of-life Python 3"
  },
  {
    "id": 23305,
    "content": "6 and 3"
  },
  {
    "id": 23306,
    "content": "7 versions is deprecated"
  },
  {
    "id": 23308,
    "content": "12"
  },
  {
    "id": 23313,
    "content": "12"
  },
  {
    "id": 23317,
    "content": "CUDA Memory Checker integration removed cuda-memcheck has been deprecated in CUDA 11"
  },
  {
    "id": 23318,
    "content": "x and replaced by Compute Sanitizer"
  },
  {
    "id": 23321,
    "content": "0 or newer"
  },
  {
    "id": 23323,
    "content": "Fixed Issues Addressed a hang that could be encountered when stepping through device system calls"
  },
  {
    "id": 23326,
    "content": "11"
  },
  {
    "id": 23330,
    "content": "11"
  },
  {
    "id": 23331,
    "content": "5 Release Python 3 support on Jetson and Drive Tegra devices Support for Python 2 has been removed"
  },
  {
    "id": 23332,
    "content": "11"
  },
  {
    "id": 23335,
    "content": "Coredump support Added support for writing coredumps to named pipe using CUDA_COREDUMP_FILE"
  },
  {
    "id": 23337,
    "content": "11"
  },
  {
    "id": 23338,
    "content": "2 Update 1 Release GDB TUI deprecation notice Support for GDB TUI mode is being deprecated"
  },
  {
    "id": 23339,
    "content": "This will avoid cross platform dependency mismatches for OSes that lack ncurses-5"
  },
  {
    "id": 23340,
    "content": "5 support"
  },
  {
    "id": 23341,
    "content": "See gdb 8"
  },
  {
    "id": 23342,
    "content": "3"
  },
  {
    "id": 23343,
    "content": "1 changes Support for SM 8"
  },
  {
    "id": 23344,
    "content": "6 CUDA-GDB now supports Devices with Compute Capability 8"
  },
  {
    "id": 23345,
    "content": "6"
  },
  {
    "id": 23350,
    "content": "9"
  },
  {
    "id": 23352,
    "content": "New environment variable: CUDA_ENABLE_USER_TRIGGERED_COREDUMP can be used to enable this feature"
  },
  {
    "id": 23353,
    "content": "9"
  },
  {
    "id": 23355,
    "content": "New environment variable: CUDA_ENABLE_LIGHTWEIGHT_COREDUMP can be used to enable this feature"
  },
  {
    "id": 23356,
    "content": "7"
  },
  {
    "id": 23357,
    "content": "0 Release GPU core dump support CUDA-GDB supports reading GPU and GPU+CPU core dump files"
  },
  {
    "id": 23359,
    "content": "6"
  },
  {
    "id": 23361,
    "content": "6"
  },
  {
    "id": 23367,
    "content": "Precise Error Attribution On Maxwell architecture (SM 5"
  },
  {
    "id": 23372,
    "content": "5"
  },
  {
    "id": 23378,
    "content": "5"
  },
  {
    "id": 23380,
    "content": "0 toolkit"
  },
  {
    "id": 23384,
    "content": "Inlined Subroutine Support Inlined subroutines are now accessible from the debugger on SM 2"
  },
  {
    "id": 23385,
    "content": "0 and above"
  },
  {
    "id": 23387,
    "content": "4"
  },
  {
    "id": 23389,
    "content": "4"
  },
  {
    "id": 23391,
    "content": "3"
  },
  {
    "id": 23392,
    "content": "5 on Darwin (the Apple branch)"
  },
  {
    "id": 23393,
    "content": "Now CUDA-GDB supports newer versions of GCC (tested up to GCC 4"
  },
  {
    "id": 23394,
    "content": "5), has better support for DWARF3 debug information, and better C++ debugging support"
  },
  {
    "id": 23395,
    "content": "Simultaneous Sessions Support With the 4"
  },
  {
    "id": 23396,
    "content": "1 release, the single CUDA-GDB process restriction is lifted"
  },
  {
    "id": 23407,
    "content": "3"
  },
  {
    "id": 23410,
    "content": "3"
  },
  {
    "id": 23411,
    "content": "1"
  },
  {
    "id": 23412,
    "content": "Setting Up the Debugger Environment  3"
  },
  {
    "id": 23413,
    "content": "1"
  },
  {
    "id": 23414,
    "content": "1"
  },
  {
    "id": 23416,
    "content": "to a user-writeable folder before launching cuda-gdb"
  },
  {
    "id": 23417,
    "content": "3"
  },
  {
    "id": 23418,
    "content": "1"
  },
  {
    "id": 23419,
    "content": "2"
  },
  {
    "id": 23421,
    "content": "2"
  },
  {
    "id": 23426,
    "content": "3"
  },
  {
    "id": 23427,
    "content": "2"
  },
  {
    "id": 23428,
    "content": "2"
  },
  {
    "id": 23431,
    "content": "3"
  },
  {
    "id": 23432,
    "content": "2"
  },
  {
    "id": 23433,
    "content": "3"
  },
  {
    "id": 23436,
    "content": "The list of GPUs and their respective compute capability, see https: developer"
  },
  {
    "id": 23437,
    "content": "nvidia"
  },
  {
    "id": 23438,
    "content": "com/cuda-gpus"
  },
  {
    "id": 23440,
    "content": "documentation at https: docs"
  },
  {
    "id": 23441,
    "content": "nvidia"
  },
  {
    "id": 23442,
    "content": "com/cuda/cuda-compiler-driver-nvcc/index"
  },
  {
    "id": 23443,
    "content": "html#extended-notation 3"
  },
  {
    "id": 23444,
    "content": "3"
  },
  {
    "id": 23449,
    "content": "3"
  },
  {
    "id": 23450,
    "content": "3"
  },
  {
    "id": 23451,
    "content": "2"
  },
  {
    "id": 23456,
    "content": "Note The same kernel can be loaded and used by different contexts and devices at the same time"
  },
  {
    "id": 23458,
    "content": "module is loaded"
  },
  {
    "id": 23459,
    "content": "3"
  },
  {
    "id": 23460,
    "content": "3"
  },
  {
    "id": 23461,
    "content": "3"
  },
  {
    "id": 23466,
    "content": "(cuda-gdb) set sysroot remote: (cuda-gdb) target remote 192"
  },
  {
    "id": 23467,
    "content": "168"
  },
  {
    "id": 23468,
    "content": "0"
  },
  {
    "id": 23469,
    "content": "2:1234 Where 192"
  },
  {
    "id": 23470,
    "content": "168"
  },
  {
    "id": 23471,
    "content": "0"
  },
  {
    "id": 23473,
    "content": "3"
  },
  {
    "id": 23474,
    "content": "3"
  },
  {
    "id": 23475,
    "content": "4"
  },
  {
    "id": 23476,
    "content": "Multiple Debuggers  For devices with compute capability 6"
  },
  {
    "id": 23477,
    "content": "0 and higher several debugging sessions may take place simultaneously"
  },
  {
    "id": 23478,
    "content": "For devices with compute capability less than 6"
  },
  {
    "id": 23483,
    "content": "3"
  },
  {
    "id": 23484,
    "content": "3"
  },
  {
    "id": 23485,
    "content": "5"
  },
  {
    "id": 23489,
    "content": "d/10-ptrace"
  },
  {
    "id": 23490,
    "content": "conf"
  },
  {
    "id": 23491,
    "content": "4"
  },
  {
    "id": 23492,
    "content": "CUDA-GDB Extensions  4"
  },
  {
    "id": 23493,
    "content": "1"
  },
  {
    "id": 23495,
    "content": "thread 1 4"
  },
  {
    "id": 23496,
    "content": "2"
  },
  {
    "id": 23498,
    "content": "GDB command CUDA commands can also be queried using the apropos command"
  },
  {
    "id": 23499,
    "content": "4"
  },
  {
    "id": 23500,
    "content": "3"
  },
  {
    "id": 23501,
    "content": "Initialization File  The initialization file for CUDA-GDB is named"
  },
  {
    "id": 23502,
    "content": "cuda-gdbinit and follows the same rules as the standard gdbinit file used by GDB"
  },
  {
    "id": 23503,
    "content": "Those commands will be processed in order when CUDA-GDB is launched"
  },
  {
    "id": 23504,
    "content": "4"
  },
  {
    "id": 23505,
    "content": "4"
  },
  {
    "id": 23506,
    "content": "GUI Integration  Emacs CUDA-GDB works with GUD in Emacs and XEmacs"
  },
  {
    "id": 23508,
    "content": "4"
  },
  {
    "id": 23509,
    "content": "5"
  },
  {
    "id": 23510,
    "content": "GPU core dump support  There are two ways to configure the core dump options for CUDA applications"
  },
  {
    "id": 23519,
    "content": "0 or higher"
  },
  {
    "id": 23521,
    "content": "QNX platform"
  },
  {
    "id": 23522,
    "content": "GPUs with compute capability less than 6"
  },
  {
    "id": 23523,
    "content": "0 will return CUDA_ERROR_NOT_SUPPORTED when using the Coredump Attributes Control API"
  },
  {
    "id": 23525,
    "content": "Unless explicitly documented as a supported use case (e"
  },
  {
    "id": 23526,
    "content": "g generate-cuda-core-file command)"
  },
  {
    "id": 23529,
    "content": "Note Starting from CUDA 11"
  },
  {
    "id": 23531,
    "content": "nvidia"
  },
  {
    "id": 23532,
    "content": "com/compute-sanitizer/ComputeSanitizer/index"
  },
  {
    "id": 23537,
    "content": "It is named core_TIME_HOSTNAME_PID"
  },
  {
    "id": 23541,
    "content": "%h"
  },
  {
    "id": 23542,
    "content": "%p Would result in GPU core dumps being written to newName"
  },
  {
    "id": 23543,
    "content": "myhost"
  },
  {
    "id": 23544,
    "content": "1234 relative to the current working directory"
  },
  {
    "id": 23545,
    "content": "Setting CUDA_COREDUMP_FILE to: export CUDA_COREDUMP_FILE=\"/home/$USER/newName"
  },
  {
    "id": 23546,
    "content": "%h"
  },
  {
    "id": 23548,
    "content": "If CUDA_COREDUMP_FILE points to an existing file of FIFO type (e"
  },
  {
    "id": 23549,
    "content": "g named pipe), the core dump will be streamed to it"
  },
  {
    "id": 23551,
    "content": "gz' Note When piping a coredump, the % specifiers will not be recognized"
  },
  {
    "id": 23563,
    "content": "(cuda-gdb) target cudacore core cuda"
  },
  {
    "id": 23564,
    "content": "localhost"
  },
  {
    "id": 23565,
    "content": "1234 This will open the core dump file and print the exception encountered during program execution"
  },
  {
    "id": 23570,
    "content": "set to the lowest granularity level–the device thread"
  },
  {
    "id": 23571,
    "content": "5"
  },
  {
    "id": 23572,
    "content": "1"
  },
  {
    "id": 23573,
    "content": "Software Coordinates vs"
  },
  {
    "id": 23574,
    "content": "Hardware Coordinates  A device thread belongs to a block, which in turn belongs to a kernel"
  },
  {
    "id": 23576,
    "content": "device thread"
  },
  {
    "id": 23577,
    "content": "5"
  },
  {
    "id": 23578,
    "content": "2"
  },
  {
    "id": 23580,
    "content": "3"
  },
  {
    "id": 23582,
    "content": "x * blockDim"
  },
  {
    "id": 23585,
    "content": "x * blockDim"
  },
  {
    "id": 23587,
    "content": "x * blockDim"
  },
  {
    "id": 23588,
    "content": "6"
  },
  {
    "id": 23593,
    "content": "6"
  },
  {
    "id": 23594,
    "content": "2"
  },
  {
    "id": 23602,
    "content": "On devices prior to Hopper (SM 9"
  },
  {
    "id": 23604,
    "content": "Note It is not possible to step into a device launch call (nor the routine launched by the call)"
  },
  {
    "id": 23605,
    "content": "7"
  },
  {
    "id": 23608,
    "content": "by additional threads"
  },
  {
    "id": 23609,
    "content": "7"
  },
  {
    "id": 23610,
    "content": "1"
  },
  {
    "id": 23613,
    "content": "2"
  },
  {
    "id": 23615,
    "content": "7"
  },
  {
    "id": 23616,
    "content": "3"
  },
  {
    "id": 23618,
    "content": "7"
  },
  {
    "id": 23619,
    "content": "4"
  },
  {
    "id": 23621,
    "content": "7"
  },
  {
    "id": 23622,
    "content": "5"
  },
  {
    "id": 23627,
    "content": "8"
  },
  {
    "id": 23628,
    "content": "3"
  },
  {
    "id": 23629,
    "content": "1"
  },
  {
    "id": 23630,
    "content": "info cuda devices  This command enumerates all the GPUs in the system sorted by device index"
  },
  {
    "id": 23633,
    "content": "3"
  },
  {
    "id": 23634,
    "content": "2"
  },
  {
    "id": 23637,
    "content": "8"
  },
  {
    "id": 23638,
    "content": "3"
  },
  {
    "id": 23639,
    "content": "3"
  },
  {
    "id": 23643,
    "content": "8"
  },
  {
    "id": 23644,
    "content": "3"
  },
  {
    "id": 23645,
    "content": "4"
  },
  {
    "id": 23649,
    "content": "8"
  },
  {
    "id": 23650,
    "content": "3"
  },
  {
    "id": 23651,
    "content": "5"
  },
  {
    "id": 23652,
    "content": "info cuda kernels  This command displays on all the active kernels on the GPU in focus"
  },
  {
    "id": 23656,
    "content": "8"
  },
  {
    "id": 23657,
    "content": "3"
  },
  {
    "id": 23658,
    "content": "6"
  },
  {
    "id": 23661,
    "content": "8"
  },
  {
    "id": 23662,
    "content": "3"
  },
  {
    "id": 23663,
    "content": "7"
  },
  {
    "id": 23666,
    "content": "cu 376 (0,0,0)(32,0,0) (191,0,0) (127,0,0) 24544 0x000000000088f800 acos"
  },
  {
    "id": 23667,
    "content": "cu 374"
  },
  {
    "id": 23668,
    "content": "Coalescing can be turned off as follows in which case more information is displayed with the output"
  },
  {
    "id": 23674,
    "content": "3"
  },
  {
    "id": 23675,
    "content": "8"
  },
  {
    "id": 23678,
    "content": "on , no kernel will be reported as active"
  },
  {
    "id": 23679,
    "content": "8"
  },
  {
    "id": 23680,
    "content": "3"
  },
  {
    "id": 23681,
    "content": "9"
  },
  {
    "id": 23683,
    "content": "(32,1,1) kernel4(b=5) This command supports filters and the default is kernel all"
  },
  {
    "id": 23684,
    "content": "8"
  },
  {
    "id": 23685,
    "content": "3"
  },
  {
    "id": 23686,
    "content": "10"
  },
  {
    "id": 23688,
    "content": "3"
  },
  {
    "id": 23689,
    "content": "11"
  },
  {
    "id": 23691,
    "content": "71000004, pi = 3"
  },
  {
    "id": 23692,
    "content": "1400000000000001} 8"
  },
  {
    "id": 23693,
    "content": "4"
  },
  {
    "id": 23696,
    "content": "For Maxwell (SM 5"
  },
  {
    "id": 23700,
    "content": "E"
  },
  {
    "id": 23701,
    "content": "U8"
  },
  {
    "id": 23702,
    "content": "STRONG"
  },
  {
    "id": 23703,
    "content": "SYS [R6"
  },
  {
    "id": 23704,
    "content": "64], R5 End of assembler dump"
  },
  {
    "id": 23705,
    "content": "8"
  },
  {
    "id": 23706,
    "content": "5"
  },
  {
    "id": 23708,
    "content": "inspecting by printing system registers group or by using their respective pseudo-names: $P0"
  },
  {
    "id": 23710,
    "content": "6"
  },
  {
    "id": 23715,
    "content": "By default, only context event messages are displayed"
  },
  {
    "id": 23716,
    "content": "9"
  },
  {
    "id": 23717,
    "content": "1"
  },
  {
    "id": 23720,
    "content": "9"
  },
  {
    "id": 23721,
    "content": "2"
  },
  {
    "id": 23725,
    "content": "10 Automatic Error Checking  10"
  },
  {
    "id": 23726,
    "content": "1"
  },
  {
    "id": 23729,
    "content": "10"
  },
  {
    "id": 23730,
    "content": "2"
  },
  {
    "id": 23736,
    "content": "Rely on the compute-sanitizer memcheck tool to catch accesses that can lead to an exception"
  },
  {
    "id": 23741,
    "content": "The main cause of this error is large amounts of divergence in the presence of function calls"
  },
  {
    "id": 23750,
    "content": "10"
  },
  {
    "id": 23751,
    "content": "3"
  },
  {
    "id": 23756,
    "content": "The rest of the program is executed normally to minimize the slow-down caused by single-stepping"
  },
  {
    "id": 23759,
    "content": "g"
  },
  {
    "id": 23760,
    "content": ", l or i )"
  },
  {
    "id": 23766,
    "content": "This command already exists for breakpoints"
  },
  {
    "id": 23767,
    "content": "11"
  },
  {
    "id": 23769,
    "content": "1"
  },
  {
    "id": 23772,
    "content": "return 0; 45 } 11"
  },
  {
    "id": 23773,
    "content": "1"
  },
  {
    "id": 23774,
    "content": "1"
  },
  {
    "id": 23776,
    "content": "cu and that no additional compiler flags are required for compilation"
  },
  {
    "id": 23778,
    "content": "Run the CUDA application, and it executes until it reaches the first breakpoint ( main ) set in 3"
  },
  {
    "id": 23780,
    "content": "++"
  },
  {
    "id": 23781,
    "content": "done Breakpoint 1, main () at bitreverse"
  },
  {
    "id": 23784,
    "content": "cu, line 21"
  },
  {
    "id": 23788,
    "content": "Continuing"
  },
  {
    "id": 23791,
    "content": "11"
  },
  {
    "id": 23792,
    "content": "2"
  },
  {
    "id": 23793,
    "content": "1"
  },
  {
    "id": 23798,
    "content": "cu, line 11"
  },
  {
    "id": 23800,
    "content": "cu, line 16"
  },
  {
    "id": 23802,
    "content": "Start it from the beginning"
  },
  {
    "id": 23806,
    "content": "11"
  },
  {
    "id": 23807,
    "content": "3"
  },
  {
    "id": 23810,
    "content": "nvidia"
  },
  {
    "id": 23811,
    "content": "com:0 xterm -e cuda-gdb a"
  },
  {
    "id": 23812,
    "content": "out Job launchers have different ways of exporting environment variables to the cluster nodes"
  },
  {
    "id": 23814,
    "content": "sleep ( 5 ); } } Recompile and launch the application"
  },
  {
    "id": 23816,
    "content": "For devices with compute capability below 6"
  },
  {
    "id": 23818,
    "content": "It may also prevent CUDA IPC working between GPUs on a node"
  },
  {
    "id": 23819,
    "content": "12"
  },
  {
    "id": 23821,
    "content": "12"
  },
  {
    "id": 23822,
    "content": "1"
  },
  {
    "id": 23825,
    "content": "12"
  },
  {
    "id": 23826,
    "content": "2"
  },
  {
    "id": 23829,
    "content": "12"
  },
  {
    "id": 23830,
    "content": "3"
  },
  {
    "id": 23832,
    "content": "12"
  },
  {
    "id": 23833,
    "content": "4"
  },
  {
    "id": 23836,
    "content": "This setting is the default and is always safe"
  },
  {
    "id": 23837,
    "content": "12"
  },
  {
    "id": 23838,
    "content": "5"
  },
  {
    "id": 23840,
    "content": "single-stepping"
  },
  {
    "id": 23841,
    "content": "This is the default starting with the 6"
  },
  {
    "id": 23842,
    "content": "0 release"
  },
  {
    "id": 23843,
    "content": "12"
  },
  {
    "id": 23844,
    "content": "6"
  },
  {
    "id": 23846,
    "content": "12"
  },
  {
    "id": 23847,
    "content": "7"
  },
  {
    "id": 23850,
    "content": "This setting may report erroneous values"
  },
  {
    "id": 23851,
    "content": "12"
  },
  {
    "id": 23852,
    "content": "8"
  },
  {
    "id": 23854,
    "content": "The user needs to also ensure that the root file system has both read/write permissions set"
  },
  {
    "id": 23856,
    "content": "9"
  },
  {
    "id": 23858,
    "content": "8 release"
  },
  {
    "id": 23860,
    "content": "12"
  },
  {
    "id": 23861,
    "content": "10"
  },
  {
    "id": 23864,
    "content": "12"
  },
  {
    "id": 23865,
    "content": "11"
  },
  {
    "id": 23868,
    "content": "12 12"
  },
  {
    "id": 23873,
    "content": "Debugging compute-intensive apps may require to increase or disable TDR"
  },
  {
    "id": 23874,
    "content": "14"
  },
  {
    "id": 23876,
    "content": "Python not initialized This happens due to a missing Python 3"
  },
  {
    "id": 23877,
    "content": "x library on the machine, installing it fixes the issue"
  },
  {
    "id": 23878,
    "content": "This can also be caused by having a mismatched major"
  },
  {
    "id": 23879,
    "content": "minor version of libpython installed with the default python3 interpreter in PATH"
  },
  {
    "id": 23880,
    "content": "For example, the following command would tell us that a libpython3"
  },
  {
    "id": 23881,
    "content": "8"
  },
  {
    "id": 23882,
    "content": "so* needs to be installed in a default library search path: $ python3 --version Python 3"
  },
  {
    "id": 23883,
    "content": "8"
  },
  {
    "id": 23885,
    "content": "04/22 04 $ sudo apt-get -y install python3 8 $ sudo apt-get -y install libpython3"
  },
  {
    "id": 23886,
    "content": "8 15"
  },
  {
    "id": 23887,
    "content": "On Windows Subsystem for Linux (WSL), the r555 WDDM driver released with the CUDA Toolkit 12"
  },
  {
    "id": 23892,
    "content": "application"
  },
  {
    "id": 23903,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 23915,
    "content": "16"
  },
  {
    "id": 23916,
    "content": "2"
  },
  {
    "id": 23917,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 23918,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 23919,
    "content": "16"
  },
  {
    "id": 23920,
    "content": "3"
  },
  {
    "id": 23922,
    "content": "S"
  },
  {
    "id": 23925,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 23926,
    "content": "Navigation"
  },
  {
    "id": 23927,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 23928,
    "content": "pageBottom();}\n1"
  },
  {
    "id": 23930,
    "content": "2"
  },
  {
    "id": 23931,
    "content": "9"
  },
  {
    "id": 23932,
    "content": "1"
  },
  {
    "id": 23933,
    "content": "22"
  },
  {
    "id": 23934,
    "content": "Introduction v12"
  },
  {
    "id": 23940,
    "content": "For more information on the CUDA programming model, consult the CUDA C++ Programming Guide"
  },
  {
    "id": 23941,
    "content": "1"
  },
  {
    "id": 23942,
    "content": "1"
  },
  {
    "id": 23943,
    "content": "2"
  },
  {
    "id": 23945,
    "content": "GPU functions as fatbinary images in the host object file"
  },
  {
    "id": 23947,
    "content": "1"
  },
  {
    "id": 23948,
    "content": "1"
  },
  {
    "id": 23949,
    "content": "3"
  },
  {
    "id": 23952,
    "content": "1"
  },
  {
    "id": 23953,
    "content": "2"
  },
  {
    "id": 23956,
    "content": "platforms, the default host compiler executable ( gcc and g++ on Linux and cl"
  },
  {
    "id": 23958,
    "content": "2"
  },
  {
    "id": 23959,
    "content": "Compilation Phases  2"
  },
  {
    "id": 23960,
    "content": "1"
  },
  {
    "id": 23965,
    "content": "2"
  },
  {
    "id": 23966,
    "content": "2"
  },
  {
    "id": 23970,
    "content": "2"
  },
  {
    "id": 23971,
    "content": "3"
  },
  {
    "id": 23973,
    "content": "cu CUDA source file, containing host code and device functions c C source file"
  },
  {
    "id": 23974,
    "content": "cc ,"
  },
  {
    "id": 23975,
    "content": "cxx ,"
  },
  {
    "id": 23976,
    "content": "cpp C++ source file"
  },
  {
    "id": 23978,
    "content": "o ,"
  },
  {
    "id": 23979,
    "content": "obj Object file"
  },
  {
    "id": 23980,
    "content": "a ,"
  },
  {
    "id": 23982,
    "content": "It just passes files of these types to the linker when the linking phase is executed"
  },
  {
    "id": 23983,
    "content": "2"
  },
  {
    "id": 23984,
    "content": "4"
  },
  {
    "id": 23986,
    "content": "compilation to C/C++ source file --cuda -cuda"
  },
  {
    "id": 23987,
    "content": "cpp"
  },
  {
    "id": 23988,
    "content": "ii appended to source file name, as in x"
  },
  {
    "id": 23989,
    "content": "cu"
  },
  {
    "id": 23990,
    "content": "cpp"
  },
  {
    "id": 23991,
    "content": "ii"
  },
  {
    "id": 23994,
    "content": "--device-link -dlink a_dlink obj on Windows or a_dlink"
  },
  {
    "id": 23996,
    "content": "exe on Windows or a"
  },
  {
    "id": 24001,
    "content": "Unless a phase option is specified, nvcc will compile and link all its input files"
  },
  {
    "id": 24002,
    "content": "3"
  },
  {
    "id": 24005,
    "content": "e"
  },
  {
    "id": 24011,
    "content": "names can be used instead of long names for the same effect"
  },
  {
    "id": 24012,
    "content": "4"
  },
  {
    "id": 24013,
    "content": "2"
  },
  {
    "id": 24015,
    "content": "4"
  },
  {
    "id": 24016,
    "content": "2"
  },
  {
    "id": 24017,
    "content": "1"
  },
  {
    "id": 24018,
    "content": "File and Path Specifications  4"
  },
  {
    "id": 24019,
    "content": "2"
  },
  {
    "id": 24020,
    "content": "1"
  },
  {
    "id": 24021,
    "content": "1"
  },
  {
    "id": 24022,
    "content": "--output-file file ( -o )  Specify name and location of the output file"
  },
  {
    "id": 24023,
    "content": "4"
  },
  {
    "id": 24024,
    "content": "2"
  },
  {
    "id": 24025,
    "content": "1"
  },
  {
    "id": 24026,
    "content": "2"
  },
  {
    "id": 24030,
    "content": "4"
  },
  {
    "id": 24031,
    "content": "2"
  },
  {
    "id": 24032,
    "content": "1"
  },
  {
    "id": 24033,
    "content": "3"
  },
  {
    "id": 24035,
    "content": "4"
  },
  {
    "id": 24036,
    "content": "2"
  },
  {
    "id": 24037,
    "content": "1"
  },
  {
    "id": 24038,
    "content": "4"
  },
  {
    "id": 24040,
    "content": "4"
  },
  {
    "id": 24041,
    "content": "2"
  },
  {
    "id": 24042,
    "content": "1"
  },
  {
    "id": 24043,
    "content": "5"
  },
  {
    "id": 24044,
    "content": "--define-macro def,"
  },
  {
    "id": 24046,
    "content": "4"
  },
  {
    "id": 24047,
    "content": "2"
  },
  {
    "id": 24048,
    "content": "1"
  },
  {
    "id": 24049,
    "content": "6"
  },
  {
    "id": 24050,
    "content": "--undefine-macro def, ( -U )  Undefine an existing macro during preprocessing or compilation"
  },
  {
    "id": 24051,
    "content": "4"
  },
  {
    "id": 24052,
    "content": "2"
  },
  {
    "id": 24053,
    "content": "1"
  },
  {
    "id": 24054,
    "content": "7"
  },
  {
    "id": 24055,
    "content": "--include-path path,"
  },
  {
    "id": 24056,
    "content": "( -L )  Specify library search paths (see Libraries )"
  },
  {
    "id": 24057,
    "content": "4"
  },
  {
    "id": 24058,
    "content": "2"
  },
  {
    "id": 24059,
    "content": "1"
  },
  {
    "id": 24060,
    "content": "10"
  },
  {
    "id": 24062,
    "content": "4"
  },
  {
    "id": 24063,
    "content": "2"
  },
  {
    "id": 24064,
    "content": "1"
  },
  {
    "id": 24065,
    "content": "11"
  },
  {
    "id": 24067,
    "content": "4"
  },
  {
    "id": 24068,
    "content": "2"
  },
  {
    "id": 24069,
    "content": "1"
  },
  {
    "id": 24070,
    "content": "12"
  },
  {
    "id": 24072,
    "content": "4"
  },
  {
    "id": 24073,
    "content": "2"
  },
  {
    "id": 24074,
    "content": "1"
  },
  {
    "id": 24075,
    "content": "13"
  },
  {
    "id": 24078,
    "content": "4"
  },
  {
    "id": 24079,
    "content": "2"
  },
  {
    "id": 24080,
    "content": "1"
  },
  {
    "id": 24081,
    "content": "14"
  },
  {
    "id": 24083,
    "content": "This option has no effect on MacOS"
  },
  {
    "id": 24084,
    "content": "4"
  },
  {
    "id": 24085,
    "content": "2"
  },
  {
    "id": 24086,
    "content": "1"
  },
  {
    "id": 24087,
    "content": "15"
  },
  {
    "id": 24089,
    "content": "4"
  },
  {
    "id": 24090,
    "content": "2"
  },
  {
    "id": 24091,
    "content": "1"
  },
  {
    "id": 24092,
    "content": "16"
  },
  {
    "id": 24094,
    "content": "4"
  },
  {
    "id": 24095,
    "content": "2"
  },
  {
    "id": 24096,
    "content": "1"
  },
  {
    "id": 24097,
    "content": "17"
  },
  {
    "id": 24099,
    "content": "4"
  },
  {
    "id": 24100,
    "content": "2"
  },
  {
    "id": 24101,
    "content": "1"
  },
  {
    "id": 24102,
    "content": "18"
  },
  {
    "id": 24104,
    "content": "4"
  },
  {
    "id": 24105,
    "content": "2"
  },
  {
    "id": 24106,
    "content": "1"
  },
  {
    "id": 24107,
    "content": "19"
  },
  {
    "id": 24109,
    "content": "4"
  },
  {
    "id": 24110,
    "content": "2"
  },
  {
    "id": 24111,
    "content": "2"
  },
  {
    "id": 24113,
    "content": "4"
  },
  {
    "id": 24114,
    "content": "2"
  },
  {
    "id": 24115,
    "content": "2"
  },
  {
    "id": 24116,
    "content": "1"
  },
  {
    "id": 24117,
    "content": "--link ( -link )  Specify the default behavior: compile and link all input files"
  },
  {
    "id": 24118,
    "content": "Default Output File Name a"
  },
  {
    "id": 24119,
    "content": "exe on Windows or a"
  },
  {
    "id": 24120,
    "content": "out on other platforms is used as the default output file name"
  },
  {
    "id": 24121,
    "content": "4"
  },
  {
    "id": 24122,
    "content": "2"
  },
  {
    "id": 24123,
    "content": "2"
  },
  {
    "id": 24124,
    "content": "2"
  },
  {
    "id": 24126,
    "content": "4"
  },
  {
    "id": 24127,
    "content": "2"
  },
  {
    "id": 24128,
    "content": "2"
  },
  {
    "id": 24129,
    "content": "3"
  },
  {
    "id": 24130,
    "content": "--device-link ( -dlink )  Link object files with relocatable device code and"
  },
  {
    "id": 24131,
    "content": "ptx ,"
  },
  {
    "id": 24132,
    "content": "cubin , and"
  },
  {
    "id": 24135,
    "content": "4"
  },
  {
    "id": 24136,
    "content": "2"
  },
  {
    "id": 24137,
    "content": "2"
  },
  {
    "id": 24138,
    "content": "4"
  },
  {
    "id": 24139,
    "content": "--device-c ( -dc )  Compile each"
  },
  {
    "id": 24140,
    "content": "c ,"
  },
  {
    "id": 24141,
    "content": "cc ,"
  },
  {
    "id": 24142,
    "content": "cpp ,"
  },
  {
    "id": 24143,
    "content": "cxx , and"
  },
  {
    "id": 24145,
    "content": "obj on Windows and"
  },
  {
    "id": 24147,
    "content": "cu is x"
  },
  {
    "id": 24148,
    "content": "obj on Windows and x"
  },
  {
    "id": 24149,
    "content": "o on other platforms"
  },
  {
    "id": 24150,
    "content": "4"
  },
  {
    "id": 24151,
    "content": "2"
  },
  {
    "id": 24152,
    "content": "2"
  },
  {
    "id": 24153,
    "content": "5"
  },
  {
    "id": 24154,
    "content": "--device-w ( -dw )  Compile each"
  },
  {
    "id": 24155,
    "content": "c ,"
  },
  {
    "id": 24156,
    "content": "cc ,"
  },
  {
    "id": 24157,
    "content": "cpp ,"
  },
  {
    "id": 24158,
    "content": "cxx , and"
  },
  {
    "id": 24159,
    "content": "cu input file into an object file that contains executable device code"
  },
  {
    "id": 24160,
    "content": "It is equivalent to --relocatable-device-code=false --compile"
  },
  {
    "id": 24161,
    "content": "4"
  },
  {
    "id": 24162,
    "content": "2"
  },
  {
    "id": 24163,
    "content": "2"
  },
  {
    "id": 24164,
    "content": "6"
  },
  {
    "id": 24165,
    "content": "--cuda ( -cuda )  Compile each"
  },
  {
    "id": 24166,
    "content": "cu input file to a cu"
  },
  {
    "id": 24167,
    "content": "cpp"
  },
  {
    "id": 24168,
    "content": "ii file Default Output File Name"
  },
  {
    "id": 24169,
    "content": "cu"
  },
  {
    "id": 24170,
    "content": "cpp"
  },
  {
    "id": 24172,
    "content": "cu is x cu"
  },
  {
    "id": 24173,
    "content": "cpp"
  },
  {
    "id": 24174,
    "content": "ii"
  },
  {
    "id": 24175,
    "content": "4"
  },
  {
    "id": 24176,
    "content": "2"
  },
  {
    "id": 24177,
    "content": "2"
  },
  {
    "id": 24178,
    "content": "7"
  },
  {
    "id": 24179,
    "content": "--compile ( -c )  Compile each"
  },
  {
    "id": 24180,
    "content": "c ,"
  },
  {
    "id": 24181,
    "content": "cc ,"
  },
  {
    "id": 24182,
    "content": "cpp ,"
  },
  {
    "id": 24183,
    "content": "cxx , and"
  },
  {
    "id": 24184,
    "content": "cu input file into an object file"
  },
  {
    "id": 24185,
    "content": "4"
  },
  {
    "id": 24186,
    "content": "2"
  },
  {
    "id": 24187,
    "content": "2"
  },
  {
    "id": 24188,
    "content": "8"
  },
  {
    "id": 24189,
    "content": "--fatbin ( -fatbin )  Compile all"
  },
  {
    "id": 24190,
    "content": "cu ,"
  },
  {
    "id": 24191,
    "content": "ptx , and"
  },
  {
    "id": 24192,
    "content": "cubin input files to device-only fatbin files"
  },
  {
    "id": 24194,
    "content": "cu is x"
  },
  {
    "id": 24195,
    "content": "fatbin"
  },
  {
    "id": 24196,
    "content": "4"
  },
  {
    "id": 24197,
    "content": "2"
  },
  {
    "id": 24198,
    "content": "2"
  },
  {
    "id": 24199,
    "content": "9"
  },
  {
    "id": 24200,
    "content": "--cubin ( -cubin )  Compile all"
  },
  {
    "id": 24201,
    "content": "cu and"
  },
  {
    "id": 24202,
    "content": "ptx input files to device-only cubin files"
  },
  {
    "id": 24204,
    "content": "cu is x"
  },
  {
    "id": 24205,
    "content": "cubin"
  },
  {
    "id": 24206,
    "content": "4"
  },
  {
    "id": 24207,
    "content": "2"
  },
  {
    "id": 24208,
    "content": "2"
  },
  {
    "id": 24209,
    "content": "10"
  },
  {
    "id": 24210,
    "content": "--ptx ( -ptx )  Compile all"
  },
  {
    "id": 24211,
    "content": "cu input files to device-only ptx files"
  },
  {
    "id": 24213,
    "content": "cu is x"
  },
  {
    "id": 24214,
    "content": "ptx"
  },
  {
    "id": 24215,
    "content": "4"
  },
  {
    "id": 24216,
    "content": "2"
  },
  {
    "id": 24217,
    "content": "2"
  },
  {
    "id": 24218,
    "content": "11"
  },
  {
    "id": 24219,
    "content": "--preprocess ( -E )  Preprocess all"
  },
  {
    "id": 24220,
    "content": "c ,"
  },
  {
    "id": 24221,
    "content": "cc ,"
  },
  {
    "id": 24222,
    "content": "cpp ,"
  },
  {
    "id": 24223,
    "content": "cxx , and"
  },
  {
    "id": 24224,
    "content": "cu input files"
  },
  {
    "id": 24225,
    "content": "Default Output File Name The output is generated in stdout by default"
  },
  {
    "id": 24226,
    "content": "4"
  },
  {
    "id": 24227,
    "content": "2"
  },
  {
    "id": 24228,
    "content": "2"
  },
  {
    "id": 24229,
    "content": "12"
  },
  {
    "id": 24231,
    "content": "c ,"
  },
  {
    "id": 24232,
    "content": "cc ,"
  },
  {
    "id": 24233,
    "content": "cpp ,"
  },
  {
    "id": 24234,
    "content": "cxx , and"
  },
  {
    "id": 24235,
    "content": "cu input file"
  },
  {
    "id": 24237,
    "content": "4"
  },
  {
    "id": 24238,
    "content": "2"
  },
  {
    "id": 24239,
    "content": "2"
  },
  {
    "id": 24240,
    "content": "13"
  },
  {
    "id": 24242,
    "content": "4"
  },
  {
    "id": 24243,
    "content": "2"
  },
  {
    "id": 24244,
    "content": "2"
  },
  {
    "id": 24245,
    "content": "14"
  },
  {
    "id": 24247,
    "content": "c ,"
  },
  {
    "id": 24248,
    "content": "cc ,"
  },
  {
    "id": 24249,
    "content": "cpp ,"
  },
  {
    "id": 24250,
    "content": "cxx , and"
  },
  {
    "id": 24252,
    "content": "d’"
  },
  {
    "id": 24253,
    "content": "Otherwise, the dependency file name is computed by replacing the input file names’s suffix with ‘"
  },
  {
    "id": 24254,
    "content": "d’"
  },
  {
    "id": 24256,
    "content": "4"
  },
  {
    "id": 24257,
    "content": "2"
  },
  {
    "id": 24258,
    "content": "2"
  },
  {
    "id": 24259,
    "content": "15"
  },
  {
    "id": 24263,
    "content": "cu is x"
  },
  {
    "id": 24264,
    "content": "optixir"
  },
  {
    "id": 24265,
    "content": "4"
  },
  {
    "id": 24266,
    "content": "2"
  },
  {
    "id": 24267,
    "content": "2"
  },
  {
    "id": 24268,
    "content": "17"
  },
  {
    "id": 24269,
    "content": "--run ( -run )  Compile and link all input files into an executable, and executes it"
  },
  {
    "id": 24271,
    "content": "4"
  },
  {
    "id": 24272,
    "content": "2"
  },
  {
    "id": 24273,
    "content": "3"
  },
  {
    "id": 24274,
    "content": "Options for Specifying Behavior of Compiler/Linker  4"
  },
  {
    "id": 24275,
    "content": "2"
  },
  {
    "id": 24276,
    "content": "3"
  },
  {
    "id": 24277,
    "content": "1"
  },
  {
    "id": 24278,
    "content": "--profile ( -pg )  Instrument generated code/executable for use by gprof"
  },
  {
    "id": 24279,
    "content": "4"
  },
  {
    "id": 24280,
    "content": "2"
  },
  {
    "id": 24281,
    "content": "3"
  },
  {
    "id": 24282,
    "content": "2"
  },
  {
    "id": 24284,
    "content": "4"
  },
  {
    "id": 24285,
    "content": "2"
  },
  {
    "id": 24286,
    "content": "3"
  },
  {
    "id": 24287,
    "content": "4"
  },
  {
    "id": 24289,
    "content": "4"
  },
  {
    "id": 24290,
    "content": "2"
  },
  {
    "id": 24291,
    "content": "3"
  },
  {
    "id": 24292,
    "content": "6"
  },
  {
    "id": 24293,
    "content": "--generate-line-info ( -lineinfo )  Generate line-number information for device code"
  },
  {
    "id": 24295,
    "content": "4"
  },
  {
    "id": 24296,
    "content": "2"
  },
  {
    "id": 24297,
    "content": "3"
  },
  {
    "id": 24298,
    "content": "8"
  },
  {
    "id": 24299,
    "content": "--optimize level ( -O )  Specify optimization level for host code"
  },
  {
    "id": 24301,
    "content": "Allowed Values on : enable device code optimization"
  },
  {
    "id": 24302,
    "content": "4"
  },
  {
    "id": 24303,
    "content": "2"
  },
  {
    "id": 24304,
    "content": "3"
  },
  {
    "id": 24305,
    "content": "10"
  },
  {
    "id": 24308,
    "content": "4"
  },
  {
    "id": 24309,
    "content": "2"
  },
  {
    "id": 24310,
    "content": "3"
  },
  {
    "id": 24311,
    "content": "11"
  },
  {
    "id": 24312,
    "content": "--gen-opt-lto ( -gen-opt-lto )  Run the optimizer passes before generating the LTO IR"
  },
  {
    "id": 24313,
    "content": "4"
  },
  {
    "id": 24314,
    "content": "2"
  },
  {
    "id": 24315,
    "content": "3"
  },
  {
    "id": 24316,
    "content": "12"
  },
  {
    "id": 24318,
    "content": "concurrently across multiple threads"
  },
  {
    "id": 24320,
    "content": "4"
  },
  {
    "id": 24321,
    "content": "2"
  },
  {
    "id": 24322,
    "content": "3"
  },
  {
    "id": 24323,
    "content": "13"
  },
  {
    "id": 24325,
    "content": "This value is also passed to the host compiler if it provides an equivalent flag"
  },
  {
    "id": 24326,
    "content": "4"
  },
  {
    "id": 24327,
    "content": "2"
  },
  {
    "id": 24328,
    "content": "3"
  },
  {
    "id": 24329,
    "content": "14"
  },
  {
    "id": 24331,
    "content": "Disable exception handling for host code, by passing “-EHs-c-” (for cl"
  },
  {
    "id": 24333,
    "content": "Use option --linker-options when other linker options are required for more control"
  },
  {
    "id": 24334,
    "content": "4"
  },
  {
    "id": 24335,
    "content": "2"
  },
  {
    "id": 24336,
    "content": "3"
  },
  {
    "id": 24337,
    "content": "17"
  },
  {
    "id": 24339,
    "content": "4"
  },
  {
    "id": 24340,
    "content": "2"
  },
  {
    "id": 24341,
    "content": "3"
  },
  {
    "id": 24342,
    "content": "18"
  },
  {
    "id": 24344,
    "content": "4"
  },
  {
    "id": 24345,
    "content": "2"
  },
  {
    "id": 24346,
    "content": "3"
  },
  {
    "id": 24347,
    "content": "19"
  },
  {
    "id": 24349,
    "content": "4"
  },
  {
    "id": 24350,
    "content": "2"
  },
  {
    "id": 24351,
    "content": "3"
  },
  {
    "id": 24352,
    "content": "20"
  },
  {
    "id": 24354,
    "content": "Note that the behavior of this flag may change in future compiler releases"
  },
  {
    "id": 24355,
    "content": "4"
  },
  {
    "id": 24356,
    "content": "2"
  },
  {
    "id": 24357,
    "content": "3"
  },
  {
    "id": 24358,
    "content": "21"
  },
  {
    "id": 24360,
    "content": "4"
  },
  {
    "id": 24361,
    "content": "2"
  },
  {
    "id": 24362,
    "content": "3"
  },
  {
    "id": 24363,
    "content": "22"
  },
  {
    "id": 24364,
    "content": "--expt-extended-lambda ( -expt-extended-lambda )  Alias for --extended-lambda"
  },
  {
    "id": 24365,
    "content": "Allowed Values 64 Default This option is set based on the host platform on which nvcc is executed"
  },
  {
    "id": 24366,
    "content": "4"
  },
  {
    "id": 24367,
    "content": "2"
  },
  {
    "id": 24368,
    "content": "3"
  },
  {
    "id": 24369,
    "content": "24"
  },
  {
    "id": 24370,
    "content": "--m64 ( -m64 )  Alias for --machine=64 4"
  },
  {
    "id": 24371,
    "content": "2"
  },
  {
    "id": 24372,
    "content": "3"
  },
  {
    "id": 24373,
    "content": "25"
  },
  {
    "id": 24378,
    "content": "4"
  },
  {
    "id": 24379,
    "content": "2"
  },
  {
    "id": 24380,
    "content": "3"
  },
  {
    "id": 24381,
    "content": "26"
  },
  {
    "id": 24383,
    "content": "4"
  },
  {
    "id": 24384,
    "content": "2"
  },
  {
    "id": 24385,
    "content": "3"
  },
  {
    "id": 24386,
    "content": "27"
  },
  {
    "id": 24388,
    "content": "4"
  },
  {
    "id": 24389,
    "content": "2"
  },
  {
    "id": 24390,
    "content": "4"
  },
  {
    "id": 24392,
    "content": "4"
  },
  {
    "id": 24393,
    "content": "2"
  },
  {
    "id": 24394,
    "content": "4"
  },
  {
    "id": 24395,
    "content": "2"
  },
  {
    "id": 24396,
    "content": "--linker-options options, ( -Xlinker )  Specify options directly to the host linker"
  },
  {
    "id": 24397,
    "content": "4"
  },
  {
    "id": 24398,
    "content": "2"
  },
  {
    "id": 24399,
    "content": "4"
  },
  {
    "id": 24400,
    "content": "3"
  },
  {
    "id": 24401,
    "content": "--archive-options options, ( -Xarchive )  Specify options directly to the library manager"
  },
  {
    "id": 24402,
    "content": "4"
  },
  {
    "id": 24403,
    "content": "2"
  },
  {
    "id": 24404,
    "content": "4"
  },
  {
    "id": 24405,
    "content": "4"
  },
  {
    "id": 24407,
    "content": "4"
  },
  {
    "id": 24408,
    "content": "2"
  },
  {
    "id": 24409,
    "content": "4"
  },
  {
    "id": 24410,
    "content": "5"
  },
  {
    "id": 24411,
    "content": "--nvlink-options options, ( -Xnvlink )  Specify options directly to nvlink , the device linker"
  },
  {
    "id": 24412,
    "content": "4"
  },
  {
    "id": 24413,
    "content": "2"
  },
  {
    "id": 24414,
    "content": "5"
  },
  {
    "id": 24415,
    "content": "Options for Guiding the Compiler Driver  4"
  },
  {
    "id": 24416,
    "content": "2"
  },
  {
    "id": 24417,
    "content": "5"
  },
  {
    "id": 24418,
    "content": "1"
  },
  {
    "id": 24422,
    "content": "4"
  },
  {
    "id": 24423,
    "content": "2"
  },
  {
    "id": 24424,
    "content": "5"
  },
  {
    "id": 24425,
    "content": "2"
  },
  {
    "id": 24427,
    "content": "4"
  },
  {
    "id": 24428,
    "content": "2"
  },
  {
    "id": 24429,
    "content": "5"
  },
  {
    "id": 24430,
    "content": "3"
  },
  {
    "id": 24432,
    "content": "4"
  },
  {
    "id": 24433,
    "content": "2"
  },
  {
    "id": 24434,
    "content": "5"
  },
  {
    "id": 24435,
    "content": "4"
  },
  {
    "id": 24437,
    "content": "4"
  },
  {
    "id": 24438,
    "content": "2"
  },
  {
    "id": 24439,
    "content": "5"
  },
  {
    "id": 24440,
    "content": "5"
  },
  {
    "id": 24441,
    "content": "--dryrun ( -dryrun )  List the compilation sub-commands without executing them"
  },
  {
    "id": 24442,
    "content": "4"
  },
  {
    "id": 24443,
    "content": "2"
  },
  {
    "id": 24444,
    "content": "5"
  },
  {
    "id": 24445,
    "content": "7"
  },
  {
    "id": 24446,
    "content": "--keep ( -keep )  Keep all intermediate files that are generated during internal compilation steps"
  },
  {
    "id": 24447,
    "content": "4"
  },
  {
    "id": 24448,
    "content": "2"
  },
  {
    "id": 24449,
    "content": "5"
  },
  {
    "id": 24450,
    "content": "8"
  },
  {
    "id": 24452,
    "content": "4"
  },
  {
    "id": 24453,
    "content": "2"
  },
  {
    "id": 24454,
    "content": "5"
  },
  {
    "id": 24455,
    "content": "10"
  },
  {
    "id": 24457,
    "content": "4"
  },
  {
    "id": 24458,
    "content": "2"
  },
  {
    "id": 24459,
    "content": "5"
  },
  {
    "id": 24460,
    "content": "11"
  },
  {
    "id": 24462,
    "content": "4"
  },
  {
    "id": 24463,
    "content": "2"
  },
  {
    "id": 24464,
    "content": "5"
  },
  {
    "id": 24465,
    "content": "12"
  },
  {
    "id": 24466,
    "content": "--use-local-env ( -use-local-env )  Skip MSVC environment initialization"
  },
  {
    "id": 24469,
    "content": "4"
  },
  {
    "id": 24470,
    "content": "2"
  },
  {
    "id": 24471,
    "content": "5"
  },
  {
    "id": 24472,
    "content": "13"
  },
  {
    "id": 24473,
    "content": "--input-drive-prefix prefix ( -idp )  Specify the input drive prefix"
  },
  {
    "id": 24475,
    "content": "Use /cygwin/ as prefix for Cygwin build environments and / as prefix for MinGW"
  },
  {
    "id": 24476,
    "content": "4"
  },
  {
    "id": 24477,
    "content": "2"
  },
  {
    "id": 24478,
    "content": "5"
  },
  {
    "id": 24479,
    "content": "14"
  },
  {
    "id": 24480,
    "content": "--dependency-drive-prefix prefix ( -ddp )  Specify the dependency drive prefix"
  },
  {
    "id": 24482,
    "content": "specifying nothing"
  },
  {
    "id": 24483,
    "content": "4"
  },
  {
    "id": 24484,
    "content": "2"
  },
  {
    "id": 24485,
    "content": "5"
  },
  {
    "id": 24486,
    "content": "15"
  },
  {
    "id": 24488,
    "content": "4"
  },
  {
    "id": 24489,
    "content": "2"
  },
  {
    "id": 24490,
    "content": "5"
  },
  {
    "id": 24491,
    "content": "16"
  },
  {
    "id": 24493,
    "content": "4"
  },
  {
    "id": 24494,
    "content": "2"
  },
  {
    "id": 24495,
    "content": "5"
  },
  {
    "id": 24496,
    "content": "17"
  },
  {
    "id": 24498,
    "content": "WARNING: this makes the ABI incompatible with the CUDA’s kernel ABI for certain 64-bit types"
  },
  {
    "id": 24499,
    "content": "4"
  },
  {
    "id": 24500,
    "content": "2"
  },
  {
    "id": 24501,
    "content": "5"
  },
  {
    "id": 24502,
    "content": "18"
  },
  {
    "id": 24503,
    "content": "--no-device-link ( -nodlink )  Skip the device link step when linking object files"
  },
  {
    "id": 24505,
    "content": "legacy is used as the default stream"
  },
  {
    "id": 24506,
    "content": "4"
  },
  {
    "id": 24507,
    "content": "2"
  },
  {
    "id": 24508,
    "content": "7"
  },
  {
    "id": 24509,
    "content": "Options for Steering GPU Code Generation  4"
  },
  {
    "id": 24510,
    "content": "2"
  },
  {
    "id": 24511,
    "content": "7"
  },
  {
    "id": 24512,
    "content": "1"
  },
  {
    "id": 24518,
    "content": "generated for compute_52 then assembled and optimized for sm_52"
  },
  {
    "id": 24519,
    "content": "4"
  },
  {
    "id": 24520,
    "content": "2"
  },
  {
    "id": 24521,
    "content": "7"
  },
  {
    "id": 24522,
    "content": "2"
  },
  {
    "id": 24526,
    "content": "4"
  },
  {
    "id": 24527,
    "content": "2"
  },
  {
    "id": 24528,
    "content": "7"
  },
  {
    "id": 24529,
    "content": "3"
  },
  {
    "id": 24532,
    "content": "4"
  },
  {
    "id": 24533,
    "content": "2"
  },
  {
    "id": 24534,
    "content": "7"
  },
  {
    "id": 24535,
    "content": "4"
  },
  {
    "id": 24537,
    "content": "4"
  },
  {
    "id": 24538,
    "content": "2"
  },
  {
    "id": 24539,
    "content": "7"
  },
  {
    "id": 24540,
    "content": "5"
  },
  {
    "id": 24542,
    "content": "4"
  },
  {
    "id": 24543,
    "content": "2"
  },
  {
    "id": 24544,
    "content": "7"
  },
  {
    "id": 24545,
    "content": "6"
  },
  {
    "id": 24549,
    "content": "Default No maximum is assumed"
  },
  {
    "id": 24550,
    "content": "4"
  },
  {
    "id": 24551,
    "content": "2"
  },
  {
    "id": 24552,
    "content": "7"
  },
  {
    "id": 24553,
    "content": "7"
  },
  {
    "id": 24555,
    "content": "4"
  },
  {
    "id": 24556,
    "content": "2"
  },
  {
    "id": 24557,
    "content": "7"
  },
  {
    "id": 24558,
    "content": "8"
  },
  {
    "id": 24560,
    "content": "4"
  },
  {
    "id": 24561,
    "content": "2"
  },
  {
    "id": 24562,
    "content": "7"
  },
  {
    "id": 24563,
    "content": "9"
  },
  {
    "id": 24565,
    "content": "4"
  },
  {
    "id": 24566,
    "content": "2"
  },
  {
    "id": 24567,
    "content": "7"
  },
  {
    "id": 24568,
    "content": "10"
  },
  {
    "id": 24570,
    "content": "4"
  },
  {
    "id": 24571,
    "content": "2"
  },
  {
    "id": 24572,
    "content": "7"
  },
  {
    "id": 24573,
    "content": "11"
  },
  {
    "id": 24575,
    "content": "DFMA)"
  },
  {
    "id": 24576,
    "content": "4"
  },
  {
    "id": 24577,
    "content": "2"
  },
  {
    "id": 24578,
    "content": "7"
  },
  {
    "id": 24579,
    "content": "12"
  },
  {
    "id": 24581,
    "content": "Some PTX ISA features may not be usable in this compilation mode"
  },
  {
    "id": 24582,
    "content": "4"
  },
  {
    "id": 24583,
    "content": "2"
  },
  {
    "id": 24584,
    "content": "7"
  },
  {
    "id": 24585,
    "content": "14"
  },
  {
    "id": 24587,
    "content": "4"
  },
  {
    "id": 24588,
    "content": "2"
  },
  {
    "id": 24589,
    "content": "7"
  },
  {
    "id": 24590,
    "content": "15"
  },
  {
    "id": 24592,
    "content": "idx instruction) will be used to implement a switch statement"
  },
  {
    "id": 24593,
    "content": "Default This option is set to 101 and nvcc disables jump table generation for switch statements"
  },
  {
    "id": 24594,
    "content": "4"
  },
  {
    "id": 24595,
    "content": "2"
  },
  {
    "id": 24596,
    "content": "8"
  },
  {
    "id": 24597,
    "content": "Generic Tool Options  4"
  },
  {
    "id": 24598,
    "content": "2"
  },
  {
    "id": 24599,
    "content": "8"
  },
  {
    "id": 24600,
    "content": "1"
  },
  {
    "id": 24601,
    "content": "--disable-warnings ( -w )  Inhibit all warning messages"
  },
  {
    "id": 24602,
    "content": "4"
  },
  {
    "id": 24603,
    "content": "2"
  },
  {
    "id": 24604,
    "content": "8"
  },
  {
    "id": 24605,
    "content": "2"
  },
  {
    "id": 24606,
    "content": "--source-in-ptx ( -src-in-ptx )  Interleave source in PTX"
  },
  {
    "id": 24607,
    "content": "May only be used in conjunction with --device-debug or --generate-line-info"
  },
  {
    "id": 24608,
    "content": "4"
  },
  {
    "id": 24609,
    "content": "2"
  },
  {
    "id": 24610,
    "content": "8"
  },
  {
    "id": 24611,
    "content": "3"
  },
  {
    "id": 24612,
    "content": "--restrict ( -restrict )  Assert that all kernel pointer parameters are restrict pointers"
  },
  {
    "id": 24613,
    "content": "4"
  },
  {
    "id": 24614,
    "content": "2"
  },
  {
    "id": 24615,
    "content": "8"
  },
  {
    "id": 24616,
    "content": "4"
  },
  {
    "id": 24618,
    "content": "4"
  },
  {
    "id": 24619,
    "content": "2"
  },
  {
    "id": 24620,
    "content": "8"
  },
  {
    "id": 24621,
    "content": "5"
  },
  {
    "id": 24623,
    "content": "4"
  },
  {
    "id": 24624,
    "content": "2"
  },
  {
    "id": 24625,
    "content": "8"
  },
  {
    "id": 24626,
    "content": "6"
  },
  {
    "id": 24627,
    "content": "--Wreorder ( -Wreorder )  Generate warnings when member initializers are reordered"
  },
  {
    "id": 24628,
    "content": "4"
  },
  {
    "id": 24629,
    "content": "2"
  },
  {
    "id": 24630,
    "content": "8"
  },
  {
    "id": 24631,
    "content": "7"
  },
  {
    "id": 24633,
    "content": "4"
  },
  {
    "id": 24634,
    "content": "2"
  },
  {
    "id": 24635,
    "content": "8"
  },
  {
    "id": 24636,
    "content": "8"
  },
  {
    "id": 24638,
    "content": "4"
  },
  {
    "id": 24639,
    "content": "2"
  },
  {
    "id": 24640,
    "content": "8"
  },
  {
    "id": 24641,
    "content": "9"
  },
  {
    "id": 24645,
    "content": "ext-lambda-captures-this Generate error when an extended lambda implicitly captures this"
  },
  {
    "id": 24646,
    "content": "deprecated-declarations Generate error on use of a deprecated entity"
  },
  {
    "id": 24647,
    "content": "4"
  },
  {
    "id": 24648,
    "content": "2"
  },
  {
    "id": 24649,
    "content": "8"
  },
  {
    "id": 24650,
    "content": "11"
  },
  {
    "id": 24652,
    "content": "4"
  },
  {
    "id": 24653,
    "content": "2"
  },
  {
    "id": 24654,
    "content": "8"
  },
  {
    "id": 24655,
    "content": "12"
  },
  {
    "id": 24657,
    "content": "4"
  },
  {
    "id": 24658,
    "content": "2"
  },
  {
    "id": 24659,
    "content": "8"
  },
  {
    "id": 24660,
    "content": "14"
  },
  {
    "id": 24662,
    "content": "4"
  },
  {
    "id": 24663,
    "content": "2"
  },
  {
    "id": 24664,
    "content": "8"
  },
  {
    "id": 24665,
    "content": "15"
  },
  {
    "id": 24667,
    "content": "4"
  },
  {
    "id": 24668,
    "content": "2"
  },
  {
    "id": 24669,
    "content": "8"
  },
  {
    "id": 24670,
    "content": "16"
  },
  {
    "id": 24671,
    "content": "--resource-usage ( -res-usage )  Show resource usage such as registers and memory of the GPU code"
  },
  {
    "id": 24673,
    "content": "4"
  },
  {
    "id": 24674,
    "content": "2"
  },
  {
    "id": 24675,
    "content": "8"
  },
  {
    "id": 24676,
    "content": "17"
  },
  {
    "id": 24677,
    "content": "--help ( -h )  Print help information on this tool"
  },
  {
    "id": 24678,
    "content": "( -optf )  Include command line options from specified file"
  },
  {
    "id": 24679,
    "content": "4"
  },
  {
    "id": 24680,
    "content": "2"
  },
  {
    "id": 24681,
    "content": "8"
  },
  {
    "id": 24682,
    "content": "20"
  },
  {
    "id": 24684,
    "content": "If the file name is - , the timing data is generated in stdout"
  },
  {
    "id": 24685,
    "content": "4"
  },
  {
    "id": 24686,
    "content": "2"
  },
  {
    "id": 24687,
    "content": "8"
  },
  {
    "id": 24688,
    "content": "21"
  },
  {
    "id": 24690,
    "content": "The argument will be forwarded to the q++ compiler with its -V flag"
  },
  {
    "id": 24691,
    "content": "4"
  },
  {
    "id": 24692,
    "content": "2"
  },
  {
    "id": 24693,
    "content": "8"
  },
  {
    "id": 24694,
    "content": "22"
  },
  {
    "id": 24696,
    "content": "4"
  },
  {
    "id": 24697,
    "content": "2"
  },
  {
    "id": 24698,
    "content": "8"
  },
  {
    "id": 24699,
    "content": "23"
  },
  {
    "id": 24701,
    "content": "4"
  },
  {
    "id": 24702,
    "content": "2"
  },
  {
    "id": 24703,
    "content": "9"
  },
  {
    "id": 24704,
    "content": "Phase Options  The following sections lists some useful options to lower level compilation tools"
  },
  {
    "id": 24705,
    "content": "4"
  },
  {
    "id": 24706,
    "content": "2"
  },
  {
    "id": 24707,
    "content": "9"
  },
  {
    "id": 24708,
    "content": "1"
  },
  {
    "id": 24710,
    "content": "4"
  },
  {
    "id": 24711,
    "content": "2"
  },
  {
    "id": 24712,
    "content": "9"
  },
  {
    "id": 24713,
    "content": "1"
  },
  {
    "id": 24714,
    "content": "1"
  },
  {
    "id": 24716,
    "content": "If unspecified, default behavior is to enable this feature for optimization level >= O2"
  },
  {
    "id": 24717,
    "content": "4"
  },
  {
    "id": 24718,
    "content": "2"
  },
  {
    "id": 24719,
    "content": "9"
  },
  {
    "id": 24720,
    "content": "1"
  },
  {
    "id": 24721,
    "content": "2"
  },
  {
    "id": 24722,
    "content": "--compile-only ( -c )  Generate relocatable object"
  },
  {
    "id": 24723,
    "content": "4"
  },
  {
    "id": 24724,
    "content": "2"
  },
  {
    "id": 24725,
    "content": "9"
  },
  {
    "id": 24726,
    "content": "1"
  },
  {
    "id": 24727,
    "content": "6"
  },
  {
    "id": 24729,
    "content": "( -e )  Semantics same as nvcc option --entries"
  },
  {
    "id": 24730,
    "content": "4"
  },
  {
    "id": 24731,
    "content": "2"
  },
  {
    "id": 24732,
    "content": "9"
  },
  {
    "id": 24733,
    "content": "1"
  },
  {
    "id": 24734,
    "content": "8"
  },
  {
    "id": 24735,
    "content": "--fmad ( -fmad )  Semantics same as nvcc option --fmad"
  },
  {
    "id": 24736,
    "content": "4"
  },
  {
    "id": 24737,
    "content": "2"
  },
  {
    "id": 24738,
    "content": "9"
  },
  {
    "id": 24739,
    "content": "1"
  },
  {
    "id": 24740,
    "content": "9"
  },
  {
    "id": 24741,
    "content": "--force-load-cache ( -flcm )  Force specified cache modifier on global/generic load"
  },
  {
    "id": 24742,
    "content": "4"
  },
  {
    "id": 24743,
    "content": "2"
  },
  {
    "id": 24744,
    "content": "9"
  },
  {
    "id": 24745,
    "content": "1"
  },
  {
    "id": 24746,
    "content": "10"
  },
  {
    "id": 24747,
    "content": "--force-store-cache ( -fscm )  Force specified cache modifier on global/generic store"
  },
  {
    "id": 24748,
    "content": "4"
  },
  {
    "id": 24749,
    "content": "2"
  },
  {
    "id": 24750,
    "content": "9"
  },
  {
    "id": 24751,
    "content": "1"
  },
  {
    "id": 24752,
    "content": "11"
  },
  {
    "id": 24753,
    "content": "--generate-line-info ( -lineinfo )  Semantics same as nvcc option --generate-line-info"
  },
  {
    "id": 24754,
    "content": "4"
  },
  {
    "id": 24755,
    "content": "2"
  },
  {
    "id": 24756,
    "content": "9"
  },
  {
    "id": 24757,
    "content": "1"
  },
  {
    "id": 24758,
    "content": "12"
  },
  {
    "id": 24759,
    "content": "--gpu-name gpuname ( -arch )  Specify name of NVIDIA GPU to generate code for"
  },
  {
    "id": 24760,
    "content": "This option also takes virtual compute architectures, in which case code generation is suppressed"
  },
  {
    "id": 24762,
    "content": "sm_72 , sm_75 , sm_80 , sm_86 , sm_87 , sm_89 , sm_90 Default value: sm_52"
  },
  {
    "id": 24763,
    "content": "4"
  },
  {
    "id": 24764,
    "content": "2"
  },
  {
    "id": 24765,
    "content": "9"
  },
  {
    "id": 24766,
    "content": "1"
  },
  {
    "id": 24767,
    "content": "13"
  },
  {
    "id": 24768,
    "content": "--help ( -h )  Semantics same as nvcc option --help"
  },
  {
    "id": 24769,
    "content": "4"
  },
  {
    "id": 24770,
    "content": "2"
  },
  {
    "id": 24771,
    "content": "9"
  },
  {
    "id": 24772,
    "content": "1"
  },
  {
    "id": 24773,
    "content": "15"
  },
  {
    "id": 24775,
    "content": "4"
  },
  {
    "id": 24776,
    "content": "2"
  },
  {
    "id": 24777,
    "content": "9"
  },
  {
    "id": 24778,
    "content": "1"
  },
  {
    "id": 24779,
    "content": "18"
  },
  {
    "id": 24780,
    "content": "--position-independent-code ( -pic )  Generate position-independent code"
  },
  {
    "id": 24782,
    "content": "4"
  },
  {
    "id": 24783,
    "content": "2"
  },
  {
    "id": 24784,
    "content": "9"
  },
  {
    "id": 24785,
    "content": "1"
  },
  {
    "id": 24786,
    "content": "20"
  },
  {
    "id": 24787,
    "content": "--sp-bound-check ( -sp-bound-check )  Generate stack-pointer bounds-checking code sequence"
  },
  {
    "id": 24788,
    "content": "This option is turned on automatically when --device-debug or --opt-level=0 is specified"
  },
  {
    "id": 24789,
    "content": "4"
  },
  {
    "id": 24790,
    "content": "2"
  },
  {
    "id": 24791,
    "content": "9"
  },
  {
    "id": 24792,
    "content": "1"
  },
  {
    "id": 24793,
    "content": "21"
  },
  {
    "id": 24795,
    "content": "tensor} instruction with sm_90"
  },
  {
    "id": 24796,
    "content": "4"
  },
  {
    "id": 24797,
    "content": "2"
  },
  {
    "id": 24798,
    "content": "9"
  },
  {
    "id": 24799,
    "content": "1"
  },
  {
    "id": 24800,
    "content": "22"
  },
  {
    "id": 24801,
    "content": "--verbose ( -v )  Enable verbose mode which prints code generation statistics"
  },
  {
    "id": 24802,
    "content": "4"
  },
  {
    "id": 24803,
    "content": "2"
  },
  {
    "id": 24804,
    "content": "9"
  },
  {
    "id": 24805,
    "content": "1"
  },
  {
    "id": 24806,
    "content": "25"
  },
  {
    "id": 24808,
    "content": "4"
  },
  {
    "id": 24809,
    "content": "2"
  },
  {
    "id": 24810,
    "content": "9"
  },
  {
    "id": 24811,
    "content": "1"
  },
  {
    "id": 24812,
    "content": "26"
  },
  {
    "id": 24813,
    "content": "--warn-on-local-memory-usage ( -warn-lmem-usage )  Warning if local memory is used"
  },
  {
    "id": 24814,
    "content": "4"
  },
  {
    "id": 24815,
    "content": "2"
  },
  {
    "id": 24816,
    "content": "9"
  },
  {
    "id": 24817,
    "content": "1"
  },
  {
    "id": 24818,
    "content": "27"
  },
  {
    "id": 24819,
    "content": "--warn-on-spills ( -warn-spills )  Warning if registers are spilled to local memory"
  },
  {
    "id": 24820,
    "content": "4"
  },
  {
    "id": 24821,
    "content": "2"
  },
  {
    "id": 24822,
    "content": "9"
  },
  {
    "id": 24823,
    "content": "1"
  },
  {
    "id": 24824,
    "content": "29"
  },
  {
    "id": 24825,
    "content": "--maxntid ( -maxntid )  Specify the maximum number of threads that a thread block can have"
  },
  {
    "id": 24826,
    "content": "This option is also ignored for entry functions that have"
  },
  {
    "id": 24827,
    "content": "maxntid directive specified"
  },
  {
    "id": 24828,
    "content": "4"
  },
  {
    "id": 24829,
    "content": "2"
  },
  {
    "id": 24830,
    "content": "9"
  },
  {
    "id": 24831,
    "content": "1"
  },
  {
    "id": 24832,
    "content": "30"
  },
  {
    "id": 24833,
    "content": "--minnctapersm ( -minnctapersm )  Specify the minimum number of CTAs to be mapped to an SM"
  },
  {
    "id": 24834,
    "content": "This option is also ignored for entry functions that have"
  },
  {
    "id": 24835,
    "content": "minnctapersm directive specified"
  },
  {
    "id": 24836,
    "content": "4"
  },
  {
    "id": 24837,
    "content": "2"
  },
  {
    "id": 24838,
    "content": "9"
  },
  {
    "id": 24839,
    "content": "1"
  },
  {
    "id": 24840,
    "content": "31"
  },
  {
    "id": 24842,
    "content": "This option is effective only for -minnctapersm , -maxntid and -maxrregcount options"
  },
  {
    "id": 24843,
    "content": "4"
  },
  {
    "id": 24844,
    "content": "2"
  },
  {
    "id": 24845,
    "content": "9"
  },
  {
    "id": 24846,
    "content": "1"
  },
  {
    "id": 24847,
    "content": "32"
  },
  {
    "id": 24849,
    "content": "4"
  },
  {
    "id": 24850,
    "content": "2"
  },
  {
    "id": 24851,
    "content": "9"
  },
  {
    "id": 24852,
    "content": "2"
  },
  {
    "id": 24854,
    "content": "4"
  },
  {
    "id": 24855,
    "content": "2"
  },
  {
    "id": 24856,
    "content": "9"
  },
  {
    "id": 24857,
    "content": "2"
  },
  {
    "id": 24858,
    "content": "1"
  },
  {
    "id": 24859,
    "content": "4"
  },
  {
    "id": 24860,
    "content": "2"
  },
  {
    "id": 24861,
    "content": "9"
  },
  {
    "id": 24862,
    "content": "2"
  },
  {
    "id": 24863,
    "content": "2"
  },
  {
    "id": 24864,
    "content": "--preserve-relocs ( -preserve-relocs )  Preserve resolved relocations in linked executable"
  },
  {
    "id": 24865,
    "content": "4"
  },
  {
    "id": 24866,
    "content": "2"
  },
  {
    "id": 24867,
    "content": "9"
  },
  {
    "id": 24868,
    "content": "2"
  },
  {
    "id": 24869,
    "content": "3"
  },
  {
    "id": 24870,
    "content": "4"
  },
  {
    "id": 24871,
    "content": "2"
  },
  {
    "id": 24872,
    "content": "9"
  },
  {
    "id": 24873,
    "content": "2"
  },
  {
    "id": 24874,
    "content": "4"
  },
  {
    "id": 24875,
    "content": "4"
  },
  {
    "id": 24876,
    "content": "2"
  },
  {
    "id": 24877,
    "content": "9"
  },
  {
    "id": 24878,
    "content": "2"
  },
  {
    "id": 24879,
    "content": "5"
  },
  {
    "id": 24881,
    "content": "4"
  },
  {
    "id": 24882,
    "content": "2"
  },
  {
    "id": 24883,
    "content": "9"
  },
  {
    "id": 24884,
    "content": "2"
  },
  {
    "id": 24885,
    "content": "6"
  },
  {
    "id": 24887,
    "content": "4"
  },
  {
    "id": 24888,
    "content": "2"
  },
  {
    "id": 24889,
    "content": "9"
  },
  {
    "id": 24890,
    "content": "2"
  },
  {
    "id": 24891,
    "content": "7"
  },
  {
    "id": 24892,
    "content": "--dump-callgraph ( -dump-callgraph )  Dump information about the callgraph and register usage"
  },
  {
    "id": 24893,
    "content": "4"
  },
  {
    "id": 24894,
    "content": "2"
  },
  {
    "id": 24895,
    "content": "9"
  },
  {
    "id": 24896,
    "content": "2"
  },
  {
    "id": 24897,
    "content": "8"
  },
  {
    "id": 24899,
    "content": "4"
  },
  {
    "id": 24900,
    "content": "2"
  },
  {
    "id": 24901,
    "content": "9"
  },
  {
    "id": 24902,
    "content": "2"
  },
  {
    "id": 24903,
    "content": "11"
  },
  {
    "id": 24904,
    "content": "--extra-warnings ( -extrawarn )  Emit extra warnings about possible problems"
  },
  {
    "id": 24905,
    "content": "4"
  },
  {
    "id": 24906,
    "content": "2"
  },
  {
    "id": 24907,
    "content": "9"
  },
  {
    "id": 24908,
    "content": "2"
  },
  {
    "id": 24909,
    "content": "12"
  },
  {
    "id": 24910,
    "content": "--gen-host-linker-script ( -ghls )  Specify the type of host linker script to be generated"
  },
  {
    "id": 24911,
    "content": "4"
  },
  {
    "id": 24912,
    "content": "2"
  },
  {
    "id": 24913,
    "content": "9"
  },
  {
    "id": 24914,
    "content": "2"
  },
  {
    "id": 24915,
    "content": "13"
  },
  {
    "id": 24917,
    "content": "4"
  },
  {
    "id": 24918,
    "content": "2"
  },
  {
    "id": 24919,
    "content": "9"
  },
  {
    "id": 24920,
    "content": "2"
  },
  {
    "id": 24921,
    "content": "14"
  },
  {
    "id": 24922,
    "content": "--keep-system-libraries ( -keep-system-libraries )  Don’t optimize away system library (e"
  },
  {
    "id": 24923,
    "content": "g"
  },
  {
    "id": 24924,
    "content": "cudadevrt) code"
  },
  {
    "id": 24925,
    "content": "4"
  },
  {
    "id": 24926,
    "content": "2"
  },
  {
    "id": 24927,
    "content": "9"
  },
  {
    "id": 24928,
    "content": "2"
  },
  {
    "id": 24929,
    "content": "15"
  },
  {
    "id": 24931,
    "content": "4"
  },
  {
    "id": 24932,
    "content": "2"
  },
  {
    "id": 24933,
    "content": "9"
  },
  {
    "id": 24934,
    "content": "2"
  },
  {
    "id": 24935,
    "content": "16"
  },
  {
    "id": 24936,
    "content": "--options-file ( -optf )  Include command line options from the specified file"
  },
  {
    "id": 24937,
    "content": "4"
  },
  {
    "id": 24938,
    "content": "2"
  },
  {
    "id": 24939,
    "content": "9"
  },
  {
    "id": 24940,
    "content": "2"
  },
  {
    "id": 24941,
    "content": "18"
  },
  {
    "id": 24943,
    "content": "4"
  },
  {
    "id": 24944,
    "content": "2"
  },
  {
    "id": 24945,
    "content": "9"
  },
  {
    "id": 24946,
    "content": "2"
  },
  {
    "id": 24947,
    "content": "19"
  },
  {
    "id": 24949,
    "content": "4"
  },
  {
    "id": 24950,
    "content": "3"
  },
  {
    "id": 24954,
    "content": "foo In this case, nvcc will choose clang as the host compiler"
  },
  {
    "id": 24955,
    "content": "5"
  },
  {
    "id": 24957,
    "content": "It goes through some technical sections, with concrete examples at the end"
  },
  {
    "id": 24958,
    "content": "5"
  },
  {
    "id": 24959,
    "content": "1"
  },
  {
    "id": 24964,
    "content": "5"
  },
  {
    "id": 24965,
    "content": "2"
  },
  {
    "id": 24971,
    "content": "a on Linux and Mac OS X,"
  },
  {
    "id": 24972,
    "content": "lib on Windows)"
  },
  {
    "id": 24974,
    "content": "nvcc --gpu-architecture=sm_50 a"
  },
  {
    "id": 24975,
    "content": "o b"
  },
  {
    "id": 24977,
    "content": "nvcc --gpu-architecture=sm_50 a"
  },
  {
    "id": 24978,
    "content": "obj b obj foo"
  },
  {
    "id": 24980,
    "content": "6"
  },
  {
    "id": 24981,
    "content": "4"
  },
  {
    "id": 24982,
    "content": "Examples  Suppose we have the following files:  - b"
  },
  {
    "id": 24983,
    "content": "h - #define N 8 extern __device__ int g [ N ]; extern __device__ void bar ( void );  - b"
  },
  {
    "id": 24984,
    "content": "cu - #include \"b"
  },
  {
    "id": 24985,
    "content": "h\" __device__ int g [ N ]; __device__ void bar ( void ) { g [ threadIdx"
  },
  {
    "id": 24986,
    "content": "x ] ++ ; }  - a"
  },
  {
    "id": 24987,
    "content": "cu - #include #include \"b"
  },
  {
    "id": 24991,
    "content": "o b"
  },
  {
    "id": 24992,
    "content": "o \\ --cubin --output-file link"
  },
  {
    "id": 24994,
    "content": "cu b cu nvcc --lib a"
  },
  {
    "id": 24995,
    "content": "o b"
  },
  {
    "id": 24996,
    "content": "o --output-file test a nvcc --gpu-architecture=sm_50 test"
  },
  {
    "id": 24997,
    "content": "a Note that only static libraries are supported by the device linker"
  },
  {
    "id": 24999,
    "content": "cu b cu nvcc --gpu-architecture=sm_50 --device-link a"
  },
  {
    "id": 25000,
    "content": "o b"
  },
  {
    "id": 25001,
    "content": "o --output-file link o nvcc --lib --output-file libgpu"
  },
  {
    "id": 25002,
    "content": "a a"
  },
  {
    "id": 25003,
    "content": "o b"
  },
  {
    "id": 25004,
    "content": "o link"
  },
  {
    "id": 25005,
    "content": "o g++ host"
  },
  {
    "id": 25008,
    "content": "g"
  },
  {
    "id": 25010,
    "content": "6"
  },
  {
    "id": 25011,
    "content": "5"
  },
  {
    "id": 25016,
    "content": "As of CUDA 12"
  },
  {
    "id": 25017,
    "content": "0 there is support for runtime LTO via the nvJitLink library"
  },
  {
    "id": 25018,
    "content": "6"
  },
  {
    "id": 25019,
    "content": "6"
  },
  {
    "id": 25020,
    "content": "Potential Separate Compilation Issues  6"
  },
  {
    "id": 25021,
    "content": "6"
  },
  {
    "id": 25022,
    "content": "1"
  },
  {
    "id": 25024,
    "content": "g"
  },
  {
    "id": 25027,
    "content": "g"
  },
  {
    "id": 25029,
    "content": "6"
  },
  {
    "id": 25030,
    "content": "6"
  },
  {
    "id": 25031,
    "content": "2"
  },
  {
    "id": 25034,
    "content": "6"
  },
  {
    "id": 25035,
    "content": "6"
  },
  {
    "id": 25036,
    "content": "3"
  },
  {
    "id": 25037,
    "content": "Implicit CUDA Host Code  A file like b"
  },
  {
    "id": 25038,
    "content": "cu above only contains CUDA device code, so one might think that the b"
  },
  {
    "id": 25039,
    "content": "o object doesn’t need to be passed to the host linker"
  },
  {
    "id": 25042,
    "content": "6"
  },
  {
    "id": 25043,
    "content": "6"
  },
  {
    "id": 25044,
    "content": "4"
  },
  {
    "id": 25046,
    "content": "For example, if an a"
  },
  {
    "id": 25048,
    "content": "cu and b cu both include a"
  },
  {
    "id": 25049,
    "content": "h and instantiate getptr for the same type, and b"
  },
  {
    "id": 25051,
    "content": "o b"
  },
  {
    "id": 25053,
    "content": "To avoid this, either a"
  },
  {
    "id": 25055,
    "content": "6"
  },
  {
    "id": 25056,
    "content": "6"
  },
  {
    "id": 25057,
    "content": "5"
  },
  {
    "id": 25061,
    "content": "7"
  },
  {
    "id": 25062,
    "content": "2"
  },
  {
    "id": 25066,
    "content": "7"
  },
  {
    "id": 25067,
    "content": "3"
  },
  {
    "id": 25077,
    "content": "8"
  },
  {
    "id": 25078,
    "content": "Notices  8"
  },
  {
    "id": 25079,
    "content": "1"
  },
  {
    "id": 25082,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 25094,
    "content": "8"
  },
  {
    "id": 25095,
    "content": "2"
  },
  {
    "id": 25096,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 25097,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 25098,
    "content": "8"
  },
  {
    "id": 25099,
    "content": "3"
  },
  {
    "id": 25101,
    "content": "S"
  },
  {
    "id": 25104,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 25105,
    "content": "Navigation"
  },
  {
    "id": 25106,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 25107,
    "content": "pageBottom();}\n1"
  },
  {
    "id": 25108,
    "content": "Overview v12"
  },
  {
    "id": 25110,
    "content": "For details, follow the link in the table to the documentation for your version"
  },
  {
    "id": 25111,
    "content": "1"
  },
  {
    "id": 25112,
    "content": "2"
  },
  {
    "id": 25113,
    "content": "Notices  1"
  },
  {
    "id": 25114,
    "content": "2"
  },
  {
    "id": 25115,
    "content": "1"
  },
  {
    "id": 25118,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 25130,
    "content": "1"
  },
  {
    "id": 25131,
    "content": "2"
  },
  {
    "id": 25132,
    "content": "2"
  },
  {
    "id": 25133,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 25134,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 25135,
    "content": "1"
  },
  {
    "id": 25136,
    "content": "2"
  },
  {
    "id": 25137,
    "content": "3"
  },
  {
    "id": 25139,
    "content": "S"
  },
  {
    "id": 25147,
    "content": "Data Center / Cloud Data Center / Cloud © Copyright 2024, NVIDIA"
  },
  {
    "id": 25150,
    "content": "3"
  },
  {
    "id": 25151,
    "content": "1"
  },
  {
    "id": 25153,
    "content": "Example: Tracing cuFileRead and cuFileWrite Failures, Print, Error Codes, and Time of Failure 16"
  },
  {
    "id": 25154,
    "content": "14"
  },
  {
    "id": 25155,
    "content": "Cheat Sheet for Diagnosing Problems NVIDIA GPUDirect Storage O_DIRECT Requirements Guide 1"
  },
  {
    "id": 25156,
    "content": "Summary Corporate Info NVIDIA"
  },
  {
    "id": 25158,
    "content": "pageBottom(); const tables = document"
  },
  {
    "id": 25159,
    "content": "querySelectorAll('"
  },
  {
    "id": 25160,
    "content": "Page-twoColumn table'); const className = 'table-wrapper' tables"
  },
  {
    "id": 25161,
    "content": "forEach(tbl => { const parent = tbl"
  },
  {
    "id": 25162,
    "content": "parentNode; if("
  },
  {
    "id": 25163,
    "content": "parent"
  },
  {
    "id": 25164,
    "content": "classList"
  },
  {
    "id": 25165,
    "content": "contains(className)){ const wrapper = document createElement('div'); wrapper"
  },
  {
    "id": 25166,
    "content": "classList"
  },
  {
    "id": 25167,
    "content": "add(className) parent"
  },
  {
    "id": 25168,
    "content": "insertBefore( wrapper, tbl ); wrapper appendChild(tbl); } })\n1"
  },
  {
    "id": 25169,
    "content": "Overview v12"
  },
  {
    "id": 25174,
    "content": "Some of the limitations depend on the platform used and could be lifted in current/future products"
  },
  {
    "id": 25180,
    "content": "See Supported Systems and PCI BAR sizes for more hardware details"
  },
  {
    "id": 25181,
    "content": "1"
  },
  {
    "id": 25182,
    "content": "2"
  },
  {
    "id": 25185,
    "content": "communication library should eventually clean up any resources used to pin the memory"
  },
  {
    "id": 25186,
    "content": "We will refer to this operation as unpinning the memory"
  },
  {
    "id": 25187,
    "content": "1"
  },
  {
    "id": 25188,
    "content": "3"
  },
  {
    "id": 25193,
    "content": "Some hardware caveats are explained in Supported Systems and PCI BAR sizes"
  },
  {
    "id": 25194,
    "content": "1"
  },
  {
    "id": 25195,
    "content": "4"
  },
  {
    "id": 25196,
    "content": "Changes in CUDA 6 0  In this section we briefly list the changes that are available in CUDA 6"
  },
  {
    "id": 25197,
    "content": "0: CUDA peer-to-peer tokens are no longer mandatory"
  },
  {
    "id": 25200,
    "content": "As a consequence of the change above, a new API cuPointerSetAttribute() has been introduced"
  },
  {
    "id": 25204,
    "content": "Caveats as of CUDA 6"
  },
  {
    "id": 25205,
    "content": "0: CUDA Unified Memory is not explicitly supported in combination with GPUDirect RDMA"
  },
  {
    "id": 25208,
    "content": "e"
  },
  {
    "id": 25209,
    "content": "This behavior has been changed since CUDA 7"
  },
  {
    "id": 25210,
    "content": "0"
  },
  {
    "id": 25211,
    "content": "1"
  },
  {
    "id": 25212,
    "content": "5"
  },
  {
    "id": 25213,
    "content": "Changes in CUDA 7 0  In this section we briefly list the changes that are available in CUDA 7"
  },
  {
    "id": 25216,
    "content": "cudaPointerGetAttributes() is now faster since it leverages cuPointerGetAttributes() internally"
  },
  {
    "id": 25218,
    "content": "1"
  },
  {
    "id": 25219,
    "content": "6"
  },
  {
    "id": 25220,
    "content": "Changes in CUDA 8 0  In this section we briefly list the changes that are available in CUDA 8"
  },
  {
    "id": 25227,
    "content": "1"
  },
  {
    "id": 25228,
    "content": "7"
  },
  {
    "id": 25229,
    "content": "Changes in CUDA 10"
  },
  {
    "id": 25230,
    "content": "1  GPUDirect RDMA is supported on Jetson AGX Xavier platform"
  },
  {
    "id": 25231,
    "content": "See Porting to Tegra section for details"
  },
  {
    "id": 25232,
    "content": "1"
  },
  {
    "id": 25233,
    "content": "8"
  },
  {
    "id": 25234,
    "content": "Changes in CUDA 11"
  },
  {
    "id": 25235,
    "content": "2  GPUDirect RDMA is supported on Drive AGX Xavier Linux based platform"
  },
  {
    "id": 25236,
    "content": "1"
  },
  {
    "id": 25237,
    "content": "9"
  },
  {
    "id": 25238,
    "content": "Changes in CUDA 11"
  },
  {
    "id": 25240,
    "content": "Users need to load the module manually"
  },
  {
    "id": 25241,
    "content": "1"
  },
  {
    "id": 25242,
    "content": "10"
  },
  {
    "id": 25243,
    "content": "Changes in CUDA 12"
  },
  {
    "id": 25246,
    "content": "nvidia_p2p_get_pages no longer accepts a NULL callback pointer"
  },
  {
    "id": 25251,
    "content": "Note that I/O drivers, which do not need persistent mappings, do not require source code changes"
  },
  {
    "id": 25252,
    "content": "The API changes described above are deployed in the R535 branch, specifically in release 535"
  },
  {
    "id": 25253,
    "content": "14 and later, and have also been back-ported to the R525 branch, for TeslaRD3 (525"
  },
  {
    "id": 25254,
    "content": "105"
  },
  {
    "id": 25255,
    "content": "17) and later"
  },
  {
    "id": 25256,
    "content": "2"
  },
  {
    "id": 25258,
    "content": "2"
  },
  {
    "id": 25259,
    "content": "1"
  },
  {
    "id": 25265,
    "content": "region failed because of BAR space exhaustion (see PCI BAR sizes )"
  },
  {
    "id": 25266,
    "content": "2"
  },
  {
    "id": 25267,
    "content": "2"
  },
  {
    "id": 25269,
    "content": "Typically it already exists for host memory, implementing lazy unpinning, LRU de-registration, etc"
  },
  {
    "id": 25275,
    "content": "g"
  },
  {
    "id": 25279,
    "content": "0"
  },
  {
    "id": 25283,
    "content": "2"
  },
  {
    "id": 25284,
    "content": "3"
  },
  {
    "id": 25286,
    "content": "e"
  },
  {
    "id": 25287,
    "content": ", wait for outstanding DMAs to complete)"
  },
  {
    "id": 25290,
    "content": "g"
  },
  {
    "id": 25294,
    "content": "2"
  },
  {
    "id": 25295,
    "content": "4"
  },
  {
    "id": 25300,
    "content": "2"
  },
  {
    "id": 25304,
    "content": "2"
  },
  {
    "id": 25305,
    "content": "5"
  },
  {
    "id": 25306,
    "content": "PCI BAR sizes  PCI devices can ask the OS/BIOS to map a region of physical address space to them"
  },
  {
    "id": 25311,
    "content": "Please consult your system vendor for more details regarding large BAR support"
  },
  {
    "id": 25312,
    "content": "2"
  },
  {
    "id": 25313,
    "content": "6"
  },
  {
    "id": 25315,
    "content": "single CUDA context (i"
  },
  {
    "id": 25316,
    "content": "e"
  },
  {
    "id": 25319,
    "content": "return different tokens at different times during the program’s execution"
  },
  {
    "id": 25322,
    "content": "2"
  },
  {
    "id": 25323,
    "content": "7"
  },
  {
    "id": 25330,
    "content": "mapping, so this optimization is disabled an the copy completed before the CUDA API returns"
  },
  {
    "id": 25336,
    "content": "which will launch the dependent GPU kernel"
  },
  {
    "id": 25337,
    "content": "3"
  },
  {
    "id": 25338,
    "content": "How to Perform Specific Tasks  3"
  },
  {
    "id": 25339,
    "content": "1"
  },
  {
    "id": 25340,
    "content": "Displaying GPU BAR space  Starting in CUDA 6"
  },
  {
    "id": 25341,
    "content": "0 the NVIDIA SMI utility provides the capability to dump BAR1 memory usage"
  },
  {
    "id": 25345,
    "content": "3"
  },
  {
    "id": 25346,
    "content": "2"
  },
  {
    "id": 25350,
    "content": "entries can be used to program the device’s DMA engine"
  },
  {
    "id": 25351,
    "content": "See Kernel API for details on nvidia_p2p_get_pages()"
  },
  {
    "id": 25352,
    "content": "3"
  },
  {
    "id": 25353,
    "content": "3"
  },
  {
    "id": 25355,
    "content": "corresponding nvidia_p2p_get_pages() has been issued"
  },
  {
    "id": 25356,
    "content": "3"
  },
  {
    "id": 25357,
    "content": "4"
  },
  {
    "id": 25359,
    "content": "be called"
  },
  {
    "id": 25360,
    "content": "3"
  },
  {
    "id": 25361,
    "content": "5"
  },
  {
    "id": 25373,
    "content": "6"
  },
  {
    "id": 25374,
    "content": "Linking a Kernel Module against nvidia"
  },
  {
    "id": 25375,
    "content": "ko  Run the extraction script:"
  },
  {
    "id": 25376,
    "content": "/NVIDIA-Linux-x86_64-"
  },
  {
    "id": 25377,
    "content": "run -x This extracts the NVIDA driver and kernel wrapper"
  },
  {
    "id": 25379,
    "content": "ko"
  },
  {
    "id": 25380,
    "content": "Modify your kernel module build process with the following line: KBUILD_EXTRA_SYMBOLS := /Module"
  },
  {
    "id": 25381,
    "content": "symvers 3"
  },
  {
    "id": 25382,
    "content": "7"
  },
  {
    "id": 25386,
    "content": "the kernel or via MLNX_OFED as a prerequisite for loading and using nvidia-peermem"
  },
  {
    "id": 25390,
    "content": "4"
  },
  {
    "id": 25391,
    "content": "References  4"
  },
  {
    "id": 25392,
    "content": "1"
  },
  {
    "id": 25394,
    "content": "0 and later releases on Fermi and Kepler GPUs running 64-bit processes"
  },
  {
    "id": 25398,
    "content": "4"
  },
  {
    "id": 25399,
    "content": "2"
  },
  {
    "id": 25408,
    "content": "In CUDA 6"
  },
  {
    "id": 25409,
    "content": "0, a new attribute has been introduced that is useful to detect memory reallocations"
  },
  {
    "id": 25413,
    "content": "g"
  },
  {
    "id": 25416,
    "content": "4"
  },
  {
    "id": 25417,
    "content": "3"
  },
  {
    "id": 25418,
    "content": "Kernel API  The following declarations can be found in the nv-p2p"
  },
  {
    "id": 25428,
    "content": "third-party device"
  },
  {
    "id": 25433,
    "content": "from the invalidation callback"
  },
  {
    "id": 25434,
    "content": "4"
  },
  {
    "id": 25435,
    "content": "4"
  },
  {
    "id": 25437,
    "content": "4"
  },
  {
    "id": 25439,
    "content": "The following sub-sections (4"
  },
  {
    "id": 25440,
    "content": "4"
  },
  {
    "id": 25441,
    "content": "1-4"
  },
  {
    "id": 25442,
    "content": "4"
  },
  {
    "id": 25443,
    "content": "3) briefs over the necessary changes"
  },
  {
    "id": 25444,
    "content": "4"
  },
  {
    "id": 25445,
    "content": "4"
  },
  {
    "id": 25446,
    "content": "1"
  },
  {
    "id": 25449,
    "content": "all the rules that are applicable to the standard GPUDirect solution also apply to Tegra"
  },
  {
    "id": 25450,
    "content": "4"
  },
  {
    "id": 25451,
    "content": "4"
  },
  {
    "id": 25452,
    "content": "2"
  },
  {
    "id": 25461,
    "content": "Incompatible combination of map and allocation attributes will lead to undefined behavior"
  },
  {
    "id": 25462,
    "content": "5"
  },
  {
    "id": 25463,
    "content": "Notices  5"
  },
  {
    "id": 25464,
    "content": "1"
  },
  {
    "id": 25467,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 25479,
    "content": "5"
  },
  {
    "id": 25480,
    "content": "2"
  },
  {
    "id": 25481,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 25482,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 25483,
    "content": "5"
  },
  {
    "id": 25484,
    "content": "3"
  },
  {
    "id": 25486,
    "content": "S"
  },
  {
    "id": 25489,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 25490,
    "content": "Navigation"
  },
  {
    "id": 25491,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 25493,
    "content": "5"
  },
  {
    "id": 25494,
    "content": "1 Debugger API 1 Deprecated List Search Results Debugger API ( PDF ) - v12"
  },
  {
    "id": 25495,
    "content": "5"
  },
  {
    "id": 25499,
    "content": "pageBottom();\nCUPTI Overview 1 Namespaces Copyright and Licenses Notices Cupti » CUPTI v2024"
  },
  {
    "id": 25500,
    "content": "2"
  },
  {
    "id": 25501,
    "content": "0 | Archive CUPTI  The API reference for CUPTI, the CUDA Profiling Tools Interface"
  },
  {
    "id": 25503,
    "content": "Affiliates"
  },
  {
    "id": 25508,
    "content": "2"
  },
  {
    "id": 25509,
    "content": "Minor Version Compatibility  2"
  },
  {
    "id": 25510,
    "content": "1"
  },
  {
    "id": 25512,
    "content": "to the same major release Table 1 Example CUDA Toolkit 11"
  },
  {
    "id": 25513,
    "content": "x and 12"
  },
  {
    "id": 25515,
    "content": "x >=525"
  },
  {
    "id": 25516,
    "content": "60"
  },
  {
    "id": 25517,
    "content": "13 >=527"
  },
  {
    "id": 25518,
    "content": "41 CUDA 11"
  },
  {
    "id": 25519,
    "content": "x >= 450"
  },
  {
    "id": 25520,
    "content": "80"
  },
  {
    "id": 25521,
    "content": "02* >=452"
  },
  {
    "id": 25522,
    "content": "39* CUDA 11"
  },
  {
    "id": 25523,
    "content": "0 was released with an earlier driver version, but by upgrading to Tesla Recommended Drivers 450"
  },
  {
    "id": 25524,
    "content": "80"
  },
  {
    "id": 25525,
    "content": "02 (Linux) / 452"
  },
  {
    "id": 25526,
    "content": "39 (Windows) as indicated, minor version compatibility is possible across the CUDA 11"
  },
  {
    "id": 25527,
    "content": "x family of toolkits"
  },
  {
    "id": 25529,
    "content": "If you are using a new CUDA 10"
  },
  {
    "id": 25531,
    "content": "1"
  },
  {
    "id": 25533,
    "content": "x releases"
  },
  {
    "id": 25535,
    "content": "2 >= 440"
  },
  {
    "id": 25536,
    "content": "33 >=441"
  },
  {
    "id": 25537,
    "content": "22 CUDA 10"
  },
  {
    "id": 25538,
    "content": "1 >= 418 39 >=418"
  },
  {
    "id": 25539,
    "content": "96 CUDA 10"
  },
  {
    "id": 25540,
    "content": "0 >= 410"
  },
  {
    "id": 25541,
    "content": "48 >=411"
  },
  {
    "id": 25542,
    "content": "31 With minor version compatibility, upgrading to CUDA 11"
  },
  {
    "id": 25543,
    "content": "1 is now possible on older drivers from within the same major release family such as 450"
  },
  {
    "id": 25544,
    "content": "80"
  },
  {
    "id": 25545,
    "content": "02 that was shipped with CUDA 11"
  },
  {
    "id": 25547,
    "content": "2"
  },
  {
    "id": 25548,
    "content": "2"
  },
  {
    "id": 25554,
    "content": "2"
  },
  {
    "id": 25555,
    "content": "3"
  },
  {
    "id": 25560,
    "content": "compatibility across major toolkit versions"
  },
  {
    "id": 25561,
    "content": "3"
  },
  {
    "id": 25562,
    "content": "Forward Compatibility  3"
  },
  {
    "id": 25563,
    "content": "1"
  },
  {
    "id": 25565,
    "content": "To support such scenarios, CUDA introduced a Forward Compatibility Upgrade path in CUDA 10"
  },
  {
    "id": 25566,
    "content": "0"
  },
  {
    "id": 25570,
    "content": "3"
  },
  {
    "id": 25571,
    "content": "2"
  },
  {
    "id": 25572,
    "content": "Installing the Forward Compatibility Package  3"
  },
  {
    "id": 25573,
    "content": "2"
  },
  {
    "id": 25574,
    "content": "1"
  },
  {
    "id": 25576,
    "content": "4"
  },
  {
    "id": 25578,
    "content": "* -GPU debugging support for CUDA Driver (CUDA 11"
  },
  {
    "id": 25580,
    "content": "so"
  },
  {
    "id": 25582,
    "content": "2"
  },
  {
    "id": 25583,
    "content": "2"
  },
  {
    "id": 25585,
    "content": "run ) available in NVIDIA driver downloads"
  },
  {
    "id": 25586,
    "content": "To do this: Download the latest NVIDIA Data Center GPU driver , and extract the"
  },
  {
    "id": 25587,
    "content": "run file using option -x"
  },
  {
    "id": 25589,
    "content": "Follow your system’s guidelines for making sure that the system linker picks up the new libraries"
  },
  {
    "id": 25591,
    "content": "3"
  },
  {
    "id": 25592,
    "content": "3"
  },
  {
    "id": 25593,
    "content": "Deployment Considerations for Forward Compatibility  3"
  },
  {
    "id": 25594,
    "content": "3"
  },
  {
    "id": 25595,
    "content": "1"
  },
  {
    "id": 25597,
    "content": "If you are on the R470 driver but require 12"
  },
  {
    "id": 25598,
    "content": "5 application support, please install the cuda-compat package for 12"
  },
  {
    "id": 25599,
    "content": "5"
  },
  {
    "id": 25601,
    "content": "For example, if you are upgrading the driver to 525"
  },
  {
    "id": 25602,
    "content": "60"
  },
  {
    "id": 25604,
    "content": "11"
  },
  {
    "id": 25608,
    "content": "Driver - Production Branch CUDA Forward Compatible Upgrade 470"
  },
  {
    "id": 25609,
    "content": "57"
  },
  {
    "id": 25610,
    "content": "02+ (CUDA 11"
  },
  {
    "id": 25611,
    "content": "4) 530"
  },
  {
    "id": 25612,
    "content": "30"
  },
  {
    "id": 25613,
    "content": "02+ (CUDA 12"
  },
  {
    "id": 25614,
    "content": "1) 535"
  },
  {
    "id": 25615,
    "content": "54"
  },
  {
    "id": 25616,
    "content": "03+ (CUDA 12"
  },
  {
    "id": 25617,
    "content": "2) 545"
  },
  {
    "id": 25618,
    "content": "23"
  },
  {
    "id": 25619,
    "content": "06+ (CUDA 12"
  },
  {
    "id": 25620,
    "content": "3) 550"
  },
  {
    "id": 25621,
    "content": "54"
  },
  {
    "id": 25622,
    "content": "14+ (CUDA 12"
  },
  {
    "id": 25623,
    "content": "4) 555"
  },
  {
    "id": 25624,
    "content": "42"
  },
  {
    "id": 25626,
    "content": "New Feature Branches (such as 495"
  },
  {
    "id": 25627,
    "content": "xx) are not supported targets for CUDA Forward Compatibility"
  },
  {
    "id": 25630,
    "content": "3 are still subject to the backwards compatibility guarantees described in this document"
  },
  {
    "id": 25631,
    "content": "3"
  },
  {
    "id": 25632,
    "content": "3"
  },
  {
    "id": 25633,
    "content": "2"
  },
  {
    "id": 25636,
    "content": "60"
  },
  {
    "id": 25637,
    "content": "04) Driver 12-x No Yes [1] System Base Installation: 450 (>="
  },
  {
    "id": 25638,
    "content": "80"
  },
  {
    "id": 25640,
    "content": "[2] Supported on Red Hat Enterprise Linux operating system version 8"
  },
  {
    "id": 25641,
    "content": "1 or higher"
  },
  {
    "id": 25642,
    "content": "3"
  },
  {
    "id": 25643,
    "content": "3"
  },
  {
    "id": 25644,
    "content": "3"
  },
  {
    "id": 25648,
    "content": "3"
  },
  {
    "id": 25649,
    "content": "4"
  },
  {
    "id": 25651,
    "content": "Using RPATH, or through LD_LIBRARY_PATH or through an automatic loader (for example, ld"
  },
  {
    "id": 25652,
    "content": "so"
  },
  {
    "id": 25653,
    "content": "conf ), point to that package"
  },
  {
    "id": 25657,
    "content": "4"
  },
  {
    "id": 25662,
    "content": "5"
  },
  {
    "id": 25663,
    "content": "Frequently Asked Questions  This section includes some FAQs related to CUDA compatibility"
  },
  {
    "id": 25664,
    "content": "What is the difference between CUDA forward compatible upgrade and CUDA minor version compatibility"
  },
  {
    "id": 25665,
    "content": "When should users use these features"
  },
  {
    "id": 25667,
    "content": "When to use If you cannot upgrade the kernel driver but need to use the latest CUDA Toolkit"
  },
  {
    "id": 25668,
    "content": "If you want to support newer applications on older drivers within the same major release family"
  },
  {
    "id": 25669,
    "content": "GPUs supported 11"
  },
  {
    "id": 25674,
    "content": "For example, R418 (CUDA 10"
  },
  {
    "id": 25676,
    "content": "Users can also set up LD_LIBRARY_PATH with the new libraries from the cuda-compat-* package"
  },
  {
    "id": 25680,
    "content": "11"
  },
  {
    "id": 25682,
    "content": "Support Maximum Driver Supported* Hopper 9"
  },
  {
    "id": 25683,
    "content": "x 11"
  },
  {
    "id": 25684,
    "content": "8 - current current 525"
  },
  {
    "id": 25685,
    "content": "60"
  },
  {
    "id": 25686,
    "content": "13+ latest NVIDIA Ampere GPU Arch"
  },
  {
    "id": 25687,
    "content": "8"
  },
  {
    "id": 25688,
    "content": "x 11"
  },
  {
    "id": 25689,
    "content": "0 - current 470"
  },
  {
    "id": 25690,
    "content": "57"
  },
  {
    "id": 25691,
    "content": "02 latest Turing 7"
  },
  {
    "id": 25692,
    "content": "5 10"
  },
  {
    "id": 25693,
    "content": "0 - current latest Volta 7"
  },
  {
    "id": 25694,
    "content": "x 9"
  },
  {
    "id": 25695,
    "content": "0 - current latest Pascal 6"
  },
  {
    "id": 25696,
    "content": "x 8"
  },
  {
    "id": 25697,
    "content": "0 - current latest Maxwell 5"
  },
  {
    "id": 25698,
    "content": "x 6"
  },
  {
    "id": 25699,
    "content": "5 - current latest Refer to CUDA Driver Lifecycle to find the latest supported driver"
  },
  {
    "id": 25700,
    "content": "What should we do"
  },
  {
    "id": 25701,
    "content": "PTX and application compatibility information can be found in Binary Compatibility"
  },
  {
    "id": 25703,
    "content": "1/R455, 11"
  },
  {
    "id": 25704,
    "content": "x etc"
  },
  {
    "id": 25705,
    "content": ")"
  },
  {
    "id": 25706,
    "content": "Or is it only the other way around"
  },
  {
    "id": 25707,
    "content": "Drivers have always been backwards compatible with CUDA"
  },
  {
    "id": 25708,
    "content": "This means that a CUDA 11 0 application will be compatible with R450 (11 0), R455 (11"
  },
  {
    "id": 25709,
    "content": "1) and beyond"
  },
  {
    "id": 25711,
    "content": "What is the minimum CUDA 11"
  },
  {
    "id": 25713,
    "content": "80"
  },
  {
    "id": 25714,
    "content": "02"
  },
  {
    "id": 25715,
    "content": "What about new features introduced in minor releases of CUDA"
  },
  {
    "id": 25716,
    "content": "How does a developer build an application using newer CUDA Toolkits (e"
  },
  {
    "id": 25717,
    "content": "g"
  },
  {
    "id": 25718,
    "content": "11 x) work on a system with a CUDA 11"
  },
  {
    "id": 25719,
    "content": "0 driver (R450)"
  },
  {
    "id": 25724,
    "content": "this error: “This container was built for NVIDIA Driver Release 450"
  },
  {
    "id": 25725,
    "content": "51 or later, but version 418"
  },
  {
    "id": 25726,
    "content": "126"
  },
  {
    "id": 25727,
    "content": "02 was detected and compatibility mode is UNAVAILABLE"
  },
  {
    "id": 25728,
    "content": "”"
  },
  {
    "id": 25730,
    "content": "6"
  },
  {
    "id": 25733,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 25745,
    "content": "6"
  },
  {
    "id": 25746,
    "content": "1"
  },
  {
    "id": 25748,
    "content": "S"
  },
  {
    "id": 25751,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 25752,
    "content": "Navigation"
  },
  {
    "id": 25753,
    "content": "enable(true); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 25759,
    "content": "even if other tasks are thrashing their own caches or saturating their DRAM interfaces"
  },
  {
    "id": 25764,
    "content": "demonstrate how users can run CUDA applications on MIG supported GPUs"
  },
  {
    "id": 25769,
    "content": "refer to the chapter in the vGPU Software User Guide"
  },
  {
    "id": 25771,
    "content": "Streaming Multiprocessor A streaming multiprocessor (SM) executes compute instructions on the GPU"
  },
  {
    "id": 25775,
    "content": ")"
  },
  {
    "id": 25778,
    "content": ")"
  },
  {
    "id": 25781,
    "content": "requires combining some number of memory slices with some number of compute slices"
  },
  {
    "id": 25787,
    "content": "10gb , 2g"
  },
  {
    "id": 25788,
    "content": "20gb , 3g"
  },
  {
    "id": 25789,
    "content": "40gb , 4g 40gb , 7g"
  },
  {
    "id": 25790,
    "content": "80gb respectively"
  },
  {
    "id": 25799,
    "content": "the SMs are shared, the GPU memory bandwidth, caches and capacity are shared"
  },
  {
    "id": 25804,
    "content": "functionality is provided as part of the NVIDIA GPU driver"
  },
  {
    "id": 25806,
    "content": "51"
  },
  {
    "id": 25813,
    "content": "g"
  },
  {
    "id": 25814,
    "content": "OpenGL, Vulkan etc"
  },
  {
    "id": 25819,
    "content": "The example shown is for subdividing a 3g"
  },
  {
    "id": 25822,
    "content": "under /dev/nvidia-caps"
  },
  {
    "id": 25825,
    "content": "Depending on the driver versions being used, two formats are supported: With drivers >= R470 ( 470"
  },
  {
    "id": 25826,
    "content": "42"
  },
  {
    "id": 25827,
    "content": "01 +), each MIG device is assigned a GPU UUID starting with MIG-"
  },
  {
    "id": 25828,
    "content": "Note: With the R470 NVIDIA datacenter drivers ( 470"
  },
  {
    "id": 25829,
    "content": "42"
  },
  {
    "id": 25836,
    "content": "8"
  },
  {
    "id": 25837,
    "content": "3"
  },
  {
    "id": 25843,
    "content": "NVDECs /7 JPEG /1 OFA Full 8 1 8"
  },
  {
    "id": 25844,
    "content": "4"
  },
  {
    "id": 25848,
    "content": "using A100/A30, then CUDA 11 and NVIDIA driver R450 ( >= 450"
  },
  {
    "id": 25849,
    "content": "80"
  },
  {
    "id": 25851,
    "content": "5"
  },
  {
    "id": 25852,
    "content": "0 or later NVIDIA K8s Device Plugin: v0"
  },
  {
    "id": 25853,
    "content": "7"
  },
  {
    "id": 25854,
    "content": "0 or later NVIDIA gpu-feature-discovery: v0"
  },
  {
    "id": 25855,
    "content": "2"
  },
  {
    "id": 25859,
    "content": "80"
  },
  {
    "id": 25860,
    "content": "02 Driver Version: 450"
  },
  {
    "id": 25861,
    "content": "80"
  },
  {
    "id": 25862,
    "content": "02 CUDA Version: 11"
  },
  {
    "id": 25863,
    "content": "0 | |-+-+-+ | GPU Name Persistence-M| Bus-Id Disp"
  },
  {
    "id": 25864,
    "content": "A | Volatile Uncorr"
  },
  {
    "id": 25865,
    "content": "| |=+=+=| | 0 A100-SXM4-40GB Off | 00000000:36:00"
  },
  {
    "id": 25868,
    "content": "e"
  },
  {
    "id": 25872,
    "content": "0 All done"
  },
  {
    "id": 25874,
    "content": "0 is currently being used by one or more other processes (e"
  },
  {
    "id": 25875,
    "content": "g"
  },
  {
    "id": 25878,
    "content": "0 All done"
  },
  {
    "id": 25881,
    "content": "Memory P2P SM DEC ENC | | Free/Total GiB CE JPEG OFA | |=| | 0 MIG 1g"
  },
  {
    "id": 25882,
    "content": "5gb 19 7/7 4"
  },
  {
    "id": 25883,
    "content": "75 No 14 0 0 | | 1 0 0 | +-+ | 0 MIG 1g"
  },
  {
    "id": 25884,
    "content": "5gb+me 20 1/1 4"
  },
  {
    "id": 25885,
    "content": "75 No 14 1 0 | | 1 1 1 | +-+ | 0 MIG 1g"
  },
  {
    "id": 25886,
    "content": "10gb 15 4/4 9"
  },
  {
    "id": 25887,
    "content": "62 No 14 1 0 | | 1 0 0 | +-+ | 0 MIG 2g 10gb 14 3/3 9 62 No 28 1 0 | | 2 0 0 | +-+ | 0 MIG 3g"
  },
  {
    "id": 25888,
    "content": "20gb 9 2/2 19"
  },
  {
    "id": 25889,
    "content": "50 No 42 2 0 | | 3 0 0 | +-+ | 0 MIG 4g"
  },
  {
    "id": 25890,
    "content": "20gb 5 1/1 19"
  },
  {
    "id": 25891,
    "content": "50 No 56 2 0 | | 4 0 0 | +-+ | 0 MIG 7g"
  },
  {
    "id": 25892,
    "content": "40gb 0 1/1 39"
  },
  {
    "id": 25893,
    "content": "25 No 98 5 0 | | 7 1 1 | +-+ List the possible placements available using the following command"
  },
  {
    "id": 25897,
    "content": "g"
  },
  {
    "id": 25898,
    "content": "MIG 3g"
  },
  {
    "id": 25902,
    "content": "20gb ), with each GPU instance having half of the available compute and memory capacity"
  },
  {
    "id": 25909,
    "content": "0"
  },
  {
    "id": 25910,
    "content": "13 or later"
  },
  {
    "id": 25911,
    "content": "See the Profiling Metrics section in the DCGM User Guide for more details on getting started"
  },
  {
    "id": 25916,
    "content": "3g"
  },
  {
    "id": 25917,
    "content": "20gb 0 0/3 14 2 0 0 | | 3 0 | +-+ | 0 1 MIG 2c"
  },
  {
    "id": 25927,
    "content": "2gb geometry: $ nvidia-smi +-+ | NVIDIA-SMI 460"
  },
  {
    "id": 25928,
    "content": "73"
  },
  {
    "id": 25929,
    "content": "01 Driver Version: 460"
  },
  {
    "id": 25930,
    "content": "73"
  },
  {
    "id": 25931,
    "content": "01 CUDA Version: 11"
  },
  {
    "id": 25932,
    "content": "2 | |-+-+-+ | GPU Name Persistence-M| Bus-Id Disp"
  },
  {
    "id": 25933,
    "content": "A | Volatile Uncorr"
  },
  {
    "id": 25934,
    "content": "$ curl https: get"
  },
  {
    "id": 25936,
    "content": "MIG support is available starting with v2"
  },
  {
    "id": 25937,
    "content": "3 of nvidia-docker2 (or v1"
  },
  {
    "id": 25938,
    "content": "1"
  },
  {
    "id": 25939,
    "content": "1 of the nvidia-container-toolkit package)"
  },
  {
    "id": 25940,
    "content": "To get access to the /dev nvidia capabilities , it is recommended to use at least v2"
  },
  {
    "id": 25941,
    "content": "5"
  },
  {
    "id": 25942,
    "content": "0 of nvidia-docker2"
  },
  {
    "id": 25943,
    "content": "/etc/os-release;echo $ID$VERSION_ID) \\ && curl -fsSL https: nvidia"
  },
  {
    "id": 25944,
    "content": "github"
  },
  {
    "id": 25946,
    "content": "github"
  },
  {
    "id": 25947,
    "content": "io/libnvidia-container/$distribution/libnvidia-container"
  },
  {
    "id": 25948,
    "content": "list | \\ sed 's#deb https: #deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring"
  },
  {
    "id": 25949,
    "content": "gpg] https: #g' | \\ sudo tee /etc/apt/sources"
  },
  {
    "id": 25950,
    "content": "list"
  },
  {
    "id": 25952,
    "content": "03+) can be used"
  },
  {
    "id": 25954,
    "content": "GPUDeviceIndex>: If using Docker 19"
  },
  {
    "id": 25959,
    "content": "dataset This is shown below: $ sudo docker run --gpus '\"device=0:1\"' \\ nvcr"
  },
  {
    "id": 25961,
    "content": "8"
  },
  {
    "id": 25962,
    "content": "0a0+17f8c32 Container image Copyright (c) 2020, NVIDIA CORPORATION"
  },
  {
    "id": 25965,
    "content": "NVIDIA modifications are covered by the license terms that apply to the underlying project or file"
  },
  {
    "id": 25967,
    "content": "33it/s] /opt/conda/lib/python3"
  },
  {
    "id": 25968,
    "content": "6/site-packages/torchvision/datasets/mnist"
  },
  {
    "id": 25970,
    "content": "Done"
  },
  {
    "id": 25971,
    "content": "Train Epoch: 1 [0/60000 (0%)] Loss: 2 320747 Train Epoch: 1 [640/60000 (1%)] Loss: 1"
  },
  {
    "id": 25972,
    "content": "278727 MIG with Kubernetes MIG support in Kubernetes is available starting with v0"
  },
  {
    "id": 25973,
    "content": "7"
  },
  {
    "id": 25974,
    "content": "0 of the NVIDIA Device Plugin for Kubernetes"
  },
  {
    "id": 25979,
    "content": "The one exception being if you are the root-user (or any user with CAP_SYS_ADMIN privileges)"
  },
  {
    "id": 25981,
    "content": "g"
  },
  {
    "id": 25985,
    "content": "The current CUDA 11/R450 GA (Linux driver 450"
  },
  {
    "id": 25986,
    "content": "51"
  },
  {
    "id": 25988,
    "content": "(as of Linux 450"
  },
  {
    "id": 25989,
    "content": "51"
  },
  {
    "id": 25990,
    "content": "06)"
  },
  {
    "id": 25997,
    "content": "g"
  },
  {
    "id": 26009,
    "content": "ci0 that sit underneath gpu0)"
  },
  {
    "id": 26013,
    "content": "injecting them into a container"
  },
  {
    "id": 26016,
    "content": "on device nodes and nvidia-capabilities with CUDA 11"
  },
  {
    "id": 26017,
    "content": "0 GA"
  },
  {
    "id": 26020,
    "content": "improvements, and any other changes to this document, at any time without notice"
  },
  {
    "id": 26034,
    "content": "== \"undefined\"){ _satellite"
  },
  {
    "id": 26035,
    "content": "pageBottom();}\n1"
  },
  {
    "id": 26041,
    "content": "running an existing GPU accelerated container on EFLOW"
  },
  {
    "id": 26042,
    "content": "1"
  },
  {
    "id": 26043,
    "content": "2"
  },
  {
    "id": 26045,
    "content": "ms/AzEFLOW-install"
  },
  {
    "id": 26047,
    "content": "1"
  },
  {
    "id": 26048,
    "content": "2"
  },
  {
    "id": 26049,
    "content": "1"
  },
  {
    "id": 26052,
    "content": "If you are preparing a CUDA docker container, ensure that the necessary toolchains are installed"
  },
  {
    "id": 26054,
    "content": "Refer to the user’s guide of the SDK that you are interested in to determine support"
  },
  {
    "id": 26055,
    "content": "1"
  },
  {
    "id": 26056,
    "content": "2"
  },
  {
    "id": 26057,
    "content": "2"
  },
  {
    "id": 26058,
    "content": "Installation of EFLOW  In an elevated powershell prompt perform the following: Enable HyperV"
  },
  {
    "id": 26061,
    "content": "$msiPath = $([io"
  },
  {
    "id": 26062,
    "content": "Path]::Combine($env:TEMP, 'AzureIoTEdge"
  },
  {
    "id": 26063,
    "content": "msi')) $ProgressPreference = 'SilentlyContinue' Invoke-WebRequest \"https: aka"
  },
  {
    "id": 26064,
    "content": "ms/AzEFLOWMSI_1_4_LTS_X64\" -OutFile $msiPath Start-Process -Wait msiexec -ArgumentList \"/i\",\"$([io"
  },
  {
    "id": 26065,
    "content": "Path]::Combine($env:TEMP, 'AzureIoTEdge"
  },
  {
    "id": 26066,
    "content": "msi'))\",\"/qn\" Determine host OS configuration"
  },
  {
    "id": 26068,
    "content": "Object[]; Name=NVIDIA RTX A2000} Deploy EFLOW"
  },
  {
    "id": 26071,
    "content": "1"
  },
  {
    "id": 26072,
    "content": "2"
  },
  {
    "id": 26073,
    "content": "3"
  },
  {
    "id": 26074,
    "content": "Prerequisites for CUDA Support  x86 64-bit support only"
  },
  {
    "id": 26076,
    "content": "1620 or higher"
  },
  {
    "id": 26078,
    "content": "microsoft"
  },
  {
    "id": 26079,
    "content": "com/en-us/azure/iot-edge/reference-iot-edge-for-linux-on-windows-functions#deploy-eflow"
  },
  {
    "id": 26080,
    "content": "Refer to https: learn"
  },
  {
    "id": 26081,
    "content": "microsoft"
  },
  {
    "id": 26082,
    "content": "com/en-us/azure/iot-edge/gpu-acceleration"
  },
  {
    "id": 26083,
    "content": "view=iotedge-1"
  },
  {
    "id": 26084,
    "content": "4"
  },
  {
    "id": 26085,
    "content": "1"
  },
  {
    "id": 26086,
    "content": "3"
  },
  {
    "id": 26088,
    "content": "24"
  },
  {
    "id": 26089,
    "content": "14"
  },
  {
    "id": 26090,
    "content": "242 retrieved directly from virtual machine 00:15:5d:b2:40:c7 172"
  },
  {
    "id": 26091,
    "content": "24"
  },
  {
    "id": 26092,
    "content": "14"
  },
  {
    "id": 26093,
    "content": "242 Connect-EflowVm 1"
  },
  {
    "id": 26094,
    "content": "4"
  },
  {
    "id": 26096,
    "content": "iotedge-user@IPP1-1490-EFLOW [ ~ ]$ sudo docker run --gpus all --env NVIDIA_DISABLE_REQUIRE=1 nvcr"
  },
  {
    "id": 26101,
    "content": "6 > Compute 8"
  },
  {
    "id": 26102,
    "content": "6 CUDA device: [NVIDIA RTX A2000] 26624 bodies, total time for 10 iterations: 31"
  },
  {
    "id": 26103,
    "content": "984 ms = 221"
  },
  {
    "id": 26104,
    "content": "625 billion interactions per second = 4432"
  },
  {
    "id": 26105,
    "content": "503 single-precision GFLOP/s at 20 flops per interaction iotedge-user@IPP1-1490-EFLOW [ ~ ]$ 1"
  },
  {
    "id": 26106,
    "content": "6"
  },
  {
    "id": 26107,
    "content": "Troubleshooting  nvidia-container-cli: requirement error: unsatisfied condition: cuda>=11"
  },
  {
    "id": 26109,
    "content": "Out of memory In case of out of memory errors, increase the system memory reserved by EFLOW"
  },
  {
    "id": 26110,
    "content": "Refer to https: learn"
  },
  {
    "id": 26111,
    "content": "microsoft"
  },
  {
    "id": 26112,
    "content": "com/en-us/azure/iot-edge/reference-iot-edge-for-linux-on-windows-functions#deploy-eflow"
  },
  {
    "id": 26113,
    "content": "2"
  },
  {
    "id": 26114,
    "content": "Notices  2"
  },
  {
    "id": 26115,
    "content": "1"
  },
  {
    "id": 26118,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 26130,
    "content": "2"
  },
  {
    "id": 26131,
    "content": "2"
  },
  {
    "id": 26132,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 26133,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 26134,
    "content": "2"
  },
  {
    "id": 26135,
    "content": "3"
  },
  {
    "id": 26137,
    "content": "S"
  },
  {
    "id": 26140,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 26141,
    "content": "Navigation"
  },
  {
    "id": 26142,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 26143,
    "content": "pageBottom();}\n1"
  },
  {
    "id": 26150,
    "content": "For some helpful examples, see https: docs"
  },
  {
    "id": 26151,
    "content": "microsoft"
  },
  {
    "id": 26155,
    "content": "1"
  },
  {
    "id": 26156,
    "content": "1"
  },
  {
    "id": 26158,
    "content": "com/Download/index"
  },
  {
    "id": 26159,
    "content": "aspx for WSL 2 support on Pascal or later GPUs"
  },
  {
    "id": 26160,
    "content": "NVIDIA Container Toolkit - Minimum versions - v2"
  },
  {
    "id": 26161,
    "content": "6"
  },
  {
    "id": 26162,
    "content": "0 with libnvidia-container - 1"
  },
  {
    "id": 26163,
    "content": "5"
  },
  {
    "id": 26164,
    "content": "1+ CLI and Docker Desktop Supported"
  },
  {
    "id": 26166,
    "content": "from 12"
  },
  {
    "id": 26167,
    "content": "x releases can be downloaded from https: developer"
  },
  {
    "id": 26168,
    "content": "nvidia"
  },
  {
    "id": 26169,
    "content": "com/cuda-downloads"
  },
  {
    "id": 26170,
    "content": "https: docs"
  },
  {
    "id": 26171,
    "content": "rapids"
  },
  {
    "id": 26172,
    "content": "ai/notices/rgn0024/ NCCL 2"
  },
  {
    "id": 26173,
    "content": "12 or later 1"
  },
  {
    "id": 26174,
    "content": "4+ Refer to the NCCL Installation guide for Linux x86"
  },
  {
    "id": 26175,
    "content": "2"
  },
  {
    "id": 26177,
    "content": "1"
  },
  {
    "id": 26179,
    "content": "com/Download/index"
  },
  {
    "id": 26180,
    "content": "aspx"
  },
  {
    "id": 26181,
    "content": "Refer to the system requirements in the Appendix"
  },
  {
    "id": 26182,
    "content": ") Note This is the only driver you need to install Do not install any Linux display driver in WSL"
  },
  {
    "id": 26183,
    "content": "2"
  },
  {
    "id": 26184,
    "content": "2"
  },
  {
    "id": 26186,
    "content": "3"
  },
  {
    "id": 26187,
    "content": "Step 3: Set Up a Linux Development Environment  From a Windows terminal, enter WSL: C:\\> wsl"
  },
  {
    "id": 26189,
    "content": "microsoft"
  },
  {
    "id": 26190,
    "content": "com/en-us/windows/wsl/install https: docs"
  },
  {
    "id": 26191,
    "content": "microsoft"
  },
  {
    "id": 26193,
    "content": "Read the next section for further information"
  },
  {
    "id": 26194,
    "content": "3"
  },
  {
    "id": 26201,
    "content": "4"
  },
  {
    "id": 26203,
    "content": "If you are continuing to use Windows 10, see Windows Insider Preview and Windows 10 Support"
  },
  {
    "id": 26204,
    "content": "4"
  },
  {
    "id": 26205,
    "content": "1"
  },
  {
    "id": 26208,
    "content": "CUDA queries will say whether it is supported or not and applications are expected to check this"
  },
  {
    "id": 26211,
    "content": "Root user on bare metal (not containers) will not find nvidia-smi at the expected location"
  },
  {
    "id": 26213,
    "content": "4"
  },
  {
    "id": 26214,
    "content": "2"
  },
  {
    "id": 26218,
    "content": "5"
  },
  {
    "id": 26219,
    "content": "2"
  },
  {
    "id": 26220,
    "content": "Troubleshooting  5"
  },
  {
    "id": 26221,
    "content": "2"
  },
  {
    "id": 26222,
    "content": "1"
  },
  {
    "id": 26229,
    "content": "5"
  },
  {
    "id": 26230,
    "content": "2"
  },
  {
    "id": 26231,
    "content": "2"
  },
  {
    "id": 26233,
    "content": "10"
  },
  {
    "id": 26234,
    "content": "16"
  },
  {
    "id": 26235,
    "content": "3-microsoft-standard-WSL2 (x86_64-msft-linux-gcc (GCC) 9"
  },
  {
    "id": 26236,
    "content": "3"
  },
  {
    "id": 26237,
    "content": "0, GNU ld (GNU Binutils) 2"
  },
  {
    "id": 26238,
    "content": "34"
  },
  {
    "id": 26239,
    "content": "0"
  },
  {
    "id": 26241,
    "content": "3"
  },
  {
    "id": 26246,
    "content": "5"
  },
  {
    "id": 26247,
    "content": "4"
  },
  {
    "id": 26249,
    "content": ", to be bundled together for development and easy and predictable deployment"
  },
  {
    "id": 26251,
    "content": "microsoft"
  },
  {
    "id": 26252,
    "content": "com/en-us/virtualization/windowscontainers/about/containers-vs-vm"
  },
  {
    "id": 26253,
    "content": "6"
  },
  {
    "id": 26254,
    "content": "Notices  6"
  },
  {
    "id": 26255,
    "content": "1"
  },
  {
    "id": 26258,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 26270,
    "content": "6"
  },
  {
    "id": 26271,
    "content": "2"
  },
  {
    "id": 26272,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 26273,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 26274,
    "content": "6"
  },
  {
    "id": 26275,
    "content": "3"
  },
  {
    "id": 26277,
    "content": "S"
  },
  {
    "id": 26280,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 26281,
    "content": "Navigation"
  },
  {
    "id": 26282,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 26283,
    "content": "pageBottom();}\n1"
  },
  {
    "id": 26284,
    "content": "Introduction v12"
  },
  {
    "id": 26285,
    "content": "5 | PDF | Archive CUDA Demo Suite The reference guide for the CUDA Demo Suite"
  },
  {
    "id": 26286,
    "content": "These applications demonstrate the capabilities and details of NVIDIA GPUs"
  },
  {
    "id": 26287,
    "content": "2"
  },
  {
    "id": 26288,
    "content": "Demos  Below are the demos within the demo suite"
  },
  {
    "id": 26289,
    "content": "2"
  },
  {
    "id": 26290,
    "content": "1"
  },
  {
    "id": 26292,
    "content": "2"
  },
  {
    "id": 26293,
    "content": "2"
  },
  {
    "id": 26295,
    "content": "2"
  },
  {
    "id": 26296,
    "content": "3"
  },
  {
    "id": 26298,
    "content": "amongst GPUs present in the system as well as pinned, unpinned memory bandwidth"
  },
  {
    "id": 26300,
    "content": "Examples:"
  },
  {
    "id": 26302,
    "content": "5"
  },
  {
    "id": 26308,
    "content": "6"
  },
  {
    "id": 26310,
    "content": "The following keys can be used to control the output: Keys Function w Toggle wireframe 2"
  },
  {
    "id": 26311,
    "content": "7"
  },
  {
    "id": 26315,
    "content": "e"
  },
  {
    "id": 26319,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 26331,
    "content": "3"
  },
  {
    "id": 26332,
    "content": "2"
  },
  {
    "id": 26333,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 26334,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 26335,
    "content": "3"
  },
  {
    "id": 26336,
    "content": "3"
  },
  {
    "id": 26338,
    "content": "S"
  },
  {
    "id": 26341,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 26342,
    "content": "Navigation"
  },
  {
    "id": 26343,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 26344,
    "content": "pageBottom();}\n1"
  },
  {
    "id": 26348,
    "content": "2"
  },
  {
    "id": 26349,
    "content": "Getting Started  2"
  },
  {
    "id": 26350,
    "content": "1"
  },
  {
    "id": 26352,
    "content": "CUDA Toolkit and Driver"
  },
  {
    "id": 26353,
    "content": "2"
  },
  {
    "id": 26354,
    "content": "2"
  },
  {
    "id": 26357,
    "content": "h lib64/libnvptxcompiler_static"
  },
  {
    "id": 26358,
    "content": "a doc/pdf/PTX_Compiler_API_User_Guide pdf 3"
  },
  {
    "id": 26360,
    "content": "4"
  },
  {
    "id": 26362,
    "content": "4"
  },
  {
    "id": 26363,
    "content": "1"
  },
  {
    "id": 26364,
    "content": "1"
  },
  {
    "id": 26366,
    "content": "4"
  },
  {
    "id": 26367,
    "content": "2"
  },
  {
    "id": 26369,
    "content": "4"
  },
  {
    "id": 26370,
    "content": "2"
  },
  {
    "id": 26371,
    "content": "1"
  },
  {
    "id": 26374,
    "content": " enumerator NVPTXCOMPILE_ERROR_UNSUPPORTED_DEVSIDE_SYNC  4"
  },
  {
    "id": 26375,
    "content": "3"
  },
  {
    "id": 26378,
    "content": "4"
  },
  {
    "id": 26379,
    "content": "3"
  },
  {
    "id": 26380,
    "content": "1"
  },
  {
    "id": 26382,
    "content": "4"
  },
  {
    "id": 26387,
    "content": "4"
  },
  {
    "id": 26388,
    "content": "4"
  },
  {
    "id": 26389,
    "content": "1"
  },
  {
    "id": 26402,
    "content": "g"
  },
  {
    "id": 26403,
    "content": ", \"--gpu-name=sm_70\""
  },
  {
    "id": 26405,
    "content": "e"
  },
  {
    "id": 26406,
    "content": "g, \"--gpu-name\" \"sm_70\""
  },
  {
    "id": 26411,
    "content": "--disable-optimizer-constants ( -disable-optimizer-consts ) Disable use of optimizer constant bank"
  },
  {
    "id": 26415,
    "content": "This option also takes virtual compute architectures, in which case code generation is suppressed"
  },
  {
    "id": 26423,
    "content": "tensor} instruction with sm_90"
  },
  {
    "id": 26426,
    "content": "--maxntid ( -maxntid ) Specify the maximum number of threads that a thread block can have"
  },
  {
    "id": 26427,
    "content": "--minnctapersm ( -minnctapersm ) Specify the minimum number of CTAs to be mapped to an SM"
  },
  {
    "id": 26428,
    "content": "This option is also ignored for entry functions that have"
  },
  {
    "id": 26431,
    "content": "6"
  },
  {
    "id": 26434,
    "content": "x * blockDim"
  },
  {
    "id": 26435,
    "content": "x + threadIdx"
  },
  {
    "id": 26439,
    "content": "for (i = 0; i -I $CUDA_PATH/include -L $CUDA_PATH/lib/x64/ -lcuda nvptxcompiler_static"
  },
  {
    "id": 26441,
    "content": "2"
  },
  {
    "id": 26444,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 26456,
    "content": "7"
  },
  {
    "id": 26457,
    "content": "2"
  },
  {
    "id": 26458,
    "content": "2"
  },
  {
    "id": 26459,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 26460,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 26461,
    "content": "7"
  },
  {
    "id": 26462,
    "content": "2"
  },
  {
    "id": 26463,
    "content": "3"
  },
  {
    "id": 26465,
    "content": "S"
  },
  {
    "id": 26468,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 26469,
    "content": "Navigation"
  },
  {
    "id": 26470,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 26471,
    "content": "pageBottom();}\n1"
  },
  {
    "id": 26472,
    "content": "Introduction v12"
  },
  {
    "id": 26480,
    "content": "1"
  },
  {
    "id": 26481,
    "content": "1"
  },
  {
    "id": 26484,
    "content": "1"
  },
  {
    "id": 26485,
    "content": "2"
  },
  {
    "id": 26489,
    "content": "1"
  },
  {
    "id": 26490,
    "content": "3"
  },
  {
    "id": 26492,
    "content": ",k"
  },
  {
    "id": 26495,
    "content": "1"
  },
  {
    "id": 26496,
    "content": "4"
  },
  {
    "id": 26498,
    "content": "type, respectively"
  },
  {
    "id": 26509,
    "content": "Finally, the return type of the cuSolverRF library routines is cusolverStatus_t"
  },
  {
    "id": 26510,
    "content": "1"
  },
  {
    "id": 26511,
    "content": "5"
  },
  {
    "id": 26514,
    "content": "1"
  },
  {
    "id": 26515,
    "content": "6"
  },
  {
    "id": 26516,
    "content": "Library Property  The libraryPropertyType data type is an enumeration of library property types"
  },
  {
    "id": 26517,
    "content": "CUDA version X"
  },
  {
    "id": 26518,
    "content": "Y"
  },
  {
    "id": 26520,
    "content": "PATCH_LEVEL , & patch ); printf ( \"CUSOLVER Version (Major,Minor,PatchLevel): %d"
  },
  {
    "id": 26521,
    "content": "%d"
  },
  {
    "id": 26522,
    "content": "%d   \" , major , minor , patch ); 1"
  },
  {
    "id": 26523,
    "content": "7"
  },
  {
    "id": 26525,
    "content": "2"
  },
  {
    "id": 26526,
    "content": "Using the CUSOLVER API  2"
  },
  {
    "id": 26527,
    "content": "1"
  },
  {
    "id": 26529,
    "content": "2"
  },
  {
    "id": 26530,
    "content": "1"
  },
  {
    "id": 26531,
    "content": "1"
  },
  {
    "id": 26533,
    "content": "2"
  },
  {
    "id": 26534,
    "content": "1"
  },
  {
    "id": 26535,
    "content": "2"
  },
  {
    "id": 26537,
    "content": "2"
  },
  {
    "id": 26538,
    "content": "1"
  },
  {
    "id": 26539,
    "content": "3"
  },
  {
    "id": 26542,
    "content": "is a data transfer that can be performed in parallel with the computation"
  },
  {
    "id": 26543,
    "content": "2"
  },
  {
    "id": 26544,
    "content": "1"
  },
  {
    "id": 26545,
    "content": "4"
  },
  {
    "id": 26547,
    "content": "a"
  },
  {
    "id": 26548,
    "content": "If the user links the application with libcusolver"
  },
  {
    "id": 26549,
    "content": "so , libcublas so , libcublasLt so and libcusparse so are also required"
  },
  {
    "id": 26550,
    "content": "If the user links the application with libcusolver_static"
  },
  {
    "id": 26551,
    "content": "a , the following libraries are also needed, libcudart_static"
  },
  {
    "id": 26552,
    "content": "a , libculibos"
  },
  {
    "id": 26553,
    "content": "a , libcusolver_lapack_static"
  },
  {
    "id": 26554,
    "content": "a , libcusolver_metis_static"
  },
  {
    "id": 26555,
    "content": "a , libcublas_static"
  },
  {
    "id": 26556,
    "content": "a and libcusparse_static"
  },
  {
    "id": 26557,
    "content": "a"
  },
  {
    "id": 26558,
    "content": "2"
  },
  {
    "id": 26559,
    "content": "1"
  },
  {
    "id": 26560,
    "content": "5"
  },
  {
    "id": 26562,
    "content": "a in order to build the application successfully"
  },
  {
    "id": 26563,
    "content": "Prior to CUDA 10"
  },
  {
    "id": 26564,
    "content": "1 update 2, the user can replace libcusolver_lapack_static"
  },
  {
    "id": 26565,
    "content": "a with a third-party LAPACK library, for example, MKL"
  },
  {
    "id": 26566,
    "content": "In CUDA 10"
  },
  {
    "id": 26568,
    "content": "Furthermore the user cannot use libcusolver_lapack_static"
  },
  {
    "id": 26569,
    "content": "a as a standalone LAPACK library because it is only a subset of LAPACK"
  },
  {
    "id": 26570,
    "content": "If you use libcusolver_static a , then you must link with libcusolver_lapack_static"
  },
  {
    "id": 26571,
    "content": "a explicitly, otherwise the linker will report missing symbols"
  },
  {
    "id": 26573,
    "content": "The libcusolver"
  },
  {
    "id": 26575,
    "content": "2"
  },
  {
    "id": 26576,
    "content": "1"
  },
  {
    "id": 26577,
    "content": "6"
  },
  {
    "id": 26579,
    "content": "2"
  },
  {
    "id": 26580,
    "content": "1"
  },
  {
    "id": 26581,
    "content": "7"
  },
  {
    "id": 26584,
    "content": "device pointer) is prepared or before the device pointer is allocated"
  },
  {
    "id": 26586,
    "content": "2"
  },
  {
    "id": 26587,
    "content": "1"
  },
  {
    "id": 26588,
    "content": "9"
  },
  {
    "id": 26590,
    "content": "g"
  },
  {
    "id": 26593,
    "content": "2"
  },
  {
    "id": 26594,
    "content": "2"
  },
  {
    "id": 26595,
    "content": "cuSolver Types Reference  2"
  },
  {
    "id": 26596,
    "content": "2"
  },
  {
    "id": 26597,
    "content": "1"
  },
  {
    "id": 26599,
    "content": "h"
  },
  {
    "id": 26600,
    "content": "In addition, cuSolverDN uses some familiar types from cuBLAS"
  },
  {
    "id": 26601,
    "content": "2"
  },
  {
    "id": 26602,
    "content": "2"
  },
  {
    "id": 26603,
    "content": "1"
  },
  {
    "id": 26604,
    "content": "1"
  },
  {
    "id": 26607,
    "content": "2"
  },
  {
    "id": 26608,
    "content": "2"
  },
  {
    "id": 26609,
    "content": "1"
  },
  {
    "id": 26610,
    "content": "2"
  },
  {
    "id": 26612,
    "content": "2"
  },
  {
    "id": 26613,
    "content": "2"
  },
  {
    "id": 26614,
    "content": "1"
  },
  {
    "id": 26615,
    "content": "3"
  },
  {
    "id": 26617,
    "content": "2"
  },
  {
    "id": 26618,
    "content": "2"
  },
  {
    "id": 26619,
    "content": "1"
  },
  {
    "id": 26620,
    "content": "4"
  },
  {
    "id": 26622,
    "content": "2"
  },
  {
    "id": 26623,
    "content": "2"
  },
  {
    "id": 26624,
    "content": "1"
  },
  {
    "id": 26625,
    "content": "5"
  },
  {
    "id": 26627,
    "content": "2"
  },
  {
    "id": 26628,
    "content": "2"
  },
  {
    "id": 26629,
    "content": "1"
  },
  {
    "id": 26630,
    "content": "6"
  },
  {
    "id": 26633,
    "content": "Higham"
  },
  {
    "id": 26634,
    "content": "2018"
  },
  {
    "id": 26642,
    "content": "preconditioned system"
  },
  {
    "id": 26643,
    "content": "2"
  },
  {
    "id": 26644,
    "content": "2"
  },
  {
    "id": 26645,
    "content": "1"
  },
  {
    "id": 26646,
    "content": "7"
  },
  {
    "id": 26649,
    "content": "2"
  },
  {
    "id": 26650,
    "content": "2"
  },
  {
    "id": 26651,
    "content": "1"
  },
  {
    "id": 26652,
    "content": "8"
  },
  {
    "id": 26654,
    "content": "g"
  },
  {
    "id": 26655,
    "content": ", cusolverDnXgesv() )"
  },
  {
    "id": 26657,
    "content": "2"
  },
  {
    "id": 26658,
    "content": "2"
  },
  {
    "id": 26659,
    "content": "1"
  },
  {
    "id": 26660,
    "content": "9"
  },
  {
    "id": 26662,
    "content": "Value Meaning CUSOLVERDN_GETRF Corresponds to Getrf"
  },
  {
    "id": 26663,
    "content": "2"
  },
  {
    "id": 26664,
    "content": "2"
  },
  {
    "id": 26665,
    "content": "1"
  },
  {
    "id": 26666,
    "content": "10"
  },
  {
    "id": 26669,
    "content": "The user can also provide NULL to use the default algorithm"
  },
  {
    "id": 26670,
    "content": "2"
  },
  {
    "id": 26671,
    "content": "2"
  },
  {
    "id": 26672,
    "content": "1"
  },
  {
    "id": 26673,
    "content": "11"
  },
  {
    "id": 26674,
    "content": "cusolverStatus_t  This is the same as cusolverStatus_t in the sparse LAPACK section"
  },
  {
    "id": 26675,
    "content": "2"
  },
  {
    "id": 26676,
    "content": "2"
  },
  {
    "id": 26677,
    "content": "1"
  },
  {
    "id": 26678,
    "content": "12"
  },
  {
    "id": 26679,
    "content": "cusolverDnLoggerCallback_t  cusolverDnLoggerCallback_t is a callback function pointer type"
  },
  {
    "id": 26681,
    "content": "Use the below function to set the callback function: cusolverDnLoggerSetCallback()"
  },
  {
    "id": 26682,
    "content": "2"
  },
  {
    "id": 26683,
    "content": "2"
  },
  {
    "id": 26684,
    "content": "1"
  },
  {
    "id": 26685,
    "content": "13"
  },
  {
    "id": 26688,
    "content": "2"
  },
  {
    "id": 26689,
    "content": "2"
  },
  {
    "id": 26690,
    "content": "1"
  },
  {
    "id": 26691,
    "content": "14"
  },
  {
    "id": 26692,
    "content": "cusolverStorevMode_t  Specifies how the vectors which define the elementary reflectors are stored"
  },
  {
    "id": 26693,
    "content": "CUBLAS_STOREV_ROWWISE Rowwise"
  },
  {
    "id": 26694,
    "content": "2"
  },
  {
    "id": 26695,
    "content": "2"
  },
  {
    "id": 26696,
    "content": "1"
  },
  {
    "id": 26697,
    "content": "15"
  },
  {
    "id": 26699,
    "content": "CUBLAS_DIRECT_BACKWARD Backward"
  },
  {
    "id": 26700,
    "content": "2"
  },
  {
    "id": 26701,
    "content": "2"
  },
  {
    "id": 26702,
    "content": "2"
  },
  {
    "id": 26703,
    "content": "cuSolverSP Types  The float , double , cuComplex , and cuDoubleComplex data types are supported"
  },
  {
    "id": 26704,
    "content": "2"
  },
  {
    "id": 26705,
    "content": "2"
  },
  {
    "id": 26706,
    "content": "2"
  },
  {
    "id": 26707,
    "content": "1"
  },
  {
    "id": 26710,
    "content": "2"
  },
  {
    "id": 26711,
    "content": "2"
  },
  {
    "id": 26712,
    "content": "2"
  },
  {
    "id": 26713,
    "content": "2"
  },
  {
    "id": 26715,
    "content": "2"
  },
  {
    "id": 26716,
    "content": "2"
  },
  {
    "id": 26717,
    "content": "2"
  },
  {
    "id": 26718,
    "content": "3"
  },
  {
    "id": 26721,
    "content": "allocated memory as much as possible"
  },
  {
    "id": 26724,
    "content": "To correct: compile and run the application on a device with compute capability 5"
  },
  {
    "id": 26725,
    "content": "0 or above"
  },
  {
    "id": 26728,
    "content": "CUSOLVER_STATUS_MATRIX_TYPE_NOT_SUPPORTED The matrix type is not supported by this function"
  },
  {
    "id": 26730,
    "content": "Parameter Memory In/out Meaning handle host input Handle to the cuSolverDN library context"
  },
  {
    "id": 26731,
    "content": "CUSOLVER_STATUS_INTERNAL_ERROR An internal error occurred"
  },
  {
    "id": 26732,
    "content": "2"
  },
  {
    "id": 26733,
    "content": "4"
  },
  {
    "id": 26734,
    "content": "1"
  },
  {
    "id": 26735,
    "content": "12"
  },
  {
    "id": 26737,
    "content": "2"
  },
  {
    "id": 26738,
    "content": "4"
  },
  {
    "id": 26739,
    "content": "1"
  },
  {
    "id": 26740,
    "content": "13"
  },
  {
    "id": 26742,
    "content": "CUSOLVER_STATUS_ALLOC_FAILED The resources could not be allocated"
  },
  {
    "id": 26743,
    "content": "2"
  },
  {
    "id": 26744,
    "content": "4"
  },
  {
    "id": 26745,
    "content": "1"
  },
  {
    "id": 26746,
    "content": "14"
  },
  {
    "id": 26748,
    "content": "Status Returned CUSOLVER_STATUS_SUCCESS The resources were released successfully"
  },
  {
    "id": 26749,
    "content": "2"
  },
  {
    "id": 26750,
    "content": "4"
  },
  {
    "id": 26751,
    "content": "1"
  },
  {
    "id": 26752,
    "content": "15"
  },
  {
    "id": 26754,
    "content": "Status Returned CUSOLVER_STATUS_SUCCESS The operation completed successfully"
  },
  {
    "id": 26755,
    "content": "2"
  },
  {
    "id": 26756,
    "content": "4"
  },
  {
    "id": 26757,
    "content": "1"
  },
  {
    "id": 26758,
    "content": "16"
  },
  {
    "id": 26760,
    "content": "2"
  },
  {
    "id": 26761,
    "content": "4"
  },
  {
    "id": 26762,
    "content": "1"
  },
  {
    "id": 26763,
    "content": "17"
  },
  {
    "id": 26765,
    "content": "2"
  },
  {
    "id": 26766,
    "content": "4"
  },
  {
    "id": 26767,
    "content": "1"
  },
  {
    "id": 26768,
    "content": "18"
  },
  {
    "id": 26771,
    "content": "2"
  },
  {
    "id": 26772,
    "content": "4"
  },
  {
    "id": 26773,
    "content": "1"
  },
  {
    "id": 26774,
    "content": "19"
  },
  {
    "id": 26776,
    "content": "2"
  },
  {
    "id": 26777,
    "content": "4"
  },
  {
    "id": 26778,
    "content": "1"
  },
  {
    "id": 26779,
    "content": "20"
  },
  {
    "id": 26781,
    "content": "2"
  },
  {
    "id": 26782,
    "content": "4"
  },
  {
    "id": 26783,
    "content": "1"
  },
  {
    "id": 26784,
    "content": "21"
  },
  {
    "id": 26786,
    "content": "2"
  },
  {
    "id": 26787,
    "content": "4"
  },
  {
    "id": 26788,
    "content": "1"
  },
  {
    "id": 26789,
    "content": "22"
  },
  {
    "id": 26791,
    "content": "2"
  },
  {
    "id": 26792,
    "content": "4"
  },
  {
    "id": 26793,
    "content": "1"
  },
  {
    "id": 26794,
    "content": "23"
  },
  {
    "id": 26796,
    "content": "2"
  },
  {
    "id": 26797,
    "content": "4"
  },
  {
    "id": 26798,
    "content": "1"
  },
  {
    "id": 26799,
    "content": "24"
  },
  {
    "id": 26801,
    "content": "2"
  },
  {
    "id": 26802,
    "content": "4"
  },
  {
    "id": 26803,
    "content": "1"
  },
  {
    "id": 26804,
    "content": "25"
  },
  {
    "id": 26809,
    "content": "Note that in CUDA 10"
  },
  {
    "id": 26812,
    "content": "2"
  },
  {
    "id": 26813,
    "content": "4"
  },
  {
    "id": 26814,
    "content": "1"
  },
  {
    "id": 26815,
    "content": "28"
  },
  {
    "id": 26817,
    "content": "destroyed yet"
  },
  {
    "id": 26818,
    "content": "2"
  },
  {
    "id": 26819,
    "content": "4"
  },
  {
    "id": 26820,
    "content": "1"
  },
  {
    "id": 26821,
    "content": "29"
  },
  {
    "id": 26825,
    "content": "The ratio of the performance of the lowest precision over the main precision (e"
  },
  {
    "id": 26826,
    "content": "g"
  },
  {
    "id": 26827,
    "content": ", Inputs/Outputs datatype) define the upper bound of the speedup that could be obtained"
  },
  {
    "id": 26829,
    "content": "g"
  },
  {
    "id": 26830,
    "content": ", GEMM where K is 256 and M=N=size of the matrix) that define the possible speedup"
  },
  {
    "id": 26833,
    "content": "Parameter Memory In/out Meaning params host in/out The cusolverDnIRSParams_t Params structure"
  },
  {
    "id": 26835,
    "content": "g"
  },
  {
    "id": 26837,
    "content": "CUSOLVER_R_TF32 2"
  },
  {
    "id": 26838,
    "content": "4"
  },
  {
    "id": 26839,
    "content": "1"
  },
  {
    "id": 26840,
    "content": "30"
  },
  {
    "id": 26844,
    "content": "2"
  },
  {
    "id": 26845,
    "content": "4"
  },
  {
    "id": 26846,
    "content": "1"
  },
  {
    "id": 26847,
    "content": "31"
  },
  {
    "id": 26849,
    "content": "g"
  },
  {
    "id": 26850,
    "content": ", Inputs/Outputs datatype) define somehow the upper bound of the speedup that could be obtained"
  },
  {
    "id": 26852,
    "content": "2"
  },
  {
    "id": 26853,
    "content": "4"
  },
  {
    "id": 26854,
    "content": "1"
  },
  {
    "id": 26855,
    "content": "32"
  },
  {
    "id": 26857,
    "content": "first call to the IRS solver because it is NOT set by default with the creating of params"
  },
  {
    "id": 26858,
    "content": "Details about values that can be set to and theirs meaning are described in the table below"
  },
  {
    "id": 26863,
    "content": "2"
  },
  {
    "id": 26864,
    "content": "4"
  },
  {
    "id": 26865,
    "content": "1"
  },
  {
    "id": 26866,
    "content": "33"
  },
  {
    "id": 26869,
    "content": "0 The user can use this function to change the tolerance to a lower or higher value"
  },
  {
    "id": 26872,
    "content": "2"
  },
  {
    "id": 26873,
    "content": "4"
  },
  {
    "id": 26874,
    "content": "1"
  },
  {
    "id": 26875,
    "content": "34"
  },
  {
    "id": 26877,
    "content": "g"
  },
  {
    "id": 26878,
    "content": ", CUSOLVER_IRS_REFINE_CLASSICAL_GMRES or CUSOLVER_IRS_REFINE_GMRES_GMRES cases)"
  },
  {
    "id": 26881,
    "content": "2"
  },
  {
    "id": 26882,
    "content": "4"
  },
  {
    "id": 26883,
    "content": "1"
  },
  {
    "id": 26884,
    "content": "35"
  },
  {
    "id": 26886,
    "content": "input Maximum total number of iterations allowed for the refinement solver"
  },
  {
    "id": 26887,
    "content": "2"
  },
  {
    "id": 26888,
    "content": "4"
  },
  {
    "id": 26889,
    "content": "1"
  },
  {
    "id": 26890,
    "content": "36"
  },
  {
    "id": 26894,
    "content": "2"
  },
  {
    "id": 26895,
    "content": "4"
  },
  {
    "id": 26896,
    "content": "1"
  },
  {
    "id": 26897,
    "content": "37"
  },
  {
    "id": 26899,
    "content": "g"
  },
  {
    "id": 26900,
    "content": ", niter potrf()  These helper functions calculate the necessary size of work buffers"
  },
  {
    "id": 26908,
    "content": "the cuSolverDN library context"
  },
  {
    "id": 26926,
    "content": "The input parameter Lwork is size of the working space, and it is returned by getrf_bufferSize()"
  },
  {
    "id": 26931,
    "content": "workspaceInBytes host input Size in bytes of pBuffer , returned by cusolverDnGetrf_bufferSize"
  },
  {
    "id": 26935,
    "content": "\\) The input parameter devIpiv is an output of getrf"
  },
  {
    "id": 26941,
    "content": "carried on"
  },
  {
    "id": 26944,
    "content": "g"
  },
  {
    "id": 26948,
    "content": "0 respectively"
  },
  {
    "id": 26950,
    "content": "The amount of bytes required can be queried by calling the respective function gesv_bufferSize()"
  },
  {
    "id": 26951,
    "content": "Note that in addition to the two mixed precision functions available in LAPACK (e"
  },
  {
    "id": 26952,
    "content": "g"
  },
  {
    "id": 26954,
    "content": "g"
  },
  {
    "id": 26955,
    "content": ", main and lowest precision are equal is equal to )"
  },
  {
    "id": 26959,
    "content": "e"
  },
  {
    "id": 26960,
    "content": ", cusolverDn[DD,ZZ]gesv for the FP64 case)"
  },
  {
    "id": 26964,
    "content": "Pointer to an allocated workspace in device memory of size lwork_bytes"
  },
  {
    "id": 26970,
    "content": "g"
  },
  {
    "id": 26971,
    "content": ", the residual norms) at each iteration and the number of iterations needed to converge"
  },
  {
    "id": 26974,
    "content": "More details about the error can be found by checking the niters and the dinfo API parameters"
  },
  {
    "id": 26976,
    "content": "get the size of the required workspace"
  },
  {
    "id": 26979,
    "content": "g"
  },
  {
    "id": 26983,
    "content": "input Number of rows and columns of the square matrix A"
  },
  {
    "id": 26988,
    "content": "gesv_irs_infos structure otherwise, it will be overwritten"
  },
  {
    "id": 26991,
    "content": "dWorkspace device input Pointer to an allocated workspace in device memory of size lwork_bytes"
  },
  {
    "id": 26994,
    "content": "CUSOLVER_STATUS_IRS_INFOS_NOT_INITIALIZED The information structure gesv_irs_infos was not created"
  },
  {
    "id": 26996,
    "content": "2"
  },
  {
    "id": 26997,
    "content": "4"
  },
  {
    "id": 26998,
    "content": "2"
  },
  {
    "id": 26999,
    "content": "12"
  },
  {
    "id": 27000,
    "content": "cusolverDngeqrf()  These helper functions calculate the size of work buffers needed"
  },
  {
    "id": 27005,
    "content": "The input parameter Lwork is size of the working space, and it is returned by geqrf_bufferSize()"
  },
  {
    "id": 27011,
    "content": "\\(A \\times X = B\\) Where A is m-by-n matrix and X is n-by-nrhs and B is m-by-nrhs matrices"
  },
  {
    "id": 27013,
    "content": "g"
  },
  {
    "id": 27017,
    "content": "0 respectively"
  },
  {
    "id": 27018,
    "content": "The amount of bytes required can be queried by calling the respective function gels_bufferSize()"
  },
  {
    "id": 27020,
    "content": "g"
  },
  {
    "id": 27021,
    "content": ", main and lowest precision are equal is equal to )"
  },
  {
    "id": 27024,
    "content": "e"
  },
  {
    "id": 27025,
    "content": ", cusolverDn[DD,ZZ]gels for the FP64 case)"
  },
  {
    "id": 27031,
    "content": "g"
  },
  {
    "id": 27032,
    "content": ", the residual norms) at each iteration and the number of iterations needed to converge"
  },
  {
    "id": 27035,
    "content": "get the size of the required workspace"
  },
  {
    "id": 27037,
    "content": "Data Type (e"
  },
  {
    "id": 27038,
    "content": "g"
  },
  {
    "id": 27042,
    "content": "params host input Xgels configuration parameters m host input Number of rows of the matrix A"
  },
  {
    "id": 27043,
    "content": "CUSOLVER_STATUS_IRS_INFOS_NOT_INITIALIZED The information structure gels_irs_infos was not created"
  },
  {
    "id": 27044,
    "content": "2"
  },
  {
    "id": 27045,
    "content": "4"
  },
  {
    "id": 27046,
    "content": "2"
  },
  {
    "id": 27047,
    "content": "16"
  },
  {
    "id": 27048,
    "content": "cusolverDnormqr()  These helper functions calculate the size of work buffers needed"
  },
  {
    "id": 27054,
    "content": "trans host input Operation op(Q) that is non- or (conj ) m host input Number of rows of matrix C"
  },
  {
    "id": 27055,
    "content": "if side is CUBLAS_SIDE_LEFT , lda >= max(1,m); if side is CUBLAS_SIDE_RIGHT , lda >= max(1,n)"
  },
  {
    "id": 27056,
    "content": "The vector tau is from geqrf , so tau(i) is the scalar of i-th elementary reflection vector"
  },
  {
    "id": 27062,
    "content": "function overwrites m×n matrix A by \\(Q = {H(1)}*{H(2)}*{"
  },
  {
    "id": 27064,
    "content": "The input parameter lwork is size of the working space, and it is returned by orgqr_bufferSize()"
  },
  {
    "id": 27066,
    "content": "m >= n >= 0; k host input Number of elementary reflections whose product defines the matrix Q"
  },
  {
    "id": 27067,
    "content": "n >= k >= 0; A device in/out array of dimension lda * n with lda is not less than max(1,m)"
  },
  {
    "id": 27082,
    "content": "workspace"
  },
  {
    "id": 27086,
    "content": "ldb host input Leading dimension of two-dimensional array used to store each matrix Barray[i]"
  },
  {
    "id": 27092,
    "content": "The off-diagonal elements of the bidiagonal matrix B : if m>=n , E(i) = A(i,i+1) for i = 1,2,"
  },
  {
    "id": 27093,
    "content": ",n-1 ; if m array of dimension min(m,n)"
  },
  {
    "id": 27098,
    "content": "The input parameter lwork is size of the working space, and it is returned by orgbr_bufferSize()"
  },
  {
    "id": 27108,
    "content": "The input parameter lwork is size of the working space, and it is returned by sytrd_bufferSize()"
  },
  {
    "id": 27137,
    "content": "The input parameter lwork is size of the working space, and it is returned by gesvd_bufferSize()"
  },
  {
    "id": 27153,
    "content": "The parallelism of Jacobi method gives GPU better performance on small and medium size matrices"
  },
  {
    "id": 27159,
    "content": "Jacobi method has quadratic convergence, so the accuracy is not proportional to number of sweeps"
  },
  {
    "id": 27162,
    "content": "params host input Structure filled with parameters of Jacobi algorithm and results of gesvdj"
  },
  {
    "id": 27172,
    "content": "sweeps by function cusolverDnXgesvdjGetResidual and cusolverDnXgesvdjGetSweeps"
  },
  {
    "id": 27187,
    "content": "e"
  },
  {
    "id": 27196,
    "content": "The input parameter lwork is size of the working space, and it is returned by syevd_bufferSize()"
  },
  {
    "id": 27198,
    "content": "If jobz = CUSOLVER_EIG_MODE_VECTOR, A contains the orthonormal eigenvectors of the matrix A"
  },
  {
    "id": 27202,
    "content": "The eigenvalue values of A , in ascending order ie, sorted so that W(i) array of size lwork"
  },
  {
    "id": 27211,
    "content": "g"
  },
  {
    "id": 27212,
    "content": ", range = CUSOLVER_EIG_RANGE_ALL ) is requested"
  },
  {
    "id": 27213,
    "content": "The input parameter lwork is size of the working space, and it is returned by syevdx_bufferSize()"
  },
  {
    "id": 27227,
    "content": "(Hermitian) n×n matrix-pair ( A , B )"
  },
  {
    "id": 27229,
    "content": "\\) where the matrix B is positive definite"
  },
  {
    "id": 27232,
    "content": "If devInfo = i (i > 0 and i 0), then the leading minor of order i of B is not positive definite"
  },
  {
    "id": 27243,
    "content": "matrix-pair ( A , B )"
  },
  {
    "id": 27244,
    "content": "The input parameter lwork is size of the working space, and it is returned by sygvdx_bufferSize()"
  },
  {
    "id": 27245,
    "content": "If jobz = CUSOLVER_EIG_MODE_VECTOR, A contains the orthogonal eigenvectors of the matrix A"
  },
  {
    "id": 27256,
    "content": "How does it work"
  },
  {
    "id": 27261,
    "content": "e"
  },
  {
    "id": 27265,
    "content": "params host in/out Structure filled with parameters of Jacobi algorithm and results of syevj"
  },
  {
    "id": 27288,
    "content": "If jobz = CUSOLVER_EIG_MODE_VECTOR, \\(A_{j}\\) contains the orthonormal eigenvectors \\(V_{j}\\)"
  },
  {
    "id": 27296,
    "content": "CUSOLVER_STATUS_SUCCESS The operation completed successfully"
  },
  {
    "id": 27297,
    "content": "CUSOLVER_STATUS_INVALID_VALUE Invalid parameters were passed ( n= k scenario is supported"
  },
  {
    "id": 27300,
    "content": "is lower triangular"
  },
  {
    "id": 27305,
    "content": "CUSOLVER_STATUS_INTERNAL_ERROR An internal operation failed"
  },
  {
    "id": 27306,
    "content": "2"
  },
  {
    "id": 27307,
    "content": "4"
  },
  {
    "id": 27308,
    "content": "5"
  },
  {
    "id": 27310,
    "content": "2"
  },
  {
    "id": 27311,
    "content": "4"
  },
  {
    "id": 27312,
    "content": "5"
  },
  {
    "id": 27313,
    "content": "1"
  },
  {
    "id": 27327,
    "content": "‘N’: no rows of V (no right singular vectors) are computed"
  },
  {
    "id": 27337,
    "content": "nonzero, csrlsvlu does \\(P*A*Q^{T} = L*U\\) where \\(Q = {symrcm}(A + A^{T})\\)"
  },
  {
    "id": 27338,
    "content": "If A is singular under given tolerance ( max(tol,0) ), then some diagonal elements of U is zero, i"
  },
  {
    "id": 27339,
    "content": "e"
  },
  {
    "id": 27344,
    "content": "e"
  },
  {
    "id": 27360,
    "content": "solved by sparse QR factorization with column pivoting, \\(A*P^{T} = Q*R\\) If A is of full rank (i"
  },
  {
    "id": 27361,
    "content": "e"
  },
  {
    "id": 27363,
    "content": "e"
  },
  {
    "id": 27364,
    "content": "The absolute value of every entry in \\(R_{22}\\) is less than or equal to tolerance=max(tol,0)"
  },
  {
    "id": 27365,
    "content": "Suppose \\(y = P*x\\) and \\(c = Q^{H}*b\\) , the least square problem can be reformed by \\(\\left"
  },
  {
    "id": 27366,
    "content": "\\min||A*x - b|| = \\min||R*y - c  ight"
  },
  {
    "id": 27368,
    "content": "\\min||y  ight"
  },
  {
    "id": 27371,
    "content": "Also, the supported index bases are CUSPARSE_INDEX_BASE_ZERO and CUSPARSE_INDEX_BASE_ONE"
  },
  {
    "id": 27373,
    "content": "Output Parameter cusolverSp MemSpace *Host MemSpace Description rankA host host Numerical rank of A"
  },
  {
    "id": 27374,
    "content": "p device host A vector of size n , which represents the permutation matrix P satisfying A*P^T=Q*R"
  },
  {
    "id": 27379,
    "content": "storage format by the three arrays csrValA , csrRowPtrA , and csrColIndA"
  },
  {
    "id": 27389,
    "content": "All matrices are aggregated one after another"
  },
  {
    "id": 27391,
    "content": "All vectors are aggregated one after another"
  },
  {
    "id": 27394,
    "content": "internalDataInBytes host Number of bytes of the internal data"
  },
  {
    "id": 27395,
    "content": "boost host output The value which is substituted for zero pivot (if the later is flagged)"
  },
  {
    "id": 27396,
    "content": "2"
  },
  {
    "id": 27397,
    "content": "6"
  },
  {
    "id": 27398,
    "content": "11"
  },
  {
    "id": 27400,
    "content": "2"
  },
  {
    "id": 27401,
    "content": "6"
  },
  {
    "id": 27402,
    "content": "12"
  },
  {
    "id": 27404,
    "content": "2"
  },
  {
    "id": 27405,
    "content": "6"
  },
  {
    "id": 27406,
    "content": "13"
  },
  {
    "id": 27408,
    "content": "alg host output The enumerated algorithm type"
  },
  {
    "id": 27409,
    "content": "2"
  },
  {
    "id": 27410,
    "content": "6"
  },
  {
    "id": 27411,
    "content": "14"
  },
  {
    "id": 27416,
    "content": "CUSOLVER_STATUS_ZERO_PIVOT A zero pivot was encountered during the computation"
  },
  {
    "id": 27417,
    "content": "2"
  },
  {
    "id": 27418,
    "content": "6"
  },
  {
    "id": 27419,
    "content": "15"
  },
  {
    "id": 27421,
    "content": "have not changed since the last call to the cusolverRfSetup[Host|Device] routine"
  },
  {
    "id": 27424,
    "content": "non-zero elements in the matrix"
  },
  {
    "id": 27425,
    "content": "CUSOLVER_STATUS_INVALID_VALUE An unsupported value or parameter was passed"
  },
  {
    "id": 27426,
    "content": "2"
  },
  {
    "id": 27427,
    "content": "6"
  },
  {
    "id": 27428,
    "content": "16"
  },
  {
    "id": 27430,
    "content": "once prior to cusolverRfSetupDevice() and cusolverRfSetupHost() routines"
  },
  {
    "id": 27431,
    "content": "CUSOLVER_STATUS_INVALID_VALUE An enumerated mode parameter is wrong"
  },
  {
    "id": 27432,
    "content": "2"
  },
  {
    "id": 27433,
    "content": "6"
  },
  {
    "id": 27434,
    "content": "17"
  },
  {
    "id": 27436,
    "content": "input The value which is substituted for zero pivot (if the later is flagged)"
  },
  {
    "id": 27437,
    "content": "2"
  },
  {
    "id": 27438,
    "content": "6"
  },
  {
    "id": 27439,
    "content": "18"
  },
  {
    "id": 27442,
    "content": "fastMode host input The enumerated mode type"
  },
  {
    "id": 27443,
    "content": "2"
  },
  {
    "id": 27444,
    "content": "6"
  },
  {
    "id": 27445,
    "content": "19"
  },
  {
    "id": 27447,
    "content": "2"
  },
  {
    "id": 27448,
    "content": "6"
  },
  {
    "id": 27449,
    "content": "20"
  },
  {
    "id": 27455,
    "content": "2"
  },
  {
    "id": 27456,
    "content": "6"
  },
  {
    "id": 27457,
    "content": "21"
  },
  {
    "id": 27463,
    "content": "Remark 2: to get best performance, batchSize should be multiple of 32 and greater or equal to 32"
  },
  {
    "id": 27465,
    "content": "batchSize host input The number of matrices in the batched mode"
  },
  {
    "id": 27469,
    "content": "array of values corresponding to the non-zero elements in the matrix U"
  },
  {
    "id": 27470,
    "content": "CUSOLVER_STATUS_ALLOC_FAILED An allocation of memory failed"
  },
  {
    "id": 27471,
    "content": "2"
  },
  {
    "id": 27472,
    "content": "6"
  },
  {
    "id": 27473,
    "content": "22"
  },
  {
    "id": 27478,
    "content": "2"
  },
  {
    "id": 27479,
    "content": "6"
  },
  {
    "id": 27480,
    "content": "23"
  },
  {
    "id": 27485,
    "content": "2"
  },
  {
    "id": 27486,
    "content": "6"
  },
  {
    "id": 27487,
    "content": "24"
  },
  {
    "id": 27490,
    "content": "The user has to call cusolverRfBatchZeroPivot() to know which matrix failed the LU refactorization"
  },
  {
    "id": 27491,
    "content": "Parameter Memory In/out Meaning handle host in/out The handle to the cuSolverRF library"
  },
  {
    "id": 27492,
    "content": "2"
  },
  {
    "id": 27493,
    "content": "6"
  },
  {
    "id": 27494,
    "content": "25"
  },
  {
    "id": 27498,
    "content": "Parameter MemSpace In/out Meaning handle host output The handle to the cuSolverRF library"
  },
  {
    "id": 27500,
    "content": "2"
  },
  {
    "id": 27501,
    "content": "6"
  },
  {
    "id": 27502,
    "content": "26"
  },
  {
    "id": 27506,
    "content": "3"
  },
  {
    "id": 27507,
    "content": "Using the CUSOLVERMG API  3"
  },
  {
    "id": 27508,
    "content": "1"
  },
  {
    "id": 27510,
    "content": "3"
  },
  {
    "id": 27511,
    "content": "1"
  },
  {
    "id": 27512,
    "content": "1"
  },
  {
    "id": 27513,
    "content": "Thread Safety  The library is thread-safe only if there is one cuSolverMG context per thread"
  },
  {
    "id": 27514,
    "content": "3"
  },
  {
    "id": 27515,
    "content": "1"
  },
  {
    "id": 27516,
    "content": "2"
  },
  {
    "id": 27518,
    "content": "3"
  },
  {
    "id": 27519,
    "content": "1"
  },
  {
    "id": 27520,
    "content": "3"
  },
  {
    "id": 27521,
    "content": "Tile Strategy  The tiling strategy of cuSolverMG is compatible with ScaLAPACK"
  },
  {
    "id": 27523,
    "content": "e"
  },
  {
    "id": 27532,
    "content": "3"
  },
  {
    "id": 27533,
    "content": "1"
  },
  {
    "id": 27534,
    "content": "4"
  },
  {
    "id": 27539,
    "content": "functionality The size is number of elements, not number of bytes"
  },
  {
    "id": 27540,
    "content": "3"
  },
  {
    "id": 27541,
    "content": "1"
  },
  {
    "id": 27542,
    "content": "6"
  },
  {
    "id": 27543,
    "content": "Synchronization  All routines are in synchronous (blocking call) manner"
  },
  {
    "id": 27545,
    "content": "3"
  },
  {
    "id": 27546,
    "content": "1"
  },
  {
    "id": 27547,
    "content": "7"
  },
  {
    "id": 27549,
    "content": "All routines set the device back to what the caller has"
  },
  {
    "id": 27550,
    "content": "3"
  },
  {
    "id": 27551,
    "content": "1"
  },
  {
    "id": 27552,
    "content": "8"
  },
  {
    "id": 27554,
    "content": "The example code H"
  },
  {
    "id": 27555,
    "content": "1 shows how to enable peer-to-peer communication"
  },
  {
    "id": 27556,
    "content": "3"
  },
  {
    "id": 27557,
    "content": "2"
  },
  {
    "id": 27558,
    "content": "cuSolverMG Types Reference  3"
  },
  {
    "id": 27559,
    "content": "2"
  },
  {
    "id": 27560,
    "content": "1"
  },
  {
    "id": 27562,
    "content": "3"
  },
  {
    "id": 27563,
    "content": "2"
  },
  {
    "id": 27564,
    "content": "2"
  },
  {
    "id": 27567,
    "content": "3"
  },
  {
    "id": 27568,
    "content": "2"
  },
  {
    "id": 27569,
    "content": "3"
  },
  {
    "id": 27570,
    "content": "cusolverMgGridMapping_t  The type indicates layout of grids"
  },
  {
    "id": 27571,
    "content": "CUDALIBMG_GRID_MAPPING_COL_MAJOR Column-major ordering"
  },
  {
    "id": 27572,
    "content": "3"
  },
  {
    "id": 27573,
    "content": "2"
  },
  {
    "id": 27574,
    "content": "4"
  },
  {
    "id": 27575,
    "content": "cudaLibMgGrid_t  Opaque structure of the distributed grid"
  },
  {
    "id": 27577,
    "content": "Status Returned CUSOLVER_STATUS_SUCCESS The initialization succeeded"
  },
  {
    "id": 27578,
    "content": "3"
  },
  {
    "id": 27579,
    "content": "3"
  },
  {
    "id": 27580,
    "content": "2"
  },
  {
    "id": 27582,
    "content": "Status Returned CUSOLVER_STATUS_SUCCESS The shutdown succeeded"
  },
  {
    "id": 27583,
    "content": "3"
  },
  {
    "id": 27584,
    "content": "3"
  },
  {
    "id": 27585,
    "content": "3"
  },
  {
    "id": 27587,
    "content": "CUSOLVER_STATUS_INVALID_VALUE nbDevices must be greater than zero, and less or equal to 32"
  },
  {
    "id": 27588,
    "content": "CUSOLVER_STATUS_INTERNAL_ERROR Internal error occurred when setting internal streams and events"
  },
  {
    "id": 27589,
    "content": "3"
  },
  {
    "id": 27590,
    "content": "3"
  },
  {
    "id": 27591,
    "content": "4"
  },
  {
    "id": 27593,
    "content": "e"
  },
  {
    "id": 27594,
    "content": "numRowDevices is not 1"
  },
  {
    "id": 27595,
    "content": "3"
  },
  {
    "id": 27596,
    "content": "3"
  },
  {
    "id": 27597,
    "content": "5"
  },
  {
    "id": 27599,
    "content": "Parameter MemSpace In/out Meaning grid host input/output The pointer to the opaque structure"
  },
  {
    "id": 27600,
    "content": "3"
  },
  {
    "id": 27601,
    "content": "3"
  },
  {
    "id": 27602,
    "content": "6"
  },
  {
    "id": 27604,
    "content": "is not equal to rowBlockSize"
  },
  {
    "id": 27605,
    "content": "3"
  },
  {
    "id": 27606,
    "content": "3"
  },
  {
    "id": 27607,
    "content": "7"
  },
  {
    "id": 27609,
    "content": "3"
  },
  {
    "id": 27610,
    "content": "4"
  },
  {
    "id": 27611,
    "content": "Dense Linear Solver Reference  This section describes the linear solver API of cuSolverMG"
  },
  {
    "id": 27612,
    "content": "3"
  },
  {
    "id": 27613,
    "content": "4"
  },
  {
    "id": 27614,
    "content": "1"
  },
  {
    "id": 27619,
    "content": "The output parameter info would indicate smallest leading minor of A which is not positive definite"
  },
  {
    "id": 27627,
    "content": "4"
  },
  {
    "id": 27629,
    "content": "2"
  },
  {
    "id": 27630,
    "content": "1 ( http: www"
  },
  {
    "id": 27631,
    "content": "netlib"
  },
  {
    "id": 27632,
    "content": "org/clapack/ ) The following is license of CLAPACK-3"
  },
  {
    "id": 27633,
    "content": "2"
  },
  {
    "id": 27634,
    "content": "1"
  },
  {
    "id": 27636,
    "content": "listed in this license in the documentation and/or other materials provided with the distribution"
  },
  {
    "id": 27640,
    "content": "METIS-5"
  },
  {
    "id": 27641,
    "content": "1"
  },
  {
    "id": 27642,
    "content": "0 ( http: glaros"
  },
  {
    "id": 27643,
    "content": "dtc"
  },
  {
    "id": 27644,
    "content": "umn"
  },
  {
    "id": 27647,
    "content": "QD (A C++/fortran-90 double-double and quad-double package) ( http: crd-legacy"
  },
  {
    "id": 27648,
    "content": "lbl"
  },
  {
    "id": 27649,
    "content": "gov/~dhbailey/mpdist/ ) The following is license of QD (modified BSD license)"
  },
  {
    "id": 27651,
    "content": "S"
  },
  {
    "id": 27653,
    "content": "documentation and/or other materials provided with the distribution"
  },
  {
    "id": 27654,
    "content": "Neither the name of the University of California, Lawrence Berkeley National Laboratory, U"
  },
  {
    "id": 27655,
    "content": "S"
  },
  {
    "id": 27659,
    "content": "5"
  },
  {
    "id": 27660,
    "content": "Bibliography  [1] Timothy A"
  },
  {
    "id": 27663,
    "content": "Comput"
  },
  {
    "id": 27664,
    "content": ", 9 (1988), pp"
  },
  {
    "id": 27665,
    "content": "862-874"
  },
  {
    "id": 27667,
    "content": "Peyton, Computing Row and Column Counts for Sparse QR and LU Factorization, BIT 2001, Vol"
  },
  {
    "id": 27671,
    "content": "973-996 [13] “A Fast and Highly Quality Multilevel Scheme for Partitioning Irregular Graphs”"
  },
  {
    "id": 27672,
    "content": "1, pp"
  },
  {
    "id": 27673,
    "content": "359-392, 1999"
  },
  {
    "id": 27676,
    "content": "” SIAM review 53"
  },
  {
    "id": 27677,
    "content": "2 (2011): 217-288"
  },
  {
    "id": 27678,
    "content": "6"
  },
  {
    "id": 27679,
    "content": "Notices  6"
  },
  {
    "id": 27680,
    "content": "1"
  },
  {
    "id": 27683,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 27695,
    "content": "6"
  },
  {
    "id": 27696,
    "content": "2"
  },
  {
    "id": 27697,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 27698,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 27699,
    "content": "6"
  },
  {
    "id": 27700,
    "content": "3"
  },
  {
    "id": 27702,
    "content": "S"
  },
  {
    "id": 27705,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 27706,
    "content": "Navigation"
  },
  {
    "id": 27707,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 27708,
    "content": "pageBottom();}\n1"
  },
  {
    "id": 27712,
    "content": "tools which make it complicated to distribute applications that use runtime compilation"
  },
  {
    "id": 27714,
    "content": "2"
  },
  {
    "id": 27715,
    "content": "Getting Started  2"
  },
  {
    "id": 27716,
    "content": "1"
  },
  {
    "id": 27718,
    "content": "CUDA Toolkit and Driver"
  },
  {
    "id": 27719,
    "content": "2"
  },
  {
    "id": 27720,
    "content": "2"
  },
  {
    "id": 27723,
    "content": "h lib64/libnvrtc so lib64/libnvrtc so"
  },
  {
    "id": 27724,
    "content": "Major Release Version Minor Release Version lib64/libnvrtc"
  },
  {
    "id": 27725,
    "content": "so"
  },
  {
    "id": 27726,
    "content": "Major Release Version Minor Release Version"
  },
  {
    "id": 27727,
    "content": "lib64/libnvrtc-builtins so lib64/libnvrtc-builtins so"
  },
  {
    "id": 27728,
    "content": "Major Release Version Minor Release Version lib64/libnvrtc-builtins"
  },
  {
    "id": 27729,
    "content": "so"
  },
  {
    "id": 27730,
    "content": "Major Release Version Minor Release Version"
  },
  {
    "id": 27731,
    "content": "Error Handling General Information Query Compilation Supported Compile Options Host Helper 3"
  },
  {
    "id": 27732,
    "content": "1"
  },
  {
    "id": 27735,
    "content": "g"
  },
  {
    "id": 27736,
    "content": ", NVRTC_SUCCESS to \"NVRTC_SUCCESS\""
  },
  {
    "id": 27737,
    "content": "3"
  },
  {
    "id": 27738,
    "content": "1"
  },
  {
    "id": 27739,
    "content": "1"
  },
  {
    "id": 27740,
    "content": "Enumerations  enum nvrtcResult  The enumerated type nvrtcResult defines API call result codes"
  },
  {
    "id": 27743,
    "content": "1"
  },
  {
    "id": 27744,
    "content": "2"
  },
  {
    "id": 27746,
    "content": "g"
  },
  {
    "id": 27747,
    "content": ", NVRTC_SUCCESS to \"NVRTC_SUCCESS\""
  },
  {
    "id": 27748,
    "content": "Returns Message string for the given nvrtcResult code"
  },
  {
    "id": 27749,
    "content": "3"
  },
  {
    "id": 27750,
    "content": "2"
  },
  {
    "id": 27751,
    "content": "General Information Query  NVRTC defines the following function for general information query"
  },
  {
    "id": 27754,
    "content": "3"
  },
  {
    "id": 27755,
    "content": "2"
  },
  {
    "id": 27756,
    "content": "1"
  },
  {
    "id": 27768,
    "content": "Typedefs nvrtcProgram nvrtcProgram is the unit of compilation, and an opaque handle for a program"
  },
  {
    "id": 27769,
    "content": "3"
  },
  {
    "id": 27770,
    "content": "3"
  },
  {
    "id": 27771,
    "content": "1"
  },
  {
    "id": 27777,
    "content": "the output parameter prog with it"
  },
  {
    "id": 27778,
    "content": "includeNames – [in] Name of each header by which they can be included in the CUDA program source"
  },
  {
    "id": 27780,
    "content": "by the previous compilation of prog in the memory pointed by cubin"
  },
  {
    "id": 27785,
    "content": "global function or device /__constant__ variable, and updates *lowered_name to point to it"
  },
  {
    "id": 27795,
    "content": "3"
  },
  {
    "id": 27796,
    "content": "4"
  },
  {
    "id": 27797,
    "content": "Supported Compile Options  NVRTC supports the compile options below"
  },
  {
    "id": 27799,
    "content": "g"
  },
  {
    "id": 27800,
    "content": ", \"--gpu-architecture=compute_60\""
  },
  {
    "id": 27802,
    "content": "e"
  },
  {
    "id": 27803,
    "content": "g, \"--gpu-architecture\" \"compute_60\""
  },
  {
    "id": 27819,
    "content": "idx instruction) will be used to implement a switch statement"
  },
  {
    "id": 27832,
    "content": "--minimal ( -minimal ) Omit certain language features to reduce compile time for small programs"
  },
  {
    "id": 27833,
    "content": "In particular, the following are omitted: Texture and surface functions and associated types, e"
  },
  {
    "id": 27834,
    "content": "g"
  },
  {
    "id": 27835,
    "content": ", cudaTextureObject_t"
  },
  {
    "id": 27837,
    "content": "g"
  },
  {
    "id": 27838,
    "content": ", cudaMalloc"
  },
  {
    "id": 27840,
    "content": "h, typically named with prefix “cuda”, e"
  },
  {
    "id": 27841,
    "content": "g"
  },
  {
    "id": 27842,
    "content": ", cudaError_t"
  },
  {
    "id": 27843,
    "content": "3"
  },
  {
    "id": 27844,
    "content": "5"
  },
  {
    "id": 27845,
    "content": "Host Helper  NVRTC defines the following functions for easier interaction with host code"
  },
  {
    "id": 27847,
    "content": "3"
  },
  {
    "id": 27848,
    "content": "5"
  },
  {
    "id": 27849,
    "content": "1"
  },
  {
    "id": 27851,
    "content": "This function is only provided when the macro NVRTC_GET_TYPE_NAME is defined with a non-zero value"
  },
  {
    "id": 27853,
    "content": "exe compilers, respectively"
  },
  {
    "id": 27857,
    "content": "Language  Unlike the offline nvcc compiler, NVRTC is meant for compiling only device CUDA C++ code"
  },
  {
    "id": 27858,
    "content": "It does not accept host code or host compiler extensions in the input code, unless otherwise noted"
  },
  {
    "id": 27859,
    "content": "4"
  },
  {
    "id": 27860,
    "content": "1"
  },
  {
    "id": 27863,
    "content": "4"
  },
  {
    "id": 27864,
    "content": "2"
  },
  {
    "id": 27865,
    "content": "Separate Compilation  NVRTC itself does not provide any linker"
  },
  {
    "id": 27867,
    "content": "4"
  },
  {
    "id": 27868,
    "content": "3"
  },
  {
    "id": 27871,
    "content": "Example: Dynamic Parallelism provides a simple example"
  },
  {
    "id": 27872,
    "content": "4"
  },
  {
    "id": 27873,
    "content": "4"
  },
  {
    "id": 27874,
    "content": "Integer Size  Different operating systems define integer type sizes differently"
  },
  {
    "id": 27876,
    "content": "128-bit integer support is not available on Windows"
  },
  {
    "id": 27877,
    "content": "4"
  },
  {
    "id": 27878,
    "content": "5"
  },
  {
    "id": 27880,
    "content": "h\" ), before the code is compiled"
  },
  {
    "id": 27881,
    "content": "4"
  },
  {
    "id": 27882,
    "content": "6"
  },
  {
    "id": 27886,
    "content": "va_start va_end va_arg va_copy : defined when language dialect C++11 or later is selected"
  },
  {
    "id": 27887,
    "content": "__CUDACC_RTC_MINIMAL__ : defined when -minimal flag is specified during compilation (since CUDA 12"
  },
  {
    "id": 27888,
    "content": "4)"
  },
  {
    "id": 27889,
    "content": "Macros defined in nv/target header are implicitly provided, e"
  },
  {
    "id": 27890,
    "content": "g"
  },
  {
    "id": 27891,
    "content": ", NV_IF_TARGET"
  },
  {
    "id": 27892,
    "content": "4"
  },
  {
    "id": 27893,
    "content": "7"
  },
  {
    "id": 27896,
    "content": "4"
  },
  {
    "id": 27897,
    "content": "8"
  },
  {
    "id": 27899,
    "content": "Other dialects can be selected using the -std flag"
  },
  {
    "id": 27900,
    "content": "5"
  },
  {
    "id": 27902,
    "content": "x * blockDim"
  },
  {
    "id": 27903,
    "content": "x + threadIdx"
  },
  {
    "id": 27904,
    "content": "x;   \\ if (tid and #include would require 2 as numHeaders , { \"\", \"\" } as headers, and { \"foo"
  },
  {
    "id": 27905,
    "content": "h\", \"bar"
  },
  {
    "id": 27906,
    "content": "h\" } as includeNames ( and must be replaced by the actual contents of foo"
  },
  {
    "id": 27907,
    "content": "h and bar"
  },
  {
    "id": 27908,
    "content": "h )"
  },
  {
    "id": 27915,
    "content": "can be further manipulated by the CUDA Driver API for execution or linking"
  },
  {
    "id": 27920,
    "content": "generated PTX (if the definition is available in the input source code)"
  },
  {
    "id": 27921,
    "content": "6"
  },
  {
    "id": 27922,
    "content": "1"
  },
  {
    "id": 27923,
    "content": "Example  Example: Using Lowered Name`_ lists a complete runnable example"
  },
  {
    "id": 27928,
    "content": "Windows: In CUDA toolkits prior to cuda 11"
  },
  {
    "id": 27930,
    "content": "NVRTC shared library in CUDA 11"
  },
  {
    "id": 27931,
    "content": "2"
  },
  {
    "id": 27935,
    "content": "8"
  },
  {
    "id": 27936,
    "content": "2"
  },
  {
    "id": 27938,
    "content": "9"
  },
  {
    "id": 27939,
    "content": "Miscellaneous Notes  9"
  },
  {
    "id": 27940,
    "content": "1"
  },
  {
    "id": 27942,
    "content": "Since CUDA 12"
  },
  {
    "id": 27944,
    "content": "Setting the environment variable NVRTC_DISABLE_CONCURRENT_NVVM disables this behavior, i"
  },
  {
    "id": 27945,
    "content": "e"
  },
  {
    "id": 27946,
    "content": ", invocations of the embedded NVVM optimizer/codegen phase will be serialized"
  },
  {
    "id": 27947,
    "content": "9"
  },
  {
    "id": 27948,
    "content": "2"
  },
  {
    "id": 27950,
    "content": "flag -modify-stack-limit=false will prevent NVRTC from modifying the stack limit"
  },
  {
    "id": 27951,
    "content": "9"
  },
  {
    "id": 27952,
    "content": "3"
  },
  {
    "id": 27954,
    "content": "Code (saxpy"
  },
  {
    "id": 27958,
    "content": "#define NVRTC_SAFE_CALL(x) \\ do { \\ nvrtcResult result = x; \\ if (result"
  },
  {
    "id": 27964,
    "content": "expected_result ; note the name expressions are parsed as constant expressions name_vec"
  },
  {
    "id": 27967,
    "content": "3"
  },
  {
    "id": 27969,
    "content": "cu to fatbinary containing LTO IR (change lto_52 to a different lto_XX architecture as appropriate)"
  },
  {
    "id": 27972,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 27984,
    "content": "14"
  },
  {
    "id": 27985,
    "content": "4"
  },
  {
    "id": 27986,
    "content": "2"
  },
  {
    "id": 27987,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 27988,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 27989,
    "content": "14"
  },
  {
    "id": 27990,
    "content": "4"
  },
  {
    "id": 27991,
    "content": "3"
  },
  {
    "id": 27993,
    "content": "S"
  },
  {
    "id": 27997,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 27998,
    "content": "Navigation"
  },
  {
    "id": 27999,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 28000,
    "content": "pageBottom();}\n1"
  },
  {
    "id": 28002,
    "content": "Supports direct input from memory, rather than requiring inputs be written to files"
  },
  {
    "id": 28003,
    "content": "2"
  },
  {
    "id": 28004,
    "content": "Getting Started  2"
  },
  {
    "id": 28005,
    "content": "1"
  },
  {
    "id": 28006,
    "content": "System Requirements  The Fatbin Creator library requires no special system configuration"
  },
  {
    "id": 28007,
    "content": "It does not require a GPU"
  },
  {
    "id": 28008,
    "content": "2"
  },
  {
    "id": 28009,
    "content": "2"
  },
  {
    "id": 28011,
    "content": "h lib64/libnvfatbin so lib64/libnvfatbin_static"
  },
  {
    "id": 28012,
    "content": "a doc/pdf/nvFatbin_User_Guide pdf 3"
  },
  {
    "id": 28014,
    "content": "3"
  },
  {
    "id": 28015,
    "content": "1"
  },
  {
    "id": 28016,
    "content": "1"
  },
  {
    "id": 28020,
    "content": "1"
  },
  {
    "id": 28021,
    "content": "2"
  },
  {
    "id": 28023,
    "content": "2"
  },
  {
    "id": 28028,
    "content": "fatbin creation, and an opaque handle for a program"
  },
  {
    "id": 28029,
    "content": "3"
  },
  {
    "id": 28030,
    "content": "2"
  },
  {
    "id": 28031,
    "content": "1"
  },
  {
    "id": 28033,
    "content": "identifier – [in] Name of the cubin, useful when extracting the fatbin with tools like cuobjdump"
  },
  {
    "id": 28035,
    "content": "nvFatbinAddIndex adds an index file to the fatbinary"
  },
  {
    "id": 28036,
    "content": "identifier – [in] Name of the index, useful when extracting the fatbin with tools like cuobjdump"
  },
  {
    "id": 28038,
    "content": "nvFatbinAddLTOIR adds LTOIR to the fatbinary"
  },
  {
    "id": 28039,
    "content": "identifier – [in] Name of the LTOIR, useful when extracting the fatbin with tools like cuobjdump"
  },
  {
    "id": 28041,
    "content": "optionsCmdLine )  nvFatbinAddPTX adds PTX to the fatbinary"
  },
  {
    "id": 28043,
    "content": "identifier – [in] Name of the PTX, useful when extracting the fatbin with tools like cuobjdump"
  },
  {
    "id": 28048,
    "content": "Use of any other pointers to the handle after calling this will result in undefined behavior"
  },
  {
    "id": 28052,
    "content": "3"
  },
  {
    "id": 28053,
    "content": "3"
  },
  {
    "id": 28055,
    "content": "g"
  },
  {
    "id": 28056,
    "content": "Didn’t do anything from the start"
  },
  {
    "id": 28057,
    "content": ") -compress= Enable (true) / disable (false) compression (default: true)"
  },
  {
    "id": 28058,
    "content": "-opencl Specify OpenCL (rather than CUDA)"
  },
  {
    "id": 28059,
    "content": "4"
  },
  {
    "id": 28065,
    "content": "8 and one with 12 4 if your nvFatbin library is at least version 12"
  },
  {
    "id": 28066,
    "content": "x"
  },
  {
    "id": 28067,
    "content": "6"
  },
  {
    "id": 28070,
    "content": "6"
  },
  {
    "id": 28071,
    "content": "1"
  },
  {
    "id": 28072,
    "content": "Code (online"
  },
  {
    "id": 28077,
    "content": "delete [] (( char * ) dynamic ); return 0 ; } 6"
  },
  {
    "id": 28078,
    "content": "2"
  },
  {
    "id": 28081,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 28093,
    "content": "6"
  },
  {
    "id": 28094,
    "content": "3"
  },
  {
    "id": 28095,
    "content": "2"
  },
  {
    "id": 28096,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 28097,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 28098,
    "content": "6"
  },
  {
    "id": 28099,
    "content": "3"
  },
  {
    "id": 28100,
    "content": "3"
  },
  {
    "id": 28102,
    "content": "S"
  },
  {
    "id": 28105,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 28106,
    "content": "Navigation"
  },
  {
    "id": 28107,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 28108,
    "content": "pageBottom();}\n1"
  },
  {
    "id": 28114,
    "content": "The clients get fine grain control and can specify low-level compiler options during linking"
  },
  {
    "id": 28115,
    "content": "2"
  },
  {
    "id": 28116,
    "content": "Getting Started  2"
  },
  {
    "id": 28117,
    "content": "1"
  },
  {
    "id": 28119,
    "content": "CUDA Toolkit and Driver"
  },
  {
    "id": 28120,
    "content": "2"
  },
  {
    "id": 28121,
    "content": "2"
  },
  {
    "id": 28123,
    "content": "h lib64/libnvJitLink so lib64/libnvJitLink_static"
  },
  {
    "id": 28124,
    "content": "a doc/pdf/nvJitLink_User_Guide pdf 3"
  },
  {
    "id": 28126,
    "content": "3"
  },
  {
    "id": 28127,
    "content": "1"
  },
  {
    "id": 28128,
    "content": "1"
  },
  {
    "id": 28131,
    "content": "2"
  },
  {
    "id": 28137,
    "content": "nvJitLinkGetLinkedPtxSize gets the size of the linked ptx"
  },
  {
    "id": 28139,
    "content": "Typedefs nvJitLinkHandle nvJitLinkHandle is the unit of linking, and an opaque handle for a program"
  },
  {
    "id": 28140,
    "content": "3"
  },
  {
    "id": 28141,
    "content": "2"
  },
  {
    "id": 28142,
    "content": "1"
  },
  {
    "id": 28145,
    "content": "2"
  },
  {
    "id": 28146,
    "content": "2"
  },
  {
    "id": 28156,
    "content": "an instance of nvJitLinkHandle must be created first with nvJitLinkCreate()"
  },
  {
    "id": 28157,
    "content": "3"
  },
  {
    "id": 28158,
    "content": "3"
  },
  {
    "id": 28159,
    "content": "Supported Link Options  nvJitLink supports the link options below"
  },
  {
    "id": 28161,
    "content": "g"
  },
  {
    "id": 28162,
    "content": "-ptx Emit ptx after linking instead of cubin; only supported with -lto -O Optimization level"
  },
  {
    "id": 28165,
    "content": "idx instruction) will be used to implement a switch statement"
  },
  {
    "id": 28166,
    "content": "-no-cache Don’t cache the intermediate steps of nvJitLink"
  },
  {
    "id": 28167,
    "content": "4"
  },
  {
    "id": 28170,
    "content": "o and b"
  },
  {
    "id": 28171,
    "content": "o), which could be created with the nvcc -dc command"
  },
  {
    "id": 28178,
    "content": "x where x >= 1"
  },
  {
    "id": 28180,
    "content": "x where x >= 1"
  },
  {
    "id": 28182,
    "content": "1 code"
  },
  {
    "id": 28183,
    "content": "Linking across major versions (like 11"
  },
  {
    "id": 28184,
    "content": "x with 12"
  },
  {
    "id": 28185,
    "content": "x) works for ELF and PTX inputs, but does not work with LTOIR inputs"
  },
  {
    "id": 28186,
    "content": "If using LTO, then compatibility is only guaranteed within a major release"
  },
  {
    "id": 28187,
    "content": "6"
  },
  {
    "id": 28190,
    "content": "cu)"
  },
  {
    "id": 28191,
    "content": "The second unit is generated online using NVRTC, by specifying the flag ‘ -dlto ’ (see online"
  },
  {
    "id": 28192,
    "content": "cpp)"
  },
  {
    "id": 28194,
    "content": "cpp)"
  },
  {
    "id": 28195,
    "content": "The cubin is then loaded on the GPU and executed"
  },
  {
    "id": 28196,
    "content": "6"
  },
  {
    "id": 28197,
    "content": "1"
  },
  {
    "id": 28198,
    "content": "Code (offline"
  },
  {
    "id": 28199,
    "content": "cu)  __device__ float compute ( float a , float x , float y ) { return a * x + y ; } 6"
  },
  {
    "id": 28200,
    "content": "2"
  },
  {
    "id": 28201,
    "content": "Code (online"
  },
  {
    "id": 28207,
    "content": "3"
  },
  {
    "id": 28209,
    "content": "cu to fatbinary containing LTO IR (change lto_52 to a different lto_XX architecture as appropriate)"
  },
  {
    "id": 28212,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 28224,
    "content": "6"
  },
  {
    "id": 28225,
    "content": "4"
  },
  {
    "id": 28226,
    "content": "2"
  },
  {
    "id": 28227,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 28228,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 28229,
    "content": "6"
  },
  {
    "id": 28230,
    "content": "4"
  },
  {
    "id": 28231,
    "content": "3"
  },
  {
    "id": 28233,
    "content": "S"
  },
  {
    "id": 28236,
    "content": "Introduction v12"
  },
  {
    "id": 28239,
    "content": "9%"
  },
  {
    "id": 28243,
    "content": "A replacement will be provided for the most important of them during the deprecation process"
  },
  {
    "id": 28247,
    "content": "1"
  },
  {
    "id": 28248,
    "content": "2"
  },
  {
    "id": 28250,
    "content": "a on Linux"
  },
  {
    "id": 28255,
    "content": "1"
  },
  {
    "id": 28256,
    "content": "3"
  },
  {
    "id": 28257,
    "content": "Library Dependencies  Starting with CUDA 12"
  },
  {
    "id": 28260,
    "content": "so is located"
  },
  {
    "id": 28262,
    "content": "2"
  },
  {
    "id": 28264,
    "content": "2"
  },
  {
    "id": 28265,
    "content": "1"
  },
  {
    "id": 28273,
    "content": "2"
  },
  {
    "id": 28274,
    "content": "2"
  },
  {
    "id": 28276,
    "content": "Y (e"
  },
  {
    "id": 28277,
    "content": "g"
  },
  {
    "id": 28278,
    "content": "11"
  },
  {
    "id": 28280,
    "content": "0 (e"
  },
  {
    "id": 28281,
    "content": "g"
  },
  {
    "id": 28282,
    "content": "12"
  },
  {
    "id": 28286,
    "content": "h or by passing the flag -DDISABLE_CUSPARSE_DEPRECATED to the compiler"
  },
  {
    "id": 28287,
    "content": "2"
  },
  {
    "id": 28288,
    "content": "3"
  },
  {
    "id": 28290,
    "content": "cuSPARSE handle"
  },
  {
    "id": 28291,
    "content": "2"
  },
  {
    "id": 28292,
    "content": "4"
  },
  {
    "id": 28296,
    "content": "2"
  },
  {
    "id": 28297,
    "content": "5"
  },
  {
    "id": 28300,
    "content": "2"
  },
  {
    "id": 28301,
    "content": "6"
  },
  {
    "id": 28305,
    "content": "2"
  },
  {
    "id": 28306,
    "content": "7"
  },
  {
    "id": 28308,
    "content": "h header file and shared library is not supported"
  },
  {
    "id": 28309,
    "content": "The library uses the standard version semantic convention for identify different releases"
  },
  {
    "id": 28310,
    "content": "The version takes the form of four fields joined by periods: MAJOR"
  },
  {
    "id": 28311,
    "content": "MINOR"
  },
  {
    "id": 28312,
    "content": "PATCH"
  },
  {
    "id": 28314,
    "content": "g"
  },
  {
    "id": 28316,
    "content": "2"
  },
  {
    "id": 28317,
    "content": "8"
  },
  {
    "id": 28319,
    "content": "This minimizes kernels launch overhead and allows the CUDA runtime to optimize the whole workflow"
  },
  {
    "id": 28322,
    "content": "0) or above"
  },
  {
    "id": 28324,
    "content": "3"
  },
  {
    "id": 28326,
    "content": "3"
  },
  {
    "id": 28327,
    "content": "1"
  },
  {
    "id": 28329,
    "content": "3"
  },
  {
    "id": 28330,
    "content": "2"
  },
  {
    "id": 28331,
    "content": "Vector Formats  This section describes dense and sparse vector formats"
  },
  {
    "id": 28332,
    "content": "3"
  },
  {
    "id": 28333,
    "content": "2"
  },
  {
    "id": 28334,
    "content": "1"
  },
  {
    "id": 28336,
    "content": "2"
  },
  {
    "id": 28337,
    "content": "1 can be stored as a sparse vector with zero-based or one-based indexing"
  },
  {
    "id": 28339,
    "content": "In the opposite case, the correctness of the computation is not always ensured"
  },
  {
    "id": 28340,
    "content": "3"
  },
  {
    "id": 28341,
    "content": "3"
  },
  {
    "id": 28342,
    "content": "Matrix Formats  Dense and several sparse formats for matrices are discussed in this section"
  },
  {
    "id": 28343,
    "content": "3"
  },
  {
    "id": 28344,
    "content": "3"
  },
  {
    "id": 28345,
    "content": "1"
  },
  {
    "id": 28348,
    "content": "representations  3"
  },
  {
    "id": 28349,
    "content": "3"
  },
  {
    "id": 28350,
    "content": "2"
  },
  {
    "id": 28351,
    "content": "Coordinate (COO)  A sparse matrix stored in COO format is represented by the following parameters"
  },
  {
    "id": 28354,
    "content": "3"
  },
  {
    "id": 28355,
    "content": "3"
  },
  {
    "id": 28358,
    "content": "3"
  },
  {
    "id": 28359,
    "content": "4"
  },
  {
    "id": 28363,
    "content": "3"
  },
  {
    "id": 28364,
    "content": "5"
  },
  {
    "id": 28368,
    "content": "The maximum row length (i"
  },
  {
    "id": 28369,
    "content": "e"
  },
  {
    "id": 28372,
    "content": "To improve memory coalescing and memory utilization, each slice is stored in column-major order"
  },
  {
    "id": 28373,
    "content": "The total number elements ( sellValuesSize ), including non-zero values and padded elements"
  },
  {
    "id": 28375,
    "content": "layout"
  },
  {
    "id": 28376,
    "content": "The following example shows a \\(5 \\times 4\\) matrix represented in SELL format"
  },
  {
    "id": 28377,
    "content": "3"
  },
  {
    "id": 28378,
    "content": "3"
  },
  {
    "id": 28379,
    "content": "6"
  },
  {
    "id": 28383,
    "content": "\\(4 \\times 7\\) matrix represented in BSR format"
  },
  {
    "id": 28384,
    "content": "3"
  },
  {
    "id": 28385,
    "content": "3"
  },
  {
    "id": 28386,
    "content": "7"
  },
  {
    "id": 28390,
    "content": "3"
  },
  {
    "id": 28391,
    "content": "3"
  },
  {
    "id": 28392,
    "content": "8"
  },
  {
    "id": 28402,
    "content": "h"
  },
  {
    "id": 28406,
    "content": "Starting from CUDA 12"
  },
  {
    "id": 28408,
    "content": "com for debugging and reproducibility purposes of a specific correctness/performance issue"
  },
  {
    "id": 28410,
    "content": "4"
  },
  {
    "id": 28411,
    "content": "3"
  },
  {
    "id": 28412,
    "content": "1"
  },
  {
    "id": 28415,
    "content": "3"
  },
  {
    "id": 28416,
    "content": "2"
  },
  {
    "id": 28418,
    "content": "3"
  },
  {
    "id": 28419,
    "content": "3"
  },
  {
    "id": 28421,
    "content": "3"
  },
  {
    "id": 28422,
    "content": "4"
  },
  {
    "id": 28424,
    "content": "3"
  },
  {
    "id": 28425,
    "content": "5"
  },
  {
    "id": 28429,
    "content": "5"
  },
  {
    "id": 28430,
    "content": "2"
  },
  {
    "id": 28431,
    "content": "cuSPARSE Legacy Types Reference  5"
  },
  {
    "id": 28432,
    "content": "2"
  },
  {
    "id": 28433,
    "content": "1"
  },
  {
    "id": 28435,
    "content": "5"
  },
  {
    "id": 28436,
    "content": "2"
  },
  {
    "id": 28437,
    "content": "2"
  },
  {
    "id": 28438,
    "content": "cusparseMatDescr_t  This structure is used to describe the shape and properties of a matrix"
  },
  {
    "id": 28440,
    "content": "2"
  },
  {
    "id": 28441,
    "content": "3"
  },
  {
    "id": 28443,
    "content": "steps are needed"
  },
  {
    "id": 28448,
    "content": "5"
  },
  {
    "id": 28449,
    "content": "2"
  },
  {
    "id": 28450,
    "content": "4"
  },
  {
    "id": 28452,
    "content": "5"
  },
  {
    "id": 28453,
    "content": "2"
  },
  {
    "id": 28454,
    "content": "5"
  },
  {
    "id": 28456,
    "content": "5"
  },
  {
    "id": 28457,
    "content": "2"
  },
  {
    "id": 28458,
    "content": "6"
  },
  {
    "id": 28460,
    "content": "5"
  },
  {
    "id": 28461,
    "content": "2"
  },
  {
    "id": 28462,
    "content": "7"
  },
  {
    "id": 28464,
    "content": "5"
  },
  {
    "id": 28465,
    "content": "2"
  },
  {
    "id": 28466,
    "content": "8"
  },
  {
    "id": 28468,
    "content": "5"
  },
  {
    "id": 28469,
    "content": "2"
  },
  {
    "id": 28470,
    "content": "9"
  },
  {
    "id": 28472,
    "content": "5"
  },
  {
    "id": 28473,
    "content": "2"
  },
  {
    "id": 28474,
    "content": "10"
  },
  {
    "id": 28476,
    "content": "5"
  },
  {
    "id": 28477,
    "content": "2"
  },
  {
    "id": 28478,
    "content": "11"
  },
  {
    "id": 28480,
    "content": "5"
  },
  {
    "id": 28481,
    "content": "3"
  },
  {
    "id": 28482,
    "content": "cuSPARSE Helper Function Reference  The cuSPARSE helper functions are described in this section"
  },
  {
    "id": 28483,
    "content": "5"
  },
  {
    "id": 28484,
    "content": "3"
  },
  {
    "id": 28485,
    "content": "1"
  },
  {
    "id": 28487,
    "content": "3"
  },
  {
    "id": 28488,
    "content": "2"
  },
  {
    "id": 28492,
    "content": "3"
  },
  {
    "id": 28493,
    "content": "4"
  },
  {
    "id": 28495,
    "content": "5"
  },
  {
    "id": 28496,
    "content": "3"
  },
  {
    "id": 28497,
    "content": "6"
  },
  {
    "id": 28499,
    "content": "5"
  },
  {
    "id": 28500,
    "content": "3"
  },
  {
    "id": 28501,
    "content": "7"
  },
  {
    "id": 28503,
    "content": "5"
  },
  {
    "id": 28504,
    "content": "3"
  },
  {
    "id": 28505,
    "content": "8"
  },
  {
    "id": 28507,
    "content": "Returned One of the enumerated matrix types"
  },
  {
    "id": 28508,
    "content": "5"
  },
  {
    "id": 28509,
    "content": "3"
  },
  {
    "id": 28510,
    "content": "9"
  },
  {
    "id": 28524,
    "content": "dir storage format of blocks, either CUSPARSE_DIRECTION_ROW or CUSPARSE_DIRECTION_COLUMN"
  },
  {
    "id": 28525,
    "content": "Also, the supported index bases are CUSPARSE_INDEX_BASE_ZERO and CUSPARSE_INDEX_BASE_ONE"
  },
  {
    "id": 28527,
    "content": "bsrMaskPtr , then bsrxmv() does not touch row block \\(i\\) of \\(A\\) and \\(y\\)"
  },
  {
    "id": 28529,
    "content": "{1\\phantom{"
  },
  {
    "id": 28534,
    "content": "&"
  },
  {
    "id": 28536,
    "content": "touched also \\(\\begin{matrix} \\text{bsrRowPtr} & = & \\begin{bmatrix} {"
  },
  {
    "id": 28537,
    "content": "\\phantom{"
  },
  {
    "id": 28538,
    "content": "0}} & 4 \\\\ \\end{bmatrix} \\\\ \\text{bsrEndPtr} & = & \\begin{bmatrix} {"
  },
  {
    "id": 28539,
    "content": "\\phantom{"
  },
  {
    "id": 28547,
    "content": "dirA storage format of blocks, either CUSPARSE_DIRECTION_ROW or CUSPARSE_DIRECTION_COLUMN"
  },
  {
    "id": 28560,
    "content": "This function may be executed multiple times for a given matrix and a particular operation type"
  },
  {
    "id": 28562,
    "content": "CUSPARSE_STATUS_INVALID_VALUE is returned"
  },
  {
    "id": 28563,
    "content": "The level information may not improve the performance, but may spend extra time doing analysis"
  },
  {
    "id": 28565,
    "content": "remaining iterations"
  },
  {
    "id": 28569,
    "content": "hand side vector on device memory"
  },
  {
    "id": 28573,
    "content": "handle ); Input handle handle to the cuSPARSE library context"
  },
  {
    "id": 28575,
    "content": "Output y solution vector of size m"
  },
  {
    "id": 28576,
    "content": "5"
  },
  {
    "id": 28577,
    "content": "4"
  },
  {
    "id": 28578,
    "content": "6"
  },
  {
    "id": 28581,
    "content": "zero, position is -1; otherwise if A(j,j) is missing or U(j,j) is zero, position=j"
  },
  {
    "id": 28585,
    "content": "5"
  },
  {
    "id": 28586,
    "content": "5"
  },
  {
    "id": 28597,
    "content": "B and X point to the same memory block, and ldb=ldx"
  },
  {
    "id": 28599,
    "content": "bsrValA array of nnzb \\(( =\\) bsrRowPtrA(mb) \\(-\\) bsrRowPtrA(0) \\()\\) non-zero blocks of matrix A"
  },
  {
    "id": 28600,
    "content": "Output X solution array with leading dimensions ldx"
  },
  {
    "id": 28601,
    "content": "5"
  },
  {
    "id": 28602,
    "content": "5"
  },
  {
    "id": 28603,
    "content": "5"
  },
  {
    "id": 28606,
    "content": "5"
  },
  {
    "id": 28607,
    "content": "6"
  },
  {
    "id": 28611,
    "content": "then finally calls function cusparse[S|D|C|Z]csrgeam2() to complete matrix C"
  },
  {
    "id": 28619,
    "content": "5"
  },
  {
    "id": 28620,
    "content": "7"
  },
  {
    "id": 28621,
    "content": "1"
  },
  {
    "id": 28626,
    "content": "The level information can extract more parallelism during incomplete Cholesky factorization"
  },
  {
    "id": 28637,
    "content": "5"
  },
  {
    "id": 28638,
    "content": "7"
  },
  {
    "id": 28639,
    "content": "1"
  },
  {
    "id": 28640,
    "content": "4"
  },
  {
    "id": 28642,
    "content": "zero or numerical zero if the user already called csric02_analysis() or csric02()"
  },
  {
    "id": 28644,
    "content": "which is either CUSPARSE_DIRECTION_COLUMN or CUSPARSE_DIRECTION_ROW"
  },
  {
    "id": 28649,
    "content": "part is provided"
  },
  {
    "id": 28655,
    "content": "5"
  },
  {
    "id": 28656,
    "content": "7"
  },
  {
    "id": 28657,
    "content": "1"
  },
  {
    "id": 28658,
    "content": "8"
  },
  {
    "id": 28661,
    "content": "5"
  },
  {
    "id": 28662,
    "content": "7"
  },
  {
    "id": 28663,
    "content": "2"
  },
  {
    "id": 28665,
    "content": "5"
  },
  {
    "id": 28666,
    "content": "7"
  },
  {
    "id": 28667,
    "content": "2"
  },
  {
    "id": 28668,
    "content": "1"
  },
  {
    "id": 28680,
    "content": "triangular factors"
  },
  {
    "id": 28681,
    "content": "5"
  },
  {
    "id": 28682,
    "content": "7"
  },
  {
    "id": 28683,
    "content": "2"
  },
  {
    "id": 28684,
    "content": "5"
  },
  {
    "id": 28691,
    "content": "pBufferSizeInBytes number of bytes of the buffer used in bsrilu02_analysis() and bsrilu02()"
  },
  {
    "id": 28703,
    "content": "dirA storage format of blocks: either CUSPARSE_DIRECTION_ROW or CUSPARSE_DIRECTION_COLUMN"
  },
  {
    "id": 28705,
    "content": "5"
  },
  {
    "id": 28706,
    "content": "7"
  },
  {
    "id": 28707,
    "content": "2"
  },
  {
    "id": 28708,
    "content": "10"
  },
  {
    "id": 28711,
    "content": "5"
  },
  {
    "id": 28712,
    "content": "7"
  },
  {
    "id": 28713,
    "content": "3"
  },
  {
    "id": 28714,
    "content": "Tridiagonal Solve  Different algorithms for tridiagonal solve are discussed in this section"
  },
  {
    "id": 28716,
    "content": "out-of-bound ( dl(1) := A(1,0) ), so dl(1) = 0"
  },
  {
    "id": 28719,
    "content": "pBuffer buffer allocated by the user, the size is return by gtsv2_nopivot_bufferSizeExt"
  },
  {
    "id": 28720,
    "content": "5"
  },
  {
    "id": 28721,
    "content": "7"
  },
  {
    "id": 28722,
    "content": "4"
  },
  {
    "id": 28726,
    "content": "pBuffer buffer allocated by the user, the size is return by gtsv2StridedBatch_bufferSizeExt"
  },
  {
    "id": 28727,
    "content": "The data layout is different from gtsvStridedBatch which aggregates all matrices one after another"
  },
  {
    "id": 28728,
    "content": "Instead, gtsvInterleavedBatch gathers different matrices of the same element in a continous manner"
  },
  {
    "id": 28730,
    "content": "pBuffer buffer allocated by the user, the size is return by gtsvInterleavedBatch_bufferSizeExt"
  },
  {
    "id": 28731,
    "content": "Output x dense solution array of dimensions (batchCount, n)"
  },
  {
    "id": 28732,
    "content": "5"
  },
  {
    "id": 28733,
    "content": "7"
  },
  {
    "id": 28734,
    "content": "5"
  },
  {
    "id": 28740,
    "content": "diagonal) of the penta-diagonal linear system"
  },
  {
    "id": 28741,
    "content": "pBuffer buffer allocated by the user, the size is return by gpsvInterleavedBatch_bufferSizeExt"
  },
  {
    "id": 28742,
    "content": "Please visit cuSPARSE Library Samples - cusparseSgpsvInterleavedBatch for a code example"
  },
  {
    "id": 28743,
    "content": "5"
  },
  {
    "id": 28744,
    "content": "8"
  },
  {
    "id": 28750,
    "content": "fractionToColor fraction of nodes to be colored, which should be in the interval [0"
  },
  {
    "id": 28751,
    "content": "0,1"
  },
  {
    "id": 28752,
    "content": "0], for example 0"
  },
  {
    "id": 28753,
    "content": "8 implies that 80 percent of nodes will be colored"
  },
  {
    "id": 28756,
    "content": "5"
  },
  {
    "id": 28757,
    "content": "9"
  },
  {
    "id": 28760,
    "content": "9"
  },
  {
    "id": 28761,
    "content": "1"
  },
  {
    "id": 28772,
    "content": "bsrColIndC of nnzc integers"
  },
  {
    "id": 28785,
    "content": "Pointer nnzTotalDevHostPtr can point to a device memory or host memory"
  },
  {
    "id": 28786,
    "content": "5"
  },
  {
    "id": 28787,
    "content": "9"
  },
  {
    "id": 28788,
    "content": "6"
  },
  {
    "id": 28791,
    "content": "5"
  },
  {
    "id": 28792,
    "content": "9"
  },
  {
    "id": 28793,
    "content": "7"
  },
  {
    "id": 28796,
    "content": "in CSC format into a matrix in CSR format"
  },
  {
    "id": 28799,
    "content": "If m == 0 or n == 0 , the pointers are not checked and the routine returns CUSPARSE_STATUS_SUCCESS"
  },
  {
    "id": 28801,
    "content": "5"
  },
  {
    "id": 28802,
    "content": "9"
  },
  {
    "id": 28803,
    "content": "10"
  },
  {
    "id": 28806,
    "content": "5"
  },
  {
    "id": 28807,
    "content": "9"
  },
  {
    "id": 28808,
    "content": "11"
  },
  {
    "id": 28814,
    "content": "returned by coosort_bufferSizeExt()"
  },
  {
    "id": 28817,
    "content": "5"
  },
  {
    "id": 28818,
    "content": "9"
  },
  {
    "id": 28819,
    "content": "12"
  },
  {
    "id": 28821,
    "content": "function sorts CSR format"
  },
  {
    "id": 28824,
    "content": "pBuffer device buffer allocated by the user; the size is returned by csrsort_bufferSizeExt()"
  },
  {
    "id": 28826,
    "content": "5"
  },
  {
    "id": 28827,
    "content": "9"
  },
  {
    "id": 28828,
    "content": "13"
  },
  {
    "id": 28830,
    "content": "function sorts CSC format"
  },
  {
    "id": 28833,
    "content": "pBuffer device buffer allocated by the user; the size is returned by cscsort_bufferSizeExt()"
  },
  {
    "id": 28839,
    "content": "sorted CSR to unsorted CSR"
  },
  {
    "id": 28842,
    "content": "Input parameter device or host description handle host handle to the cuSPARSE library context"
  },
  {
    "id": 28844,
    "content": "pBuffer device buffer allocated by the user; the size is returned by csru2csr_bufferSizeExt()"
  },
  {
    "id": 28851,
    "content": "pBuffer device buffer allocated by the user; the size is returned by pruneDense2csr_bufferSizeExt()"
  },
  {
    "id": 28874,
    "content": "part"
  },
  {
    "id": 28875,
    "content": "For example tol = 1e-8 + 0*i and we extract cureal, that is the x component of this struct"
  },
  {
    "id": 28876,
    "content": "csrValA csr noncompressed values array csrRowPtrA the corresponding input noncompressed row pointer"
  },
  {
    "id": 28878,
    "content": "6"
  },
  {
    "id": 28881,
    "content": "This also allows mixed data-type computation"
  },
  {
    "id": 28882,
    "content": "6"
  },
  {
    "id": 28883,
    "content": "1"
  },
  {
    "id": 28884,
    "content": "Generic Types Reference  The cuSPARSE generic type references are described in this section"
  },
  {
    "id": 28887,
    "content": "1"
  },
  {
    "id": 28888,
    "content": "2"
  },
  {
    "id": 28890,
    "content": "1"
  },
  {
    "id": 28891,
    "content": "3"
  },
  {
    "id": 28892,
    "content": "cusparseIndexType_t  This type indicates the index type for representing the sparse matrix indices"
  },
  {
    "id": 28894,
    "content": "2"
  },
  {
    "id": 28896,
    "content": "6"
  },
  {
    "id": 28897,
    "content": "2"
  },
  {
    "id": 28898,
    "content": "1"
  },
  {
    "id": 28901,
    "content": "See cudaDataType_t for the description of the datatypes"
  },
  {
    "id": 28902,
    "content": "6"
  },
  {
    "id": 28903,
    "content": "2"
  },
  {
    "id": 28904,
    "content": "2"
  },
  {
    "id": 28906,
    "content": "6"
  },
  {
    "id": 28907,
    "content": "2"
  },
  {
    "id": 28908,
    "content": "3"
  },
  {
    "id": 28911,
    "content": "6"
  },
  {
    "id": 28912,
    "content": "2"
  },
  {
    "id": 28913,
    "content": "4"
  },
  {
    "id": 28915,
    "content": "of the dense vector See cusparseStatus_t for the description of the return status"
  },
  {
    "id": 28916,
    "content": "6"
  },
  {
    "id": 28917,
    "content": "2"
  },
  {
    "id": 28918,
    "content": "5"
  },
  {
    "id": 28920,
    "content": "be aligned to the size of the datatype specified in dnVecDescr"
  },
  {
    "id": 28921,
    "content": "6"
  },
  {
    "id": 28922,
    "content": "3"
  },
  {
    "id": 28924,
    "content": "6"
  },
  {
    "id": 28925,
    "content": "3"
  },
  {
    "id": 28926,
    "content": "1"
  },
  {
    "id": 28930,
    "content": "6"
  },
  {
    "id": 28931,
    "content": "3"
  },
  {
    "id": 28932,
    "content": "2"
  },
  {
    "id": 28934,
    "content": "6"
  },
  {
    "id": 28935,
    "content": "3"
  },
  {
    "id": 28936,
    "content": "3"
  },
  {
    "id": 28940,
    "content": "6"
  },
  {
    "id": 28941,
    "content": "3"
  },
  {
    "id": 28942,
    "content": "4"
  },
  {
    "id": 28944,
    "content": "cusparseStatus_t for the description of the return status"
  },
  {
    "id": 28945,
    "content": "6"
  },
  {
    "id": 28946,
    "content": "3"
  },
  {
    "id": 28947,
    "content": "5"
  },
  {
    "id": 28949,
    "content": "Values of the sparse vector"
  },
  {
    "id": 28950,
    "content": "Array with nnz elements See cusparseStatus_t for the description of the return status"
  },
  {
    "id": 28951,
    "content": "6"
  },
  {
    "id": 28952,
    "content": "3"
  },
  {
    "id": 28953,
    "content": "6"
  },
  {
    "id": 28955,
    "content": "be aligned to the size of the datatype specified in spVecDescr"
  },
  {
    "id": 28956,
    "content": "6"
  },
  {
    "id": 28957,
    "content": "4"
  },
  {
    "id": 28959,
    "content": "6"
  },
  {
    "id": 28960,
    "content": "4"
  },
  {
    "id": 28961,
    "content": "1"
  },
  {
    "id": 28965,
    "content": "6"
  },
  {
    "id": 28966,
    "content": "4"
  },
  {
    "id": 28967,
    "content": "2"
  },
  {
    "id": 28969,
    "content": "6"
  },
  {
    "id": 28970,
    "content": "4"
  },
  {
    "id": 28971,
    "content": "3"
  },
  {
    "id": 28975,
    "content": "6"
  },
  {
    "id": 28976,
    "content": "4"
  },
  {
    "id": 28977,
    "content": "4"
  },
  {
    "id": 28979,
    "content": "of the dense matrix"
  },
  {
    "id": 28980,
    "content": "Array with ld * cols elements See cusparseStatus_t for the description of the return status"
  },
  {
    "id": 28981,
    "content": "6"
  },
  {
    "id": 28982,
    "content": "4"
  },
  {
    "id": 28983,
    "content": "5"
  },
  {
    "id": 28985,
    "content": "must be aligned to the size of the datatype specified in dnMatDescr"
  },
  {
    "id": 28986,
    "content": "6"
  },
  {
    "id": 28987,
    "content": "4"
  },
  {
    "id": 28988,
    "content": "6"
  },
  {
    "id": 28991,
    "content": "6"
  },
  {
    "id": 28992,
    "content": "4"
  },
  {
    "id": 28993,
    "content": "7"
  },
  {
    "id": 28996,
    "content": "6"
  },
  {
    "id": 28997,
    "content": "5"
  },
  {
    "id": 29000,
    "content": "6"
  },
  {
    "id": 29001,
    "content": "5"
  },
  {
    "id": 29002,
    "content": "1"
  },
  {
    "id": 29003,
    "content": "Coordinate (COO)  6"
  },
  {
    "id": 29004,
    "content": "5"
  },
  {
    "id": 29005,
    "content": "1"
  },
  {
    "id": 29006,
    "content": "1"
  },
  {
    "id": 29011,
    "content": "respectively"
  },
  {
    "id": 29012,
    "content": "6"
  },
  {
    "id": 29013,
    "content": "5"
  },
  {
    "id": 29014,
    "content": "1"
  },
  {
    "id": 29015,
    "content": "2"
  },
  {
    "id": 29019,
    "content": "description of the return status"
  },
  {
    "id": 29020,
    "content": "6"
  },
  {
    "id": 29021,
    "content": "5"
  },
  {
    "id": 29022,
    "content": "1"
  },
  {
    "id": 29023,
    "content": "3"
  },
  {
    "id": 29026,
    "content": "6"
  },
  {
    "id": 29027,
    "content": "5"
  },
  {
    "id": 29028,
    "content": "1"
  },
  {
    "id": 29029,
    "content": "4"
  },
  {
    "id": 29032,
    "content": "6"
  },
  {
    "id": 29033,
    "content": "5"
  },
  {
    "id": 29034,
    "content": "2"
  },
  {
    "id": 29035,
    "content": "Compressed Sparse Row (CSR)  6"
  },
  {
    "id": 29036,
    "content": "5"
  },
  {
    "id": 29037,
    "content": "2"
  },
  {
    "id": 29038,
    "content": "1"
  },
  {
    "id": 29043,
    "content": "the return status"
  },
  {
    "id": 29044,
    "content": "6"
  },
  {
    "id": 29045,
    "content": "5"
  },
  {
    "id": 29046,
    "content": "2"
  },
  {
    "id": 29047,
    "content": "3"
  },
  {
    "id": 29050,
    "content": "6"
  },
  {
    "id": 29051,
    "content": "5"
  },
  {
    "id": 29052,
    "content": "2"
  },
  {
    "id": 29053,
    "content": "4"
  },
  {
    "id": 29056,
    "content": "6"
  },
  {
    "id": 29057,
    "content": "5"
  },
  {
    "id": 29058,
    "content": "3"
  },
  {
    "id": 29059,
    "content": "Compressed Sparse Column (CSC)  6"
  },
  {
    "id": 29060,
    "content": "5"
  },
  {
    "id": 29061,
    "content": "3"
  },
  {
    "id": 29062,
    "content": "1"
  },
  {
    "id": 29067,
    "content": "the return status"
  },
  {
    "id": 29068,
    "content": "6"
  },
  {
    "id": 29069,
    "content": "5"
  },
  {
    "id": 29070,
    "content": "3"
  },
  {
    "id": 29071,
    "content": "3"
  },
  {
    "id": 29074,
    "content": "6"
  },
  {
    "id": 29075,
    "content": "5"
  },
  {
    "id": 29076,
    "content": "4"
  },
  {
    "id": 29077,
    "content": "Blocked-Ellpack (Blocked-ELL)  6"
  },
  {
    "id": 29078,
    "content": "5"
  },
  {
    "id": 29079,
    "content": "4"
  },
  {
    "id": 29080,
    "content": "1"
  },
  {
    "id": 29085,
    "content": "The array can contain -1 values for indicating empty blocks"
  },
  {
    "id": 29086,
    "content": "6"
  },
  {
    "id": 29087,
    "content": "5"
  },
  {
    "id": 29088,
    "content": "4"
  },
  {
    "id": 29089,
    "content": "2"
  },
  {
    "id": 29094,
    "content": "6"
  },
  {
    "id": 29095,
    "content": "5"
  },
  {
    "id": 29096,
    "content": "5"
  },
  {
    "id": 29097,
    "content": "Sliced-Ellpack (SELL)  6"
  },
  {
    "id": 29098,
    "content": "5"
  },
  {
    "id": 29099,
    "content": "5"
  },
  {
    "id": 29100,
    "content": "1"
  },
  {
    "id": 29104,
    "content": "6"
  },
  {
    "id": 29105,
    "content": "5"
  },
  {
    "id": 29106,
    "content": "6"
  },
  {
    "id": 29107,
    "content": "Block Sparse Row (BSR)  6"
  },
  {
    "id": 29108,
    "content": "5"
  },
  {
    "id": 29109,
    "content": "6"
  },
  {
    "id": 29110,
    "content": "1"
  },
  {
    "id": 29113,
    "content": "See cusparseStatus_t for the description of the return status"
  },
  {
    "id": 29114,
    "content": "6"
  },
  {
    "id": 29115,
    "content": "5"
  },
  {
    "id": 29116,
    "content": "7"
  },
  {
    "id": 29117,
    "content": "All Sparse Formats  6"
  },
  {
    "id": 29118,
    "content": "5"
  },
  {
    "id": 29119,
    "content": "7"
  },
  {
    "id": 29120,
    "content": "1"
  },
  {
    "id": 29122,
    "content": "6"
  },
  {
    "id": 29123,
    "content": "5"
  },
  {
    "id": 29124,
    "content": "7"
  },
  {
    "id": 29125,
    "content": "2"
  },
  {
    "id": 29128,
    "content": "6"
  },
  {
    "id": 29129,
    "content": "5"
  },
  {
    "id": 29130,
    "content": "7"
  },
  {
    "id": 29131,
    "content": "3"
  },
  {
    "id": 29133,
    "content": "description of the return status"
  },
  {
    "id": 29134,
    "content": "6"
  },
  {
    "id": 29135,
    "content": "5"
  },
  {
    "id": 29136,
    "content": "7"
  },
  {
    "id": 29137,
    "content": "4"
  },
  {
    "id": 29139,
    "content": "the description of the return status"
  },
  {
    "id": 29140,
    "content": "6"
  },
  {
    "id": 29141,
    "content": "5"
  },
  {
    "id": 29142,
    "content": "7"
  },
  {
    "id": 29143,
    "content": "5"
  },
  {
    "id": 29145,
    "content": "Values of the sparse matrix"
  },
  {
    "id": 29146,
    "content": "6"
  },
  {
    "id": 29147,
    "content": "5"
  },
  {
    "id": 29148,
    "content": "7"
  },
  {
    "id": 29149,
    "content": "6"
  },
  {
    "id": 29151,
    "content": "must be aligned to the size of its corresponding datatype specified in spMatDescr"
  },
  {
    "id": 29152,
    "content": "6"
  },
  {
    "id": 29153,
    "content": "5"
  },
  {
    "id": 29154,
    "content": "7"
  },
  {
    "id": 29155,
    "content": "7"
  },
  {
    "id": 29157,
    "content": "cusparseStatus_t for the description of the return status"
  },
  {
    "id": 29158,
    "content": "6"
  },
  {
    "id": 29159,
    "content": "5"
  },
  {
    "id": 29160,
    "content": "7"
  },
  {
    "id": 29161,
    "content": "8"
  },
  {
    "id": 29164,
    "content": "See cusparseStatus_t for the description of the return status"
  },
  {
    "id": 29165,
    "content": "6"
  },
  {
    "id": 29166,
    "content": "5"
  },
  {
    "id": 29167,
    "content": "7"
  },
  {
    "id": 29168,
    "content": "9"
  },
  {
    "id": 29171,
    "content": "for the description of the return status"
  },
  {
    "id": 29172,
    "content": "6"
  },
  {
    "id": 29173,
    "content": "6"
  },
  {
    "id": 29174,
    "content": "Generic API Functions  6"
  },
  {
    "id": 29175,
    "content": "6"
  },
  {
    "id": 29176,
    "content": "1"
  },
  {
    "id": 29179,
    "content": "Please visit cuSPARSE Library Samples - cusparseAxpby for a code example"
  },
  {
    "id": 29180,
    "content": "6"
  },
  {
    "id": 29181,
    "content": "6"
  },
  {
    "id": 29182,
    "content": "2"
  },
  {
    "id": 29184,
    "content": "code example"
  },
  {
    "id": 29185,
    "content": "6"
  },
  {
    "id": 29186,
    "content": "6"
  },
  {
    "id": 29187,
    "content": "3"
  },
  {
    "id": 29189,
    "content": "for a code example"
  },
  {
    "id": 29190,
    "content": "6"
  },
  {
    "id": 29191,
    "content": "6"
  },
  {
    "id": 29192,
    "content": "4"
  },
  {
    "id": 29196,
    "content": "May produce slightly different results during different runs with the same input parameters"
  },
  {
    "id": 29209,
    "content": "return status"
  },
  {
    "id": 29211,
    "content": "dense matrices layout: \\(\\begin{array}{l} \\left"
  },
  {
    "id": 29213,
    "content": "It provides performance advantages is used with CUSPARSE_SPMM_CSR_ALG1 or CUSPARSE_SPMM_CSR_ALG3"
  },
  {
    "id": 29216,
    "content": "batched computation please visit cusparseSpMM CSR Batched and cusparseSpMM COO Batched"
  },
  {
    "id": 29225,
    "content": "g"
  },
  {
    "id": 29230,
    "content": "return status"
  },
  {
    "id": 29235,
    "content": "intermediate products being computed in a chunk"
  },
  {
    "id": 29236,
    "content": "If it is not sufficient, the routine will returns CUSPARSE_STATUS_INSUFFICIENT_RESOURCES status"
  },
  {
    "id": 29238,
    "content": "CUSPARSE_SPGEMM_ALG3 Algorithm 3 Computes the intermediate products in chunks, one chunk at a time"
  },
  {
    "id": 29241,
    "content": "return status"
  },
  {
    "id": 29249,
    "content": "CUSPARSE_SPGEMM_CSR_ALG_NONDETERMINITIC Default algorithm"
  },
  {
    "id": 29253,
    "content": "6"
  },
  {
    "id": 29254,
    "content": "6"
  },
  {
    "id": 29255,
    "content": "14"
  },
  {
    "id": 29261,
    "content": "7"
  },
  {
    "id": 29264,
    "content": "functions, which are written in C and are located in the file cusparse_fortran"
  },
  {
    "id": 29265,
    "content": "c"
  },
  {
    "id": 29271,
    "content": "The sample wrappers provided in cusparse_fortran"
  },
  {
    "id": 29274,
    "content": "On Linux and Mac OS X, preprocessing can be done by using the option '-cpp' with g95 or gfortran"
  },
  {
    "id": 29279,
    "content": "OR"
  },
  {
    "id": 29281,
    "content": "0 end 8"
  },
  {
    "id": 29284,
    "content": "This product includes {fmt} - A modern formatting library https: fmt"
  },
  {
    "id": 29285,
    "content": "dev Copyright (c) 2012 - present, Victor Zverovich"
  },
  {
    "id": 29286,
    "content": "9"
  },
  {
    "id": 29287,
    "content": "Bibliography  [1] N"
  },
  {
    "id": 29289,
    "content": "Young, “ITPACK 2"
  },
  {
    "id": 29291,
    "content": "[4] Pedro Valero-Lara, Ivan Martínez-Pérez, Raül Sirvent, Xavier Martorell, and Antonio J"
  },
  {
    "id": 29292,
    "content": "In Parallel Processing and Applied Mathematics - 12th International Conference (PPAM), 2017"
  },
  {
    "id": 29293,
    "content": "10 Notices  10"
  },
  {
    "id": 29294,
    "content": "1"
  },
  {
    "id": 29297,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 29309,
    "content": "10"
  },
  {
    "id": 29310,
    "content": "2"
  },
  {
    "id": 29311,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 29312,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 29313,
    "content": "10"
  },
  {
    "id": 29314,
    "content": "3"
  },
  {
    "id": 29316,
    "content": "S"
  },
  {
    "id": 29319,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 29320,
    "content": "Navigation"
  },
  {
    "id": 29321,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 29323,
    "content": "5"
  },
  {
    "id": 29324,
    "content": "1 cuRAND Introduction 1 Acknowledgements Search Results cuRAND ( PDF ) - v12"
  },
  {
    "id": 29325,
    "content": "5"
  },
  {
    "id": 29329,
    "content": "2"
  },
  {
    "id": 29331,
    "content": "The APIs with GPU buffers should be called in a valid CUDA context and stream if applicable"
  },
  {
    "id": 29332,
    "content": "Note: Starting from CUDA toolkit 12"
  },
  {
    "id": 29333,
    "content": "2 (GDS version 1"
  },
  {
    "id": 29334,
    "content": "7"
  },
  {
    "id": 29335,
    "content": "x) release cuFile APIs support memory allocated on GPU device as well as host memory"
  },
  {
    "id": 29338,
    "content": "2"
  },
  {
    "id": 29339,
    "content": "1"
  },
  {
    "id": 29340,
    "content": "Dynamic Interactions The following describes the dynamic interactions between the cuFile APIs"
  },
  {
    "id": 29342,
    "content": "opened or registered by a previous cuFile * API call results in an error"
  },
  {
    "id": 29348,
    "content": "2"
  },
  {
    "id": 29349,
    "content": "2"
  },
  {
    "id": 29353,
    "content": "Call cuFileHandleRegister to wrap an existing file descriptor in an OS-agnostic CUfileHandle_t"
  },
  {
    "id": 29357,
    "content": "The best practice is to always call these APIs in the application cleanup paths"
  },
  {
    "id": 29358,
    "content": "2"
  },
  {
    "id": 29359,
    "content": "3"
  },
  {
    "id": 29363,
    "content": "Alternatively the admin can unload the nvidia_fs"
  },
  {
    "id": 29364,
    "content": "ko or not expose the character devices in the docker container environment"
  },
  {
    "id": 29370,
    "content": "It has not been tested to work on all other filesystems"
  },
  {
    "id": 29371,
    "content": "3"
  },
  {
    "id": 29373,
    "content": "Introduction v12"
  },
  {
    "id": 29380,
    "content": "In general the smaller the prime factor, the better the performance, i"
  },
  {
    "id": 29381,
    "content": "e"
  },
  {
    "id": 29382,
    "content": ", powers of two are fastest"
  },
  {
    "id": 29386,
    "content": "See Deprecated Functionality"
  },
  {
    "id": 29387,
    "content": "2"
  },
  {
    "id": 29388,
    "content": "Using the cuFFT API  This chapter provides a general overview of the cuFFT library API"
  },
  {
    "id": 29389,
    "content": "Users are encouraged to read this chapter before continuing with more detailed descriptions"
  },
  {
    "id": 29391,
    "content": "If the sign on the exponent of e is changed to be positive, the transform is an inverse transform"
  },
  {
    "id": 29398,
    "content": "Product Location and name Include file nvcc compiler /bin/nvcc cuFFT library {lib, lib64}/libcufft"
  },
  {
    "id": 29400,
    "content": "h The most common case is for developers to modify an existing CUDA routine (for example, filename"
  },
  {
    "id": 29401,
    "content": "cu ) to call cuFFT routines In this case the include file cufft"
  },
  {
    "id": 29402,
    "content": "h or cufftXt"
  },
  {
    "id": 29403,
    "content": "h should be inserted into filename"
  },
  {
    "id": 29407,
    "content": "2"
  },
  {
    "id": 29408,
    "content": "2"
  },
  {
    "id": 29411,
    "content": "Execution of a transform of a particular size and type may take several stages of processing"
  },
  {
    "id": 29412,
    "content": "When a plan for the transform is generated, cuFFT derives the internal steps that need to be taken"
  },
  {
    "id": 29413,
    "content": "In addition, all the intermediate buffer allocations (on CPU/GPU memory) take place during planning"
  },
  {
    "id": 29414,
    "content": "In the worst case, the cuFFT Library allocates space for 8*batch*n[0]*"
  },
  {
    "id": 29416,
    "content": "In some specific cases, the temporary space allocations can be as low as 1*batch*n[0]*"
  },
  {
    "id": 29417,
    "content": "*n[rank-1] cufftComplex or cufftDoubleComplex elements"
  },
  {
    "id": 29418,
    "content": "This temporary space is allocated separately for each individual plan when it is created (i"
  },
  {
    "id": 29419,
    "content": "e"
  },
  {
    "id": 29420,
    "content": ", temporary space is not shared between the plans)"
  },
  {
    "id": 29424,
    "content": "2"
  },
  {
    "id": 29425,
    "content": "2"
  },
  {
    "id": 29426,
    "content": "1"
  },
  {
    "id": 29428,
    "content": "by creating a plan) and then allocating memory"
  },
  {
    "id": 29429,
    "content": "2"
  },
  {
    "id": 29430,
    "content": "2"
  },
  {
    "id": 29431,
    "content": "2"
  },
  {
    "id": 29433,
    "content": "Starting from CUDA 12"
  },
  {
    "id": 29437,
    "content": "2"
  },
  {
    "id": 29438,
    "content": "3"
  },
  {
    "id": 29442,
    "content": "cuFFT takes advantage of this redundancy and works only on the first half of the Hermitian vector"
  },
  {
    "id": 29444,
    "content": "Each of those functions demands different input data layout (see Data Layout for details)"
  },
  {
    "id": 29446,
    "content": "e"
  },
  {
    "id": 29449,
    "content": "2"
  },
  {
    "id": 29450,
    "content": "3"
  },
  {
    "id": 29451,
    "content": "1"
  },
  {
    "id": 29453,
    "content": "function for plan creation details"
  },
  {
    "id": 29454,
    "content": "The CUDA Toolkit provides the cuda_fp16"
  },
  {
    "id": 29455,
    "content": "h header with types and intrinsic functions for handling half-precision arithmetic"
  },
  {
    "id": 29456,
    "content": "2"
  },
  {
    "id": 29457,
    "content": "3"
  },
  {
    "id": 29458,
    "content": "2"
  },
  {
    "id": 29461,
    "content": "The CUDA Toolkit provides the cuda_bf16"
  },
  {
    "id": 29462,
    "content": "h header with types and intrinsic functions for handling bfloat16-precision arithmetic"
  },
  {
    "id": 29463,
    "content": "2"
  },
  {
    "id": 29464,
    "content": "4"
  },
  {
    "id": 29467,
    "content": "1})\\) of non-redundant complex elements"
  },
  {
    "id": 29471,
    "content": "imaginary input point values when non-unit input and output strides are chosen"
  },
  {
    "id": 29483,
    "content": "2"
  },
  {
    "id": 29484,
    "content": "7"
  },
  {
    "id": 29486,
    "content": "(See the NVIDIA CUDA Programming Guide for more information on streams"
  },
  {
    "id": 29489,
    "content": "However, calls to cufftXtMemcpy() are still synchronous across multiple GPUs when using streams"
  },
  {
    "id": 29492,
    "content": "2"
  },
  {
    "id": 29493,
    "content": "8"
  },
  {
    "id": 29498,
    "content": "The highest performance is obtained using NVLink interconnect ( https: www"
  },
  {
    "id": 29499,
    "content": "nvidia"
  },
  {
    "id": 29500,
    "content": "com/object/nvlink"
  },
  {
    "id": 29501,
    "content": "html )"
  },
  {
    "id": 29502,
    "content": "The second best option is using PCI Express 3"
  },
  {
    "id": 29503,
    "content": "0 between the GPUs and ensuring that both GPUs are on the same switch"
  },
  {
    "id": 29508,
    "content": "8"
  },
  {
    "id": 29509,
    "content": "1"
  },
  {
    "id": 29513,
    "content": "2"
  },
  {
    "id": 29514,
    "content": "8"
  },
  {
    "id": 29515,
    "content": "2"
  },
  {
    "id": 29517,
    "content": "On a single GPU users may call cudaMalloc() and cudaFree() to allocate and free GPU memory"
  },
  {
    "id": 29519,
    "content": "memories"
  },
  {
    "id": 29522,
    "content": "2"
  },
  {
    "id": 29523,
    "content": "8"
  },
  {
    "id": 29524,
    "content": "3"
  },
  {
    "id": 29526,
    "content": "creates a 2D or 3D plan for a single transform on multiple GPUs, it actually creates two plans"
  },
  {
    "id": 29529,
    "content": "The ability of cuFFT to process data in either order makes the following sequence possible"
  },
  {
    "id": 29533,
    "content": "8"
  },
  {
    "id": 29534,
    "content": "4"
  },
  {
    "id": 29542,
    "content": "2"
  },
  {
    "id": 29543,
    "content": "9"
  },
  {
    "id": 29545,
    "content": "Note Starting from CUDA 11"
  },
  {
    "id": 29547,
    "content": "2"
  },
  {
    "id": 29548,
    "content": "9"
  },
  {
    "id": 29549,
    "content": "1"
  },
  {
    "id": 29557,
    "content": "2"
  },
  {
    "id": 29558,
    "content": "9"
  },
  {
    "id": 29559,
    "content": "2"
  },
  {
    "id": 29563,
    "content": "pointers, and the cudaMemcpyFromSymbol will have to be invoked for each GPU"
  },
  {
    "id": 29565,
    "content": "2"
  },
  {
    "id": 29566,
    "content": "9"
  },
  {
    "id": 29567,
    "content": "3"
  },
  {
    "id": 29573,
    "content": "the zero frequency result to the center of the ouput"
  },
  {
    "id": 29577,
    "content": "2"
  },
  {
    "id": 29578,
    "content": "9"
  },
  {
    "id": 29579,
    "content": "4"
  },
  {
    "id": 29581,
    "content": "threads per block, will vary depending on how cuFFT decomposes the transform"
  },
  {
    "id": 29589,
    "content": "2"
  },
  {
    "id": 29590,
    "content": "9"
  },
  {
    "id": 29591,
    "content": "4"
  },
  {
    "id": 29592,
    "content": "1"
  },
  {
    "id": 29594,
    "content": "Results in this case would be undefined"
  },
  {
    "id": 29595,
    "content": "2"
  },
  {
    "id": 29596,
    "content": "10"
  },
  {
    "id": 29598,
    "content": "2"
  },
  {
    "id": 29599,
    "content": "11"
  },
  {
    "id": 29600,
    "content": "CUDA Graphs Support  Using CUDA Graphs with cuFFT is supported on single GPU plans"
  },
  {
    "id": 29602,
    "content": "Note Starting from CUDA 11"
  },
  {
    "id": 29603,
    "content": "8 (including CUDA 12"
  },
  {
    "id": 29606,
    "content": "4"
  },
  {
    "id": 29607,
    "content": "2"
  },
  {
    "id": 29608,
    "content": "12"
  },
  {
    "id": 29609,
    "content": "Static Library and Callback Support  Starting with release 6"
  },
  {
    "id": 29610,
    "content": "5, the cuFFT libraries are also delivered in a static form as libcufft_static"
  },
  {
    "id": 29611,
    "content": "a and libcufftw_static"
  },
  {
    "id": 29612,
    "content": "a on Linux and Mac"
  },
  {
    "id": 29613,
    "content": "The static cufft and cufftw libraries depend on thread abstraction layer library libculibos"
  },
  {
    "id": 29614,
    "content": "a"
  },
  {
    "id": 29616,
    "content": "need to be taken"
  },
  {
    "id": 29618,
    "content": "a"
  },
  {
    "id": 29619,
    "content": "It is also possible to use the native Host C++ compiler and perform device link as a separate step"
  },
  {
    "id": 29623,
    "content": "2"
  },
  {
    "id": 29624,
    "content": "12"
  },
  {
    "id": 29625,
    "content": "1"
  },
  {
    "id": 29627,
    "content": "a , was added"
  },
  {
    "id": 29629,
    "content": "2"
  },
  {
    "id": 29630,
    "content": "13"
  },
  {
    "id": 29633,
    "content": "The cuFFT Library implements the following building blocks: radix-2, radix-3, radix-5, and radix-7"
  },
  {
    "id": 29636,
    "content": "g"
  },
  {
    "id": 29637,
    "content": "LD_LIBRARY_PATH on Unix systems, or PATH on Windows systems)"
  },
  {
    "id": 29638,
    "content": "2"
  },
  {
    "id": 29639,
    "content": "15"
  },
  {
    "id": 29640,
    "content": "1"
  },
  {
    "id": 29641,
    "content": "3"
  },
  {
    "id": 29643,
    "content": "3"
  },
  {
    "id": 29644,
    "content": "1"
  },
  {
    "id": 29646,
    "content": "3"
  },
  {
    "id": 29647,
    "content": "2"
  },
  {
    "id": 29648,
    "content": "cuFFT Basic Plans  3"
  },
  {
    "id": 29649,
    "content": "2"
  },
  {
    "id": 29650,
    "content": "1"
  },
  {
    "id": 29652,
    "content": "g"
  },
  {
    "id": 29653,
    "content": ", CUFFT_C2C for single precision complex to complex)"
  },
  {
    "id": 29654,
    "content": "CUFFT_INVALID_SIZE – The nx or batch parameter is not a supported size"
  },
  {
    "id": 29655,
    "content": "3"
  },
  {
    "id": 29656,
    "content": "2"
  },
  {
    "id": 29657,
    "content": "2"
  },
  {
    "id": 29660,
    "content": "g"
  },
  {
    "id": 29661,
    "content": ", CUFFT_C2R for single precision complex to real)"
  },
  {
    "id": 29662,
    "content": "CUFFT_INVALID_SIZE – Either or both of the nx or ny parameters is not a supported size"
  },
  {
    "id": 29663,
    "content": "3"
  },
  {
    "id": 29664,
    "content": "2"
  },
  {
    "id": 29665,
    "content": "3"
  },
  {
    "id": 29667,
    "content": "This function is the same as cufftPlan2d() except that it takes a third size parameter nz"
  },
  {
    "id": 29668,
    "content": "type[In] – The transform data type (e"
  },
  {
    "id": 29669,
    "content": "g"
  },
  {
    "id": 29670,
    "content": ", CUFFT_R2C for single precision real to complex)"
  },
  {
    "id": 29671,
    "content": "CUFFT_INVALID_SIZE – One or more of the nx , ny , or nz parameters is not a supported size"
  },
  {
    "id": 29672,
    "content": "3"
  },
  {
    "id": 29673,
    "content": "2"
  },
  {
    "id": 29674,
    "content": "4"
  },
  {
    "id": 29678,
    "content": "e"
  },
  {
    "id": 29679,
    "content": ", innermost) dimension"
  },
  {
    "id": 29681,
    "content": "e"
  },
  {
    "id": 29682,
    "content": ", innermost) dimension"
  },
  {
    "id": 29684,
    "content": "CUFFT_INVALID_SIZE – One or more of the parameters is not a supported size"
  },
  {
    "id": 29685,
    "content": "3"
  },
  {
    "id": 29686,
    "content": "3"
  },
  {
    "id": 29688,
    "content": "3"
  },
  {
    "id": 29689,
    "content": "3"
  },
  {
    "id": 29690,
    "content": "1"
  },
  {
    "id": 29692,
    "content": "CUFFT_ALLOC_FAILED – The allocation of resources for the plan failed"
  },
  {
    "id": 29693,
    "content": "3"
  },
  {
    "id": 29694,
    "content": "3"
  },
  {
    "id": 29695,
    "content": "2"
  },
  {
    "id": 29697,
    "content": "3"
  },
  {
    "id": 29698,
    "content": "3"
  },
  {
    "id": 29699,
    "content": "3"
  },
  {
    "id": 29702,
    "content": "type[In] – The transform data type (e"
  },
  {
    "id": 29703,
    "content": "g"
  },
  {
    "id": 29704,
    "content": ", CUFFT_C2C for single precision complex to complex)"
  },
  {
    "id": 29705,
    "content": "CUFFT_SETUP_FAILED` – The cuFFT library failed to initialize"
  },
  {
    "id": 29706,
    "content": "3"
  },
  {
    "id": 29707,
    "content": "3"
  },
  {
    "id": 29708,
    "content": "4"
  },
  {
    "id": 29710,
    "content": "g"
  },
  {
    "id": 29711,
    "content": ", CUFFT_C2R for single precision complex to real)"
  },
  {
    "id": 29712,
    "content": "workSize[In] – Pointer to the size(s), in bytes, of the work areas"
  },
  {
    "id": 29713,
    "content": "3"
  },
  {
    "id": 29714,
    "content": "3"
  },
  {
    "id": 29715,
    "content": "5"
  },
  {
    "id": 29717,
    "content": "g"
  },
  {
    "id": 29718,
    "content": ", CUFFT_R2C for single precision real to complex)"
  },
  {
    "id": 29719,
    "content": "*workSize[Out] – Pointer to the size(s) of the work area(s)"
  },
  {
    "id": 29720,
    "content": "3"
  },
  {
    "id": 29721,
    "content": "3"
  },
  {
    "id": 29722,
    "content": "6"
  },
  {
    "id": 29726,
    "content": "e"
  },
  {
    "id": 29728,
    "content": "array in the least significant (i"
  },
  {
    "id": 29729,
    "content": "e"
  },
  {
    "id": 29731,
    "content": "g"
  },
  {
    "id": 29733,
    "content": "3"
  },
  {
    "id": 29734,
    "content": "3"
  },
  {
    "id": 29735,
    "content": "7"
  },
  {
    "id": 29737,
    "content": "with sizes specified in the array n"
  },
  {
    "id": 29743,
    "content": "3"
  },
  {
    "id": 29744,
    "content": "3"
  },
  {
    "id": 29745,
    "content": "8"
  },
  {
    "id": 29751,
    "content": "Handle is not valid when multi-GPU restrictions are not met"
  },
  {
    "id": 29752,
    "content": "3"
  },
  {
    "id": 29753,
    "content": "4"
  },
  {
    "id": 29756,
    "content": "4"
  },
  {
    "id": 29757,
    "content": "1"
  },
  {
    "id": 29759,
    "content": "CUFFT_NOT_SUPPORTED – The property is not supported, or it cannot be set at the time (e"
  },
  {
    "id": 29760,
    "content": "g"
  },
  {
    "id": 29766,
    "content": "3"
  },
  {
    "id": 29767,
    "content": "5"
  },
  {
    "id": 29768,
    "content": "1"
  },
  {
    "id": 29770,
    "content": "CUFFT_INVALID_SIZE – The nx parameter is not a supported size"
  },
  {
    "id": 29771,
    "content": "3"
  },
  {
    "id": 29772,
    "content": "5"
  },
  {
    "id": 29773,
    "content": "2"
  },
  {
    "id": 29775,
    "content": "ny[In] – The transform size in the y dimension (number of columns)"
  },
  {
    "id": 29776,
    "content": "3"
  },
  {
    "id": 29777,
    "content": "5"
  },
  {
    "id": 29778,
    "content": "3"
  },
  {
    "id": 29780,
    "content": "Parameters nx[In] – The transform size in the x dimension"
  },
  {
    "id": 29781,
    "content": "3"
  },
  {
    "id": 29782,
    "content": "5"
  },
  {
    "id": 29783,
    "content": "4"
  },
  {
    "id": 29785,
    "content": "advanced data layout parameters: inembed , istride , idist , onembed , ostride , and odist"
  },
  {
    "id": 29787,
    "content": "3"
  },
  {
    "id": 29788,
    "content": "6"
  },
  {
    "id": 29790,
    "content": "not multiples of powers of 2, 3, 5 and 7"
  },
  {
    "id": 29791,
    "content": "3"
  },
  {
    "id": 29792,
    "content": "6"
  },
  {
    "id": 29793,
    "content": "1"
  },
  {
    "id": 29795,
    "content": "Please consider using cufftGetSizeMany for multiple transforms"
  },
  {
    "id": 29796,
    "content": "3"
  },
  {
    "id": 29797,
    "content": "6"
  },
  {
    "id": 29798,
    "content": "2"
  },
  {
    "id": 29800,
    "content": "nx[In] – The transform size in the x dimension (number of rows)"
  },
  {
    "id": 29801,
    "content": "3"
  },
  {
    "id": 29802,
    "content": "6"
  },
  {
    "id": 29803,
    "content": "3"
  },
  {
    "id": 29805,
    "content": "3"
  },
  {
    "id": 29806,
    "content": "6"
  },
  {
    "id": 29807,
    "content": "4"
  },
  {
    "id": 29809,
    "content": "any plan settings that may have been made *workSize[Out] – Pointer to the size of the work area"
  },
  {
    "id": 29810,
    "content": "3"
  },
  {
    "id": 29811,
    "content": "6"
  },
  {
    "id": 29812,
    "content": "5"
  },
  {
    "id": 29816,
    "content": "3"
  },
  {
    "id": 29817,
    "content": "6"
  },
  {
    "id": 29818,
    "content": "6"
  },
  {
    "id": 29822,
    "content": "3"
  },
  {
    "id": 29823,
    "content": "7"
  },
  {
    "id": 29825,
    "content": "calls subsequent to plan generation, if those calls might alter the required work space size"
  },
  {
    "id": 29826,
    "content": "3"
  },
  {
    "id": 29827,
    "content": "8"
  },
  {
    "id": 29828,
    "content": "cuFFT Caller Allocated Work Area Support  3"
  },
  {
    "id": 29829,
    "content": "8"
  },
  {
    "id": 29830,
    "content": "1"
  },
  {
    "id": 29832,
    "content": "autoAllocate[In] – Indicates whether to allocate work area"
  },
  {
    "id": 29833,
    "content": "3"
  },
  {
    "id": 29834,
    "content": "8"
  },
  {
    "id": 29835,
    "content": "2"
  },
  {
    "id": 29837,
    "content": "given"
  },
  {
    "id": 29838,
    "content": "3"
  },
  {
    "id": 29839,
    "content": "8"
  },
  {
    "id": 29840,
    "content": "3"
  },
  {
    "id": 29844,
    "content": "CUFFT_INVALID_SIZE – FFT size does not allow use of the selected policy"
  },
  {
    "id": 29845,
    "content": "3"
  },
  {
    "id": 29846,
    "content": "9"
  },
  {
    "id": 29847,
    "content": "cuFFT Execution  3"
  },
  {
    "id": 29848,
    "content": "9"
  },
  {
    "id": 29849,
    "content": "1"
  },
  {
    "id": 29852,
    "content": "CUFFT_EXEC_FAILED – cuFFT failed to execute the transform on the GPU"
  },
  {
    "id": 29853,
    "content": "3"
  },
  {
    "id": 29854,
    "content": "9"
  },
  {
    "id": 29855,
    "content": "2"
  },
  {
    "id": 29858,
    "content": "3"
  },
  {
    "id": 29859,
    "content": "9"
  },
  {
    "id": 29860,
    "content": "3"
  },
  {
    "id": 29863,
    "content": "Return values CUFFT_SUCCESS – cuFFT successfully executed the FFT plan"
  },
  {
    "id": 29864,
    "content": "3"
  },
  {
    "id": 29865,
    "content": "9"
  },
  {
    "id": 29866,
    "content": "4"
  },
  {
    "id": 29868,
    "content": "output[Out] – Contains the complex Fourier coefficients"
  },
  {
    "id": 29869,
    "content": "3"
  },
  {
    "id": 29870,
    "content": "9"
  },
  {
    "id": 29871,
    "content": "5"
  },
  {
    "id": 29873,
    "content": "CUFFT_INVALID_DEVICE – An invalid GPU index was specified in a descriptor"
  },
  {
    "id": 29874,
    "content": "3"
  },
  {
    "id": 29875,
    "content": "10"
  },
  {
    "id": 29876,
    "content": "cuFFT and Multiple GPUs  3"
  },
  {
    "id": 29877,
    "content": "10"
  },
  {
    "id": 29878,
    "content": "1"
  },
  {
    "id": 29880,
    "content": "In cuFFT prior to 10"
  },
  {
    "id": 29881,
    "content": "4"
  },
  {
    "id": 29885,
    "content": "4"
  },
  {
    "id": 29886,
    "content": "0"
  },
  {
    "id": 29887,
    "content": "CUFFT_INVALID_SIZE – Transform size that plan was created for does not meet minimum size criteria"
  },
  {
    "id": 29888,
    "content": "3"
  },
  {
    "id": 29889,
    "content": "10"
  },
  {
    "id": 29890,
    "content": "2"
  },
  {
    "id": 29893,
    "content": "CUFFT_INVALID_DEVICE – A GPU associated with the plan could not be selected"
  },
  {
    "id": 29894,
    "content": "3"
  },
  {
    "id": 29895,
    "content": "10"
  },
  {
    "id": 29896,
    "content": "3"
  },
  {
    "id": 29897,
    "content": "cuFFT Multiple GPU Execution  3"
  },
  {
    "id": 29898,
    "content": "10"
  },
  {
    "id": 29899,
    "content": "3"
  },
  {
    "id": 29900,
    "content": "1"
  },
  {
    "id": 29903,
    "content": "3"
  },
  {
    "id": 29904,
    "content": "10"
  },
  {
    "id": 29905,
    "content": "3"
  },
  {
    "id": 29906,
    "content": "2"
  },
  {
    "id": 29908,
    "content": "real-to-complex transform plan"
  },
  {
    "id": 29910,
    "content": "3"
  },
  {
    "id": 29911,
    "content": "10"
  },
  {
    "id": 29912,
    "content": "3"
  },
  {
    "id": 29913,
    "content": "3"
  },
  {
    "id": 29915,
    "content": "complex-to-real transform plan in the transform direction as specified by direction parameter"
  },
  {
    "id": 29916,
    "content": "3"
  },
  {
    "id": 29917,
    "content": "10"
  },
  {
    "id": 29918,
    "content": "4"
  },
  {
    "id": 29920,
    "content": "They must be called after the call to cufftMakePlan*()"
  },
  {
    "id": 29921,
    "content": "3"
  },
  {
    "id": 29922,
    "content": "10"
  },
  {
    "id": 29923,
    "content": "4"
  },
  {
    "id": 29924,
    "content": "1"
  },
  {
    "id": 29927,
    "content": "Return values CUFFT_SUCCESS – cuFFT successfully allows user to allocate descriptor and GPU memory"
  },
  {
    "id": 29928,
    "content": "CUFFT_INVALID_PLAN – The plan parameter is not a valid handle or it is not a multiple GPU plan"
  },
  {
    "id": 29929,
    "content": "CUFFT_INVALID_DEVICE – An invalid GPU index was specified in the descriptor"
  },
  {
    "id": 29930,
    "content": "3"
  },
  {
    "id": 29931,
    "content": "10"
  },
  {
    "id": 29932,
    "content": "4"
  },
  {
    "id": 29933,
    "content": "1"
  },
  {
    "id": 29934,
    "content": "1"
  },
  {
    "id": 29937,
    "content": "10"
  },
  {
    "id": 29938,
    "content": "4"
  },
  {
    "id": 29939,
    "content": "2"
  },
  {
    "id": 29941,
    "content": "3"
  },
  {
    "id": 29942,
    "content": "10"
  },
  {
    "id": 29943,
    "content": "4"
  },
  {
    "id": 29944,
    "content": "3"
  },
  {
    "id": 29946,
    "content": "Note that starting from CUDA 11"
  },
  {
    "id": 29947,
    "content": "2 (cuFFT 10"
  },
  {
    "id": 29948,
    "content": "4"
  },
  {
    "id": 29949,
    "content": "0), cufftSetStream() is supported on multi-GPU plans"
  },
  {
    "id": 29950,
    "content": "When associating a stream with a plan, cufftXtMemcpy() remains synchronous across the multiple GPUs"
  },
  {
    "id": 29952,
    "content": "3"
  },
  {
    "id": 29953,
    "content": "10"
  },
  {
    "id": 29954,
    "content": "4"
  },
  {
    "id": 29955,
    "content": "3"
  },
  {
    "id": 29956,
    "content": "1"
  },
  {
    "id": 29965,
    "content": "10"
  },
  {
    "id": 29966,
    "content": "5"
  },
  {
    "id": 29969,
    "content": "10"
  },
  {
    "id": 29970,
    "content": "5"
  },
  {
    "id": 29971,
    "content": "2"
  },
  {
    "id": 29973,
    "content": "g"
  },
  {
    "id": 29975,
    "content": "This call is valid only after a call to cufftMakePlan*() , which does the plan generation"
  },
  {
    "id": 29977,
    "content": "callerInfo[In] – Optional array of device pointers to caller specific information, one per GPU"
  },
  {
    "id": 29978,
    "content": "Return values CUFFT_SUCCESS – cuFFT successfully associated the callback function with the plan"
  },
  {
    "id": 29979,
    "content": "3"
  },
  {
    "id": 29980,
    "content": "11"
  },
  {
    "id": 29981,
    "content": "2"
  },
  {
    "id": 29983,
    "content": "3"
  },
  {
    "id": 29984,
    "content": "11"
  },
  {
    "id": 29985,
    "content": "3"
  },
  {
    "id": 29988,
    "content": "3"
  },
  {
    "id": 29989,
    "content": "12"
  },
  {
    "id": 29991,
    "content": "g"
  },
  {
    "id": 29993,
    "content": "Note that starting from CUDA 12"
  },
  {
    "id": 29994,
    "content": "2 (cuFFT 11"
  },
  {
    "id": 29995,
    "content": "0"
  },
  {
    "id": 29996,
    "content": "8), on multi-GPU plans, stream can be associated with any context on any GPU"
  },
  {
    "id": 29998,
    "content": "stream[In] – A valid CUDA stream created with cudaStreamCreate() ; 0 for the default stream"
  },
  {
    "id": 30000,
    "content": "4"
  },
  {
    "id": 30001,
    "content": "0"
  },
  {
    "id": 30002,
    "content": "3"
  },
  {
    "id": 30003,
    "content": "13"
  },
  {
    "id": 30005,
    "content": "3"
  },
  {
    "id": 30006,
    "content": "14"
  },
  {
    "id": 30009,
    "content": "15"
  },
  {
    "id": 30010,
    "content": "2"
  },
  {
    "id": 30013,
    "content": "3"
  },
  {
    "id": 30014,
    "content": "15"
  },
  {
    "id": 30015,
    "content": "3"
  },
  {
    "id": 30017,
    "content": "The user receives a handle after creating a cuFFT plan and uses this handle to execute the plan"
  },
  {
    "id": 30021,
    "content": "a pair of unsigned integers } cudaDataType ; 3"
  },
  {
    "id": 30022,
    "content": "16"
  },
  {
    "id": 30023,
    "content": "2"
  },
  {
    "id": 30024,
    "content": "libraryPropertyType  The libraryPropertyType data type is an enumeration of library property types"
  },
  {
    "id": 30025,
    "content": "CUDA version X"
  },
  {
    "id": 30026,
    "content": "Y"
  },
  {
    "id": 30029,
    "content": "5"
  },
  {
    "id": 30031,
    "content": "5"
  },
  {
    "id": 30032,
    "content": "1"
  },
  {
    "id": 30035,
    "content": "5"
  },
  {
    "id": 30036,
    "content": "2"
  },
  {
    "id": 30041,
    "content": "5"
  },
  {
    "id": 30042,
    "content": "3"
  },
  {
    "id": 30045,
    "content": "Factor2 transforms of size Factor1"
  },
  {
    "id": 30049,
    "content": "has substrings with indices 0 7 64"
  },
  {
    "id": 30050,
    "content": "71 128"
  },
  {
    "id": 30051,
    "content": "135"
  },
  {
    "id": 30052,
    "content": "960"
  },
  {
    "id": 30053,
    "content": "967 string 1 has substrings with indices 8"
  },
  {
    "id": 30054,
    "content": "15 72"
  },
  {
    "id": 30055,
    "content": "79 136"
  },
  {
    "id": 30056,
    "content": "143"
  },
  {
    "id": 30057,
    "content": "968"
  },
  {
    "id": 30058,
    "content": "975"
  },
  {
    "id": 30059,
    "content": "On GPU 1 : string 4 has substrings with indices 32"
  },
  {
    "id": 30060,
    "content": "63 120"
  },
  {
    "id": 30061,
    "content": "127 184"
  },
  {
    "id": 30062,
    "content": "191"
  },
  {
    "id": 30063,
    "content": "1016"
  },
  {
    "id": 30078,
    "content": "Other wisdom functions do not have entry points in the library"
  },
  {
    "id": 30079,
    "content": "8"
  },
  {
    "id": 30080,
    "content": "Deprecated Functionality  Starting from CUDA 12"
  },
  {
    "id": 30081,
    "content": "0: GPU architectures SM35 and SM37 are no longer supported"
  },
  {
    "id": 30082,
    "content": "Starting from CUDA 11"
  },
  {
    "id": 30084,
    "content": "Starting from CUDA 11"
  },
  {
    "id": 30088,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 30100,
    "content": "9"
  },
  {
    "id": 30101,
    "content": "2"
  },
  {
    "id": 30102,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 30103,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 30104,
    "content": "9"
  },
  {
    "id": 30105,
    "content": "3"
  },
  {
    "id": 30107,
    "content": "S"
  },
  {
    "id": 30110,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 30111,
    "content": "Navigation"
  },
  {
    "id": 30112,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 30113,
    "content": "pageBottom();}\n1"
  },
  {
    "id": 30117,
    "content": "e"
  },
  {
    "id": 30118,
    "content": ", host) and the GPU (i"
  },
  {
    "id": 30119,
    "content": "e"
  },
  {
    "id": 30120,
    "content": ", device) User-provided memory manager for the device and pinned host memory allocations"
  },
  {
    "id": 30121,
    "content": "1"
  },
  {
    "id": 30122,
    "content": "2"
  },
  {
    "id": 30125,
    "content": "1"
  },
  {
    "id": 30126,
    "content": "3"
  },
  {
    "id": 30127,
    "content": "Thread Safety  Not all nvJPEG types are thread safe"
  },
  {
    "id": 30129,
    "content": "For user-provided allocators (inputs to nvJPEGCreateEx() ), the user needs to ensure thread safety"
  },
  {
    "id": 30130,
    "content": "1"
  },
  {
    "id": 30131,
    "content": "4"
  },
  {
    "id": 30133,
    "content": "The user is responsible of keeping track of the current device"
  },
  {
    "id": 30134,
    "content": "1"
  },
  {
    "id": 30135,
    "content": "5"
  },
  {
    "id": 30138,
    "content": "2"
  },
  {
    "id": 30139,
    "content": "1"
  },
  {
    "id": 30140,
    "content": "1"
  },
  {
    "id": 30150,
    "content": "channels supported by the library"
  },
  {
    "id": 30152,
    "content": "Yes(c) Yes No No NOTES: Must be enabled using nvjpegDecodeParamsSetAllowCMYK()"
  },
  {
    "id": 30156,
    "content": "library is able to decompress"
  },
  {
    "id": 30158,
    "content": "2"
  },
  {
    "id": 30159,
    "content": "1"
  },
  {
    "id": 30160,
    "content": "2"
  },
  {
    "id": 30165,
    "content": "1"
  },
  {
    "id": 30166,
    "content": "3"
  },
  {
    "id": 30168,
    "content": "2"
  },
  {
    "id": 30169,
    "content": "1"
  },
  {
    "id": 30170,
    "content": "3"
  },
  {
    "id": 30171,
    "content": "1"
  },
  {
    "id": 30173,
    "content": "2"
  },
  {
    "id": 30174,
    "content": "2"
  },
  {
    "id": 30175,
    "content": "nvJPEG Type Declarations  2"
  },
  {
    "id": 30176,
    "content": "2"
  },
  {
    "id": 30177,
    "content": "1"
  },
  {
    "id": 30181,
    "content": "2"
  },
  {
    "id": 30182,
    "content": "2"
  },
  {
    "id": 30183,
    "content": "2"
  },
  {
    "id": 30185,
    "content": "2"
  },
  {
    "id": 30186,
    "content": "2"
  },
  {
    "id": 30187,
    "content": "3"
  },
  {
    "id": 30189,
    "content": "2"
  },
  {
    "id": 30190,
    "content": "2"
  },
  {
    "id": 30191,
    "content": "4"
  },
  {
    "id": 30193,
    "content": "2"
  },
  {
    "id": 30194,
    "content": "2"
  },
  {
    "id": 30195,
    "content": "5"
  },
  {
    "id": 30197,
    "content": "2"
  },
  {
    "id": 30198,
    "content": "2"
  },
  {
    "id": 30199,
    "content": "6"
  },
  {
    "id": 30201,
    "content": "It is used as input to the Decode API—Decoupled Decoding"
  },
  {
    "id": 30202,
    "content": "2"
  },
  {
    "id": 30203,
    "content": "2"
  },
  {
    "id": 30204,
    "content": "7"
  },
  {
    "id": 30208,
    "content": "function to create library handle, the default host pinned memory allocator will be used"
  },
  {
    "id": 30209,
    "content": "2"
  },
  {
    "id": 30210,
    "content": "2"
  },
  {
    "id": 30211,
    "content": "8"
  },
  {
    "id": 30214,
    "content": "2"
  },
  {
    "id": 30215,
    "content": "2"
  },
  {
    "id": 30216,
    "content": "9"
  },
  {
    "id": 30218,
    "content": "2"
  },
  {
    "id": 30219,
    "content": "2"
  },
  {
    "id": 30220,
    "content": "10"
  },
  {
    "id": 30227,
    "content": "2"
  },
  {
    "id": 30228,
    "content": "2"
  },
  {
    "id": 30229,
    "content": "11"
  },
  {
    "id": 30232,
    "content": "2"
  },
  {
    "id": 30233,
    "content": "2"
  },
  {
    "id": 30234,
    "content": "12"
  },
  {
    "id": 30236,
    "content": "nvjpegDecodePhaseOne )"
  },
  {
    "id": 30237,
    "content": "2"
  },
  {
    "id": 30238,
    "content": "2"
  },
  {
    "id": 30239,
    "content": "13"
  },
  {
    "id": 30241,
    "content": "2"
  },
  {
    "id": 30242,
    "content": "2"
  },
  {
    "id": 30243,
    "content": "14"
  },
  {
    "id": 30245,
    "content": "2"
  },
  {
    "id": 30246,
    "content": "2"
  },
  {
    "id": 30247,
    "content": "15"
  },
  {
    "id": 30251,
    "content": "2"
  },
  {
    "id": 30252,
    "content": "2"
  },
  {
    "id": 30253,
    "content": "16"
  },
  {
    "id": 30256,
    "content": "2"
  },
  {
    "id": 30257,
    "content": "17"
  },
  {
    "id": 30259,
    "content": "using nvJPEGCreateEx() or nvJPEGCreateExV2()"
  },
  {
    "id": 30261,
    "content": "NVJPEG_FLAGS_ENABLE_MEMORY_POOLS [Deprecated] Starting with CUDA 11"
  },
  {
    "id": 30262,
    "content": "1 this flag will be ignored"
  },
  {
    "id": 30265,
    "content": "interpolation when performing chroma upsampling during the YCbCr to RGB conversion stage"
  },
  {
    "id": 30266,
    "content": "2"
  },
  {
    "id": 30267,
    "content": "2"
  },
  {
    "id": 30268,
    "content": "18"
  },
  {
    "id": 30273,
    "content": "2"
  },
  {
    "id": 30274,
    "content": "3"
  },
  {
    "id": 30277,
    "content": "2"
  },
  {
    "id": 30278,
    "content": "3"
  },
  {
    "id": 30279,
    "content": "1"
  },
  {
    "id": 30280,
    "content": "2"
  },
  {
    "id": 30283,
    "content": "2"
  },
  {
    "id": 30284,
    "content": "3"
  },
  {
    "id": 30285,
    "content": "1"
  },
  {
    "id": 30286,
    "content": "3"
  },
  {
    "id": 30288,
    "content": "parameter for nvjpegDecodeBatched() API"
  },
  {
    "id": 30291,
    "content": "2"
  },
  {
    "id": 30292,
    "content": "3"
  },
  {
    "id": 30293,
    "content": "1"
  },
  {
    "id": 30294,
    "content": "4"
  },
  {
    "id": 30296,
    "content": "Returns: nvjpegStatus_t - An error code as specified in nvJPEG API Return Codes"
  },
  {
    "id": 30297,
    "content": "2"
  },
  {
    "id": 30298,
    "content": "3"
  },
  {
    "id": 30299,
    "content": "1"
  },
  {
    "id": 30300,
    "content": "5"
  },
  {
    "id": 30301,
    "content": "nvjpegCreateEx()  Allocates and initializes the library handle using the provided arguments"
  },
  {
    "id": 30304,
    "content": "unsigned int flags Input Host Refer to nvJPEG Flags for details"
  },
  {
    "id": 30305,
    "content": "2"
  },
  {
    "id": 30306,
    "content": "3"
  },
  {
    "id": 30307,
    "content": "1"
  },
  {
    "id": 30308,
    "content": "6"
  },
  {
    "id": 30309,
    "content": "nvjpegCreateExV2()  Allocates and initializes the library handle using the provided arguments"
  },
  {
    "id": 30311,
    "content": "2"
  },
  {
    "id": 30312,
    "content": "3"
  },
  {
    "id": 30313,
    "content": "1"
  },
  {
    "id": 30314,
    "content": "7"
  },
  {
    "id": 30316,
    "content": "2"
  },
  {
    "id": 30317,
    "content": "3"
  },
  {
    "id": 30318,
    "content": "1"
  },
  {
    "id": 30319,
    "content": "8"
  },
  {
    "id": 30321,
    "content": "A large number will help to amortize the need for device memory reallocations when needed"
  },
  {
    "id": 30323,
    "content": "2"
  },
  {
    "id": 30324,
    "content": "3"
  },
  {
    "id": 30325,
    "content": "1"
  },
  {
    "id": 30326,
    "content": "9"
  },
  {
    "id": 30328,
    "content": "2"
  },
  {
    "id": 30329,
    "content": "3"
  },
  {
    "id": 30330,
    "content": "1"
  },
  {
    "id": 30331,
    "content": "10"
  },
  {
    "id": 30333,
    "content": "Host Pinned host memory padding to use for all further pinned host memory allocations"
  },
  {
    "id": 30334,
    "content": "2"
  },
  {
    "id": 30335,
    "content": "3"
  },
  {
    "id": 30336,
    "content": "1"
  },
  {
    "id": 30337,
    "content": "11"
  },
  {
    "id": 30339,
    "content": "2"
  },
  {
    "id": 30340,
    "content": "3"
  },
  {
    "id": 30341,
    "content": "1"
  },
  {
    "id": 30342,
    "content": "12"
  },
  {
    "id": 30345,
    "content": "2"
  },
  {
    "id": 30346,
    "content": "3"
  },
  {
    "id": 30347,
    "content": "1"
  },
  {
    "id": 30348,
    "content": "13"
  },
  {
    "id": 30350,
    "content": "2"
  },
  {
    "id": 30351,
    "content": "3"
  },
  {
    "id": 30352,
    "content": "1"
  },
  {
    "id": 30353,
    "content": "14"
  },
  {
    "id": 30355,
    "content": "2"
  },
  {
    "id": 30356,
    "content": "3"
  },
  {
    "id": 30357,
    "content": "1"
  },
  {
    "id": 30358,
    "content": "15"
  },
  {
    "id": 30360,
    "content": "The back end applies to all the functions under the decoupled API , when called with this handle"
  },
  {
    "id": 30361,
    "content": "nvjpegJpegDecoder_t decoder_handle Input/Output Host Decoder state handle"
  },
  {
    "id": 30362,
    "content": "2"
  },
  {
    "id": 30363,
    "content": "3"
  },
  {
    "id": 30364,
    "content": "1"
  },
  {
    "id": 30365,
    "content": "16"
  },
  {
    "id": 30367,
    "content": "2"
  },
  {
    "id": 30368,
    "content": "3"
  },
  {
    "id": 30369,
    "content": "1"
  },
  {
    "id": 30370,
    "content": "17"
  },
  {
    "id": 30373,
    "content": "API Return Codes"
  },
  {
    "id": 30374,
    "content": "2"
  },
  {
    "id": 30375,
    "content": "3"
  },
  {
    "id": 30376,
    "content": "1"
  },
  {
    "id": 30377,
    "content": "18"
  },
  {
    "id": 30380,
    "content": "2"
  },
  {
    "id": 30381,
    "content": "3"
  },
  {
    "id": 30382,
    "content": "1"
  },
  {
    "id": 30383,
    "content": "19"
  },
  {
    "id": 30385,
    "content": "Returns: nvjpegStatus_t — An error code as specified in nvJPEG API Return Codes"
  },
  {
    "id": 30386,
    "content": "2"
  },
  {
    "id": 30387,
    "content": "3"
  },
  {
    "id": 30388,
    "content": "1"
  },
  {
    "id": 30389,
    "content": "20"
  },
  {
    "id": 30391,
    "content": "2"
  },
  {
    "id": 30392,
    "content": "3"
  },
  {
    "id": 30393,
    "content": "1"
  },
  {
    "id": 30394,
    "content": "21"
  },
  {
    "id": 30396,
    "content": "2"
  },
  {
    "id": 30397,
    "content": "3"
  },
  {
    "id": 30398,
    "content": "1"
  },
  {
    "id": 30399,
    "content": "22"
  },
  {
    "id": 30401,
    "content": "Input Host Extended pinned host memory allocator"
  },
  {
    "id": 30402,
    "content": "2"
  },
  {
    "id": 30403,
    "content": "3"
  },
  {
    "id": 30404,
    "content": "1"
  },
  {
    "id": 30405,
    "content": "23"
  },
  {
    "id": 30407,
    "content": "2"
  },
  {
    "id": 30408,
    "content": "3"
  },
  {
    "id": 30409,
    "content": "1"
  },
  {
    "id": 30410,
    "content": "24"
  },
  {
    "id": 30411,
    "content": "nvjpegStateAttachPinnedBuffer()  Link the nvJPEG pinned buffer handle to decoder_state"
  },
  {
    "id": 30415,
    "content": "2"
  },
  {
    "id": 30416,
    "content": "3"
  },
  {
    "id": 30417,
    "content": "1"
  },
  {
    "id": 30418,
    "content": "25"
  },
  {
    "id": 30420,
    "content": "pinned buffer"
  },
  {
    "id": 30421,
    "content": "2"
  },
  {
    "id": 30422,
    "content": "3"
  },
  {
    "id": 30423,
    "content": "1"
  },
  {
    "id": 30424,
    "content": "26"
  },
  {
    "id": 30427,
    "content": "2"
  },
  {
    "id": 30428,
    "content": "3"
  },
  {
    "id": 30429,
    "content": "1"
  },
  {
    "id": 30430,
    "content": "27"
  },
  {
    "id": 30432,
    "content": "2"
  },
  {
    "id": 30433,
    "content": "3"
  },
  {
    "id": 30434,
    "content": "1"
  },
  {
    "id": 30435,
    "content": "28"
  },
  {
    "id": 30437,
    "content": "Host Extended device memory allocator"
  },
  {
    "id": 30438,
    "content": "2"
  },
  {
    "id": 30439,
    "content": "3"
  },
  {
    "id": 30440,
    "content": "1"
  },
  {
    "id": 30441,
    "content": "29"
  },
  {
    "id": 30443,
    "content": "Device pointers are stored within the host structures"
  },
  {
    "id": 30444,
    "content": "2"
  },
  {
    "id": 30445,
    "content": "3"
  },
  {
    "id": 30446,
    "content": "1"
  },
  {
    "id": 30447,
    "content": "30"
  },
  {
    "id": 30448,
    "content": "nvjpegStateAttachDeviceBuffer()  Link the nvJPEG device buffer handle to the decoder_state"
  },
  {
    "id": 30452,
    "content": "2"
  },
  {
    "id": 30453,
    "content": "3"
  },
  {
    "id": 30454,
    "content": "1"
  },
  {
    "id": 30455,
    "content": "31"
  },
  {
    "id": 30457,
    "content": "device buffer"
  },
  {
    "id": 30458,
    "content": "2"
  },
  {
    "id": 30459,
    "content": "3"
  },
  {
    "id": 30460,
    "content": "1"
  },
  {
    "id": 30461,
    "content": "32"
  },
  {
    "id": 30464,
    "content": "2"
  },
  {
    "id": 30465,
    "content": "3"
  },
  {
    "id": 30466,
    "content": "1"
  },
  {
    "id": 30467,
    "content": "33"
  },
  {
    "id": 30468,
    "content": "nvjpegDecodeParamsCreate()  Creates a handle for the parameters"
  },
  {
    "id": 30469,
    "content": "The parameters that can be programmed include: output format, ROI decode, CMYK to RGB conversion"
  },
  {
    "id": 30471,
    "content": "2"
  },
  {
    "id": 30472,
    "content": "3"
  },
  {
    "id": 30473,
    "content": "1"
  },
  {
    "id": 30474,
    "content": "34"
  },
  {
    "id": 30476,
    "content": "2"
  },
  {
    "id": 30477,
    "content": "3"
  },
  {
    "id": 30478,
    "content": "2"
  },
  {
    "id": 30480,
    "content": "2"
  },
  {
    "id": 30481,
    "content": "3"
  },
  {
    "id": 30482,
    "content": "2"
  },
  {
    "id": 30483,
    "content": "1"
  },
  {
    "id": 30484,
    "content": "nvjpegGetImageInfo()  Decodes the JPEG header and retrieves the basic information about the image"
  },
  {
    "id": 30487,
    "content": "2"
  },
  {
    "id": 30488,
    "content": "3"
  },
  {
    "id": 30489,
    "content": "2"
  },
  {
    "id": 30490,
    "content": "2"
  },
  {
    "id": 30491,
    "content": "nvJPEG Stream API  These functions store the parsed bit-stream data on the host"
  },
  {
    "id": 30492,
    "content": "2"
  },
  {
    "id": 30493,
    "content": "3"
  },
  {
    "id": 30494,
    "content": "2"
  },
  {
    "id": 30495,
    "content": "2"
  },
  {
    "id": 30496,
    "content": "1"
  },
  {
    "id": 30498,
    "content": "If not 0, then the JPEG stream metadata (headers, app markers, etc"
  },
  {
    "id": 30501,
    "content": "2"
  },
  {
    "id": 30502,
    "content": "3"
  },
  {
    "id": 30503,
    "content": "2"
  },
  {
    "id": 30504,
    "content": "2"
  },
  {
    "id": 30505,
    "content": "2"
  },
  {
    "id": 30507,
    "content": "2"
  },
  {
    "id": 30508,
    "content": "3"
  },
  {
    "id": 30509,
    "content": "2"
  },
  {
    "id": 30510,
    "content": "2"
  },
  {
    "id": 30511,
    "content": "3"
  },
  {
    "id": 30512,
    "content": "nvjpegJpegStreamParseTables()  To be used when decoding TIFF files with JPEG compression"
  },
  {
    "id": 30514,
    "content": "nvJPEG bitstream handle that stores the parsed bitstream information"
  },
  {
    "id": 30515,
    "content": "2"
  },
  {
    "id": 30516,
    "content": "3"
  },
  {
    "id": 30517,
    "content": "2"
  },
  {
    "id": 30518,
    "content": "2"
  },
  {
    "id": 30519,
    "content": "4"
  },
  {
    "id": 30521,
    "content": "2"
  },
  {
    "id": 30522,
    "content": "3"
  },
  {
    "id": 30523,
    "content": "2"
  },
  {
    "id": 30524,
    "content": "2"
  },
  {
    "id": 30525,
    "content": "5"
  },
  {
    "id": 30527,
    "content": "channels in the input"
  },
  {
    "id": 30528,
    "content": "2"
  },
  {
    "id": 30529,
    "content": "3"
  },
  {
    "id": 30530,
    "content": "2"
  },
  {
    "id": 30531,
    "content": "2"
  },
  {
    "id": 30532,
    "content": "6"
  },
  {
    "id": 30534,
    "content": "height Output Host Component width"
  },
  {
    "id": 30535,
    "content": "2"
  },
  {
    "id": 30536,
    "content": "3"
  },
  {
    "id": 30537,
    "content": "2"
  },
  {
    "id": 30538,
    "content": "2"
  },
  {
    "id": 30539,
    "content": "7"
  },
  {
    "id": 30540,
    "content": "nvjpegJpegStreamGetChromaSubsampling()  Gets the chroma subsampling from the jpeg_stream"
  },
  {
    "id": 30543,
    "content": "2"
  },
  {
    "id": 30544,
    "content": "3"
  },
  {
    "id": 30545,
    "content": "2"
  },
  {
    "id": 30546,
    "content": "2"
  },
  {
    "id": 30547,
    "content": "8"
  },
  {
    "id": 30549,
    "content": "progressive"
  },
  {
    "id": 30550,
    "content": "2"
  },
  {
    "id": 30551,
    "content": "3"
  },
  {
    "id": 30552,
    "content": "2"
  },
  {
    "id": 30553,
    "content": "2"
  },
  {
    "id": 30554,
    "content": "9"
  },
  {
    "id": 30557,
    "content": "2"
  },
  {
    "id": 30558,
    "content": "3"
  },
  {
    "id": 30559,
    "content": "2"
  },
  {
    "id": 30560,
    "content": "2"
  },
  {
    "id": 30561,
    "content": "10"
  },
  {
    "id": 30563,
    "content": "precision value"
  },
  {
    "id": 30564,
    "content": "2"
  },
  {
    "id": 30565,
    "content": "3"
  },
  {
    "id": 30566,
    "content": "3"
  },
  {
    "id": 30567,
    "content": "Decode API—Single Phase  Functions for decoding single image or batched images in a single phase"
  },
  {
    "id": 30568,
    "content": "2"
  },
  {
    "id": 30569,
    "content": "3"
  },
  {
    "id": 30570,
    "content": "3"
  },
  {
    "id": 30571,
    "content": "1"
  },
  {
    "id": 30575,
    "content": "e"
  },
  {
    "id": 30577,
    "content": "2"
  },
  {
    "id": 30578,
    "content": "3"
  },
  {
    "id": 30579,
    "content": "3"
  },
  {
    "id": 30580,
    "content": "2"
  },
  {
    "id": 30581,
    "content": "​nvjpegDecodeBatchedInitialize()  This function initializes the batched decoder state"
  },
  {
    "id": 30584,
    "content": "2"
  },
  {
    "id": 30585,
    "content": "3"
  },
  {
    "id": 30586,
    "content": "3"
  },
  {
    "id": 30587,
    "content": "3"
  },
  {
    "id": 30590,
    "content": "element of array of the input data"
  },
  {
    "id": 30594,
    "content": "cudaStream_t stream Input Host The CUDA stream where all the GPU work will be submitted"
  },
  {
    "id": 30595,
    "content": "2"
  },
  {
    "id": 30596,
    "content": "3"
  },
  {
    "id": 30597,
    "content": "3"
  },
  {
    "id": 30598,
    "content": "4"
  },
  {
    "id": 30603,
    "content": "2"
  },
  {
    "id": 30604,
    "content": "3"
  },
  {
    "id": 30605,
    "content": "3"
  },
  {
    "id": 30606,
    "content": "5"
  },
  {
    "id": 30610,
    "content": "2"
  },
  {
    "id": 30611,
    "content": "3"
  },
  {
    "id": 30612,
    "content": "3"
  },
  {
    "id": 30613,
    "content": "6"
  },
  {
    "id": 30617,
    "content": "2"
  },
  {
    "id": 30618,
    "content": "3"
  },
  {
    "id": 30619,
    "content": "3"
  },
  {
    "id": 30620,
    "content": "7"
  },
  {
    "id": 30628,
    "content": "Input Host Chroma-subsampling of the images"
  },
  {
    "id": 30629,
    "content": "2"
  },
  {
    "id": 30630,
    "content": "3"
  },
  {
    "id": 30631,
    "content": "3"
  },
  {
    "id": 30632,
    "content": "8"
  },
  {
    "id": 30635,
    "content": "Can be set to NULL to reset the jpeg tables"
  },
  {
    "id": 30636,
    "content": "2"
  },
  {
    "id": 30637,
    "content": "3"
  },
  {
    "id": 30638,
    "content": "4"
  },
  {
    "id": 30645,
    "content": "2"
  },
  {
    "id": 30646,
    "content": "3"
  },
  {
    "id": 30647,
    "content": "4"
  },
  {
    "id": 30648,
    "content": "2"
  },
  {
    "id": 30652,
    "content": "2"
  },
  {
    "id": 30653,
    "content": "3"
  },
  {
    "id": 30654,
    "content": "4"
  },
  {
    "id": 30655,
    "content": "3"
  },
  {
    "id": 30662,
    "content": "See nvJPEG Image for details"
  },
  {
    "id": 30663,
    "content": "2"
  },
  {
    "id": 30664,
    "content": "3"
  },
  {
    "id": 30665,
    "content": "4"
  },
  {
    "id": 30666,
    "content": "4"
  },
  {
    "id": 30671,
    "content": "nvjpegDecodeParams_t decode_params Input Host The handle which stores the decode output properties"
  },
  {
    "id": 30672,
    "content": "2"
  },
  {
    "id": 30673,
    "content": "3"
  },
  {
    "id": 30674,
    "content": "5"
  },
  {
    "id": 30676,
    "content": "2"
  },
  {
    "id": 30677,
    "content": "3"
  },
  {
    "id": 30678,
    "content": "5"
  },
  {
    "id": 30679,
    "content": "1"
  },
  {
    "id": 30682,
    "content": "2"
  },
  {
    "id": 30683,
    "content": "3"
  },
  {
    "id": 30684,
    "content": "5"
  },
  {
    "id": 30685,
    "content": "2"
  },
  {
    "id": 30687,
    "content": "e"
  },
  {
    "id": 30688,
    "content": ", to decode the whole image, set: offset_x = 0, offset_y = 0, roi_width = -1, and roi_height = -1"
  },
  {
    "id": 30689,
    "content": "It is not supported when the nvJPEG decoder handle is created using NVJPEG_BACKEND_HARDWARE"
  },
  {
    "id": 30692,
    "content": "int roi_height Input Host Image height relative to offset_y"
  },
  {
    "id": 30693,
    "content": "2"
  },
  {
    "id": 30694,
    "content": "3"
  },
  {
    "id": 30695,
    "content": "5"
  },
  {
    "id": 30696,
    "content": "3"
  },
  {
    "id": 30700,
    "content": "2"
  },
  {
    "id": 30701,
    "content": "3"
  },
  {
    "id": 30702,
    "content": "5"
  },
  {
    "id": 30703,
    "content": "4"
  },
  {
    "id": 30704,
    "content": "nvjpegDecodeParamsSetScaleFactor()  Allows the user to scale decode output"
  },
  {
    "id": 30712,
    "content": "2"
  },
  {
    "id": 30713,
    "content": "3"
  },
  {
    "id": 30714,
    "content": "6"
  },
  {
    "id": 30723,
    "content": "3"
  },
  {
    "id": 30724,
    "content": "8"
  },
  {
    "id": 30726,
    "content": "3"
  },
  {
    "id": 30727,
    "content": "1"
  },
  {
    "id": 30729,
    "content": "3"
  },
  {
    "id": 30730,
    "content": "1"
  },
  {
    "id": 30731,
    "content": "1"
  },
  {
    "id": 30734,
    "content": "encoding can fail if the quality parameter is set too high"
  },
  {
    "id": 30735,
    "content": "This is due to the fact that the compressed bitstream would be larger than the input image"
  },
  {
    "id": 30737,
    "content": "3"
  },
  {
    "id": 30738,
    "content": "1"
  },
  {
    "id": 30739,
    "content": "2"
  },
  {
    "id": 30741,
    "content": "3"
  },
  {
    "id": 30742,
    "content": "1"
  },
  {
    "id": 30743,
    "content": "3"
  },
  {
    "id": 30745,
    "content": "See below"
  },
  {
    "id": 30746,
    "content": "3"
  },
  {
    "id": 30747,
    "content": "1"
  },
  {
    "id": 30748,
    "content": "3"
  },
  {
    "id": 30749,
    "content": "1"
  },
  {
    "id": 30750,
    "content": "nvjpegEncodeYUV  Input for this function is an image in YUV colorspace"
  },
  {
    "id": 30752,
    "content": "That is, the chrominance image planes should have sizes aligned to the corresponding subsamplings"
  },
  {
    "id": 30754,
    "content": "1"
  },
  {
    "id": 30755,
    "content": "3"
  },
  {
    "id": 30756,
    "content": "2"
  },
  {
    "id": 30757,
    "content": "Input for this function, i"
  },
  {
    "id": 30758,
    "content": "e"
  },
  {
    "id": 30761,
    "content": "The nvJPEG library will perform the color transformation to the YCbCr, and will compress the result"
  },
  {
    "id": 30762,
    "content": "3"
  },
  {
    "id": 30763,
    "content": "1"
  },
  {
    "id": 30764,
    "content": "4"
  },
  {
    "id": 30769,
    "content": "3"
  },
  {
    "id": 30770,
    "content": "1"
  },
  {
    "id": 30771,
    "content": "5"
  },
  {
    "id": 30774,
    "content": "nvJPEG Encoder Type Declarations  This section describes the nvJPEG Encoder Type Declarations"
  },
  {
    "id": 30775,
    "content": "3"
  },
  {
    "id": 30776,
    "content": "2"
  },
  {
    "id": 30777,
    "content": "1"
  },
  {
    "id": 30779,
    "content": "3"
  },
  {
    "id": 30780,
    "content": "2"
  },
  {
    "id": 30781,
    "content": "2"
  },
  {
    "id": 30783,
    "content": "3"
  },
  {
    "id": 30784,
    "content": "2"
  },
  {
    "id": 30785,
    "content": "3"
  },
  {
    "id": 30786,
    "content": "nvjpegEncoderParams_t  The nvjpegEncoderParams_t structure stores JPEG encode parameters"
  },
  {
    "id": 30787,
    "content": "3"
  },
  {
    "id": 30788,
    "content": "3"
  },
  {
    "id": 30789,
    "content": "nvJPEG Encoder Helper API Reference  The nvJPEG Encoder helper functions are used for initializing"
  },
  {
    "id": 30790,
    "content": "3"
  },
  {
    "id": 30791,
    "content": "3"
  },
  {
    "id": 30792,
    "content": "1"
  },
  {
    "id": 30795,
    "content": "3"
  },
  {
    "id": 30796,
    "content": "3"
  },
  {
    "id": 30797,
    "content": "2"
  },
  {
    "id": 30799,
    "content": "3"
  },
  {
    "id": 30800,
    "content": "3"
  },
  {
    "id": 30801,
    "content": "3"
  },
  {
    "id": 30803,
    "content": "structure will be placed"
  },
  {
    "id": 30804,
    "content": "3"
  },
  {
    "id": 30805,
    "content": "3"
  },
  {
    "id": 30806,
    "content": "4"
  },
  {
    "id": 30808,
    "content": "3"
  },
  {
    "id": 30809,
    "content": "3"
  },
  {
    "id": 30810,
    "content": "5"
  },
  {
    "id": 30812,
    "content": "stream where all the required device operations will be placed"
  },
  {
    "id": 30813,
    "content": "3"
  },
  {
    "id": 30814,
    "content": "3"
  },
  {
    "id": 30815,
    "content": "6"
  },
  {
    "id": 30818,
    "content": "3"
  },
  {
    "id": 30819,
    "content": "3"
  },
  {
    "id": 30820,
    "content": "7"
  },
  {
    "id": 30823,
    "content": "3"
  },
  {
    "id": 30824,
    "content": "3"
  },
  {
    "id": 30825,
    "content": "8"
  },
  {
    "id": 30829,
    "content": "3"
  },
  {
    "id": 30830,
    "content": "4"
  },
  {
    "id": 30831,
    "content": "nvJPEG Encoder API Reference  This section describes the nvJPEG Encoder API"
  },
  {
    "id": 30832,
    "content": "3"
  },
  {
    "id": 30833,
    "content": "4"
  },
  {
    "id": 30834,
    "content": "1"
  },
  {
    "id": 30836,
    "content": "handle Input Host Library handle image_height Input Host Input image height"
  },
  {
    "id": 30837,
    "content": "3"
  },
  {
    "id": 30838,
    "content": "4"
  },
  {
    "id": 30839,
    "content": "2"
  },
  {
    "id": 30843,
    "content": "3"
  },
  {
    "id": 30844,
    "content": "4"
  },
  {
    "id": 30845,
    "content": "3"
  },
  {
    "id": 30848,
    "content": "nvjpegInputFormat_t type that describes the input data"
  },
  {
    "id": 30849,
    "content": "3"
  },
  {
    "id": 30850,
    "content": "4"
  },
  {
    "id": 30851,
    "content": "4"
  },
  {
    "id": 30855,
    "content": "3"
  },
  {
    "id": 30856,
    "content": "4"
  },
  {
    "id": 30857,
    "content": "5"
  },
  {
    "id": 30860,
    "content": "4"
  },
  {
    "id": 30861,
    "content": "JPEG Transcoding  This section describes the transcoding functions of the nvJPEG Library"
  },
  {
    "id": 30862,
    "content": "4"
  },
  {
    "id": 30863,
    "content": "1"
  },
  {
    "id": 30864,
    "content": "nvJPEG Transcoder Helper API Reference  This section describes the nvJPEG Transcoder helper API"
  },
  {
    "id": 30865,
    "content": "4"
  },
  {
    "id": 30866,
    "content": "1"
  },
  {
    "id": 30867,
    "content": "1"
  },
  {
    "id": 30870,
    "content": "required device operations will be placed"
  },
  {
    "id": 30871,
    "content": "4"
  },
  {
    "id": 30872,
    "content": "1"
  },
  {
    "id": 30873,
    "content": "2"
  },
  {
    "id": 30875,
    "content": "4"
  },
  {
    "id": 30876,
    "content": "1"
  },
  {
    "id": 30877,
    "content": "3"
  },
  {
    "id": 30881,
    "content": "4"
  },
  {
    "id": 30882,
    "content": "2"
  },
  {
    "id": 30883,
    "content": "JPEG Transcoding Example  See below the example code"
  },
  {
    "id": 30885,
    "content": "7"
  },
  {
    "id": 30886,
    "content": "Notices  7"
  },
  {
    "id": 30887,
    "content": "1"
  },
  {
    "id": 30890,
    "content": "other changes to this document, at any time without notice"
  },
  {
    "id": 30902,
    "content": "7"
  },
  {
    "id": 30903,
    "content": "2"
  },
  {
    "id": 30904,
    "content": "OpenCL  OpenCL is a trademark of Apple Inc"
  },
  {
    "id": 30905,
    "content": "used under license to the Khronos Group Inc"
  },
  {
    "id": 30906,
    "content": "7"
  },
  {
    "id": 30907,
    "content": "3"
  },
  {
    "id": 30909,
    "content": "S"
  },
  {
    "id": 30912,
    "content": "jQuery(function () { SphinxRtdTheme"
  },
  {
    "id": 30913,
    "content": "Navigation"
  },
  {
    "id": 30914,
    "content": "enable(false); }); if (typeof _satellite == \"undefined\"){_satellite"
  },
  {
    "id": 30915,
    "content": "pageBottom();}"
  }
]